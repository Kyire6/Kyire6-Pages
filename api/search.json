[{"title":"Windows Terminal + PowerShell 7 + Scoop 打造 Windows 系统下最强终端","slug":"WindowsTerminal+PowerShell7+Scoop打造Windows系统下最强终端","url":"/2024/07/23/e3012d83.html","content":"\n## 简介\n\n最近因电脑系统故障而重装系统，借此机会正好使用 Windows 全新的 `Terminal(终端)` + `PowerShell 7` + `Scoop` 来打造 Windows 系统下最强终端，之前一直用的 `Git for Windows` 提供的 `Git Bash`，安装 `Zsh + Oh My Zsh` 优化体验，但是 `Zsh` 毕竟是 `UNIX/类UNIX` 系统的命令行解释器，在 Windows 系统上体验终归不是最优的。\n\n`Windows Terminal` 是一个现代、功能强大的终端应用程序，支持多标签页、自定义主题、Unicode 和 UTF-8 字符、以及与 PowerShell、CMD 和 WSL 的无缝集成。\n\n`PowerShell` 作为微软开发任务自动化和配置管理框架，最初就是为 Windows 系统设计(现在也支持 Linux 和 MacOS)，且通过强大的脚本语言，适合更灵活更复杂的自动化任务。\n\n`Scoop` 是一个用于 Windows 的命令行安装器，简化了软件的安装、更新和管理过程，并支持无管理员权限安装。新系统的软件开发环境也在本文中通过 Scoop 来管理安装。\n\n## 安装\n\n按照以下步骤，一步一步打造 Windows Terminal + PowerShell 7 + Scoop 最强 Windows 终端\n\n### Scoop\n\n#### 执行策略\n\n以管理员身份打开 Windows Terminal/PowerShell，执行以下命令\n\n```powershell\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n```\n\n#### 安装路径\n\nScoop 可以自定义 Scoop 安装路径与使用 Scoop 安装的软件路径：\n\n- Scoop 本身和安装软件的路径为：`C:\\Users\\[username]\\scoop`\n- Scoop 全局安装软件的路径为：`C:\\ProgramData\\scoop`\n\n在开始安装 Scoop 前，可以提前设置环境变量来决定其安装路径\n\n对于 Scoop 本身和安装软件的路径，打开 Windows Terminal/PowerShell，执行以下命令\n\n```powershell\n$env:SCOOP='D:\\Scoop'\n[Environment]::SetEnvironmentVariable('SCOOP', $env:SCOOP, 'User')\n```\n\n对于 Scoop 全局安装软件的路径，以 `管理员身份` 打开 Windows Terminal/PowerShell，执行以下命令\n\n```powershell\n$env:SCOOP_GLOBAL='D:\\Scoop\\Global'\n[Environment]::SetEnvironmentVariable('SCOOP_GLOBAL', $env:SCOOP_GLOBAL, 'Machine')\n```\n\n#### 开始安装\n\n打开 Windows Terminal/PowerShell，执行以下命令\n\n```powershell\nInvoke-Expression (New-Object System.Net.WebClient).DownloadString('https://get.scoop.sh')\n# 或者短命令\niwr -useb get.scoop.sh | iex\n\n# https://get.scoop.sh 地址实际是 https://raw.githubusercontent.com/scoopinstaller/install/master/install.ps1，若网络环境无法访问 GitHub，可以使用第三方 GitHub 加速服务\n```\n\n> 详细教程：[使用 Scoop 管理 Windows 下的软件和开发环境 · Dejavu's Blog](https://blog.dejavu.moe/posts/windows-scoop/)\n\n### Windows Terminal\n\nWindows 11 自带新版本 [Windows Terminal](https://github.com/microsoft/terminal)，无需额外安装，若某些 LTSC 版本系统没有，建议直接从 [微软应用商店](https://www.microsoft.com/store/productId/9N0DX20HK701) 安装最新稳定版\n\n### PowerShell 7\n\n[PowerShell 7](https://github.com/PowerShell/PowerShell) 直接在 [Releases]([Releases · PowerShell/PowerShell](https://github.com/PowerShell/PowerShell/releases)) 页面下载最新版本的安装包（根据系统架构选择，例如：Windows 11 x64 选择 `PowerShell-x-win-x64.msi.msi` 格式），双击运行安装程序，在 `Optional Actions` 勾选以下三项：\n\n- 添加到系统环境变量\n- 注册到 Windows 事件日志报表\n- 开启远程处理\n\n![image-20241118160856468](D:\\workspace\\OtherProjects\\Blog\\source\\_posts\\assets\\image-20241118160856468.png)\n\n下一步选择 PowerShell 更新选项，勾选以下两个选项后续可以通过 Microsoft Update 更新 PowerShell\n\n![image-20241118160919429](D:\\workspace\\OtherProjects\\Blog\\source\\_posts\\assets\\image-20241118160919429.png)\n\n### Nerd Font\n\n[oh-my-posh](https://github.com/jandedobbeleer/oh-my-posh) 内置主题里的图标、符号需要安装额外的字体才能完美显示，这里我们选择 [Nerd Font](https://github.com/ryanoasis/nerd-fonts) 字体， Nerd Fonts 是一个专为开发者设计的字体聚合器和修补工具，它增强了原有字体的功能\n\n![sankey-glyphs-combined-diagram](D:\\workspace\\OtherProjects\\Blog\\source\\_posts\\assets\\sankey-glyphs-combined-diagram.png)\n\n可以在 [Nerd Fonts 官网](https://www.nerdfonts.com/) 挑选喜欢的字体，然后在 [Releases](https://github.com/ryanoasis/nerd-fonts/releases) 页面下载对应的字体文件安装\n\n> 本文中演示使用的是 Nerd Fonts 修补过的 JetBrainsMono 字体\n\n### PSReadLine\n\n[PSReadLine](https://github.com/PowerShell/PSReadLine) 是一个 PowerShell 模块，可以让 PowerShell 的命令行更好用，这里我们通过 Scoop 安装\n\n```powershell\n# 添加 extras bucket\nscoop bucket add extras\n\n# 安装 PSReadLine\nscoop install PSReadLine\n```\n\n### posh-git\n\n[posh-git](https://github.com/dahlbyk/posh-git) 是一个 PowerShell 模块，可以让 git 更好用，这里我们通过 Scoop 安装\n\n```powershell\n# 通过 scoop 安装 posh-git\nscoop install posh-git\n```\n\n### oh-my-posh\n\n[oh-my-posh](https://ohmyposh.dev/) 是一个全平台终端美化工具，可以让 PowerShell 终端更美观，这里我们通过 Scoop 安装\n\n```\n# 通过 scoop 安装 oh-my-posh\nscoop install oh-my-posh\n```\n\n","tags":["技巧","笔记"],"categories":["Windows"]},{"title":"玩转网络文件系统（NFS）服务","slug":"玩转网络文件系统（NFS）服务","url":"/2023/08/17/96e40473.html","content":"\n## 背景\n\n公司有一个前后端不分离的单体项目，遇到一个场景，甲方要求应用服务分别部署到两台不同的服务器（`Windows Server 2022`）上，通过网关负载均衡进行访问（`集群部署`）。\n\n其中项目中有块业务涉及到文件上传、在线预览等功能。项目是部署在内网服务器，并且甲方也没有提供专门的文件服务器，所以项目中的文件上传都是上传到应用服务所在服务器上，因为是集群部署负载均衡进行访问，避免两台应用服务器之间的文件不同步，导致用户预览时异常，最终选择了 `NFS 网络文件系统` 实现共享文件夹。\n\n## NFS 共享文件夹实现步骤\n\n### Windows 服务器\n\n#### 准备工作\n\n1. 需要配置源服务器（被共享文件夹所在的服务器）的防火墙端口 `111` 和 `2049`\n2. 可以先关闭两台机器的防火墙，配置完成之后再打开，如果有问题再检查防火墙出入站规则\n\n#### 安装 NFS 服务器功能（已安装可略过）\n\n1. 打开服务器管理器，添加角色和功能\n\n![image-20230818171512533](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402971.png)\n\n![image-20230818171638594](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402932.png)\n\n![image-20230818171728872](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402145.png)\n\n![image-20230818171801367](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402008.png)\n\n![image-20230818171914089](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402407.png)\n\n![image-20230818172010661](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402833.png)\n\n2. 安装所选功能，默认 `下一步 -> 安装` 即可\n\n![image-20230818172537913](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402739.png)\n\n#### 在源服务器上设置共享文件夹\n\n1. 选中需要共享的文件夹，右键属性，设置 NFS 共享\n\n![image-20230818173043659](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402816.png)\t\n\n![image-20230818173126286](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402641.png)\t\n\n2. 设置读写权限\n\n![image-20230818173159245](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402336.png)\t\n\n#### 在目标服务器上添加网络驱动器\n\n![image-20230818173737941](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181402579.png)\n\n![image-20230918140756876](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181407601.png)\t\n\n映射完成之后会在此电脑中的网络位置中显示\n\n![image-20230918140849304](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202309181408416.png)\n\n#### 可以通过命令创建目录链接，将网络位置添加的 Z 盘映射成一个文件目录，供其他位置使用\n\n命令如下：\n\n```bash\nmklink /H D:\\opt Z:\\\n```\n\n### Linux 服务器\n\n步骤如下：\n\n192.168.116.17 作为服务端，共享数据给 192.168.116.18\n\n#### 服务端配置\n\n1. 安装 nfs server\n\n2. 设置 nfs 共享目录\n3. 重启 nfs server\n\n```bash\n# 安装 nfs server（Ubuntu 系统）\nsudo apt-get install nfs-kernel-server nfs-common\n# 安装 nfs server（Centos 系统）\nsudo yum install nfs-utils\n\n# 设置 nfs 共享目录\nsudo vim /etc/exports\n/u01/opt            *(rw,no_root_squash,sync)\n\n# 重启 nfs server（Ubuntu 系统）\nsudo service nfs-kernel-server restart\n# 重启 nfs server（Centos 系统）\nsudo systemctl restart nfs-server \n```\n\n#### 客户端配置\n\n1. 安装 nfs client\n2. 查看服务端上共享的目录\n3. 创建共享挂载点，并执行挂载\n\n```bash\n# 安装 nfs client（Ubuntu 系统）\nsudo apt-get install nfs-common\n# 安装 nfs client（Centos 系统）\nsudo yum install nfs-common\n\n# 查看服务端上共享的目录\nshowmount -e 192.168.116.17\n\n# 创建共享挂载点，并执行挂载\nmkdir -p /u01/opt\nmount -t nfs 192.168.116.17:/u01/opt /u01/opt\n\n# 设置开机自动挂载\n# Ubuntu 系统\n192.168.116.17:/u01/opt /u01/opt nfs defaults 0 0\n# CentOS 系统\n192.168.88.230:/u01/opt /u01/opt nfs rw,auto,nofail,noatime,nolock,intr,tcp,actimeo=1800,noac 0 0\n\n# 取消挂载\numount -lf /u01/opt\n```\n\n## 总结\n\n本文简单记录了 Windows 服务器、Linux 服务器上使用 NFS 共享文件夹的步骤。\n","tags":["Linux","Windows","NFS"],"categories":["随笔小记"]},{"title":"Java 中的 try-with-resources","slug":"Java中的try-with-resources","url":"/2023/07/06/5fbf5da7.html","content":"\n## 介绍\n\n在 Java 7 中引入了 try-with-resources 语句，用于简化处理资源关闭的代码。它提供了一种便捷的方式来确保在使用完资源后正确关闭它们，无需手动编写繁琐的关闭逻辑。\n\n## 使用方法\n\ntry-with-resources 使用以下语法：\n\n```java\ntry (ResourceType resource1 = new ResourceType1();\n     ResourceType resource2 = new ResourceType2();\n     // 可以有更多的资源声明\n) {\n    // 执行需要使用资源的代码\n    // ...\n}\ncatch (ExceptionType ex) {\n    // 异常处理逻辑\n}\n```\n\n- 在 `try` 关键字后面的括号中声明要使用的资源。每个资源都必须实现 `AutoCloseable` 接口或其子接口 `Closeable`。\n- 在 `try` 代码块执行结束后，无论是否发生异常，都会自动调用每个资源的 `close()` 方法进行关闭。\n- 如果发生异常，可以使用 `catch` 块处理异常。\n\n## 优点\n\n使用 try-with-resources 有以下优点：\n\n- 简化资源关闭逻辑，无需手动编写 `finally` 块来关闭资源。\n- 代码更加简洁、清晰，减少出错的可能性。\n- 能够处理多个资源的自动关闭，避免资源泄漏。\n\n## 注意事项\n\n- 自动关闭资源的顺序由声明顺序决定，先声明的资源会先关闭，后声明的资源会后关闭。\n- 在 try-with-resources 语句中声明的资源的范围限定在该语句的作用域内。一旦超出作用域，资源将自动关闭。\n\n- 资源必须实现 `AutoCloseable` 接口或其子接口 `Closeable`（这两个接口都包含了 `close()` 方法的定义，用于资源的关闭操作），否则无法在 try-with-resources 中使用。\n- 尽量避免在 `try` 块中修改资源的引用，以免影响资源的关闭。\n- 异常处理逻辑应该根据实际需求进行编写，确保适当处理异常。\n","tags":["技巧","笔记","Java"],"categories":["后端开发"]},{"title":"Vue 项目中如何缓存 Iframe 页面","slug":"Vue项目中如何缓存Iframe页面","url":"/2023/07/03/be3dc2ee.html","content":"\n## 项目背景\n\n在我们日常项目开发中，可能会涉及到其他项目嵌入到本项目中。本人在工作中正好碰到了一个需求，需要将旧系统中大量的 `HTML` 页面嵌入到 `Vue` 的项目中，嵌入方式是采用 `Iframe`，但是若使用 Iframe 嵌入页面，那么页面缓存就相当重要，否则用户每次切换到 Iframe 页面类型的菜单，都要重新加载页面，这样非常浪费时间，并且很影响用户的体验。经过网上查阅资料以及结合项目情况，这里记录一下本次问题的解决思路及实现方案。\n\n> 项目框架：[jeecgboot/ant-design-vue-jeecg: 基于 Vue2 + AntDesignVue 实现的 Ant Design Pro（github.com）](https://github.com/jeecgboot/ant-design-vue-jeecg)\n>\n> 参考：[vue 应用缓存 iframe 页面 - 掘金 (juejin.cn)](https://juejin.cn/post/7160873633408090119)\n\n## 解决思路\n\n1. 通过自定义规则区分 Iframe 类型路由与非 Iframe 类型路由\n2. 手动获取 Iframe 类型路由的路由信息，并且手动注册所有的 Iframe 路由组件\n3. Iframe 页面打开时或页面切换时，设置对应的 Iframe 组件为打开状态\n4. 获取所有已打开的 Iframe 路由组件，`v-for` 循环展示 Iframe 路由组件，并根据当前路由信息结合组件信息判断，使用 `v-show` 控制组件的显隐\n\n> **关键：将所有 Iframe 类型页面全部注册为 Vue 组件，并且通过打开状态进行展示（懒加载），通过路由信息来控制组件的显隐状态（缓存）**\n\n## 实现方案\n\n### 区分 Iframe 路由\n\n本项目中是使用路由信息中 `meta` 数据中的 `componentName` 来判断的，只要 componentName 包含 Iframe 就代表是 `Iframe` 类型的路由（区分规则以实际项目为准）\n\n### 获取所有的 Iframe 路由组件\n\n本项目中采用了动态路由，数据存放在 `Vuex` 中，用户登录时从数据库加载当前用户的路由菜单。并且项目脚手架是使用 `Ant Design Pro`，采用的是 Tab 多页签模式，所以在关闭 Tab 时也需要修改 Iframe 组件的状态，所以将 Iframe 组件列表也存放在 Vuex 中，方便在不同组件中共享数据\n\n```javascript\ncomputed: {\n  ...mapState({\n    // 动态路由\n    mainMenu: state => state.user.allPermissionList,\n    iframeComponentList: state => state.app.iframeComponentList\n  })\n},\nmethods: {\n  getIframeComponentList() {\n    const iframeMenuList = this.handleIframe(this.mainMenu, [])\n    const iframeComponentList = iframeMenuList.map((item, index) => {\n      // 设置组件\n      let component = \"\";\n      if(item.component.indexOf(\"layouts\")>=0){\n        component = \"components/\"+item.component;\n      }else{\n        component = \"views/\"+item.component;\n      }\n      const componentPath = resolve => require(['@/' + component+'.vue'], resolve)\n      // 根据 index 生成唯一的组件名称\n      const name = `iframe-${index}`\n      return {\n        hasOpen: false, // 是否打开过，默认false\n        ...item,\n        name, // 组件名称\n        component: componentPath // 组件文件的引用\n      }\n    })\n    // 交给vuex管理\n    this.$store.dispatch('setIframeComponentList', iframeComponentList)\n  },\n  handleIframe(menu, newMenu) {\n    menu.forEach((item) => {\n      // 根据规则判断是否为 Iframe 类型的路由\n      if (item.meta && item.meta.componentName && item.meta.componentName.includes('Iframe')) {\n        newMenu.push(item)\n      }\n      if (item.children && item.children.length) {\n        this.handleIframe(item.children, newMenu)\n      }\n    })\n    return newMenu\n  }\n}\n```\n\n### 设置 Iframe 路由在打开后为打开状态，用于缓存\n\n```javascript\ncomputed: {\n  // 实现懒加载，只渲染已经打开过（hasOpen:true）的 iframe 页\n  hasOpenComponentList() {\n    return this.iframeComponentList.filter((item) => item.hasOpen)\n  }\n},\nmethods: {\n  // 根据当前路由设置 hasOpen\n  isOpenIframePage() {\n    const target = this.iframeComponentList.find((item) => {\n      return this.$route.path.includes(item.path)\n    })\n    if (target && !target.hasOpen) {\n      let index = this.iframeComponentList.indexOf(target)\n      let hasOpen = true\n\t  // 更改 vuex 中 iframe 路由列表中的打开状态\n      this.$store.dispatch('setIframeComponentHasOpen', { index, hasOpen })\n    }\n  }\n}\n```\n\n### 使用 Iframe 路由组件\n\n```html\n<component\n    v-for=\"item in hasOpenComponentList\"\n    :key=\"item.name\"\n    :is=\"item.name\"\n    :linkUrl=\"item.meta.url\"\n    v-show=\"$route.path.includes(item.path)\"\n></component>\n```\n\n### Iframe 路由出口组件完整代码\n\n在项目中的菜单页面的路由出口处，将 `route-view` 组件更换成以下封装的 `iframe-route-view` 即可使用\n\n**注意：这里的 `route-view` 是 `JEECG` 框架在 `vue-router` 官方提供的 `router-view` 上封装了一层的自定义组件**\n\n```html\n<template>\n  <div class='main'>\n    <!-- 非 iframe 页 -->\n    <route-view v-if='!$route.meta.componentName.includes(\"Iframe\")'></route-view>\n\n    <!-- iframe 页 -->\n    <template v-if='hasOpenComponentList.length'>\n      <component\n        v-for='item in hasOpenComponentList'\n        :key='item.name'\n        :is='item.name'\n        :linkUrl='item.meta.url'\n        v-show='$route.path.includes(item.path)'\n      ></component>\n    </template>\n  </div>\n</template>\n\n<script>\nimport Vue from 'vue'\nimport { mapState } from 'vuex'\nimport RouteView from '@/components/layouts/RouteView'\n\nexport default {\n  name: 'IframeRouteView',\n  components: {\n    RouteView\n  },\n  created() {\n    if (this.iframeComponentList.length === 0) {\n      this.getIframeComponentList()\n    }\n    // 注册 iframe 页组件\n    this.iframeComponentList.forEach((item) => {\n      Vue.component(item.name, item.component)\n    })\n    // 初始化判断当前路由是否 iframe 页\n    this.isOpenIframePage()\n  },\n  watch: {\n    $route() {\n      if (this.iframeComponentList.length === 0) {\n        this.getIframeComponentList()\n      }\n      // 判断当前路由是否iframe页\n      this.isOpenIframePage()\n    }\n  },\n  computed: {\n    ...mapState({\n      // 动态主路由\n      mainMenu: state => state.user.allPermissionList,\n      iframeComponentList: state => state.app.iframeComponentList\n    }),\n    // 实现懒加载，只渲染已经打开过（hasOpen:true）的 iframe 页\n    hasOpenComponentList() {\n      return this.iframeComponentList.filter((item) => item.hasOpen)\n    }\n  },\n  methods: {\n    // 根据当前路由设置hasOpen\n    isOpenIframePage() {\n      const target = this.iframeComponentList.find((item) => {\n        return this.$route.path.includes(item.path)\n      })\n      if (target && !target.hasOpen) {\n        let index = this.iframeComponentList.indexOf(target)\n        let hasOpen = true\n        // 更改 vuex 中 iframe 路由列表中的打开状态\n        this.$store.dispatch('setIframeComponentHasOpen', { index, hasOpen })\n      }\n    },\n    getIframeComponentList() {\n      const iframeMenuList = this.handleIframe(this.mainMenu, [])\n      const iframeComponentList = iframeMenuList.map((item, index) => {\n        // 设置组件\n        let component = \"\";\n        if(item.component.indexOf(\"layouts\")>=0){\n          component = \"components/\"+item.component;\n        }else{\n          component = \"views/\"+item.component;\n        }\n        const componentPath = resolve => require(['@/' + component+'.vue'], resolve)\n        // 根据 index 生成唯一的组件名称\n        const name = `iframe-${index}`\n        return {\n          hasOpen: false, // 是否打开过，默认false\n          ...item,\n          name, // 组件名称\n          component: componentPath // 组件文件的引用\n        }\n      })\n      // 交给 vuex 管理\n      this.$store.dispatch('setIframeComponentList', iframeComponentList)\n    },\n    handleIframe(menu, newMenu) {\n      menu.forEach((item) => {\n        // push所有的iframe节点\n        if (item.meta && item.meta.componentName && item.meta.componentName.includes('Iframe')) {\n          newMenu.push(item)\n        }\n        if (item.children && item.children.length) {\n          this.handleIframe(item.children, newMenu)\n        }\n      })\n      return newMenu\n    }\n  }\n}\n</script>\n<style lang='less'>\n</style>\n```\n\n### 扩展一：使用 Vuex 管理 Iframe 组件列表\n\n```javascript\nimport Vue from 'vue'\n\nconst IFRAME_COMPONENT_LIST = \"IFRAME_COMPONENT_LIST\"\n\nconst iframe = {\n  state: {\n    iframeComponentList: [], //iframe组件列表\n  },\n  mutations: {\n    SET_IFRAME_COMPONENT_LIST (state, iframeComponentList) {\n      Vue.ls.set(IFRAME_COMPONENT_LIST, iframeComponentList)\n      state.iframeComponentList = iframeComponentList\n    },\n    SET_IFRAME_COMPONENT_HAS_OPENED (state, {index, hasOpen}) {\n      state.iframeComponentList[index].hasOpen = hasOpen\n      Vue.ls.set(IFRAME_COMPONENT_LIST, state.iframeComponentList)\n    }\n  },\n  actions: {\n    setIframeComponentList({ commit }, iframeComponentList) {\n      commit('SET_IFRAME_COMPONENT_LIST', iframeComponentList)\n    },\n    setIframeComponentHasOpen({ commit }, {index, hasOpen}) {\n      commit('SET_IFRAME_COMPONENT_HAS_OPENED', {index, hasOpen})\n    }\n  }\n}\n\nexport default iframe\n```\n\n### 扩展二：在关闭 Tab 标签页时改变页面的打开状态\n\n**注意：以下修改方式仅适用于当前项目，经供参考**\n\n```javascript\nclose(pageKey) {\n    let index = this.iframeComponentList.findIndex(item => pageKey.includes(item.path))\n    let hasOpen = false\n    this.$store.dispatch('setIframeComponentHasOpen', { index, hasOpen })\n}\n```\n\n## 总结\n\n整体的实现思路并不复杂，但是运用到实际项目中还是会牵动到项目框架本身的结构，可能会引起其他的问题，个人工作记录，仅供参考，如有不足之处，欢迎友友们在文章末尾进行留言交流指正。\n","tags":["技巧","笔记","Vue"],"categories":["前端开发"]},{"title":"JJLUO 的个人备忘录","slug":"JJLUO的个人备忘录","url":"/2023/05/18/fa915e12.html","content":"\n## 工作备忘录\n\n### 账号管理\n\n```\n百度 OCR 账号：\n1、账号/密码：wxocr1/Wx12345678\n   - APPID：24444661\n   - APIKEY：OCFFyaL2iBzQSFYwLi4q5bRZ\n   - SECRETKEY：a7LGvf9H1xhlxGYGmCBna3jhPSnqCsyS\n2、账号/密码：wxocr2/Wx12345678\n   - APPID：24454992\n   - APIKEY：VxnWUsfCmCxlK7CFtnNN7u1o\n   - SECRETKEY：MZk8IH7U0gfbVqYYE46f1pSkaptcuwsR\n3、账号/密码：wxocr3/Wx12345678\n   - APPID：24455011\n   - APIKEY：Baiy3otfpeqNEkXCLyZRuCRd\n   - SECRETKEY：fW4rGI3td97YFcZhlFZYzUroKf5huGZG\n   \n天翼云账号：12354226@qq.com\n密码：Ysy12!#1\n\n阿里云 OSS AccessKey\nLTAI5tDC6NcHk5Dd4rLS9YJE\nUVLXHUailxDLMuWbyhzlwhhRLNZj1N\n\n腾讯云\n子用户\n主账号ID 100019836036 \n用户名 translate \n登录密码 2QxZOgqg \nSecretId - \nSecretKey - \n快捷登录 https://cloud.tencent.com/login/subAccount/100019836036?type=subAccount&username=translate\nSecretId:AKIDUoDRVN1RfhW6Yt1ubAaWFk3B4iKlymPq\nSecretKey:JSL5Zu9NYZQ2ShnfJkwudfS4TfgdbR4V\n\nOracle 共享账号\n账户：1602404824@qq.com \n密码：wf1996ROOT#\n\nDNSPod Token\n名称\tnginx proxy manager\nID\t529151\nToken\t77dbe005d3117d3950439463dfd46c53\n```\n\n### VPN 管理\n\n```\n1、万序健康：\nwxuser066\nNc533Dp765$(-\n\nZsy008\nTg!274Bt%567Ie*630\n\n2、雷西精益\nluojunjie\nljj567$#@\n\n3、第一医药\nhttps://vpn.dyyy.com.cn\n10.168.21.42\n10.168.21.45\nDyyyy&042\n\n4、新嘉万序\nXjwxUser061\nJg935Pq257e227\n\nXjwxUser059\nBz463Vm772q987\n```\n\n### 服务器地址\n\n```\n1、ESLINK\n219.152.53.113\noracle/^SGDSmGha=RQ/l\nroot/3q>YO\"Nn/E$a]ZE%\n\n219.153.98.227\nadministrator/bw@C0PRuC4Pk\n\n2、公司服务器\n# 官网服务器 页面资源路径：/www/web/www_vanxsoft_com\n106.54.207.59:52213\nroot\nzUMY(4fVtma[$@72\n\n# 管理后台：\nhttp://www.vanxsoft.com/index.php?m=admin \nadmin/Wx123!@#\n\n106.54.207.59:52214\nroot\nxT;_]8AnYpP2%\n# 百度云客户机\n106.13.169.206:22\nroot\nKHh0*XSJ8vpc\n\n# nginx配置路径：/etc/nginx/nginx.conf\n106.54.207.59:52214\nroot\nxT;_]8AnYpP2%\n\n3、SPD\n192.168.99.228\nadministrator\nwx123!@#\n\n192.168.99.81\nadministrator\nwx123!@#9981\n\n118.25.143.88\nadministrator\nWx12345!@#$%\n\n4、雷西开发环境\nOpenVPN：\nhttps://180.168.103.82:50443/\n账号：\nadministrator\n密码：\nWx1234$#@!\n独立网段：\n10.168.110.0/24\n独立网关：\n10.168.110.254\n网关密码：\nWx1234$#@!\n\n5、VCSA 控制台\n172.123.1.109 vcsa109.sphere.xjwx\nadministrator@vsphere.xjwx\nWx123!@#\n192.168.99.186 vcsa.wxjksphere.com\nadministrator@sphere.wxjk\nWx123!@#\n172.32.1.9 vcsa.2022ha.lys\nadministrator@sphere.lys\nWx1234$#@!\n\n6、长护公网服务器\n58.40.67.190:17933\nadministrator/Wx123!@#179\n```\n\n## Oracle 脚本\n\n### 导入数据（Excle）\n\n```sql\nsqlldr PL_RUN_USER/bcX_4Nix@127.0.0.1:1521/shyy control=import.ctl errors=1000 rows=1000 log=log_AA.txt bad=bad_AA.txt\n```\n\n### sqlldr 脚本（.ctl）\n\n```sql\nLOAD DATA\nCHARACTERSET ZHS16GBK\nINFILE 'impData.csv'\nTRUNCATE\nINTO TABLE po_in\nfields terminated by X'09'\nTRAILING NULLCOLS(\n  字段名\n)\n-- 脚本解释\nLoad data\nInfile '新增的分包企业.txt'  \t\t--数据源文件名称\nAppend|insert|replace \t\t\t--append在表后追加insert插入空表replace替代原有内容\nInto table pm_construction_team --要导入的数据库表名称\n[when id = id_memo]      \t\t--过滤条件\nFields terminated by X'09'    \t--字段分隔符, 是一个制表符\n(id,name,telphone)          \t--字段名称列表\n-- 中文列名需要在linux系统中设置字符编码 vim中 使用:set fileencoding=gbk\n```\n\n### 查看锁表、杀进程\n\n```sql\n-- 查看锁表\nSELECT object_name, machine, s.sid, s.serial#\nFROM gv$locked_object l, dba_objects o, gv$session s\nWHERE l.object_id　 = o.object_id\nAND l.session_id = s.sid;\n-- 杀进程\nalter system kill session  '160,59268';\n-- 杀用户连接\nselect 'alter system kill session '''||sid ||','||serial#||''';',username,status from v$session where username='WX_TEST2' AND status = 'INACTIVE';\n```\n\n### 创建用户、分配权限\n\n```sql\n-- 创建用户并分配权限\ncreate user VANSYS_BOOT identified by VANSYS_BOOT;\n\nGRANT CREATE ANY SEQUENCE TO \"VANSYS_BOOT\";\nGRANT CREATE SESSION TO \"VANSYS_BOOT\";\nGRANT CREATE TABLE TO \"VANSYS_BOOT\";\nGRANT CREATE TABLESPACE TO \"VANSYS_BOOT\";\nGRANT CREATE VIEW TO \"VANSYS_BOOT\";\nGRANT SELECT ANY TABLE TO \"VANSYS_BOOT\";\nGRANT UNLIMITED TABLESPACE TO \"VANSYS_BOOT\";\nGRANT \"CONNECT\" TO \"VANSYS_BOOT\";\nGRANT \"DBA\" TO \"VANSYS_BOOT\";\nGRANT \"RESOURCE\" TO \"VANSYS_BOOT\";\n```\n\n### 创建表空间、分配给用户\n\n```sql\n-- 查看表空间位置\nselect t1.name,t2.name  from v$tablespace t1,v$datafile t2 where t1.ts# = t2.ts#\n-- 创建表空间\nCREATE  TABLESPACE sps ADD  datafile '/data/oracle/oradata/matrix/pdb1/sps.dbf' size 10240m AUTOEXTEND ON NEXT 500M MAXSIZE UNLIMITED;\n-- 创建临时表空间\n-----创建临时表空间-----\ncreate temporary tablespace TS_TEMP_01 tempfile '/data/oracle/oradata/matrix/pdb1/TS_TEMP_01.dbf'\n-----初始化大小-----\nsize 200m\n-----自动增长-------\nautoextend on\n-----每次扩展50m,无限制增长-----\nnext 200m maxsize unlimited\n-----本地管理表空间--------\nextent management local;\n-- 追加表空间\nALTER TABLESPACE SPS ADD DATAFILE '/data/oracle/oradata/matrix/sps2.dbf' SIZE 1G AUTOEXTEND ON NEXT 1G MAXSIZE unlimited;\n-- 追加临时表空间\nALTER tablespace TS_TEMP_01 ADD TEMPFILE '/data/oracle/oradata/matrix/pdb1/TS_TEMP_02.dbf' SIZE 1G AUTOEXTEND ON NEXT 1G MAXSIZE unlimited;\n-- 查看表空间大小\nSELECT t.tablespace_name,\n       round(SUM(bytes / (1024 * 1024 * 1024)), 0) ts_size\n  FROM dba_tablespaces t, dba_data_files d\n WHERE t.tablespace_name = d.tablespace_name\n GROUP BY t.tablespace_name;\n\n-- 查看表空间文件大小\nSELECT tablespace_name,\n       file_id,\n       file_name,\n       round(bytes / (1024 * 1024 * 1024), 0) total_space\n  FROM dba_data_files\n ORDER BY tablespace_name;\n\n-- 查看表空间使用情况\nSELECT SUM(bytes) / (1024 * 1024) AS free_space, tablespace_name\n  FROM dba_free_space\n GROUP BY tablespace_name;\n-- 百分比占比\nSELECT a.tablespace_name,\n       a.bytes total,\n       b.bytes used,\n       c.bytes free,\n       (b.bytes * 100) / a.bytes \"% USED \",\n       (c.bytes * 100) / a.bytes \"% FREE \"\n  FROM sys.sm$ts_avail a, sys.sm$ts_used b, sys.sm$ts_free c\n WHERE a.tablespace_name = b.tablespace_name\n   AND a.tablespace_name = c.tablespace_name;\n\n-- 分配给用户\nalter user username default tablespace tablespacename;\n-- 将名字为tablespacename的表空间分配给username\n```\n\n### 用户相关命令\n\n```sql\n-- 创建用户\ncreate user user_name identified by \"user_password\"\ndefault tablespace USERS\ntemporary tablespace TEMP profile DEFAULT;\n\n-- 授权\ngrant connect to user_name;\ngrant create indextype to user_name;\ngrant create job to user_name;\ngrant create materialized view to user_name;\ngrant create procedure to user_name;\ngrant create public synonym to user_name;\ngrant create sequence to user_name;\ngrant create session to user_name;\ngrant create table to user_name;\ngrant create trigger to user_name;\ngrant create type to user_name;\ngrant create view to user_name;\ngrant unlimited tablespace to user_name;\nalter user user_name quota unlimited on tbs_name;\n\n-- 表空间、临时表空间\ndba_data_files、dba_temp_files\n-- 查询用户默认使用的表空间\nselect username,default_tablespace from dba_users;\n-- 修改默认表空间\nalter user TRANSWATCH default tablespace TMS5_TABLES;\n-- 给用户赋权限\ngrant create session,create table,unlimited tablespace to TRANSWATCH;\n-- 查询用户使用的表空间\nselect table_name,tablespace_name from user_tables;\n-- 查指定表空间下当前用户的所有表\nselect 'alter table '||table_name||' move tablespace TMS5_TABLES;' from\nuser_tables where tablespace_name = 'USERS';\n-- 批量修改表空间\nalter table SANCTIONED_CITIES move tablespace TMS5_TABLES;\n\n-- 查询索引\nselect * from user_indexes;\n-- 查指定索引表空间下当前用户的所有=索引\nselect 'alter index '||index_name||' rebuild tablespace TMS5_INDEXES;'from user_indexes;\n-- 批量修改索引表空间\nalter index SYS_IL0000077055C00004$$ rebuild tablespace TMS5_INDEXES;\nalter index PK_SUPPORT_FILES rebuild tablespace TMS5_INDEXES;\n\n-- 查询函LOB类型表所在索引表空间(ORA-02327: cannot create index on expression with datatype LOB 02327. 00000,报这个错是因为LOB类型导致)\nselect * from user_indexes where index_name like 'SYS%'\n-- 表结构\ndesc SCREENING_IWL_ENTITY;\n-- 移动含LOB类型表的索引到其他表空间\nALTER TABLE SCREENING_IWL_ENTITY MOVE LOB(DETAIL) STORE AS (TABLESPACE TMS5_INDEXES);\n\n-- 删除用户\ndrop user xxx cascade;\n```\n\n### 数据泵导出/导入\n\n```sql\n-- 自动创建用户的前提是有对应的表空间和临时表空间\n-- 创建directory\ncreate or replace directory dmp\n  as 'D:/'\n-- 导出\nexpdp PL_RUN_USER/bcX_4Nix@127.0.0.1/shyy directory=dmp dumpfile=erp1218.dmp logfile=erp1218.log  job_name=exp_wx_schema\n\nexpdp VXSCCP/VXSCCP@127.0.0.1/orcl directory=dmp dumpfile=vxsccp0223.dmp logfile=vxsccp0223.log  job_name=exp_wx_schema\n-- 导入\nimpdp PL_RUN_USER/bcX_4Nix@127.0.0.1/shyy remap_schema=PL_RUN_USER:PL_RUN_USER2 remap_tablespace=TS_PL_DATA01:TS_PL_DATA01 directory=dmp dumpfile=erp1218.dmp logfile=erp1218.log table_exists_action=replace content=all job_name=imp_schema transform=OID:N\n\nimpdp VXSFMS/VXSFMS@127.0.0.1/orcl remap_schema=VXSCCP:VXSFMS directory=dmp dumpfile=vxsccp0223.dmp logfile=vxsccp0223.log table_exists_action=replace content=all job_name=imp_schema transform=OID:N\n\nimp VXSPD_BOOT/VXSPD_BOOT@127.0.0.1/orcl file=f:\\VXSPD_2302.DMP log=f:\\VXSPD_2302.log full=y\n\n/*\n说明：\nremap_schema 当导出导入用户不一致时,zbtms为导出用户,tms 为导入用户\nremap_tablespace 当导出导入表空间不一致时,zbtms为导出表空间,tms 为导入表空间\ndirectory=dump_dir 指定逻辑目录\ndumpfile=ZBTMS2021031701.DMP 需要导入的文件,不能携带路径,需放在指定逻辑目录下\n*/\n```\n\n### 系统连接数\n\n```sql\n-- 查询数据库当前进程的连接数：\nselect count(*) from v$process;\n\n-- 查看数据库当前会话的连接数：\nselect count(*) from v$session;\n\n-- 查看数据库的并发连接数：\nselect count(*) from v$session where status='ACTIVE';\n\n-- 查看当前数据库建立的会话情况：\nselect sid,serial#,username,program,machine,status from v$session;\n\n-- 查询数据库允许的最大连接数：\nselect value from v$parameter where name = 'processes';\nshow parameter processes;\n\n-- 修改数据库允许的最大连接数：(需要重启数据库才能实现连接数的修改)\nalter system set processes = 300 scope = spfile;\n\n# 连接 sqlplus\nsqlplus / as sysdba\n\n-- 重启数据库：\nSQL> shutdown immediate;\nSQL> startup;\n\n-- 查看当前有哪些用户正在使用数据：\nselect osuser,a.username,cpu_time/executions/1000000||'s',sql_fulltext,machine\nfrom v$session a,v$sqlarea b\nwhere a.sql_address = b.address\norder by cpu_time/executions desc;\n```\n\n### 容器相关\n\n```sql\n-- 查看所有容器\nshow pdbs;\n-- 当前连接容器\nshow con_name;\n-- 切换容器\nalter session set container=pdb1;\n```\n\n### 其他命令\n\n```sql\n-- 查看某张表约束条件\nselect * from user_constraints where table_name='COM_INV_FACT'\n```\n\n## Linux 命令\n\n### 查看进程\n\n```\n-- 查看进程\nps -ef | grep nginx\nps -C nginx -o pid\nnetstat -anp | grep :80\n```\n\n### Tomcat\n\n```\n-- 后台启动tomcat\nsudo nohup apache-tomcat-8.5.55/bin/startup.sh >> server.log 2>&1 &\n-- 杀tomcat进程\nps -ef|grep -v grep|grep  apache-tomcat-8.5.57 | grep java |awk '{print \"sudo kill -9 \"$2}'|sh\n```\n\n### sftp\n\n```\n-- sftp 常用命令\nservice sshd status #查看 sftp 的状态\nservice sshd start #启动服务\nservice sshd stop #停止服务\nservice sshd restart #重启 sftp\n```\n\n### scp\n\n语法：\n\n```\nscp [option] /path/to/source/file user@server-ip:/path/to/destination/directory\n```\n\n`/path/to/source/file` – 这是打算复制到远程主机的源文件。\n\n`user@server-IP`: – 这是远程系统的用户名和 IP 地址。请注意 IP 地址后面加冒号。\n\n`/path/to/destination/directory` – 这是文件将复制到的远程系统上的目标目录。\n\n以下是 scp 命令常用的几个选项：\n\n`-C` - 这会在复制过程中压缩文件或目录。\n`-P` - 如果默认 SSH 端口不是 22，则使用此选项指定 SSH 端口。\n`-r` - 此选项递归复制目录及其内容。\n`-p` - 保留文件的访问和修改时间。\n\n### wget\n\n```shell\n# 下载单个文件\nwget http://www.baidu.com。命令会直接在当前目录下载一个index.html的文件\n# 将下载的文件存放到指定的文件夹下，同时重命名下载的文件，利用-O\nwget -O /home/index http://www.baidu.com\n# 断点续传\nwget -c http://www.baidu.com\n# 限制下载的的速度\nwget --limit-rate=100k -O zfj.html http://www.baidu.com\n# 测试是否能正常访问\nwget --spider http://www.baidu.com\n# 设置下载重试的次数\nwget --tries=3 http://www.baidu.com\n# 使用wget实现FTP下载\nwget --file-user=USERNAME --file-password=PASSWORD url\n```\n\n### 解压与压缩\n\n```shell\n# 解压\nunzip -o -d 解压目标文件夹 压缩文件\n# 压缩\nzip -r 压缩文件 目标文件夹\n# 打包压缩为一个.gz格式的压缩包\ntar -zcvf pack.tar.gz pack/\n# 打包压缩为一个.bz2格式的压缩包\ntar -jcvf pack.tar.bz2 pack/\n# 打包压缩为一个.xz格式的压缩包\ntar -Jcvf pack.tar.xz pack/\n# 解包解压.gz格式的压缩包到pack文件夹\ntar -zxvf pack.tar.gz /pack\n# 解包解压.bz2格式的压缩包到pack文件夹\ntar -jxvf pack.tar.bz2 /pack\n# 解包解压.xz格式的压缩包到pack文件夹\ntar -Jxvf pack.tar.xz /pack\n\n\n# 解压带有中文名的文件乱码问题，携带 -O CP936 或者 -O GBK 参数\nunzip -O CP936 filename.zip\n```\n\n### 校准服务器时间\n\n```\nCentOS6-7\n# 安装校准工具\nyum install -y ntpdate\nor\napt-get install ntpdate\n# 校准时间\nntpdate ntp1.aliyun.com\n# 选择时区\ndpkg-reconfigure tzdata\n\nCentOS8\n#1. 查看当前时间\ndate\n#2. 添加wlnmp源\nrpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm\n#3. 安装ntp服务\nyum install wntp\n#4. 时间同步\nntpdate ntp1.aliyun.com\n```\n\n### 修改静态 IP\n\n```\n# ifconfig 查看网卡信息\nifconfig\n# 进入网卡配置文件目录\ncd /etc/sysconfig/network-scripts/\n# 修改对应的网卡配置文件\nvim /etc/sysconfig/network-scripts/ifcfg-ethxxx\n# 重启网络服务\nservice network restart\n```\n\n### 修改用户密码\n\n```\n# 重置当前用户密码\npasswd\n```\n\n### 磁盘分区和挂载\n\n> [Ubuntu 硬盘分区和挂载](https://blog.csdn.net/MuZhi233/article/details/121540077)\n>\n> [CentOS7 磁盘挂载](https://blog.csdn.net/China_hdy/article/details/124119924)\n>\n> [Linux 磁盘扩容三种方式](https://blog.csdn.net/m0_54853503/article/details/126434591)\n\n### 防火墙\n\n```\ncentos6 关闭防火墙\n\n1.service命令\n关闭防火墙：service iptables stop\n开启防火墙：service iptables start\n重启防火墙：service iptables restart\n查看防火墙状态：service iptables status\n\n2.通过：/etc/init.d/iptables 进行操作\n关闭防火墙：/etc/init.d/iptables stop（这是临时关闭，关闭的是当前运行的防火墙，重启之后防火墙又会启动，因为它是开机自启动的,它相当于/etc/init.d/iptables start）\n查看防火墙状态：/etc/init.d/iptables/status\n\n3.需要改为开机不启动，使用chkconfig命令\n永久关闭防火墙： chkconfig iptables off\n永久开启防火墙： chkconfig iptables on\n查看状态：chkconfig --list iptables\n\nCentOS7 的防火墙配置跟以前版本有很大区别，CentOS7这个版本的防火墙默认使用的是firewall，与之前的版本使用iptables不一样。\n\n1、关闭防火墙\nsystemctl stop firewalld.service\n2、开启防火墙\nsystemctl start firewalld.servicee\n3、关闭开机启动防火墙\nsystemctl disable firewalld.service\n4、开机启动防火墙\nsystemctl enable firewalld.service\n5、常用端口放行\n#放行8080端口\nfirewall-cmd --zone=public --add-port=8080/tcp --permanent\n#重启防火墙\nfirewall-cmd --reload\n- -zone ，作用域\n- -add-port=8080/tcp ，添加端口，格式为：端口/通讯协议\n- -permanent，永久生效，没有此参数，重启后失效\n\nCentos8关闭防火墙\n\nsystemctl status firewalld.service（查看防火墙状态）\n# active表示当前防火墙处于开启状态 inactive表示关闭状态\nsystemctl stop firewalld.service （关闭防火墙）\nsystemctl start firewalld.service （开启防火墙）\nsystemctl disable firewalld.service （禁止防火墙自启动）\nsystemctl enable firewalld.service （防火墙随系统开启启动）\n```\n\n**centos7**\n\n```\n# 开启防火墙\nsystemctl start firewalld\n\n# 重启防火墙\nsystemctl restart firewalld\n\n# 重载规则\nfirewall-cmd --reload\n\n# 查看已配置规则\nfirewall-cmd --list-all\n\n# 指定端口和ip访问\nfirewall-cmd --permanent --add-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.44.101\"\nport protocol=\"tcp\" port=\"8080\" accept\"\n\n# 移除规则\nfirewall-cmd --permanent --remove-rich-rule=\"rule family=\"ipv4\" source\naddress=\"192.168.44.101\" port port=\"8080\" protocol=\"tcp\" accept\"\n\n# 开放指定端口\nfirewall-cmd --zone=public --add-port=3306/tcp --permanent\n\nfirewall-cmd --zone=public --add-port=620/tcp --permanent\n\n# 关闭指定端口\nfirewall-cmd --zone=public --remove-port=6379/tcp --permanent\n\n 命令含义：\n--zone #作用域\n--add-port=1935/tcp  #添加端口，格式为：端口/通讯协议\n--permanent  #永久生效，没有此参数重启后失效\n\n# 查看端口号\nnetstat -ntlp   //查看当前所有tcp端口·\nnetstat -ntulp |grep 3306   //查看所有3306端口使用情况\n```\n\n### yum 包管理器\n\n#### CentOS6 的 yum 命令不能使用解决方案\n\n```\n# linux centos6的yum命令不能使用解决方案\n# 1.关闭fastestmirrors\nsed -i \"s|enabled=1|enabled=0|g\" /etc/yum/pluginconf.d/fastestmirror.conf\n\n# 2.备份\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak\n\n# 3.替换yum源为国内的\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://www.xmpan.com/Centos-6-Vault-Aliyun.repo\n\n# 4.清理/更新/建立缓存\nyum clean all\nyum update\nyun makecache\n```\n\n#### nginx 安装依赖\n\n```\n# nginx gcc 依赖\nyum -y install gcc gcc-c++ autoconf automake make\n```\n\n#### CentOS 升级 git 到 2.x\n\nCentos6.x\n\n```bash\nyum -y remove git\n\nwget http://opensource.wandisco.com/centos/6/git/x86_64/wandisco-git-release-6-1.noarch.rpm && rpm -ivh wandisco-git-release-6-1.noarch.rpm\n\nyum install git -y\n\ngit version\n```\n\nCentos7.x\n\n```\nyum remove git\n\nrpm -ivh http://opensource.wandisco.com/centos/7/git/x86_64/wandisco-git-release-7-1.noarch.rpm\n\nyum -y install git\n\ngit version\n```\n\n#### yum 卸载软件\n\n```\n# 1、查找软件包名\nyum list installed\n# 2、执行卸载\nyum remove xxx\n```\n\n### apt 包管理器\n\n```\n# 卸载软件\napt purge python\n\napt remove 删除已安装的软件包（保留配置文件），不会删除依赖软件包，保留配置文件`；\n\napt purge 删除已安装包（不保留配置文件)，删除软件包，同时删除相应依赖软件包`。\n\napt clean 此命令会将 /var/cache/apt/archives/ 下的 所有 deb 删掉，相当于清理下载的软件安装包。\n\napt autoclean 删除为了满足某些依赖安装的，但现在不再需要的软件包。\n\n以上最推荐使用 apt purge 最简单 如果提示权限不够 命令前加上sudo即可\n```\n\n### VIM\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220401200925.png)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220401200935.png)\n\n```\n:set ff 查看当前文本的模式类型，一般为dos,unix\n:set ff=dos 设置为dos模式， 也可以用 sed -i 's/$/\\r/'\n:set ff=unix 设置为unix模式，也可以用一下方式转换为unix模式:sed -i 's/.$//g'\n\n:set fileencoding查看现在文本的编码\n:set fenc=编码 转换当前文本的编码为指定的编码\n:set enc=编码 以指定的编码显示文本，但不保存到文件中。\n```\n\n### 清除内存缓存\n\n```\nsync\necho 1 > /proc/sys/vm/drop_caches\n\n# 在/usr/local文件文件夹创建cleanCache.sh\ntouch cleanCache.sh\n# 修改权限\nchmod 777 /usr/local/cleanCache.sh\n# 测试执行\n/usr/local/cleanCache.sh\n# 编写定时任务 crontab -e\n# 在末尾添加如下内容：（每天0点的时候执行一次，可以按需更改）\n50 23 * * * /usr/local/cleanCache.sh\n# 查看定时器crontab -l\n\n# cleanCache.sh内容\n#!/bin/bash\n#每天定时清除一次缓存\necho \"开始清理缓存\"\nsync;sync;sync #写入硬盘，防止数据丢失\nsleep 5 #延迟10秒\necho 1 > /proc/sys/vm/drop_caches\necho 2 > /proc/sys/vm/drop_caches\necho 3 > /proc/sys/vm/drop_caches\necho \"清理结束\"\n```\n\n### 查看内存/CPU\n\n```\n# 查看内存用量和交换区用量\nfree -h\n# 查看物理CPU个数\ncat /proc/cpuinfo| grep \"physical id\"| sort| uniq| wc -l\n# 查看逻辑CPU个数\ncat /proc/cpuinfo| grep \"processor\"| wc -l\n# 查看CPU核心数\ncat /proc/cpuinfo| grep \"cpu cores\"| uniq\n# 查看CPU型号\ncat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c\n# linux查看系统版本\nlsb_release -a\n```\n\n### 磁盘分区/文件大小\n\n```\n# df 主要是检查文件系统磁盘占用情况，所以这里可以看到文件系统\n\n# du 主要是检查磁盘空间占用情况，统计目录或者文件大小的，和ll功能有相同之处。\n\n# disk 一般用来磁盘分区，也可以用来查看磁盘分区情况。\n\n# lsblk 命令用于列出所有可用块设备的信息，而且还能显示他们之间的依赖关系，这个命令很好用，因为可以让电脑上的磁盘和分区信息很清晰。\n\n1. df命令：\n查看一级文件大小、使用比例、档案系统以及挂入点\n\n1.1 查看分区的文件系统: df -T\n\n1.2 显示目前所有文件系统的可用空间及使用情形： df -h\n\n2. du命令：\n可以查看文件及文件夹的大小\n\n2.1 查看系统中文件的使用情况： du -h\n\n2.2. 查看当前目录下各个文件及目录占用空间大小：du -sh *（把*换掉，查具体的文件）\n```\n\n### 设置 Hostname\n\n```bash\n# centos6.x\nvim /etc/sysconfig/network\nvim /etc/hosts\n\n# centos7+\nhostnamectl set-hostname xxx\n\n# ubuntu20+\nvi /etc/hostname\nvi /etc/hosts\nhostname xxx\n```\n\n### vphere 安装 Anolis OS 并设置静态 IP\n\n#### 网络配置\n\n```bash\nvi /etc/sysconfig/network-scripts/ifcfg-ens32\nbootproto=static\nonboot=yes\n```\n\n在最后加上几行，IP 地址、网关、dns 服务器\n\n```bash\nIPADDR=\"192.168.88.237\"\nPREFIX=\"24\"\nGATEWAY=\"192.168.88.1\"\nDNS1=\"202.96.209.133\"\nIPV6_PRIVACY=\"no\"\nZONE=public\n```\n\n重启网络服务\n\n```bash\nnmcli c reload\n```\n\n#### 挂载硬盘\n\n查看当前未挂载的硬盘\n\n```bash\nfdisk -l\n```\n\n创建硬盘分区\n\n```bash\nfdisk /dev/sdb\n```\n\n根据提示，依次输入 \"n\"，\"p\" \"1\"，两次回车，\"wq\"，分区就开始了，很快就会完成。\n\n格式化硬盘\n\n```bash\nmkfs.xfs -f /dev/sdb\n```\n\n建立挂载目录\n\n```bash\nmkdir /u01\n```\n\n挂载硬盘\n\n```bash\nmount /dev/sdb /u01\n```\n\n设置开机自动挂载\n\n```bash\nnano /etc/fstab\n/dev/sdb    /u01    xfs    defaults    0 0\n```\n\n重启服务器\n\n```bash\nreboot\n```\n\n## Docker\n\n### CentOS6.9 安装 Docker\n\n```\n# 升级内核\n# 1、准备 kernel-lt-4.4.210-1.el6.elrepo.x86_64.rpm 内核镜像\n# 2、安装内核镜像\nrpm -ivh kernel-lt-4.4.210-1.el6.elrepo.x86_64.rpm\nvi /etc/grub.conf\n# 将 default=1 改为 default=0\n# 3、重启\nreboot\n\n# 安装 Docker\n# 1、准备docker-17.03.1-ce.tgz\n# 2、tar -zxvf docker-17.03.1-ce.tgz\n# 3、cp ./docker/* /usr/bin\n# 4、dockerd &\n```\n\n解决 Error starting daemon: Devices cgroup isn't mounted，新建 sh 脚本，内容如下：\n\n```\nset -e\n# 这句是告诉bash如何有任何语句执行结果不为ture，就应该退出。\n\nif grep -v '^#' /etc/fstab | grep -q cgroup; then\n\techo 'cgroups mounted from fstab, not mounting /sys/fs/cgroup'\n\texit 0\nfi\n\n# kernel provides cgroups?\nif [ ! -e /proc/cgroups ]; then\n\texit 0\nfi\n\n# 确保目录存在\nif [ ! -d /sys/fs/cgroup ]; then\n\texit 0\nfi\n\n# mount /sys/fs/cgroup if not already done\nif ! mountpoint -q /sys/fs/cgroup; then\n\tmount -t tmpfs -o uid=0,gid=0,mode=0755 cgroup /sys/fs/cgroup\nfi\n\ncd /sys/fs/cgroup\n\n# get/mount list of enabled cgroup controllers\nfor sys in $(awk '!/^#/ { if ($4 == 1) print $1 }' /proc/cgroups); do\n\tmkdir -p $sys\n\tif ! mountpoint -q $sys; then\n\t\tif ! mount -n -t cgroup -o $sys cgroup $sys; then\n\t\t\trmdir $sys || true\n\t\tfi\n\tfi\ndone\n\n\nexit 0\n```\n\n解决 service docker start/status 等命令不能用的问题：\n\n```\n1、下载资源\n\nhttp://ftp.pbone.net/mirror/vault.centos.org/6.9/updates/x86_64/Packages/libcgroup-0.40.rc1-24.el6_9.x86_64.rpm\n\n2、rpm -ivh libcgroup-0.40.rc1-24.el6_9.x86_64.rpm\n\n3、vi /etc/sysconfig/docker 将下面内容copy进去\n\n# /etc/sysconfig/docker\n#\n# Other arguments to pass to the docker daemon process\n# These will be parsed by the sysv initscript and appended\n# to the arguments list passed to docker -d\nother_args=\"\"\n\n4、vi /etc/init.d/docker\n\n#!/bin/sh\n#\n#       /etc/rc.d/init.d/docker\n#\n#       Daemon for docker.com\n#\n# chkconfig:   2345 95 95\n# description: Daemon for docker.com\n### BEGIN INIT INFO\n\n# Provides:       docker\n\n# Required-Start: $network cgconfig\n\n# Required-Stop:\n\n# Should-Start:\n\n# Should-Stop:\n\n# Default-Start: 2 3 4 5\n\n# Default-Stop:  0 1 6\n\n# Short-Description: start and stop docker\n\n# Description: Daemon for docker.com\n\n### END INIT INFO\n\n# Source function library.\n\n. /etc/rc.d/init.d/functions\n\nprog=\"docker\"\n\nunshare=/usr/bin/unshare\n\nexec=\"/usr/bin/$prog\"\n\npidfile=\"/var/run/$prog.pid\"\n\nlockfile=\"/var/lock/subsys/$prog\"\n\nlogfile=\"/var/log/$prog\"\n\n[ -e /etc/sysconfig/$prog ] && . /etc/sysconfig/$prog\n\nprestart() {\n    service cgconfig status > /dev/null\n\n    if [[ $? != 0 ]]; then\n\n        service cgconfig start\n\n    fi\n\n}\n\nstart() {\n    [ -x $exec ] || exit 5\n\n    check_for_cleanup\n\n    if ! [ -f $pidfile ]; then\n\n        prestart\n\n        printf \"Starting $prog:\\t\"\n\n        echo \"\\n$(date)\\n\" >> $logfile\n\n        \"$unshare\" -m -- $exec daemon $other_args &>> $logfile &\n\n        pid=$!\n\n        touch $lockfile\n\n        # wait up to 10 seconds for the pidfile to exist.  see\n\n        # https://github.com/docker/docker/issues/5359\n\n        tries=0\n\n        while [ ! -f $pidfile -a $tries -lt 10 ]; do\n\n            sleep 1\n\n            tries=$((tries + 1))\n\n        done\n\n        success\n\n        echo\n\n    else\n\n        failure\n\n        echo\n\n        printf \"$pidfile still exists...\\n\"\n\n        exit 7\n\n    fi\n\n}\n\nstop() {\n    echo -n $\"Stopping $prog: \"\n\n    killproc -p $pidfile -d 300 $prog\n\n    retval=$?\n\n    echo\n\n    [ $retval -eq 0 ] && rm -f $lockfile\n\n    return $retval\n\n}\n\nrestart() {\n    stop\n\n    start\n\n}\n\nreload() {\n    restart\n\n}\n\nforce_reload() {\n    restart\n\n}\n\nrh_status() {\n    status -p $pidfile $prog\n\n}\n\nrh_status_q() {\n    rh_status >/dev/null 2>&1\n\n}\n\ncheck_for_cleanup() {\n    if [ -f ${pidfile} ]; then\n\n        /bin/ps -fp $(cat ${pidfile}) > /dev/null || rm ${pidfile}\n\n    fi\n\n}\n\ncase \"$1\" in\n\n    start)\n\n        rh_status_q && exit 0\n\n        $1\n\n        ;;\n\n    stop)\n\n        rh_status_q || exit 0\n\n        $1\n\n        ;;\n\n    restart)\n\n        $1\n\n        ;;\n\n    reload)\n\n        rh_status_q || exit 7\n\n        $1\n\n        ;;\n\n    force-reload)\n\n        force_reload\n\n        ;;\n\n    status)\n\n        rh_status\n\n        ;;\n\n    condrestart|try-restart)\n\n        rh_status_q || exit 0\n\n        restart\n\n        ;;\n\n    *)\n\n        echo $\"Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload}\"\n\n        exit 2\n\nesac\n\nexit $?\n\n5、chkconfig --add docker\n\n6、chkconfig docker on\n\n7、service docker status\n\n# tips\n[root@88231 opt]# service docker status\nenv: /etc/init.d/docker: Permission denied\n解决办法：chmod a+x /etc/init.d/docker\n```\n\n### Centos6.9 安装 Docker Compose\n\n```bash\n# 下载 docker-compose\ncurl -L https://github.com/docker/compose/releases/download/1.25.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\n# 更改可执行权限\nchmod +x /usr/local/bin/docker-compose\n```\n\n**会报错**\n\n```\ndocker-compose version\ndocker-compose: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /tmp/_MEI3RKpZw/libz.so.1)\n\n# 解决办法\n# 准备 glibc-2.17.tar.gz\n# 解压 glibc-2.17.tar.gz\ntar -xvf glibc-2.17.tar.gz\ncd glibc-2.17\n\n# 创建 build 目录\nmkdir build; cd build\n\n# 编译安装\n../configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin\n\nmake -j 8 && make install\n```\n\n### 配置私有 docker 仓库地址\n\ndocker 版本 17.03.1-ce\n\n```\nvim /etc/sysconfig/docker\n# /etc/sysconfig/docker\n#\n# Other arguments to pass to the docker daemon process\n# These will be parsed by the sysv initscript and appended\n# to the arguments list passed to docker -d\n\nother_args=\"--insecure-registry=仓库所在主机IP:端口\"\n```\n\ndocker 版本 20.10.13\n\n```\nvim /etc/docker/daemon.json\n{\n    \"insecure-registries\":[\"仓库所在主机IP:端口\"]\n}\n```\n\n### 修改默认存储路径\n\ncentos6/17.03.1-ce\n\n```\nmkdir -p /u01/docker\ncp -ra /var/lib/docker/* /u01/docker/\n\n# 添加更改的路径 \"--graph=/u01/docker\"\nvim /docketc/sysconfig/docker\n\nservice docker restart\n\ndocker info|grep 'Docker Root Dir'\n```\n\nubuntu20.04/20.10.17\n\n```bash\n# 查看Docker目前存储位置\n[root@docker ~]# docker info | grep -i dir\n Docker Root Dir: /var/lib/docker\n\n# 关闭Docker\n[root@docker ~]# systemctl stop docker\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\n\n# 迁移原有数据\n[root@docker ~]# mkdir -p /u01/docker\n[root@docker ~]# mv /var/lib/docker/* /u01/docker/\n\n# 修改配置文件，graph指定docker默认数据存放位置\n[root@docker ~]# vim /etc/docker/daemon.json\n{\n\t\"graph\": \"/u01/docker\",\n\t\"registry-mirrors\": [\"https://alq7pwwu.mirror.aliyuncs.com\"]\n}\n\n# 启动docker\n[root@docker ~]# systemctl start docker\n[root@docker ~]# docker info | grep -i dir\n Docker Root Dir: /u01/docker\n```\n\ncentos7.9/24.0.6\n\n```\n# 查看Docker目前存储位置\n[root@docker ~]# docker info | grep -i dir\n Docker Root Dir: /var/lib/docker\n\n# 关闭Docker\n[root@docker ~]# systemctl stop docker\nWarning: Stopping docker.service, but it can still be activated by:\n  docker.socket\n\n# 迁移原有数据\n[root@docker ~]# mkdir -p /u01/docker\n[root@docker ~]# mv /var/lib/docker/* /u01/docker/\n\n# 修改配置文件，graph指定docker默认数据存放位置\n[root@docker ~]# vim /etc/docker/daemon.json\n{\n\t\"data-root\": \"/u01/docker\",\n\t\"registry-mirrors\": [\"https://alq7pwwu.mirror.aliyuncs.com\"]\n}\n\n# 启动docker\n[root@docker ~]# systemctl start docker\n[root@docker ~]# docker info | grep -i dir\n Docker Root Dir: /u01/docker\n```\n\n### 配置远程访问\n\n> 开启 TLS 加密：https://docs.docker.com/engine/security/protect-access/#use-tls-https-to-protect-the-docker-daemon-socket\n>\n> ExecStart =/usr/bin/dockerd --tlsverify --tlscacert =/etc/docker/ca.pem --tlscert =/etc/docker/server-cert.pem --tlskey =/etc/docker/server-key.pem -H fd:// -H tcp://0.0.0.0:2375 --containerd =/run/containerd/containerd.sock\n\ncentos6/17.03.1-ce\n\n```\n# 添加配置 \"-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock\"\nvim /etc/sysconfig/docker\nother_args=\"-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock\"\n\nservice docker restart\n\ncurl http://localhost:2375/version\n```\n\nubuntu20.4\n\n```\n# vim /usr/lib/systemd/system/docker.service\n...第13行\nExecStart=/usr/bin/dockerd -H fd:// \\\n    -H tcp://0.0.0.0:2375 \\\n    --containerd=/run/containerd/containerd.sock\n...\n# systemctl daemon-reload\n# service docker restart\n```\n\n### 已运行容器添加端口映射\n\n```bash\n#1、查看容器的信息\ndocker ps -a\n\n#2、查看容器的端口映射情况，在容器外执行：\ndocker port 容器ID 或者 docker port 容器名称\n\n#3、查找要修改容器的全ID\ndocker inspect 容器ID |grep Id\n\n#4、进到/var/lib/docker/containers 目录下找到与全 Id 相同的目录，修改 其中的hostconfig.json 和 config.v2.json文件：\n#注意：若该容器还在运行中，需要先停掉\ndocker stop 容器ID\n#再停掉docker服务\nsystemctl stop docker\n\n#5、修改hostconfig.json如下，添加端口绑定\"9003/tcp\": [{\"HostIp\": \"\",\"HostPort\": \"9003\"}]，表示绑定端口9003\n\n#6、修改config.v2.json在ExposedPorts中加上要暴露的端口，即9003\n```\n\n### Jenkins Docker Agent 制作\n\n```bash\n#1、拉取 Jenkins 官方的 jenkins/inbound-agent 镜像并启动容器\ndocker pull jenkins/inbound-agent:latest\ndocker run -it --user root jenkins/inbound-agent:latest /bin/bash\n\n#2、容器内安装 ansible\napt update && apt install -y ansible\n```\n\n### Dockerfile 中 alpine 安装 curl\n\n```dockerfile\nRUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories\n\nRUN apk add curl\n```\n\n### Docker 设置已运行容器开机自启\n\n```\ndocker update --restart=unless-stopped 容器ID\n```\n\n## Git\n\n### 常用命令清单\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202310121028990.jpeg)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202310121108686.png)\n\n- Workspace：工作区\n- Index / Stage：暂存区\n- Repository：仓库区（或本地仓库）\n- Remote：远程仓库\n\n### 新建代码库\n\n```bash\n# 在当前目录新建一个Git代码库\ngit init\n\n# 新建一个目录，将其初始化为Git代码库\ngit init [project-name]\n\n# 下载一个项目和它的整个代码历史\ngit clone [url]\n```\n\n### 配置\n\nGit 的设置文件为 `.gitconfig`，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。\n\n```bash\n# 显示当前的Git配置\ngit config --list\n\n# 编辑Git配置文件\ngit config -e [--global]\n\n# 设置提交代码时的用户信息\ngit config [--global] user.name \"[name]\"\ngit config [--global] user.email \"[email address]\"\n```\n\n### 增加/删除文件\n\n```bash\n# 添加指定文件到暂存区\ngit add [file1] [file2] ...\n\n# 添加指定目录到暂存区，包括子目录\ngit add [dir]\n\n# 添加当前目录的所有文件到暂存区\ngit add .\n\n# 添加每个变化前，都会要求确认\n# 对于同一个文件的多处变化，可以实现分次提交\ngit add -p\n\n# 删除工作区文件，并且将这次删除放入暂存区\ngit rm [file1] [file2] ...\n\n# 停止追踪指定文件，但该文件会保留在工作区\ngit rm --cached [file]\n\n# 改名文件，并且将这个改名放入暂存区\ngit mv [file-original] [file-renamed]\n```\n\n### 代码提交\n\n```bash\n# 提交暂存区到仓库区\ngit commit -m [message]\n\n# 提交暂存区的指定文件到仓库区\ngit commit [file1] [file2] ... -m [message]\n\n# 提交工作区自上次commit之后的变化，直接到仓库区\ngit commit -a\n\n# 提交时显示所有diff信息\ngit commit -v\n\n# 使用一次新的commit，替代上一次提交\n# 如果代码没有任何新变化，则用来改写上一次commit的提交信息\ngit commit --amend -m [message]\n\n# 重做上一次commit，并包括指定文件的新变化\ngit commit --amend [file1] [file2] ...\n```\n\n### 分支\n\n```bash\n# 列出所有本地分支\ngit branch\n\n# 列出所有远程分支\ngit branch -r\n\n# 列出所有本地分支和远程分支\ngit branch -a\n\n# 新建一个分支，但依然停留在当前分支\ngit branch [branch-name]\n\n# 新建一个分支，并切换到该分支\ngit checkout -b [branch]\n\n# 新建一个分支，指向指定commit\ngit branch [branch] [commit]\n\n# 新建一个分支，与指定的远程分支建立追踪关系\ngit branch --track [branch] [remote-branch]\n\n# 切换到指定分支，并更新工作区\ngit checkout [branch-name]\n\n# 切换到上一个分支\ngit checkout -\n\n# 建立追踪关系，在现有分支与指定的远程分支之间\ngit branch --set-upstream [branch] [remote-branch]\n\n# 合并指定分支到当前分支\ngit merge [branch]\n\n# 选择一个commit，合并进当前分支\ngit cherry-pick [commit]\n\n# 删除分支\ngit branch -d [branch-name]\n\n# 删除远程分支\ngit push origin --delete [branch-name]\ngit branch -dr [remote/branch]\n```\n\n### 标签\n\n```bash\n# 列出所有tag\ngit tag\n\n# 新建一个tag在当前commit\ngit tag [tag]\n\n# 新建一个tag在指定commit\ngit tag [tag] [commit]\n\n# 删除本地tag\ngit tag -d [tag]\n\n# 删除远程tag\ngit push origin :refs/tags/[tagName]\n\n# 查看tag信息\ngit show [tag]\n\n# 提交指定tag\ngit push [remote] [tag]\n\n# 提交所有tag\ngit push [remote] --tags\n\n# 新建一个分支，指向某个tag\ngit checkout -b [branch] [tag]\n```\n\n### 查看信息\n\n```bash\n# 显示有变更的文件\ngit status\n\n# 显示当前分支的版本历史\ngit log\n\n# 显示commit历史，以及每次commit发生变更的文件\ngit log --stat\n\n# 搜索提交历史，根据关键词\ngit log -S [keyword]\n\n# 显示某个commit之后的所有变动，每个commit占据一行\ngit log [tag] HEAD --pretty=format:%s\n\n# 显示某个commit之后的所有变动，其\"提交说明\"必须符合搜索条件\ngit log [tag] HEAD --grep feature\n\n# 显示某个文件的版本历史，包括文件改名\ngit log --follow [file]\ngit whatchanged [file]\n\n# 显示指定文件相关的每一次diff\ngit log -p [file]\n\n# 显示过去5次提交\ngit log -5 --pretty --oneline\n\n# 显示所有提交过的用户，按提交次数排序\ngit shortlog -sn\n\n# 显示指定文件是什么人在什么时间修改过\ngit blame [file]\n\n# 显示暂存区和工作区的差异\ngit diff\n\n# 显示暂存区和上一个commit的差异\ngit diff --cached [file]\n\n# 显示工作区与当前分支最新commit之间的差异\ngit diff HEAD\n\n# 显示两次提交之间的差异\ngit diff [first-branch]...[second-branch]\n\n# 显示今天你写了多少行代码\ngit diff --shortstat \"@{0 day ago}\"\n\n# 显示某次提交的元数据和内容变化\ngit show [commit]\n\n# 显示某次提交发生变化的文件\ngit show --name-only [commit]\n\n# 显示某次提交时，某个文件的内容\ngit show [commit]:[filename]\n\n# 显示当前分支的最近几次提交\ngit reflog\n```\n\n### 远程同步\n\n```bash\n# 下载远程仓库的所有变动\ngit fetch [remote]\n\n# 显示所有远程仓库\ngit remote -v\n\n# 显示某个远程仓库的信息\ngit remote show [remote]\n\n# 增加一个新的远程仓库，并命名\ngit remote add [shortname] [url]\n\n# 取回远程仓库的变化，并与本地分支合并\ngit pull [remote] [branch]\n\n# 上传本地指定分支到远程仓库\ngit push [remote] [branch]\n\n# 强行推送当前分支到远程仓库，即使有冲突\ngit push [remote] --force\n\n# 推送所有分支到远程仓库\ngit push [remote] --all\n```\n\n### 撤销\n\n```bash\n# 恢复暂存区的指定文件到工作区\ngit checkout [file]\n\n# 恢复某个commit的指定文件到暂存区和工作区\ngit checkout [commit] [file]\n\n# 恢复暂存区的所有文件到工作区\ngit checkout .\n\n# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变\ngit reset [file]\n\n# 重置暂存区与工作区，与上一次commit保持一致\ngit reset --hard\n\n# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变\ngit reset [commit]\n\n# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致\ngit reset --hard [commit]\n\n# 重置当前HEAD为指定commit，但保持暂存区和工作区不变\ngit reset --keep [commit]\n\n# 新建一个commit，用来撤销指定commit\n# 后者的所有变化都将被前者抵消，并且应用到当前分支\ngit revert [commit]\n\n# 暂时将未提交的变化移除，稍后再移入\ngit stash\ngit stash pop\n```\n\n### 其他\n\n\n```bash\n# 生成一个可供发布的压缩包\ngit archive\n# 创建密钥对\nssh-keygen -t rsa -C \"example@qq.com\"\n# 将公钥发送到远程机器（绵）\nssh-copy-id -i  id_rsa.pub 远程服务器IP\n# 创建文件并设置权限\ntouch authorized_keys\nchmod 600 authorized_keys\n# authorized_keys 文件必须是600权限(也就是-rw——-)或者644\n# .ssh目录必须是700权限(也就是drwx——)\n# /home/git目录 必须是 755权限 即drwxr-xr-x\n# 信任客户端公钥\ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n\n# git删除无用文件\ngit rm -r --cached */target/\n\n#修改.gitignore不生效，\ngit rm -r --cached .\ngit add .\n\n需要特别注意的是：\n1）.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。\n2）想要.gitignore起作用，必须要在这些文件不在暂存区中才可以，.gitignore文件只是忽略没有被staged(cached)文件，\n对于已经被staged文件，加入ignore文件时一定要先从staged移除，才可以忽略。\n\n#取消跟踪配置文件改动\ngit update-index --assume-unchanged \".env.development\" //git关闭跟踪文件修改提交\ngit update-index --no-assume-unchanged \".env.development\"//git打开跟踪文件修改提交\n\n#清除git缓存的用户密码\ngit config --system --unset credential.helper\n\n#修改最近一次提交的作者&邮箱信息\n# 替换用户名、邮箱信息\ngit commit --amend --author=\"{username} <{email}>\" --no-edit\n\n# 如果已经修改了仓库的用户信息，直接执行命令重置\ngit commit --amend --reset-author --no-edit\n\n#批量修改git提交历史作者&邮箱信息-方法一\ngit filter-branch --env-filter '\n\nOLD_EMAIL=\"kyire666@outlook.com\"\nCORRECT_NAME=\"骆俊杰\"\nCORRECT_EMAIL=\"luo_jj@vanxsoft.net\"\n\nif [ \"$GIT_COMMITTER_EMAIL\" = \"$OLD_EMAIL\" ]\nthen\n    export GIT_COMMITTER_NAME=\"$CORRECT_NAME\"\n    export GIT_COMMITTER_EMAIL=\"$CORRECT_EMAIL\"\nfi\nif [ \"$GIT_AUTHOR_EMAIL\" = \"$OLD_EMAIL\" ]\nthen\n    export GIT_AUTHOR_NAME=\"$CORRECT_NAME\"\n    export GIT_AUTHOR_EMAIL=\"$CORRECT_EMAIL\"\nfi\n'\n\ngit filter-branch -f --tree-filter -f 'rm -f featrue/xxx' -- --all\ngit update-ref -d refs/original/refs/heads/featrue/xxx\n\n#批量修改git提交历史作者&邮箱信息-方法二\ngit filter-branch --commit-filter '\n        if [ \"$GIT_AUTHOR_NAME\" = \"JJLUO\" ];\n        then\n                GIT_AUTHOR_NAME=\"骆俊杰\";\n                GIT_AUTHOR_EMAIL=\"luo_jj@vanxsoft.net\";\n                git commit-tree \"$@\";\n        else\n                git commit-tree \"$@\";\n        fi' HEAD\n\n# Git For Windows 下载缓慢\nhttps://registry.npmmirror.com/binary.html?path=git-for-windows\n\n# 设置当前项目的作者&邮箱\ngit config user.name \"骆俊杰\"\ngit config user.email \"luo_jj@vanxsoft.net\"\n\n\n# 设置Git大小写敏感\ngit config core.ignorecase false\n```\n\n## Windows\n\n### 端口占用\n\n```shell\n# 查看被占用端口对应的 PID\nnetstat -aon|findstr \"8081\"\n# 查看指定 PID 的进程\ntasklist|findstr \"9088\"\n# 结束进程\ntaskkill /T /F /PID 9088\n```\n\n### 磁盘脱机\n\n```\n1、首先打开电脑命令提示符，输入diskpart命令，然后点击键盘上面的Enter按键\n2、进到了磁盘管理命令中，继续输入san命令，然后点击键盘上面的Enter按键\n3、进到了磁盘策略管理命令中了，继续输入san policy =onlineall命令，然后点击键盘上面的Enter按键\n4、磁盘策略已经更改，输入list disk来查看磁盘状态，然后点击键盘上面的Enter按键\n5、看到目前电脑磁盘的状态，输入select disk 1命令选择磁盘1，然后点击键盘上面的Enter 按键\n6、输入attributes disk clear readonly命令来改变磁盘1的属性，然后点击键盘上面的Enter按键执行\n7、提示磁盘1的属性已经更改，输入online disk 来使磁盘1联机，然后点击键盘上面的Enter按键执行\n8、可以看到磁盘1已经联机了\n```\n\n### 安装 PSCP 工具，通过命令上传文件到 Linux 服务器\n\n```\n# 1、下载 pscp.exe 工具\nhttp://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\n# 2、拷贝到\nC:\\Windows\\System32\n# 3、打开CMD运行pscp命令\npscp demo.txt root@192.168.88.10:/tmp\n```\n\n> 进阶操作：免密登录 Linux 服务器\n>\n> [Download PuTTY: latest release](https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html)\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/202401231609708.png\" alt=\"image-20240123160917033\" style=\"zoom:50%;\" />\t\n\n```\n# 1、下载 puttygen.exe 工具，并打开\nhttp://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\n# 2、生成密钥对（鼠标不停地在软件区域内晃动，生成随机数，直到进度条结束）\n# 3、点击 'Save private key',保存到指定目录\n# 4、将公钥添加到对应 Linux 服务器的 authorized_keys 文件中\necho \"ssh-rsa xxx rsa-key-20230601\" >> ~/.ssh/authorized_key\n# 5、执行 pscp 时使用 -i 命令指定 ppk 私钥文件进行免密传输\npscp -i demo.ppk demo.txt root@192.168.88.10:/tmp\n```\n\n### Windows Terminal 安装 Zsh + Oh My Zsh\n\n> [Windows 安装 Zsh 终端 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/625583037)\n\n```bash\nsh -c \"$(curl -fsSL --ssl-no-revoke https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\ncd ~/.oh-my-zsh/custom/plugins\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n```\n\n### 使用 CertBot 申请 HTTPS 证书，并自动续签\n\n> [Certbot 使用说明 |Certbot 的 --- Certbot Instructions | Certbot (eff.org)](https://certbot.eff.org/instructions?ws=nginx&os=windows&tab=standard)\n\n1. 安装 certbot-windows 版本\n\n2. 运行以下命令：\n\n   ```cmd\n   certbot certonly -d \"*.example.com\" --manual --preferred-challenges dns-01 --server https://acme-v02.api.letsencrypt.org/directory\n   \n   certbot certonly -d \"*.espdlink.com\" --manual --preferred-challenges dns-01 --server https://acme-v02.api.letsencrypt.org/directory\n   ```\n\n3. 根据提示在 DNS 解析添加 TXT 解析记录\n4. 申请完成\n\n## Nginx\n\n### 常用配置\n\n```nginx\n# Nginx服务的Banner隐藏状态\nserver{\n\tserver_tokens off;\n}\n# 隐藏Nginx后端服务X-Powered-By头\nhttp{\n    proxy_hide_header X-Powered-By;\n    proxy_hide_header Server;\n}\n```\n\n### 反向代理模板\n\n```nginx\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    include mime.types;\n    default_type application/octet-stream;\n    sendfile on;\n    keepalive_timeout 65;\n    underscores_in_headers on; #支持下划线的 header key\n\n    client_max_body_size 50m;\n    client_body_buffer_size 10m;\n    client_header_timeout 1m;\n    client_body_timeout 1m;\n\n    large_client_header_buffers 4 10m;\n\n    gzip on;\n    gzip_min_length 1k;\n    gzip_buffers 4 16k;\n    gzip_comp_level 4;\n    gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;\n    gzip_vary on;\n    add_header X-Frame-Options SAMEORIGIN always;\n    server {\n        listen 80;\n        server_name 192.168.88.234;\n        proxy_set_header Host $host:$server_port; # 转发请求时将请求的域名端口一起转发\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n\n        location / {\n            root /u01/jeecg-vue;\n            index index.html index.htm;\n            try_files $uri $uri/ /index.html?A03A01;\n        }\n\n        location /jeecg-boot {\n            proxy_pass http://192.168.88.230:8080/jeecg-boot;\n            proxy_http_version 1.1;\n            proxy_connect_timeout 3600s;\n            proxy_read_timeout 3600s;\n            proxy_send_timeout 3600s;\n        }\n    }\n}\n```\n\n### SSL 配置模板\n\n```nginx\nserver {\n    listen 443 ssl;\n    server_name www.vansys.cn;\n    ssl_certificate /u01/webserver/nginx/cert/www.vansys.cn_bundle.pem;\n    ssl_certificate_key /u01/webserver/nginx/cert/www.vansys.cn.key;\n    ssl_session_timeout 5m;\n    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    ssl_prefer_server_ciphers on;\n\n    location / {\n        root   html;\n        index  index.html index.htm;\n    }\n\n}\nserver {\n    listen 80;\n    server_name www.vanxsoft.com;\n\n    location / {\n    \trewrite ^(.*)$ https://$host:443$1 permanent;\n    }\n}\n```\n\n## Maven\n\n```shell\n# 添加依赖\nmvn install:install-file -Dfile=D:\\ojdbc8.jar -DgroupId=com.oracle -DartifactId=ojdbc8 -Dversion=1.0 -Dpackaging=jar -DgeneratePom=true\nmvn install:install-file -Dfile=/opt/dm.jdbc.driver-7.0.1.jar -DgroupId=dm -DartifactId=dm.jdbc.driver -Dversion=7.1.0 -Dpackaging=jar -DgeneratePom=true\n\n# 下载依赖\nmvn dependency:get -DremoteRepositories=https://central.sonatype.com/artifact/com.tencentcloudapi/tencentcloud-sdk-java -DgroupId=com.tencentcloudapi -DartifactId=tencentcloud-sdk-java -Dversion=3.1.864\n\nmvn dependency:get -DremoteRepositories=https://oss.sonatype.org/content/repositories/snapshots -DgroupId=net.coobird -DartifactId=thumbnailator -Dversion=0.4.2\n\nmvn dependency:get -DremoteRepositories=https://oss.sonatype.org/content/repositories/snapshots -DgroupId=id.zelory -DartifactId=compressor -Dversion=1.0.4\n\nmvn dependency:get -DremoteRepositories=https://mvnrepository.com/artifact/com.twelvemonkeys.imageio/imageio-jpeg -DgroupId=com.twelvemonkeys.imageio -DartifactId=imageio-jpeg -Dversion=3.10.1\n\nmvn clean install -Dmaven.test.skip=true -Ptest\nmvn clean install -Dmaven.test.skip=true -Pdev\nmvn clean install -Dmaven.test.skip=true -Pprod\n```\n\n## Java\n\n### jar 启动脚本\n\n```\n# JAR 后台启动\nnohup java -jar $project > /dev/null 2>&1 &\n\n# 打 WAR 包（最后一个点号表示要将当前目录中所有内容打包）\njar cvf xxx.war .\n```\n\n## IDEA 快捷键大全\n\n### Ctrl 快捷键\n\n**Ctrl + F 在当前文件进行文本查找 （必备）**\n\n**Ctrl + R 在当前文件进行文本替换 （必备）**\n\n**Ctrl + Z 撤销 （必备）**\n\n**Ctrl + Y 删除光标所在行 或 删除选中的行 （必备）**\n\nCtrl + X 剪切光标所在行 或 剪切选择内容\n\nCtrl + C 复制光标所在行 或 复制选择内容\n\n**Ctrl + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 （必备）**\n\n**Ctrl + W 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围（必备）**\n\n**Ctrl + E 显示最近打开的文件记录列表 （必备）**\n\n**Ctrl + N 根据输入的 名/类名 查找类文件 （必备）**\n\nCtrl + G 在当前文件跳转到指定行处\n\n**Ctrl + J 插入自定义动态代码模板 （必备）**\n\n**Ctrl + P 方法参数提示显示 （必备）**\n\nCtrl + Q 光标所在的变量 / 类名 / 方法名等上面（也可以在提示补充的时候按），显示文档内容\n\n**Ctrl + U 前往当前光标所在的方法的父类的方法 / 接口定义 （必备）**\n\n**Ctrl + B 进入光标所在的方法/变量的接口或是定义处，等效于 Ctrl + 左键单击 （必备）**\n\nCtrl + K 版本控制提交项目，需要此项目有加入到版本控制才可用\n\nCtrl + T 版本控制更新项目，需要此项目有加入到版本控制才可用\n\nCtrl + H 显示当前类的层次结构\n\nCtrl + O 选择可重写的方法\n\nCtrl + I 选择可继承的方法\n\nCtrl + + 展开代码\n\nCtrl + - 折叠代码\n\n**Ctrl + / 释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 （必备）**\n\nCtrl + [ 移动光标到当前所在代码的花括号开始位置\n\nCtrl + \\] 移动光标到当前所在代码的花括号结束位置\n\n**Ctrl + F1 在光标所在的错误代码处显示错误信息 （必备）**\n\n**Ctrl + F3 调转到所选中的词的下一个引用位置 （必备）**\n\nCtrl + F4 关闭当前编辑文件\n\nCtrl + F8 在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点\n\nCtrl + F9 执行 Make Project 操作\n\n**Ctrl + F11 选中文件 / 文件夹，使用助记符设定 / 取消书签 （必备）**\n\nCtrl + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选\n\nCtrl + Tab 编辑窗口切换，如果在切换的过程又加按上 delete，则是关闭对应选中的窗口\n\nCtrl + End 跳到文件尾\n\nCtrl + Home 跳到文件头\n\nCtrl + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议 修改为 Ctrl +逗号 （必备）\n\n**Ctrl + Delete 删除光标后面的单词或是中文句 （必备）**\n\n**Ctrl +BackSpace 删除光标前面的单词或是中文句 （必备）**\n\n**Ctrl +1,2,3...9 定位到对应数值的书签位置 （必备）**\n\n**Ctrl + 左键单击 在打开的文件标题上，弹出该文件路径 （必备）**\n\n**Ctrl + 光标定位按 Ctrl 不要松开，会显示光标所在的类信息摘要**\n\n**Ctrl + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 （必备）**\n\n**Ctrl + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 （必备）**\n\n**Ctrl + 前方向键 等效于鼠标滚轮向前效果 （必备）**\n\n**Ctrl + 后方向键 等效于鼠标滚轮向后效果 （必备）**\n\n### Alt 快捷键\n\nAlt + Q 弹出一个提示，显示当前类的声明 / 上下文信息\n\n**Alt + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 （必备）**\n\nAlt + F2 对于前面页面，显示各类浏览器打开目标选择弹出层\n\nAlt + F3 选中文本，逐个往下查找相同文本，并高亮显示\n\nAlt + F7 查找光标所在的方法 / 变量 / 类被调用的地方\n\nAlt + F8 在 Debug 的状态下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果\n\nAlt + Home 定位 / 显示到当前文件的 Navigation Bar\n\n**Alt + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示 的结果也不同 （必备）**\n\n**Alt + Insert 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 （必备）**\n\n**Alt + 左方向键 切换当前已打开的窗口中的子视图，比如 Debug 窗口中有 Output、Debugger 等子视图，用此快捷键就可以在子视图中切换 （必备）**\n\n**Alt + 右方向键 按切换当前已打开的窗口中的子视图，比如 Debug 窗口中有 Output、Debugger 等子视图，用此快捷键就可以在子视图中切换 （必备）**\n\n**Alt + 前方向键 当前光标跳转到当前文件的前一个方法名位置 （必备）**\n\n**Alt + 后方向键 当前光标跳转到当前文件的后一个方法名位置 （必备）**\n\n**Alt +1,2,3...9 显示对应数值的选项卡，其中 1 是 Project 用得最多 （必备）**\n\n### Shift 快捷键\n\nShift + F1 如果有外部文档可以连接外部文档\n\nShift + F2 跳转到上一个高亮错误 或 警告位置\n\nShift + F3 在查找模式下，查找匹配上一个\n\nShift + F4 对当前打开的文件，使用新 Windows 窗口打开，旧窗口保留\n\nShift + F6 对文件 / 文件夹 重命名\n\nShift + F7 在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法\n\nShift + F8 在 Debug 模式下，跳出，表现出来的效果跟 F9 一样\n\nShift + F9 等效于点击工具栏的 Debug 按钮\n\nShift + F10 等效于点击工具栏的 Run 按钮\n\n**Shift + F11 弹出书签显示层 （必备）**\n\n**Shift + Tab 取消缩进 （必备）**\n\nShift + ESC 隐藏当前 或 最后一个激活的工具窗口\n\nShift + End 选中光标到当前行尾位置\n\nShift + Home 选中光标到当前行头位置\n\n**Shift + Enter 开始新一行。光标所在行下空出一行，光标定位到新行位置 （必备）**\n\n**Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 （必备）**\n\n**Shift + 滚轮前后滚动 当前文件的横向滚动轴滚动 （必备）**\n\n### Ctrl + Alt 快捷键\n\n**Ctrl + Alt + L 格式化代码，可以对当前文件和整个包目录使用 （必备）**\n\n**Ctrl + Alt + O 优化导入的类，可以对当前文件和整个包目录使用 （必备）**\n\nCtrl + Alt + I 光标所在行 或 选中部分进行自动代码缩进，有点类似格式化\n\n**Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 （必备）**\n\nCtrl + Alt + J 弹出模板选择窗口，将选定的代码加入动态模板中\n\nCtrl + Alt + H 调用层次\n\nCtrl + Alt + B 在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口\n\nCtrl + Alt + V 快速引进变量\n\nCtrl + Alt + Y 同步、刷新\n\n**Ctrl + Alt + S 打开 IntelliJ IDEA 系统设置 （必备）**\n\nCtrl + Alt + F7 显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来\n\nCtrl + Alt + F11 切换全屏模式\n\n**Ctrl + Alt + Enter 光标所在行上空出一行，光标定位到新行 （必备）**\n\nCtrl + Alt + Home 弹出跟当前文件有关联的文件弹出层\n\nCtrl + Alt + Space 类名自动完成\n\n**Ctrl + Alt + 左方向键 退回到上一个操作的地方 （必备）**\n\n**Ctrl + Alt + 右方向键 前进到上一个操作的地方 （必备）**\n\nCtrl + Alt + 前方向键 在查找模式下，跳到上个查找的文件\n\nCtrl + Alt + 后方向键 在查找模式下，跳到下个查找的文件\n\n### Ctrl + Shift 快捷键\n\n**Ctrl + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 （必备）**\n\n**Ctrl + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 （必备）**\n\n**Ctrl + Shift + J 自动将下一行合并到当前行末尾 （必备）**\n\n**Ctrl + Shift + Z 取消撤销 （必备）**\n\n**Ctrl + Shift + W 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 （必备）**\n\n**Ctrl + Shift + N 通过文件名定位 / 打开文件 / 目录，打开目录需要在 输入的内容后面多加一个正斜杠 （必备）**\n\n**Ctrl + Shift + U 对选中的代码进行大 / 小写轮流转换 （必备）**\n\n**Ctrl + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 （必备）**\n\n**Ctrl + Shift + C 复制当前文件磁盘路径到剪贴板 （必备）**\n\nCtrl + Shift + V 弹出缓存的最近拷贝的内容管理器弹出层\n\nCtrl + Shift + E 显示最近修改的文件列表的弹出层\n\nCtrl + Shift + H 显示方法层次结构\n\n**Ctrl + Shift + B 跳转到类型声明处 （必备）**\n\nCtrl + Shift + I 快速查看光标所在的方法 或 类的定义\n\nCtrl + Shift + A 查找动作 / 设置\n\n**Ctrl + Shift + / 代码块注释 （必备）**\n\n**Ctrl + Shift + [ 选中从光标所在位置到它的顶部中括号位置 （必备）**\n\n**Ctrl + Shift + ] 选中从光标所在位置到它的底部中括号位置 （必备）**\n\n**Ctrl + Shift + + 展开所有代码 （必备）**\n\n**Ctrl + Shift + - 折叠所有代码 （必备）**\n\n**Ctrl + Shift + F7 高亮显示所有该选中文本，按 Esc 高亮消失 （必备）**\n\nCtrl + Shift + F8 在 Debug 模式下，指定断点进入条件\n\nCtrl + Shift + F9 编译选中的文件 / 包 / Module\n\nCtrl + Shift + F12 编辑器最大化 （必备）\n\nCtrl + Shift + Space 智能代码提示\n\n**Ctrl + Shift + Enter 自动结束代码，行末自动添加分号 （必备）**\n\n**Ctrl + Shift +Backspace 退回到上次修改的地方 （必备）**\n\n**Ctrl + Shift +1,2,3...9 快速添加指定数值的书签 （必备）**\n\n**Ctrl + Shift + 左键单击 把光标放在某个类变量上，按此快捷键可以直接定位到该类中 （必备）**\n\n**Ctrl + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置， 同时选中该单词 / 中文句（必备）**\n\n**Ctrl + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置， 同时选中该单词 / 中文句（必备）**\n\n**Ctrl + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 （必备）**\n\n**Ctrl + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 （必备）**\n\n### Alt + Shift 快捷键\n\n**Alt + Shift + N 选择 / 添加 task （必备）**\n\nAlt + Shift + F 显示添加到收藏夹弹出层 / 添加到收藏夹\n\nAlt + Shift + C 查看最近操作项目的变化情况列表\n\nAlt + Shift + I 查看项目当前文件\n\nAlt + Shift + F7 在 Debug 模式下，下一步，进入当前方法体内，如果方法体还有方法，则会进入该内嵌的方法中，依此循环进入\n\nAlt + Shift + F9 弹出 Debug 的可选择菜单\n\nAlt + Shift + F10 弹出 Run 的可选择菜单\n\n**Alt + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 （必备）**\n\n**Alt + Shift + 前方向键 移动光标所在行向上移动 （必备）**\n\n**Alt + Shift + 后方向键 移动光标所在行向下移动 （必备）**\n\n### Ctrl + Shift + Alt 快捷键\n\n**Ctrl + Shift + Alt + V 无格式黏贴 （必备）**\n\nCtrl + Shift + Alt + N 前往指定的变量 / 方法\n\n**Ctrl + Shift + Alt + S 打开当前项目设置 （必备）**\n\nCtrl + Shift + Alt + C 复制参考信息\n\n### 其他快捷键\n\n**F2 跳转到下一个高亮错误 或 警告位置 （必备）**\n\nF3 在查找模式下，定位到下一个匹配处\n\n**F4 编辑源 （必备）**\n\nF7 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中\n\nF8 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内\n\nF9 在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上\n\n**F11 添加书签 （必备）**\n\n**F12 回到前一个工具窗口 （必备）**\n\nTab 缩进 （必备）\n\nESC 从工具窗口进入代码文件窗口 （必备） 连按两次 Shift 弹出 Search Everywhere 弹出层\n\n## 问题记录\n\n### Random 产生随机数出现堵塞问题\n\n[Java 8 SecureRandom 生成随机数 - 尚码园 (shangmayuan.com)](https://www.shangmayuan.com/a/4506dbbd0e9b4fa9ab6c8f07.html)\n\n### jenkins BlueOcean 修复 Pipeline 不支持中文的问题\n\n**问题**\n\n在 Jenkins 的 BlueOcean 中，修改 Pipeline，结果发现，如果编写过程中，凡是 jenkinsFile 有中文信息的，点击 save and run 之后 Console 中出现错误，无法保存。\n\n**分析**\n\n根据错误信息，定位到问题来源 jenkins-js-extension.js，该问题和 js 的 btoa 和 atob 不支持 unicode 有关。\n\n**解决**\n\n1. 将 jenkins 的 `jenkins_home/plugins/blueocean-pipeline-editor/WEB-INF/lib/blueocean-pipeline-editor.jar` 下载到本地，\n2. 解压出 jenkins-js-extension.js，搜索 btoa，有两处一样的代码，搜索 atob 也是一样的，成对出现。\n3. 修改代码，将两处 encode 和 decode 修改为以下结果：\n4. 将修改之后的 jenkins-js-extension.js 拖入 blueocean-pipeline-editor.jar。\n5. 将修改之后的 blueocean-pipeline-editor.jar 上传到 Jenkins 的原处：`jenkins_home/plugins/blueocean-pipeline-editor/WEB-INF/lib/blueocean-pipeline-editor.jar`\n\n```\nvar Base64 = {\n    encode: function encode(data) {\n        return btoa(unescape(encodeURIComponent(data)));\n    },\n    decode: function decode(str) {\n        return decodeURIComponent(escape(atob(str)));\n    }\n};\n```\n\n### Linux 上 MySQL 区分大小写的坑\n\n简介： lower_case_table_names 是 mysql 设置大小写是否敏感的一个参数。\n\n```\n1.参数说明：\nlower_case_table_names=0 表名存储为给定的大小和比较是区分大小写的\nlower_case_table_names = 1 表名存储在磁盘是小写的，但是比较的时候是不区分大小写\nlower_case_table_names=2 表名存储为给定的大小写但是比较的时候是小写的\nunix,linux下lower_case_table_names默认值为 0 .Windows下默认值是 1 .Mac OS X下默认值是 2\n\n2.查看方法：\n# 进入mysql命令行 执行以下任一语句查看：\nshow variables like 'lower_case_table_names';\nselect @@lower_case_table_names;\n\n3.更改方法：\n更改数据库参数文件my.cnf\n在mysqld下 添加或修改 lower_case_table_names = 1\n之后重启数据库\n\n4.现实情况修改 注意事项：\n因目前MySQL安装在Linux系统上较多 初始化时采取了默认的 lower_case_table_names 值 即区分大小写，后续可能会造成同一实例大小写库表都存在的情况，调用时还要注意大小写。\n这时 更改步骤如下：\n修改表名为全大写或小写\nsql命令：alter table 原表名 rename to 新表名;\n\nSELECT\n concat(\"alter table \", TABLE_NAME , ' rename to ' , upper(TABLE_NAME) ,' ;' )\nFROM information_schema.TABLES t\nWHERE  TABLE_SCHEMA = '数据库名';\n\n注意：如果是大写改小写将 upper 改为 lower 即可；将查询结果复制出来到查询分析器进行批量执行即可完成表名的批量转换。\n```\n\n### Linux 机器无法解析域名\n\n```bash\n# 1、编辑网卡配置文件\nvim /etc/sysconfig/network-scripts/ifcfg-ens192\n# 2、添加 dns 配置\nDNS1=114.114.114.114\nDNS2=202.96.209.133\n# 3、重启网卡配置\nnmcli c reload\n# 4、若无效重启机器\nreboot\n```\n\n### CentOS7 机器 OpenJDK 导致验证码无法显示的问题\n\n```bash\n# 1、安装 fontconfig\nyum -y install fontconfig\nfc-cache -fv\nfc-list\n# 2、安装 libjpeg-turbo.x86_64\nyum install -y libjpeg-turbo.x86_64\n```\n\n### Linux 机器上 Tomcat 控制台日志输出中文乱码\n\n修改 `tomcat/conf/logging.properties`，统一里面的所有 Handler 的文件编码，一般为 `UTF-8`\n\n### Nginx 配置 87 端口，谷歌浏览器报错 ERR_UNSAFE_PORT\n\n```\nGoogle Chrome 默认非安全端口列表\n \n  1,    // tcpmux\n  7,    // echo\n  9,    // discard\n  11,   // systat\n  13,   // daytime\n  15,   // netstat\n  17,   // qotd\n  19,   // chargen\n  20,   // ftp data\n  21,   // ftp access\n  22,   // ssh\n  23,   // telnet\n  25,   // smtp\n  37,   // time\n  42,   // name\n  43,   // nicname\n  53,   // domain\n  77,   // priv-rjs\n  79,   // finger\n  87,   // ttylink\n  95,   // supdup\n  101,  // hostriame\n  102,  // iso-tsap\n  103,  // gppitnp\n  104,  // acr-nema\n  109,  // pop2\n  110,  // pop3\n  111,  // sunrpc\n  113,  // auth\n  115,  // sftp\n  117,  // uucp-path\n  119,  // nntp\n  123,  // NTP\n  135,  // loc-srv /epmap\n  139,  // netbios\n  143,  // imap2\n  179,  // BGP\n  389,  // ldap\n  465,  // smtp+ssl\n  512,  // print / exec\n  513,  // login\n  514,  // shell\n  515,  // printer\n  526,  // tempo\n  530,  // courier\n  531,  // chat\n  532,  // netnews\n  540,  // uucp\n  556,  // remotefs\n  563,  // nntp+ssl\n  587,  // stmp?\n  601,  // ??\n  636,  // ldap+ssl\n  993,  // ldap+ssl\n  995,  // pop3+ssl\n  2049, // nfs\n  3659, // apple-sasl / PasswordServer\n  4045, // lockd\n  6000, // X11\n  6665, // Alternate IRC [Apple addition]\n  6666, // Alternate IRC [Apple addition]\n  6667, // Standard IRC [Apple addition]\n  6668, // Alternate IRC [Apple addition]\n  6669, // Alternate IRC [Apple addition]\n```\n\n### No buffer space available 异常问题解决\n\n> [TCP/IP 端口耗尽故障排除 - Windows Client | Microsoft Learn](https://learn.microsoft.com/zh-cn/troubleshoot/windows-client/networking/tcp-ip-port-exhaustion-troubleshooting)\n\n1、**问题原因：** 服务器端口不够导致的，可以通过以下命令来查询 Windows 端口的启用情况\n\n`netsh int ipv4 show dynamicportrange tcp`\n\n```\n❯ netsh int ipv4 show dynamicportrange tcp\n\n协议 tcp 动态端口范围\n---------------------------------\n启动端口        : 1024\n端口数          : 13977\n```\n\n2、**解决方法：** 使用管理员身份运行命令行窗口，执行命令\n\n`netsh int ipv4 set dynamicport tcp start=2000 num=63000`\n\n> 修改端口数，其中 start 为起始端口号，num 为的端口数量\n\n```\n❯ netsh int ipv4 set dynamicport tcp start=2000 num=63000\n确定。\n\n❯ netsh int ipv4 show dynamicportrange tcp\n\n协议 tcp 动态端口范围\n---------------------------------\n启动端口        : 2000\n端口数          : 63000\n```\n\n3、**总结：** 端口的最大数量为 65536，可以使用任务管理器中的详细信息 -> 查看句柄数来查找端口占用较多的程序\n\n## DevOps 心得\n\n- ansible 部署工具使用\n- jenkisnfile 脚本实现 pipeline 流水线\n- 参数化构建神器（Active Choices）\n- jenkins 凭据使用\n- docker stack deploy 需要提前创建挂载文件夹和拉取镜像\n- 添加节点到 docker swarm 集群中\n  - docker swarm join-token {worker/manager}\n  - 复制 docker swarm join 命令到目标机器上执行（如果是 manage 节点需要开放 2377 端口）\n  - 配置 nexus docker 镜像私服\n\n### 微软账号登录一直转圈问题\n\n1. 打开控制面板，右上角查看方式选择小图标\n2. 点击网络和共享中心功能\n3. 点击左侧更改适配器设置\n4. 右键点击正在使用的网络，选择属性\n5. 选中新页面中的 Internet 协议 4（TCP/IPv4）\n6. 点击属性按钮，在新页面中将首选 Dns 改为 `4.2.2.1`，备用 Dns 改为 `4.2.2.2`\n\n## Jenkins\n\n### 简单脚本发布配置\n\n1. 配置 Jenkins 服务器免密访问应用服务器\n\n```\n# 创建 ssh 密钥对\ncd ~/.ssh && ssh-keygen -t rsa\n# 发送密钥到目标主机\nssh-copy-id -i ~/.ssh/id_rsa.pub -p SSH端口 IP\n```\n\n2. 配置 **Publish over SSH** 插件\n   1. 填写 `Jenkins SSH Key` 配置\n   2. 添加 `SSH Servers`\n","tags":["技巧","笔记","私有"],"categories":["随笔小记"]},{"title":"实战 - 分析 Java 项目线上内存泄漏、频繁GC、CPU飙升的原因","slug":"实战-分析Java项目线上内存泄漏、频繁GC、CPU飙升的原因","url":"/2022/11/02/5c089f9f.html","content":"\n## 问题背景\n\n我们的 Java 服务都是封装在 Docker 容器里运行的，今天早上到公司发现有个服务内存跑满，`CPU 100%~500%` 之间跳动，第一时间想到的是 dump 快照到本地进行分析。\n\n> 这是本人首次在容器内分析线上问题，遇到几个坑，特此记录下来！\n\n## 分析过程\n\n通过容器监控工具发现 A 容器内存和 CPU 占用都不正常：\n\n> [Portainer | Docker 图形化管理工具](https://www.portainer.io/)\n\n![image-20221102113101648](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105726.png)\n\n### 安装 Arthas\n\n本来选择使用 jvm 自带的分析工具进行内存分析，但是我们所有的 Java 服务镜像都是基于 `anapsix/alpine-java:8_server-jre_unlimited` 构建的，此镜像默认是没有 jvm 分析工具，故选择阿里的 Arthas 线上监控诊断产品进行分析：\n\n```bash\n# 下载 arthas-boot 启动包\ncurl -O https://arthas.aliyun.com/arthas-boot.jar\n# 直接启动（使用和目标进程一致的用户启动，否则可能 attach 失败）\njava -jar arthas-boot.jar\n```\n\n![image-20221102155819797](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105737.png)\n\n#### 坑 1：提示无法找到可用的 Java 进程\n\n主要是因为基础镜像是 jre，arthas 无法 attach 目标进程，只需要安装一个 openjdk8 即可解决问题：\n\n```bash\n# 安装 openjdk\napk add openjdk8\n# 再次尝试 attach 目标进程（注意：要进入到 openjdk8 的安装 bin 目录中，默认是 /usr/lib/jvm/java-8-openjdk 下）\n/usr/lib/jvm/java-8-openjdk/bin/java -jar arthas-boot.jar\n```\n\n![image-20221102160738482](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105741.png)\n\n#### 坑 2：提示无法获取 LinuxThreads 管理器线程\n\narthas 无法获取 PID 1 的线程，原因及解决方案如下：\n\n> **为什么 Docker 中运行的 Java 进程 PID 为 1？**\n>\n> 在 Linux 上有了容器的概念之后，一旦容器建立了自己的 Pid Namespace（进程命名空间），这个 Namespace 里的进程号也是从 1 开始标记的。所以，容器的 init 进程也被称为 1 号进程。你只需要记住：1 号进程是第一个用户态的进程，由它直接或者间接创建了 Namespace 中的其他进程。\n>\n> 每个 Docker 容器都是一个 PID 命名空间，这意味着容器中的进程与主机上的其他进程是隔离的。PID 命名空间是一棵树，从 PID 1 开始，通常称为 init。\n>\n> **注意：当你运行一个 Docker 容器时，镜像的 ENTRYPOINT 就是你的根进程，即 PID 1（如果你没有 ENTRYPOINT，那么 CMD 就会作为根进程）。**\n\n可以看到，启动 arthas 之后，提示没有找到可用的 java 进程 PID，这是因为容器内只有 Java 一个进程，通过 ps 查看 PID 为 1，而 PID 1 是特殊的进程号，不会处理任何信号。所以我们要让 Java 进程的 PID 不为 1。可以使用 `tini` 占用 PID 1，我们在容器中启动 init 系统有很多种，这里推荐使用 `tini`，它是专用于容器的轻量级 init 系统，用起来也很简单，只需要在原来的 Dockerfile 中添加一段 `ENTRYPOINT`，用于启动 `tini` 进程即可：\n\n```bash\nFROM anapsix/alpine-java:8_server-jre_unlimited\n...\nRUN apk add --no-cache tini\nENTRYPOINT [\"/sbin/tini\", \"--\"]\n...\n```\n\n添加之后重新启动容器，可以发现 PID 1 已经是 tini 进程了，而 Java 进程变成了 PID 7！\n\n![image-20221102153345994](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105746.png)\n\n再重复之前的操作，使用 arthas 进行 attach 目标进程，成功进入到 arthas 的命令行：\n\n![image-20221102161204036](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105750.png)\n\n## 使用 Arthas 诊断问题\n\n### 诊断内存问题\n\n使用 arthas 的 `dashboard` 命令查看当前系统的实时数据（默认 5s 刷新一次，可以通过 -n 参数设置）\n\n![image-20221102163552087](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105802.png)\n\n> 此处截图只是正常情况下的，今天出现问题时**老年代内存占比**达到 **百分之 90** 以上，**Full GC** 次数也多得恐怖，说明有大量的 GC 线程在运行，这么多次 GC 的情况下，那些垃圾还没被清理掉，说明系统已经出现了内存泄漏，接下来的工作就是找到那些还未被清理的垃圾究竟是什么对象，然后解决掉！\n\n要分析堆内存中有那些对象，需要使用到 arthas 的一个工具（`heapdump`），这个工具的作用类似于 jdk 的 jmap，都是转储堆内存快照，命令如下：\n\n```bash\n# dump 堆内存到指定文件中，--live 表示只 dump live 对象\n[arthas@6]$ heapdump --live /opt/dump.hprof\n# 通过 docker cp 命令将容器内的 hprof 文件复制到宿主机，再从服务器上传输到本地机器上\ndocker cp 容器ID:/opt/dump.hprof ./\n```\n\n![image-20221102164606224](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105807.png)\n\n导出的 dump.hprof 是 Java 的内存快照文件（Heap Profile）,咱们可以借助一些工具分析内存快照，比如：`JProfiler`、JDK 自带的 `jhat` 和 `jvisualVM`。我这里选择使用 `JProfiler`。\n\n![image-20221102165919594](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103133248.png)\n\n由此结果可以看到，`Date` 对象一直无法回收，个数达到了 `2亿` 多，代码里可能出现了死循环，不停地创建 `Date` 对象，只增不减，导致内存泄漏！\n\n### 诊断 CPU 问题\n\n通过分析内存快照，猜测可能是死循环导致的内存泄漏，死循环导致 CPU 居高不下，通过 Arthas 分析占用 CPU 高的线程，定位到具体代码片段，结合上面内存分析结果针对性地解决问题。\n\n通过 arthas 的 `thread` 命令，查看当前系统的线程（默认查看第一页，按 CPU 增量时间降序排序）\n\n> [thread | arthas (阿尔萨斯-线上监控诊断)](https://arthas.aliyun.com/doc/thread.html)\n\n```bash\n# 查看当前系统的线程信息\n[arthas@6]$ thread\n```\n\n> 此处截图是正常情况下的线程信息\n\n![image-20221103104908660](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105811.png)\n\n找出 CPU 占用前列的线程 ID，通过 `thread id` 命令, 显示指定线程的运行堆栈，排查堆栈上方法的代码，解决问题！\n\n```bash\n[arthas@6]$ thread 64\n```\n\n![image-20221103105238315](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103105814.png)\n\n## 结论\n\n本文记录了真实工作中的一次线上问题诊断过程，代码中因 while 循坏条件设置不合理导致死循环，不停地创建 `Date` 对象，导致内存泄漏和 CPU 飙升...\n\n借助 Arthas 这款线上问题诊断神器，能够快速地定位到问题，在容器中可能会踩几个坑，好在最终还是解决了问题！\n","tags":["笔记","实战"],"categories":["后端开发"]},{"title":"Java 常见面试题","slug":"Java常见面试题","url":"/2022/10/31/e5210e5c.html","content":"\n> 面试题节选自：[Java 面试指南 | JavaGuide](https://javaguide.cn/)、[Road 2 Coding | 编程自学之路](https://r2coding.com/#/)\n>\n> 每天一记，始终如一...\n\n## 基础概念与常识\n\n### Java 语言有哪些特点?\n\n1. 简单易学；\n2. 面向对象（封装，继承，多态）；\n3. 平台无关性（Java 虚拟机实现平台无关性）；\n4. 支持多线程\n5. 可靠性；\n6. 安全性；\n7. 支持网络编程并且很方便（ Java 语言诞生本身就是为简化网络编程设计的，因此 Java 语言不仅支持网络编程而且很方便）；\n8. 编译与解释并存；\n\n> `一次编写，随处运行` 是 Java 经典的跨平台口号。\n>\n> 但是目前市面上虚拟化技术已经非常成熟，通过 Docker 容器化技术就很容易实现跨平台。\n>\n> Java 最大的优势应该是强大的生态！\n\n### JVM vs JDK vs JRE\n\n#### JVM\n\nJava 虚拟机（JVM）是运行 Java 字节码的虚拟机。JVM 有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。字节码和不同系统的 JVM 实现是 Java 语言“一次编译，随处可以运行”的关键所在。\n\n**JVM 并不是只有一种！只要满足 JVM 规范，每个公司、组织或者个人都可以开发自己的专属 JVM。** 也就是说我们平时接触到的 HotSpot VM 仅仅是是 JVM 规范的一种实现而已。\n\n除了我们平时最常用的 HotSpot VM 外，还有 J9 VM、Zing VM、JRockit VM 等 JVM 。维基百科上就有常见 JVM 的对比：[Comparison of Java virtual machinesopen in new window](https://en.wikipedia.org/wiki/Comparison_of_Java_virtual_machines) ，感兴趣的可以去看看。并且，你可以在 [Java SE Specificationsopen in new window](https://docs.oracle.com/javase/specs/index.html) 上找到各个版本的 JDK 对应的 JVM 规范。\n\n#### JDK 和 JRE\n\nJDK 是 Java Development Kit 缩写，它是功能齐全的 Java SDK。它拥有 JRE 所拥有的一切，还有编译器（javac）和工具（如 javadoc 和 jdb）。它能够创建和编译程序。\n\nJRE 是 Java 运行时环境。它是运行已编译 Java 程序所需的所有内容的集合，包括 Java 虚拟机（JVM），Java 类库，java 命令和其他的一些基础构件。但是，它不能用于创建新程序。\n\n如果你只是为了运行一下 Java 程序的话，那么你只需要安装 JRE 就可以了。如果你需要进行一些 Java 编程方面的工作，那么你就需要安装 JDK 了。但是，这不是绝对的。有时，即使您不打算在计算机上进行任何 Java 开发，仍然需要安装 JDK。例如，如果要使用 JSP 部署 Web 应用程序，那么从技术上讲，您只是在应用程序服务器中运行 Java 程序。那你为什么需要 JDK 呢？因为应用程序服务器会将 JSP 转换为 Java servlet，并且需要使用 JDK 来编译 servlet。\n\n### 什么是字节码？采用字节码的好处是什么？\n\n在 Java 中，JVM 可以理解的代码就叫做字节码（即扩展名为 `.class` 的文件），它不面向任何特定的处理器，只面向虚拟机。Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以， Java 程序运行时相对来说还是高效的（不过，和 C++，Rust，Go 等语言还是有一定差距的），而且，由于字节码并不针对一种特定的机器，因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行。\n\n**Java 程序从源代码到运行的过程如下所示：**\n\n`.java -> javac 编译 -> .class -> 解释器&JIT -> 机器可理解的代码 -> 机器运行`\n\n我们需要格外注意的是 `.class->机器码` 这一步。在这一步 JVM 类加载器首先加载字节码文件，然后通过解释器逐行解释执行，这种方式的执行速度会相对比较慢。而且，有些方法和代码块是经常需要被调用的(也就是所谓的热点代码)，所以后面引进了 JIT（just-in-time compilation） 编译器，而 JIT 属于运行时编译。当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。这也解释了我们为什么经常会说 **Java 是编译与解释共存的语言** 。\n\n> HotSpot 采用了惰性评估(Lazy Evaluation)的做法，根据二八定律，消耗大部分系统资源的只有那一小部分的代码（热点代码），而这也就是 JIT 所需要编译的部分。JVM 会根据代码每次被执行的情况收集信息并相应地做出一些优化，因此执行的次数越多，它的速度就越快。JDK 9 引入了一种新的编译模式 AOT(Ahead of Time Compilation)，它是直接将字节码编译成机器码，这样就避免了 JIT 预热等各方面的开销。JDK 支持分层编译和 AOT 协作使用。\n\n### AIT 和 AOT 的区别？为什么不全部使用 AOT 呢？\n\n- **JIT（Just-in-Time，即时编译）**\n\n- **AOT（Ahead-of-Time，预编译）**\n\nAOT 可以提前编译节省启动时间，那为什么不全部使用这种编译方式呢？\n\n长话短说，这和 Java 语言的动态特性有千丝万缕的联系了。举个例子，CGLIB 动态代理使用的是 ASM 技术，而这种技术大致原理是运行时直接在内存中生成并加载修改后的字节码文件也就是 `.class` 文件，如果全部使用 AOT 提前编译，也就不能使用 ASM 技术了。为了支持类似的动态特性，所以选择使用 JIT 即时编译器。\n\n### 为什么说 Java 语言“编译与解释并存”？\n\n- **编译型：**[编译型语言](https://zh.wikipedia.org/wiki/%E7%B7%A8%E8%AD%AF%E8%AA%9E%E8%A8%80)会通过[编译器](https://zh.wikipedia.org/wiki/%E7%B7%A8%E8%AD%AF%E5%99%A8)将源代码一次性翻译成可被该平台执行的机器码。一般情况下，编译语言的执行速度比较快，开发效率比较低。常见的编译型语言有 C、C++、Go、Rust 等等。\n- **解释型：**[解释型语言](https://zh.wikipedia.org/wiki/%E7%9B%B4%E8%AD%AF%E8%AA%9E%E8%A8%80)会通过[解释器](https://zh.wikipedia.org/wiki/%E7%9B%B4%E8%AD%AF%E5%99%A8)一句一句的将代码解释（interpret）为机器代码后再执行。解释型语言开发效率比较快，执行速度比较慢。常见的解释型语言有 Python、JavaScript、PHP 等等。\n\n> **维基百科中介绍：**\n>\n> 为了改善编译语言的效率而发展出的[即时编译](https://zh.wikipedia.org/wiki/即時編譯)技术，已经缩小了这两种语言间的差距。这种技术混合了编译语言与解释型语言的优点，它像编译语言一样，先把程序源代码编译成[字节码](https://zh.wikipedia.org/wiki/字节码)。到执行期时，再将字节码直译，之后执行。[Java](https://zh.wikipedia.org/wiki/Java)与[LLVM](https://zh.wikipedia.org/wiki/LLVM)是这种技术的代表产物。\n>\n> **相关阅读：**[基本功 | Java 即时编译器原理解析及实践](https://tech.meituan.com/2020/10/22/java-jit-practice-in-meituan.html)\n\n**为什么说 Java 语言“编译与解释并存”？**\n\n这是因为 Java 语言既具有编译型语言的特征，也具有解释型语言的特征。因为 Java 程序要经过先编译，后解释两个步骤，由 Java 编写的程序需要先经过编译步骤，生成字节码（`.class` 文件），这种字节码必须由 Java 解释器来解释执行。\n\n## 基本语法\n\n### 标识符和关键字的区别是什么？\n\n在我们编写程序的时候，需要大量地为程序、类、变量、方法等取名字，于是就有了 **标识符** 。简单来说， **标识符就是一个名字** 。\n\n有一些标识符，Java 语言已经赋予了其特殊的含义，只能用于特定的地方，这些特殊的标识符就是 **关键字** 。简单来说，**关键字是被赋予特殊含义的标识**符 。比如，在我们的日常生活中，如果我们想要开一家店，则要给这个店起一个名字，起的这个“名字”就叫标识符。但是我们店的名字不能叫“警察局”，因为“警察局”这个名字已经被赋予了特殊的含义，而“警察局”就是我们日常生活中的关键字。\n\n### Java 语言关键字有哪些？true、false 和 null 是关键字吗？\n\n> 官方文档：[Java 语言关键字 | (oracle.com)](https://docs.oracle.com/javase/tutorial/java/nutsandbolts/_keywords.html)\n\n![image-20221103173508830](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221103173519.png)\n\n>Tips：所有的关键字都是小写的，在 IDE 中会以特殊颜色显示。\n>\n>`default` 这个关键字很特殊，既属于程序控制，也属于类，方法和变量修饰符，还属于访问控制。\n>\n>- 在程序控制中，当在 `switch` 中匹配不到任何情况时，可以使用 `default` 来编写默认匹配的情况。\n>- 在类，方法和变量修饰符中，从 JDK8 开始引入了默认方法，可以使用 `default` 关键字来定义一个方法的默认实现。\n>- 在访问控制中，如果一个方法前没有任何修饰符，则默认会有一个修饰符 `default`，但是这个修饰符加上了就会报错。\n\n**虽然 `true`, `false`, 和 `null` 看起来像关键字但实际上他们是字面值，同时你也不可以作为标识符来使用**\n\n### continue、break 和 return 的区别是什么？\n\n在循环结构中，当循环条件不满足或者循环次数达到要求时，循环会正常结束。但是，有时候可能需要在循环的过程中，当发生了某种条件之后，提前终止循环，这就需要用到下面几个关键词：\n\n1. `continue`：指跳出当前的这一次循环，继续下一次循环。\n2. `break`：指跳出整个循环体，继续执行循环下面的语句。\n\n`return` 用于跳出所在的方法，结束该方法的运行。return 一般有两种用法：\n\n1. `return;`：直接使用 return 结束方法执行，用于没有返回值函数的方法\n2. `return value;`：return 一个特定值，用于有返回值函数的方法\n\n### 变量\n\n#### 成员变量与局部变量的区别？\n\n- **语法形式**：从语法形式上看，成员变量是属于类的，而局部变量是在代码块或方法中定义的变量或是方法的参数；成员变量可以被 `public`、`private`、`static` 等修饰符所修饰，而局部变量不能被访问控制符及 `static` 所修饰；但是，成员变量和局部变量都能被 `final` 所修饰。\n- **存储方式**：从变量在内存中的存储方式来看，如果成员变量是使用 `static` 修饰的，那么这个成员变量是属于类的，如果没有使用 `static` 修饰，这个成员变量是属于实例的。而对象存在于堆内存，局部变量存在于栈内存。\n- **生存时间**：从变量在内存中的生存时间上看，成员变量是对象的一部分，它随着对象的创建而存在，而局部变量随着方法的调用而自动生成，随着方法的调用结束而消亡。\n- **默认值**：从变量是否有默认值来看，成员变量如果没有被赋初始值，则会自动以类型的默认值而赋值（一种情况例外：被 `final` 修饰的成员变量也必须显式地赋值），而局部变量则不会自动赋值。\n\n#### 静态变量有什么作用？\n\n静态变量可以被类的所有实例共享。无论一个类创建了多少个对象，他们都共享同一份静态变量。\n\n通常情况下，静态变量会被 `final` 关键字修饰成为常量。\n\n#### 字符型常量和字符串常量的区别？\n\n1. **形式**：字符常量是单引号引起的一个字符，字符串常量是双引号引起的 0 个或若干个字符。\n2. **含义**：字符常量相当于一个整型值(ASCII 值)，可以参加表达式运算；字符串常量代表一个地址值(该字符串在内存中存放的位置)。\n\n3. **占内存大小**：字符常量只占 2 个字节；字符串常量占若干个字节。\n\n**(注意：`char` 在 Java 中占两个字节)**\n\n### 方法\n\n#### 静态方法为什么不能调用非静态成员？\n\n1. 静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。\n2. 在类的非静态成员不存在的时候静态成员就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作。\n\n#### 静态方法和实例方法有何不同？\n\n**1、调用方式**\n\n在外部调用静态方法时，可以使用 `类名.方法名` 的方式，也可以使用 `对象.方法名` 的方式，而实例方法只有后面这种方式。也就是说，**调用静态方法可以无需创建对象**。\n\n**2、访问类成员是否存在限制**\n\n静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），不允许访问实例成员（即实例成员变量和实例方法），而实例方法不存在这个限制。\n\n#### 重载和重写有什么区别？\n\n> 重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理\n>\n> 重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法\n\n**重载**\n\n发生在同一个类中（或者父类与之类之间），方法名必须相同，参数类型不同、个数不同，顺序不同，方法返回值和访问修饰符可以不同。\n\n综上：重载就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。\n\n**重写**\n\n重写发生在运行期，是子类对付类的允许访问的方法的实现过程进行重新编写。\n\n1. 方法名、参数列表必须相同，子类方法返回值类型应比父类方法返回值类型更小或相等，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。\n2. 如果父类方法访问修饰符为 `private/final/static` 则子类就不能重写该方法，但是被 `static` 修饰的方法能够被再次声明。\n3. 构造方法无法被重写\n\n综上：**重写就是子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变。**\n\n| 区别点     | 重载方法 | 重写方法                                                     |\n| :--------- | :------- | :----------------------------------------------------------- |\n| 发生范围   | 同一个类 | 子类                                                         |\n| 参数列表   | 必须修改 | 一定不能修改                                                 |\n| 返回类型   | 可修改   | 子类方法返回值类型应比父类方法返回值类型更小或相等           |\n| 异常       | 可修改   | 子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等； |\n| 访问修饰符 | 可修改   | 一定不能做更严格的限制（可以降低限制）                       |\n| 发生阶段   | 编译期   | 运行期                                                       |\n\n**方法的重写要遵循“两同两小一大”**\n\n- ”两同“即方法名相同、形参列表相同；\n- ”两小“指的是子类方法返回值类型应比父类方法返回值类型更小或相等，子类方法声明抛出的异常类型应比父类方法抛出的异常类型更小或相等；\n- ”一大“指的是子类方法的访问权限应比父类方法的访问权限更大或相等。\n\n> 关于 **重写的返回值类型** 这里需要额外说明一下：如果方法的返回类型是 void 和基本数据类型，则返回值重写时不可修改。但是如果方法的返回值是引用类型，重写时是可以返回该引用类型的子类的。\n\n#### 什么是可变长参数？\n\n从 Java5 开始，Java 支持定义可变长参数，所谓可变长参数就是允许在调用方法时传入不定长度的参数。就比如下面的这个方法就可以接受 0 个或者多个参数。\n\n```java\npublic static void method1(String... args) {\n   //......\n}\n```\n\n另外，可变参数只能作为函数的最后一个参数，但其前面可以有也可以没有任何其他参数。\n\n```java\npublic static void method2(String arg1,String... args) {\n    //......\n}\n```\n\n**遇到方法重载的情况怎么办呢？会优先匹配固定参数还是可变参数的方法呢？**\n\n会优先匹配固定参数的方法，因为固定参数的方法匹配度更高！\n\n## 基本数据类型\n\n### Java 中的几种基本数据类型了解吗？\n\nJava 中有 8 种基本数据类型，分别为：\n\n- 6 种数字类型：\n  - 4 种整数型：`byte`、`short`、`int`、`long`\n  - 2 种浮点型：`float`、`double`\n- 1 种字符类型：`char`\n- 1 种布尔型：`boolean`\n\n这 8 种基本数据类型的默认值以及所占空间的大小如下：\n\n| 基本类型  | 位数 | 字节 | 默认值  | 取值范围                                   |\n| :-------- | :--- | :--- | :------ | ------------------------------------------ |\n| `byte`    | 8    | 1    | 0       | -128 ~ 127                                 |\n| `short`   | 16   | 2    | 0       | -32768 ~ 32767                             |\n| `int`     | 32   | 4    | 0       | -2147483648 ~ 2147483647                   |\n| `long`    | 64   | 8    | 0L      | -9223372036854775808 ~ 9223372036854775807 |\n| `char`    | 16   | 2    | 'u0000' | 0 ~ 65535                                  |\n| `float`   | 32   | 4    | 0f      | 1.4E-45 ~ 3.4028235E38                     |\n| `double`  | 64   | 8    | 0d      | 4.9E-324 ~ 1.7976931348623157E308          |\n| `boolean` | 1    |      | false   | true、false                                |\n\n> 对于 `boolean`，官方文档未明确定义，它依赖于 JVM 厂商的具体实现。逻辑上理解是占用 1 位，但是实际中会考虑计算机高效存储因素。\n>\n> 另外，Java 的每种基本数据类型所占存储空间的大小不会像其他大多数语言那样随机器硬件架构的变化而变化。这种所占存储空间大小的不变性是 Java 程序比用其他大多数语言编写的程序更具可移植性的原因之一（《Jav··a 编程思想》2.2 节有提到）。\n\n**注意**：\n\n1. Java 里使用 `long` 类型的数据一定要在数值后面加上 **L**，否则将作为整型解析；\n2. `char a = 'h'` 字符：单引号，`String a = \"hello\"` 字符串：双引号。\n\n这八种基本类型都有对应的包装类分别为：`Byte`、`Short`、`Integer`、`Long`、`Float`、`Double`、`Character`、`Boolean`。\n\n### 基本类型和包装类型的区别？\n\n- 成员变量包装类型不赋值就是 `null`，而基本类型有默认值且不是 `null`；\n- 包装类型可用于泛型，而基本类型不可以；\n- 基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，而基本数据类型的成员变量（未被 `static` 修饰）存放在 Java 虚拟机的堆中。包装类型属于对象类型，我们知道几乎所有的对象实例都存在于堆中；\n- 相比于对象类型，基本数据类型占用的空间非常小。\n\n**为什么说是几乎所有对象实例呢？** 这是因为 HotSpot 虚拟机引入了 JIT 优化之后，会对对象进行 `逃逸分析`，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存。\n\n> [基本功 | Java即时编译器原理解析及实践 - 逃逸分析](https://tech.meituan.com/2020/10/22/java-jit-practice-in-meituan.html)\n\n**注意：基本数据类型存放在栈中是一个常见的误区！**基本数据类型的成员变量如果没有被 `static` 修饰的话（不建议这么使用，应该给要使用基本数据类型对应的包装类型），就存放在堆中。\n\n```java\nclass BasicTypeVar {\n    private int x;\n}\n```\n\n### 包装类型的缓存机制了解吗？\n\nJava 基本数据类型的包装类型的大部分都用到了缓存机制来提升性能。\n\n`Byte`、`Short`、`Integer`、`Long` 这 4 种包装类默认创建了数值 **[-128,127]** 的相应类型的缓存数据，`Character` 创建了数值在 **[0,127]** 范围的缓存数据，`Boolean` 直接返回 `Ture` or `False`。\n\n**`Integer` 缓存源码：**\n\n```java\npublic static Integer valueOf(int i) {\n    if (i >= IntegerCache.low && i <= IntegerCache.high)\n        return IntegerCache.cache[i + (-IntegerCache.low)];\n    return new Integer(i);\n}\nprivate static class IntegerCache {\n    static final int low = -128;\n    static final int high;\n    static {\n        // high value may be configured by property\n        int h = 127;\n    }\n}\n\n```\n\n**`Character` 缓存源码：**\n\n```java\npublic static Character valueOf(char c) {\n    if (c <= 127) { // must cache\n      return CharacterCache.cache[(int)c];\n    }\n    return new Character(c);\n}\n\nprivate static class CharacterCache {\n    private CharacterCache(){}\n    static final Character cache[] = new Character[127 + 1];\n    static {\n        for (int i = 0; i < cache.length; i++)\n            cache[i] = new Character((char)i);\n    }\n\n}\n```\n\n**`Boolean` 缓存源码：**\n\n```java\npublic static final Boolean TRUE = new Boolean(true);\n\npublic static final Boolean FALSE = new Boolean(false);\n\npublic static Boolean valueOf(boolean b) {\n    return (b ? TRUE : FALSE);\n}\n```\n\n如果超过对应范围仍然回去创建新的对象，缓存的范围区间的大小只是在性能和资源之间的权衡。\n\n两种浮点数类型的包装类 `Fload`、`Double` 并没有实现缓存机制。\n\n```java\nInteger i1 = 33;\nInteger i2 = 33;\nSystem.out.println(i1 == i2);// 输出 true\n\nFloat i11 = 333f;\nFloat i22 = 333f;\nSystem.out.println(i11 == i22);// 输出 false\n\nDouble i3 = 1.2;\nDouble i4 = 1.2;\nSystem.out.println(i3 == i4);// 输出 false\n```\n\n下面我们来看一下问题：下面的代码的输出结果是 `true` 还是 `false` 呢？\n\n```java\nInteger i1 = 40;\nInteger i2 = new Integer(40);\nSystem.out.println(i1 == i2);\n```\n\n`Integer i1 = 40` 这一行代码会发生装箱，也就是说这行代码等价于 `Integer i1 = Integer.valueOf(40)`。因此，`i1` 直接使用的是缓存中的对象。而 `Integer i2 = new Integer(40)` 会直接创建新的对象。\n\n因此，答案是 `false`。\n\n**记住：所有整型包装类对象之间值的比较，全部使用 `equals` 方法比较。**\n\n### 自动装箱与拆箱了解吗？原理是什么？\n\n**什么是自动拆装箱？**\n\n- **装箱：**将基本类型用它们对应的引用类型包装起来；\n- **拆箱：**将包装类型转换为基本数据类型\n\n举例：\n\n```java\nInteger i = 10; // 装箱\nint n = i; // 拆箱\n```\n\n上面这两行代码对应的字节码为：\n\n```java\n   L1\n\n    LINENUMBER 8 L1\n\n    ALOAD 0\n\n    BIPUSH 10\n\n    INVOKESTATIC java/lang/Integer.valueOf (I)Ljava/lang/Integer;\n\n    PUTFIELD AutoBoxTest.i : Ljava/lang/Integer;\n\n   L2\n\n    LINENUMBER 9 L2\n\n    ALOAD 0\n\n    ALOAD 0\n\n    GETFIELD AutoBoxTest.i : Ljava/lang/Integer;\n\n    INVOKEVIRTUAL java/lang/Integer.intValue ()I\n\n    PUTFIELD AutoBoxTest.n : I\n\n    RETURN\n```\n\n从字节码中，我们发现装箱其实就是调用了包装类的 `valueOf` 方法，拆箱其实就是调用了 `xxxValue()` 方法。\n\n因此：\n\n- `Integer i = 10` 等价于 `Integer i = Integer.valueOf(10)`\n- `int n = i` 等价于 `int n = i.intValue()`；\n\n注意：**如果频繁拆装箱的话，也会严重影响系统的性能。我们应该尽量避免不必要的拆装箱操作。**\n\n### 为什么浮点数运算的时候会有精度丢失的风险？\n\n浮点数运算精度丢失代码演示：\n\n```java\nfloat a = 2.0f - 1.9f;\nfloat b = 1.8f - 1.7f;\nSystem.out.println(a); // 0.100000024\nSystem.out.println(b);// 0.099999905\nSystem.out.println(a == b); // false\n```\n\n为什么会出现这个问题呢？\n\n这个和计算机保存浮点数的机制有很大关系。我们知道计算机是二进制的，而且计算机在表示一个数字时，宽度是有限的，无限循环的小数存储再计算机时，只能被截断，所以就会导致小数精度发生损失的情况。这也就是解释了为什么浮点数没有办法用二进制精确表示。\n\n就比如说十进制下的 0.2 就没办法精确转换为二进制小数：\n\n```java\n// 0.2 转换为二进制数的过程为，不断乘以 2，直到不存在小数为止，\n// 在这个计算过程中，得到的整数部分从上到下排列就是二进制的结果。\n0.2 * 2 = 0.4 -> 0\n0.4 * 2 = 0.8 -> 0\n0.8 * 2 = 1.6 -> 1\n0.6 * 2 = 1.2 -> 1\n0.2 * 2 = 0.4 -> 0（发生循环）\n...\n```\n\n关于浮点数的更多内容，建议看一下[计算机系统基础（四）浮点数](http://kaito-kidd.com/2018/08/08/computer-system-float-point/)这篇文章。\n\n### 如何解决浮点数运算的精度丢失问题？\n\n`BigDecimal` 可以实现对浮点数的运算，不会造成精度丢失。通常情况下，大部门需要将浮点数精确运算结果的业务场景（比如涉及到钱的场景）都是通过 `BigDecimal` 来做的。\n\n```java\nBigDecimal a = new BigDecimal(\"1.0\");\nBigDecimal b = new BigDecimal(\"0.9\");\nBigDecimal c = new BigDecimal(\"0.8\");\n\nBigDecimal x = a.subtract(b);\nBigDecimal y = b.subtract(c);\n\nSystem.out.println(x); /* 0.1 */\nSystem.out.println(y); /* 0.1 */\nSystem.out.println(Objects.equals(x, y)); /* true */\n```\n\n### 超过 long 整型的数据应该如何表示？\n\n基本数值类型都有一个表达范围，如果超过这个范围就会有数值溢出的风险。\n\n在 Java 中，64 位 long 整型是最大的整数类型。\n\n```java\nlong l = Long.MAX_VALUE;\nSystem.out.println(l + 1); // -9223372036854775808\nSystem.out.println(l + 1 == Long.MIN_VALUE); // true\n```\n\n`BigInteger` 内部使用 `int[]` 数组来存储任意大小的整型数据。\n\n相对于常规整数类型的运算来说，`BigInteger` 运算的效率会相对较低。\n\n## 面向对象基础\n\n### 面向对象和面向过程的区别？\n\n两者的主要区别在于解决问题的方式不同：\n\n- 面向过程把解决问题的过程拆成一个个方法，通过一个个方法的执行解决问题；\n- 面向对象会先抽象出对象，然后用对象执行方法的方式解决问题；\n\n另外，面向对象开发的程序一般更易维护、易复用、易扩展。\n\n### 面向对象的三大特征\n\n#### 封装\n\n封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供外界访问的方法，那么这个类也没有什么意义了。\n\n#### 继承\n\n不同类型的对象，相互之间经常有一定数量的共同点。继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承，可以快速地创建新的类，可以提高代码地重用，程序的可维护性，节省大量创建新类的时间，提高我们的开发效率。\n\n**关于继承如下 3 点请记住：**\n\n1. 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问的，**只是拥有**\n2. 子类可以拥有自己属性和方法，即子类可以对父类进行扩展\n3. 子类可以用自己的方式实现父类的方法（以后介绍）  \n\n#### 多态\n\n多态，顾名思义，表示一个对象具有多种的状态，具体表现为父类打得引用指向子类的实例。\n\n**多态的特点：**\n\n- 对象类型和引用类型之间具有继承（类）/实现（接口）的关系；\n- 引用类型变量发出的方法调用的到底是哪个类中的方法，必须在程序运行期间才能确定；\n- 多态不能调用“只在子类存在但在父类不存在”的方法\n- 如果子类重写了父类的方法，真正执行的是子类覆盖的方法，如果子类没有覆盖父类的方法，执行的是父类的方法。\n\n### 接口和抽象类有什么共同点和区别？\n\n**共同点：**\n\n- 都不能被实例化\n- 都可以包含抽象方法\n- 都可以有默认实现方法（Java 8 可以用 `default` 关键字在接口中定义默认方法）\n\n**区别：**\n\n- 接口主要用于对类的行为进行约束，你是实现了某个接口就具有了对应的行为。抽象类主要用于代码复用，强调的是所属关系\n- 一个类只能继承一个类，但是可以实现多个接口\n- 接口中成员变量只能是 `public static final` 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认是 `default`，可在子类中被重新定义，也可被重新赋值\n\n### 深拷贝和浅拷贝区别了解吗？什么是引用拷贝？\n\n结论：\n\n- **浅拷贝：**浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是拷贝对象和原对象共用同一个内部对象\n\n- **浅拷贝：**深拷贝会完全复制整个对象，包括这个对象所包含的内部对象\n\n案例：\n\n**浅拷贝**\n\n浅拷贝的示例代码如下，我们这里实现了 `Cloneable` 接口，并重写了 `clone()` 方法。\n\n`clone()` 方法的实现很简单，直接调用的是父类 `Object` 的 `clone()` 方法。\n\n```java\npublic class Address implements Cloneable{\n    private String name;\n    // 省略构造函数、Getter&Setter方法\n    @Override\n    public Address clone() {\n        try {\n            return (Address) super.clone();\n        } catch (CloneNotSupportedException e) {\n            throw new AssertionError();\n        }\n    }\n}\n\npublic class Person implements Cloneable {\n    private Address address;\n    // 省略构造函数、Getter&Setter方法\n    @Override\n    public Person clone() {\n        try {\n            Person person = (Person) super.clone();\n            return person;\n        } catch (CloneNotSupportedException e) {\n            throw new AssertionError();\n        }\n    }\n}\n```\n\n测试：\n\n```java\nPerson person1 = new Person(new Address(\"武汉\"));\nPerson person1Copy = person1.clone();\n// true\nSystem.out.println(person1.getAddress() == person1Copy.getAddress());\n```\n\n从输出结构就可以看出，`person1` 的克隆对象和 `person1` 使用的仍然是同一个 `Address` 对象。\n\n**深拷贝**\n\n这里我们简单对 `Person` 类的 `clone()` 方法进行修改，连带着要把 `Person` 对象内部的 `Address` 对象一起复制。\n\n```java\n@Override\npublic Person clone() {\n    try {\n        Person person = (Person) super.clone();\n        person.setAddress(person.getAddress().clone());\n        return person;\n    } catch (CloneNotSupportedException e) {\n        throw new AssertionError();\n    }\n}\n```\n\n测试：\n\n```java\nPerson person1 = new Person(new Address(\"武汉\"));\nPerson person1Copy = person1.clone();\n// false\nSystem.out.println(person1.getAddress() == person1Copy.getAddress());\n```\n\n从输出结果就可以看出，虽然 `person1` 的克隆对象和 `person1` 包含的 `Address` 对象已经是不同的了。\n\n**那什么是引用拷贝呢？**简单来说，引用拷贝就是两个不同的引用指向同一个对象。\n\n下图可以描述浅拷贝、深拷贝、引用拷贝：\n\n![浅拷贝、深拷贝、引用拷贝示意图](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221122165417.png)\n\n## Java 常见类\n\n### Object\n\n#### Object 类的常见方法有哪些？\n\nObject 类是一个特殊的类，是所有类的父类。主要提供有以下 11 个方法：\n\n```java\n/**\n * native 方法，用于返回当前运行时对象的 Class 对象，使用了 final 关键字修饰，故不允许子类重写。\n */\npublic final native Class<?> getClass();\n    \n/**\n * native 方法，用于返回对象的哈希码，主要使用在哈希表中，比如 JDK 中的HashMap。\n */\npublic native int hashCode();\n    \n/**\n * 用于比较 2 个对象的内存地址是否相等，String 类对该方法进行了重写以用于比较字符串的值是否相等。\n */\npublic boolean equals(Object obj);\n    \n/**\n * naitive 方法，用于创建并返回当前对象的一份拷贝。\n */\nprotected native Object clone() throws CloneNotSupportedException;\n    \n/**\n * 返回类的名字实例的哈希码的 16 进制的字符串。建议 Object 所有的子类都重写这个方法。\n */\npublic String toString();\n    \n/**\n * native 方法，并且不能重写。唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果有多个线程在等待只会任意唤醒一个。\n */\npublic final native void notify();\n    \n/**\n * native 方法，并且不能重写。跟 notify 一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。\n */\npublic final native void notifyAll();\n    \n/**\n * native方法，并且不能重写。暂停线程的执行。注意：sleep 方法没有释放锁，而 wait 方法释放了锁 ，timeout 是等待时间。\n */\npublic final native void wait(long timeout) throws InterruptedException;\n    \n/**\n * 多了 nanos 参数，这个参数表示额外时间（以毫微秒为单位，范围是 0-999999）。 所以超时的时间还需要加上 nanos 毫秒。。\n */\npublic final void wait(long timeout, int nanos) throws InterruptedException;\n    \n/**\n * 跟之前的2个wait方法一样，只不过该方法一直等待，没有超时时间这个概念\n */\npublic final void wait() throws InterruptedException;\n    \n/**\n * 实例被垃圾回收器回收的时候触发的操作\n */\nprotected void finalize() throws Throwable { }\n```\n\n#### == 和 equals() 的区别？\n\n`==` 对于基本类型来和引用类型的作用效果是不同的：\n\n- 对于基本数据类型来说，`==` 比较的是值\n- 对于引用类型来说，`==` 比较的是对象的内存地址\n\n> 因为 Java 只有值传递，所以，对于 == 来说，不管是比较基本类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。\n\n`equals()` 不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等。`equals()` 方法存在于 `Object` 类中，而 `Object` 类是所有类的直接或间接父类，因此所有的类都有 `equals()` 方法。 \n\n`Object` 类 `equals()` 方法：\n\n```java\npublic boolean equals(Object obj) {\n     return (this == obj);\n}\n```\n\n`equals()` 方法存在两种使用情况：\n\n- **类没有重写 `equals()` 方法**：通过 `equals()` 方法比较该类的两个对象时，等价于通过“==”比较这两个对象，使用的默认是 `Object` 类 `equals()` 方法。\n- **类重写了 `equals()` 方法**：一般我们都重写 `equals()` 方法来比较两个对象中属性是否相等；若它们的属性相等，则返回 `true`（即认为这两个对象相等）。\n\n`String` 类 `equals()` 方法：\n\n```java\npublic boolean equals(Object anObject) {\n    if (this == anObject) {\n        return true;\n    }\n    if (anObject instanceof String) {\n        String anotherString = (String)anObject;\n        int n = value.length;\n        if (n == anotherString.value.length) {\n            char v1[] = value;\n            char v2[] = anotherString.value;\n            int i = 0;\n            while (n-- != 0) {\n                if (v1[i] != v2[i])\n                    return false;\n                i++;\n            }\n            return true;\n        }\n    }\n    return false;\n}\n```\n\n#### hashCode() 有什么用？\n\n`hashCode()` 的作用是获取哈希码（`int` 整数）\n","tags":["Java","面试"],"categories":["面试指北"]},{"title":"基于 GitLab 的代码审查","slug":"基于GitLab的代码审查","url":"/2022/10/28/328074fd.html","content":"\n## Code Review 流程\n\n根据 `Git Flow` 工作流，开发人员在 `feature` 分支进行开发，开发完成之后 `Merge` 到 `develop` 分支进行测试。\n\n那么最适合做 `Code Review` 就是 `featrue` 分支合并到 `develop` 分支的环节\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028112809.png)\n\n> 注：为了保证必须以 Merge 的方式变更 develop 分支、release 分支、以及 master 分支，我们对 Push 以及 Merge 权限进行限制\n>\n> `项目仓库 -> 设置 -> 仓库设置 -> Protected Branches`\n>\n> **Protected Branches 配置**\n>\n> ![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028112923.png)\n>\n> 这里，我们限制分支，所有的开发人员对 `develop` 分支、`release` 分支、以及 `master` 分支均无 `Push` 权限，只能以 `Merge` 方式合并到对应分支，而且只有 `Maintainers（Masters）` 组的用户有 `Merge` 权限。\n\n## Code View 示例\n\n### 准备工作\n\n变更 `feature 分支` 分支 `README.md` 文件，为 `Merge Request` 提供基础\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028112941.png)\n\n随意更改一行内容，然后 `Commit Changes` 即可\n\n### 创建 `Merge Request`\n\n`左侧菜单 -> Merge Request -> 点击 New Merge Request`\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028112952.png)\n\nSource branch 选择：`feature/test`\n\nTarget branch 选择：`develop`\n\n然后：`Compare branches and continue`\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028113007.png)\n\n操作项/填写项说明：\n\n| 操作项/填写项 | 说明                                                                                                                        |\n| ------------- | --------------------------------------------------------------------------------------------------------------------------- |\n| Title         | 标题，没有特殊要求保持默认即可                                                                                              |\n| Description   | 描述，需要将变更的需求描述清楚，最好附件 Code Review 要点                                                                   |\n| Assignee      | 分配到的人，被分配到的人将会收到邮件通知，跟 Merge 权限没有必然关系，仍然是项目的 Maintainers（Masters）角色拥有 Merge 权限 |\n| Milestone     | 里程碑，如果没有可不选                                                                                                      |\n| Label         | 标签，如果没有可不选                                                                                                        |\n| Merge options | 合并选项，可以勾选当合并请求被接受时，删除源分支或压缩请求                                                                  |\n\n### `Merge Request` 操作\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028113020.png)\n\n`Merge Request` 创建之后就会转到该页面，被分配到的人（Assignee）会收到邮件提醒，如果需要多个人进行 `Code Review`，只要将该页面的链接发给其他项目成员即可。项目成员可以查看变更并评论，只不过按照之前的配置，只有 `Maintainers（Masters）`角色的成员才有 `Merge` 的权限。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028113030.png)\n\n在 `变更（Changes）` 选项卡中，我们可以看到所有的变更。将光标移动到行号处会出现评论按钮，我们可以点击评论按钮发起评论，这个评论是对项目成员可见的，大家可在讨论区进行讨论。最终讨论发起者有权将讨论标记为已解决 `resolved`\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028113036.png)\n\n当所有的问题已解决之后（如果选择了审批人也需要审批通过），`Maintainers（Masters）`成员点击 `合并（Merge）` 完成合并即可。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028113040.png)\n\n`Merge` 完成之后，可以选择 `删除源分支（Remove Source Branch）` 等操作。\n\n`develop` 分支合并到 `release` 分支，以及 `release` 分支合并到 `master` 是不需要经过 `Code Review` 的，直接 `Merge` 即可。这里就省略了...\n","tags":["Git","开发规范"],"categories":["DevOps"]},{"title":"Git 分支管理规范","slug":"Git分支管理规范","url":"/2022/10/26/3c24a376.html","content":"\n## 分支分类\n\n1. **根据生命周期区分**\n\n- **主分支：**master，develop；\n- **临时分支：**feature/_，release/_，hotfix/\\*；\n\n2. **根据用途区分**\n\n- **发布/预发布分支：**master，release/\\*；\n- **开发分支：**develop；\n- **功能分支：**feature/\\*；\n  - **热修复分支：**hotfix/\\*；\n\n## 分支用途\n\n### master 分支\n\nmaster 分支主要放稳定、随时可上线的版本。这个分支只能从别的分支上合并过来，一般来讲，从 develop 上合并，或者从 bugfix 分支上合并过来。不能直接在 master 分支上进行 commit 文件。因为是稳定的版本，所以每次版本发布都要在这个分支上添加`标签`(tag)。\n\n### develop 分支\n\ndevelop 分支是所有开发分支的母体，所有的开发分支都要从 develop 上切出来，开发完成之后最后都要合并到 develop 上。\n\n### hotfix 分支\n\n命名规则：`hotfix/*` --> `hotfix/v+bug修复的版本号`\n\nhotfix 分支用来修复生产中的紧急 bug，由于 develop 分支尚处于开发过程中，代码不稳定，不能直接应用于生产。所以从 master 分支上切出一个分支，修复完成之后合并到 master 分支，并且合并到 develop 上。\n\n### release 分支\n\n命名规则：`release/*` --> `release/v+发布的版本号`\n\nrelease 分支可以称之为预发布的版本。当我们认为 develop 版本的代码已经趋于成熟，我们可以打一个 release 分支。在 release 分支上测试完成之后，要将代码合并到 master 分支和 develop 上。master 分支是线上版本，而合并到 develop 版本是因为，在测试过程中，一些细节的东西可能会修改，因此这些优化的内容也应该合并到最终版本以及开发版本中。\n\n### feature 分支\n\n命名规则：`feature/*` --> `feature/功能名称`\n\nfeature 分支是最经常使用的分支了。当我们收到一个新的开发功能时，应该在 develop 分支上切出一个 feature 分支。用来完成新功能的开发，开发完成之后，要合并进 develop 分支上。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20221028110813.png)\n\n> [Git Flow 工作流 | Kyire の Blog](https://blog.kyire.site/2022/08/05/c7bea606.html)\n","tags":["Git","开发规范"],"categories":["DevOps"]},{"title":"Docker 部署的微服务注册到 Nacos 的 IP 为私网无法访问","slug":"Docker部署的微服务注册到Nacos的IP为私网无法访问","url":"/2022/08/11/e8458f8e.html","content":"\n## 问题描述\n\n使用 docker 集群部署微服务时，注册到 nacos 上的 ip 会使用 docker 容器的虚拟内网 ip 作为注册地址，这会导致集群部署服务时，nacos 无法解析对应服务的 ip。\n\n## 解决方案\n\n> 参考：[注册服务获取 IP 的问题 · Issue #310 · alibaba/nacos (github.com)](https://github.com/alibaba/nacos/issues/310)\n\n### 方法一：\n\ndocker compose 配置文件中设置网络模式为 host\n\n```yaml\nnetwork_mode: host\n```\n\nhost 网络模式是直接使用宿主机的 IP 地址与外界进行通信\n\n### 方法二：\n\nnacos 配置指定注册 ip/host\n\napplication.yml 配置文件中添加如下配置即可：\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      discovery:\n        # 配置host，避免docker部署nacos注册服务ip为内网地址\n        ip: xxx\n```\n","tags":["技巧","开发工具"],"categories":["Linux"]},{"title":"MapStruct 对象转换","slug":"MapStruct对象转换","url":"/2022/08/07/2e504595.html","content":"\n## 前言\n\n随着微服务和分布式应用程序迅速占领开发领域，数据完整性和安全性比以往任何时候都更加重要。在这些松散耦合的系统之间，安全的通信渠道和有限的数据传输是最重要的。大多数时候，终端用户或服务不需要访问模型中的全部数据，而只需要访问某些特定的部分。\n\n数据传输对象(Data Transfer Objects, DTO)经常被用于这些应用中。DTO 只是持有另一个对象中被请求的信息的对象。通常情况下，这些信息是有限的一部分。例如，在持久化层定义的实体和发往客户端的 DTO 之间经常会出现相互之间的转换。由于 DTO 是原始对象的反映，因此这些类之间的映射器在转换过程中扮演着关键角色。\n\n这就是 MapStruct 解决的问题：手动创建 bean 映射器非常耗时。 但是该库可以自动生成 Bean 映射器类。\n\n## 简介 MapStruct\n\nMapStruct 是一个开源的基于 Java 的代码生成器，用于创建实现 Java Bean 之间转换的扩展映射器。使用 MapStruct，我们只需要创建接口，而该库会通过注解在编译过程中自动创建具体的映射实现，大大减少了通常需要手工编写的样板代码的数量。\n\n## **MapStruct 依赖**\n\n**如果你使用**`**Maven**`**的话，可以通过引入依赖安装**`**MapStruct**`：\n\n```HTML\n<dependencies>\n    <dependency>\n        <groupId>org.mapstruct</groupId>\n        <artifactId>mapstruct</artifactId>\n        <version>${org.mapstruct.version}</version>\n    </dependency>\n</dependencies>\n```\n\n这个依赖项会导入`MapStruct`的核心注释。由于`MapStruct`在编译时工作，并且会集成到像`Maven`和`Gradle`这样的构建工具上，我们还必须在<build/>标签中添加一个插件`maven-compiler-plugin`，并在其配置中添加`annotationProcessorPaths`，该插件会在构建时生成对应的代码。\n\n```HTML\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-compiler-plugin</artifactId>\n            <version>3.5.1</version>\n            <configuration>\n                <source>1.8</source>\n                <target>1.8</target>\n                <annotationProcessorPaths>\n                    <path>\n                        <groupId>org.mapstruct</groupId>\n                        <artifactId>mapstruct-processor</artifactId>\n                        <version>${org.mapstruct.version}</version>\n                    </path>\n                </annotationProcessorPaths>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\n**[MapStruct](https://link.zhihu.com/?target=https://search.maven.org/classic/#search|ga|1|g%3A\"org.mapstruct\" AND a%3A\"mapstruct\")**及其**[处理器](https://link.zhihu.com/?target=https://search.maven.org/classic/#search|ga|1|g%3A\"org.mapstruct\" AND a%3A\"mapstruct-processor\")**的最新稳定版本都可以从**[Maven 中央仓库](https://link.zhihu.com/?target=https://search.maven.org/search?q=g:org.mapstruct)**中获得。\n\n## **映射**\n\n### **基本映射**\n\n我们先从一些基本的映射开始。我们会创建一个`Doctor`对象和一个`DoctorDto`。为了方便起见，它们的属性字段都使用相同的名称：\n\n```Java\npublic class Doctor {\n    private int id;\n    private String name;\n    // getters and setters or builder\n}\n\npublic class DoctorDto {\n    private int id;\n    private String name;\n    // getters and setters or builder\n}\n```\n\n现在，为了在这两者之间进行映射，我们要创建一个`DoctorMapper`接口。对该接口使用`@Mapper`注解，`MapStruct`就会知道这是两个类之间的映射器。\n\n```Java\n@Mapper\npublic interface DoctorMapper {\n    DoctorMapper INSTANCE = Mappers.getMapper(DoctorMapper.class);\n    DoctorDto toDto(Doctor doctor);\n}\n```\n\n这段代码中创建了一个`DoctorMapper`类型的实例`INSTANCE`，在生成对应的实现代码后，这就是我们调用的“入口”。\n\n我们在接口中定义了`toDto()`方法，该方法接收一个`Doctor`实例为参数，并返回一个`DoctorDto`实例。这足以让 MapStruct 知道我们想把一个`Doctor`实例映射到一个`DoctorDto`实例。\n\n当我们构建/编译应用程序时，`MapStruct`注解处理器插件会识别出`DoctorMapper`接口并为其生成一个实现类。\n\n```Java\npublic class DoctorMapperImpl implements DoctorMapper {\n    @Override\n    public DoctorDto toDto(Doctor doctor) {\n        if ( doctor == null ) {\n            return null;\n        }\n        DoctorDtoBuilder doctorDto = DoctorDto.builder();\n\n        doctorDto.id(doctor.getId());\n        doctorDto.name(doctor.getName());\n\n        return doctorDto.build();\n    }\n}\n```\n\n`DoctorMapperImpl`类中包含一个`toDto()`方法，将我们的`Doctor`属性值映射到`DoctorDto`的属性字段中。如果要将`Doctor`实例映射到一个`DoctorDto`实例，可以这样写\n\n```Nginx\nDoctorDto doctorDto = DoctorMapper.INSTANCE.toDto(doctor);\n```\n\n**注意**：你可能也注意到了上面实现代码中的`DoctorDtoBuilder`。因为 builder 代码往往比较长，为了简洁起见，这里省略了 builder 模式的实现代码。如果你的类中包含 Builder，MapStruct 会尝试使用它来创建实例；如果没有的话，MapStruct 将通过`new`关键字进行实例化。\n\n- ##### **不同字段间映射**\n\n通常，模型和`DTO`的字段名不会完全相同。由于团队成员各自指定命名，以及针对不同的调用服务，开发者对返回信息的打包方式选择不同，名称可能会有轻微的变化。\n\n`MapStruct`通过`@Mapping`注解对这类情况提供了支持。\n\n我们先更新`Doctor`类，添加一个属性`specialty`：\n\n```PHP\npublic class Doctor {\n    private int id;\n    private String name;\n    private String specialty;\n    // getters and setters or builder\n}\n```\n\n在`DoctorDto`类中添加一个`specialization`属性：\n\n```PHP\npublic class DoctorDto {\n    private int id;\n    private String name;\n    private String specialization;\n    // getters and setters or builder\n}\n```\n\n现在，我们需要让 `DoctorMapper` 知道这里的不一致。我们可以使用 `@Mapping` 注解，并设置其内部的 `source` 和 `target` 标记分别指向不一致的两个字段。\n\n```Kotlin\n@Mapper\npublic interface DoctorMapper {\n    DoctorMapper INSTANCE = Mappers.getMapper(DoctorMapper.class);\n\n    @Mapping(source = \"doctor.specialty\", target = \"specialization\")\n    DoctorDto toDto(Doctor doctor);\n}\n@Mapping`这个注解代码的含义是：`Doctor`中的`specialty`字段对应于`DoctorDto`类的 `specialization\n```\n\n编译之后，会生成如下实现代码：\n\n```Java\npublic class DoctorMapperImpl implements DoctorMapper {\n@Override\n    public DoctorDto toDto(Doctor doctor) {\n        if (doctor == null) {\n            return null;\n        }\n\n        DoctorDtoBuilder doctorDto = DoctorDto.builder();\n\n        doctorDto.specialization(doctor.getSpecialty());\n        doctorDto.id(doctor.getId());\n        doctorDto.name(doctor.getName());\n\n        return doctorDto.build();\n    }\n}\n```\n\n- ##### **多个源类**\n\n有时，单个类不足以构建`DTO`，我们可能希望将多个类中的值聚合为一个`DTO`，供终端用户使用。这也可以通过在`@Mapping`注解中设置适当的标志来完成。\n\n我们先新建另一个对象 `Education`:\n\n```PHP\npublic class Education {\n    private String degreeName;\n    private String institute;\n    private Integer yearOfPassing;\n    // getters and setters or builder\n}\n```\n\n然后向 `DoctorDto`中添加一个新的字段：\n\n```PHP\npublic class DoctorDto {\n    private int id;\n    private String name;\n    private String degree;\n    private String specialization;\n    // getters and setters or builder\n}\n```\n\n接下来，将 `DoctorMapper` 接口更新为如下代码：\n\n```Kotlin\n@Mapper\npublic interface DoctorMapper {\n    DoctorMapper INSTANCE = Mappers.getMapper(DoctorMapper.class);\n\n    @Mapping(source = \"doctor.specialty\", target = \"specialization\")\n    @Mapping(source = \"education.degreeName\", target = \"degree\")\n    DoctorDto toDto(Doctor doctor, Education education);\n}\n```\n\n我们添加了另一个`@Mapping`注解，并将其`source`设置为`Education`类的`degreeName`，将`target`设置为`DoctorDto`类的`degree`字段。\n\n如果 `Education` 类和 `Doctor` 类包含同名的字段，我们必须让映射器知道使用哪一个，否则它会抛出一个异常。举例来说，如果两个模型都包含一个`id`字段，我们就要选择将哪个类中的`id`映射到 DTO 属性中。\n\n- ##### **子对象映射**\n\n多数情况下，POJO 中不会*只*包含基本数据类型，其中往往会包含其它类。比如说，一个`Doctor`类中会有多个患者类：\n\n```Java\npublic class Patient {\n    private int id;\n    private String name;\n    // getters and setters or builder\n}\n```\n\n在 Doctor 中添加一个患者列表`List`:\n\n```PHP\npublic class Doctor {\n    private int id;\n    private String name;\n    private String specialty;\n    private List<Patient> patientList;\n    // getters and setters or builder\n}\n```\n\n因为`Patient`需要转换，为其创建一个对应的 DTO\n\n```Java\npublic class PatientDto {\n    private int id;\n    private String name;\n    // getters and setters or builder\n}\n```\n\n最后，在 `DoctorDto` 中新增一个存储 `PatientDto`的列表：\n\n```PHP\npublic class DoctorDto {\n    private int id;\n    private String name;\n    private String degree;\n    private String specialization;\n    private List<PatientDto> patientDtoList;\n    // getters and setters or builder\n}\n```\n\n在修改 `DoctorMapper`之前，我们先创建一个支持 `Patient` 和 `PatientDto` 转换的映射器接口：\n\n```Java\n@Mapper\npublic interface PatientMapper {\n    PatientMapper INSTANCE = Mappers.getMapper(PatientMapper.class);\n    PatientDto toDto(Patient patient);\n}\n```\n\n这是一个基本映射器，只会处理几个基本数据类型。\n\n然后，我们再来修改 `DoctorMapper` 处理一下患者列表：\n\n```Kotlin\n@Mapper(uses = {PatientMapper.class})\npublic interface DoctorMapper {\n\n    DoctorMapper INSTANCE = Mappers.getMapper(DoctorMapper.class);\n\n    @Mapping(source = \"doctor.patientList\", target = \"patientDtoList\")\n    @Mapping(source = \"doctor.specialty\", target = \"specialization\")\n    DoctorDto toDto(Doctor doctor);\n}\n```\n\n因为我们要处理另一个需要映射的类，所以这里设置了`@Mapper`注解的`uses`标志，这样现在的 `@Mapper` 就可以使用另一个 `@Mapper`映射器。我们这里只加了一个，但你想在这里添加多少 class/mapper 都可以。\n\n我们已经添加了`uses`标志，所以在为`DoctorMapper`接口生成映射器实现时，MapStruct 也会把 `Patient` 模型转换成 `PatientDto` ——因为我们已经为这个任务注册了 `PatientMapper`。\n\n编译查看最新想实现代码：\n\n```TypeScript\npublic class DoctorMapperImpl implements DoctorMapper {\n    private final PatientMapper patientMapper = Mappers.getMapper( PatientMapper.class );\n\n    @Override\n    public DoctorDto toDto(Doctor doctor) {\n        if ( doctor == null ) {\n            return null;\n        }\n\n        DoctorDtoBuilder doctorDto = DoctorDto.builder();\n\n        doctorDto.patientDtoList( patientListToPatientDtoList(doctor.getPatientList()));\n        doctorDto.specialization( doctor.getSpecialty() );\n        doctorDto.id( doctor.getId() );\n        doctorDto.name( doctor.getName() );\n\n        return doctorDto.build();\n    }\n\n    protected List<PatientDto> patientListToPatientDtoList(List<Patient> list) {\n        if ( list == null ) {\n            return null;\n        }\n\n        List<PatientDto> list1 = new ArrayList<PatientDto>( list.size() );\n        for ( Patient patient : list ) {\n            list1.add( patientMapper.toDto( patient ) );\n        }\n\n        return list1;\n    }\n}\n```\n\n显然，除了`toDto()`映射方法外，最终实现中还添加了一个新的映射方法——>`patientListToPatientDtoList()`。这个方法是在没有显式定义的情况下添加的，只是因为我们把`PatientMapper`添加到了`DoctorMapper`中。\n\n该方法会遍历一个`Patient`列表，将每个元素转换为`PatientDto`，并将转换后的对象添加到`DoctorDto`对象内中的列表中。\n\n### **更新现有实例**\n\n有时，我们希望用 DTO 的最新值更新一个模型中的属性，对目标对象(我们的例子中是`DoctorDto`)使用`@MappingTarget`注解，就可以更新现有的实例.\n\n```Plain%20Text\n@Mapper(uses = {PatientMapper.class})\npublic interface DoctorMapper {\n\n    DoctorMapper INSTANCE = Mappers.getMapper(DoctorMapper.class);\n\n    @Mapping(source = \"doctorDto.patientDtoList\", target = \"patientList\")\n    @Mapping(source = \"doctorDto.specialization\", target = \"specialty\")\n    void updateModel(DoctorDto doctorDto, @MappingTarget Doctor doctor);\n}\n```\n\n重新生成实现代码，就可以得到`updateModel()`方法：\n\n```Plain%20Text\npublic class DoctorMapperImpl implements DoctorMapper {\n\n    @Override\n    public void updateModel(DoctorDto doctorDto, Doctor doctor) {\n        if (doctorDto == null) {\n            return;\n        }\n\n        if (doctor.getPatientList() != null) {\n            List<Patient> list = patientDtoListToPatientList(doctorDto.getPatientDtoList());\n            if (list != null) {\n                doctor.getPatientList().clear();\n                doctor.getPatientList().addAll(list);\n            }\n            else {\n                doctor.setPatientList(null);\n            }\n        }\n        else {\n            List<Patient> list = patientDtoListToPatientList(doctorDto.getPatientDtoList());\n            if (list != null) {\n                doctor.setPatientList(list);\n            }\n        }\n        doctor.setSpecialty(doctorDto.getSpecialization());\n        doctor.setId(doctorDto.getId());\n        doctor.setName(doctorDto.getName());\n    }\n}\n```\n\n值得注意的是，由于患者列表是该模型中的子实体，因此患者列表也会进行更新。\n\n### **数据类型映射**\n\nMapStruct 支持`source`和`target`属性之间的数据类型转换。它还提供了基本类型及其相应的包装类之间的自动转换。\n\n自动类型转换适用于：\n\n- 基本类型及其对应的包装类之间。比如， `int` 和 `Integer`， `float` 和 `Float`， `long` 和 `Long`，`boolean` 和 `Boolean` 等。\n- 任意基本类型与任意包装类之间。如 `int` 和 `long`， `byte` 和 `Integer` 等。\n- 所有基本类型及包装类与`String`之间。如 `boolean` 和 `String`， `Integer` 和 `String`， `float` 和 `String` 等。\n- 枚举和`String`之间。\n- Java 大数类型(`java.math.BigInteger`， `java.math.BigDecimal`) 和 Java 基本类型(包括其包装类)与`String`之间。\n- 其它情况详见 **[MapStruct 官方文档](https://link.zhihu.com/?target=https://mapstruct.org/documentation/stable/reference/html/#implicit-type-conversions)**。\n\n因此，在生成映射器代码的过程中，如果源字段和目标字段之间属于上述任何一种情况，则 MapStrcut 会自行处理类型转换。\n\n我们修改 `PatientDto` ，新增一个 `dateofBirth`字段：\n\n```Plain%20Text\npublic class PatientDto {\n    private int id;\n    private String name;\n    private LocalDate dateOfBirth;\n    // getters and setters or builder\n}\n```\n\n另一方面，加入 `Patient` 对象中有一个`String` 类型的 `dateOfBirth` ：\n\n```Plain%20Text\npublic class Patient {\n    private int id;\n    private String name;\n    private String dateOfBirth;\n    // getters and setters or builder\n}\n```\n\n在两者之间创建一个映射器：\n\n```Plain%20Text\n@Mapper\npublic interface PatientMapper {\n\n    @Mapping(source = \"dateOfBirth\", target = \"dateOfBirth\", dateFormat = \"dd/MMM/yyyy\")\n    Patient toModel(PatientDto patientDto);\n}\n```\n\n当对日期进行转换时，我们也可以使用 `dateFormat` 设置格式声明。生成的实现代码形式大致如下：\n\n```Plain%20Text\npublic class PatientMapperImpl implements PatientMapper {\n\n    @Override\n    public Patient toModel(PatientDto patientDto) {\n        if (patientDto == null) {\n            return null;\n        }\n\n        PatientBuilder patient = Patient.builder();\n\n        if (patientDto.getDateOfBirth() != null) {\n            patient.dateOfBirth(DateTimeFormatter.ofPattern(\"dd/MMM/yyyy\")\n                                .format(patientDto.getDateOfBirth()));\n        }\n        patient.id(patientDto.getId());\n        patient.name(patientDto.getName());\n\n        return patient.build();\n    }\n}\n```\n\n可以看到，这里使用了 `dateFormat` 声明的日期格式。如果我们没有声明格式的话，MapStruct 会使用 `LocalDate`的默认格式，大致如下：\n\n```Plain%20Text\nif (patientDto.getDateOfBirth() != null) {\n    patient.dateOfBirth(DateTimeFormatter.ISO_LOCAL_DATE\n                        .format(patientDto.getDateOfBirth()));\n}\n```\n\n- ##### **数字格式转换**\n\n上面的例子中可以看到，在进行日期转换的时候，可以通过`dateFormat`标志指定日期的格式。\n\n除此之外，对于数字的转换，也可以使用`numberFormat`指定显示格式：\n\n```Plain%20Text\n// 数字格式转换示例\n   @Mapping(source = \"price\", target = \"price\", numberFormat = \"$#.00\")\n```\n\n### **枚举映射**\n\n枚举映射的工作方式与字段映射相同。MapStruct 会对具有相同名称的枚举进行映射，这一点没有问题。但是，对于具有不同名称的枚举项，我们需要使用`@ValueMapping`注解。同样，这与普通类型的`@Mapping`注解也相似。\n\n我们先创建两个枚举。第一个是 `PaymentType`:\n\n```Plain%20Text\npublic enum PaymentType {\n    CASH,\n    CHEQUE,\n    CARD_VISA,\n    CARD_MASTER,\n    CARD_CREDIT\n}\n```\n\n比如说，这是一个应用内可用的支付方式，现在我们要根据这些选项创建一个更一般、有限的识图：\n\n```Plain%20Text\npublic enum PaymentTypeView {\n    CASH,\n    CHEQUE,\n    CARD\n}\n```\n\n现在，我们创建这两个`enum`之间的映射器接口：\n\n```Plain%20Text\n@Mapper\npublic interface PaymentTypeMapper {\n\n    PaymentTypeMapper INSTANCE = Mappers.getMapper(PaymentTypeMapper.class);\n\n    @ValueMappings({\n            @ValueMapping(source = \"CARD_VISA\", target = \"CARD\"),\n            @ValueMapping(source = \"CARD_MASTER\", target = \"CARD\"),\n            @ValueMapping(source = \"CARD_CREDIT\", target = \"CARD\")\n    })\n    PaymentTypeView paymentTypeToPaymentTypeView(PaymentType paymentType);\n}\n```\n\n这个例子中，我们设置了一般性的`CARD`值，和更具体的 `CARD_VISA`, `CARD_MASTER` 和 `CARD_CREDIT` 。两个枚举间的枚举项数量不匹配—— `PaymentType` 有 5 个值，而 `PaymentTypeView` 只有 3 个。\n\n为了在这些枚举项之间建立桥梁，我们可以使用`@ValueMappings`注解，该注解中可以包含多个`@ValueMapping`注解。这里，我们将`source`设置为三个具体枚举项之一，并将`target`设置为`CARD`。\n\nMapStruct 自然会处理这些情况：\n\n```Plain%20Text\npublic class PaymentTypeMapperImpl implements PaymentTypeMapper {\n\n    @Override\n    public PaymentTypeView paymentTypeToPaymentTypeView(PaymentType paymentType) {\n        if (paymentType == null) {\n            return null;\n        }\n\n        PaymentTypeView paymentTypeView;\n\n        switch (paymentType) {\n            case CARD_VISA: paymentTypeView = PaymentTypeView.CARD;\n            break;\n            case CARD_MASTER: paymentTypeView = PaymentTypeView.CARD;\n            break;\n            case CARD_CREDIT: paymentTypeView = PaymentTypeView.CARD;\n            break;\n            case CASH: paymentTypeView = PaymentTypeView.CASH;\n            break;\n            case CHEQUE: paymentTypeView = PaymentTypeView.CHEQUE;\n            break;\n            default: throw new IllegalArgumentException( \"Unexpected enum constant: \" + paymentType );\n        }\n        return paymentTypeView;\n    }\n}\n```\n\n`CASH`和`CHEQUE`默认转换为对应值，特殊的 `CARD` 值通过`switch`循环处理。\n\n但是，如果你要将很多值转换为一个更一般的值，这种方式就有些不切实际了。其实我们不必手动分配每一个值，只需要让 MapStruct 将所有剩余的可用枚举项（在目标枚举中找不到相同名称的枚举项），直接转换为对应的另一个枚举项。\n\n可以通过 `MappingConstants`实现这一点：\n\n```Plain%20Text\n@ValueMapping(source = MappingConstants.ANY_REMAINING, target = \"CARD\")\nPaymentTypeView paymentTypeToPaymentTypeView(PaymentType paymentType);\n```\n\n在这个例子中，完成默认映射之后，所有剩余（未匹配）的枚举项都会映射为`CARD`：\n\n```Plain%20Text\n@Override\npublic PaymentTypeView paymentTypeToPaymentTypeView(PaymentType paymentType) {\n    if ( paymentType == null ) {\n        return null;\n    }\n\n    PaymentTypeView paymentTypeView;\n\n    switch ( paymentType ) {\n        case CASH: paymentTypeView = PaymentTypeView.CASH;\n        break;\n        case CHEQUE: paymentTypeView = PaymentTypeView.CHEQUE;\n        break;\n        default: paymentTypeView = PaymentTypeView.CARD;\n    }\n    return paymentTypeView;\n}\n```\n\n还有一种选择是使用`ANY UNMAPPED`：\n\n```Plain%20Text\n@ValueMapping(source = MappingConstants.ANY_UNMAPPED, target = \"CARD\")\nPaymentTypeView paymentTypeToPaymentTypeView(PaymentType paymentType);\n```\n\n采用这种方式时，MapStruct 不会像前面那样先处理默认映射，再将剩余的枚举项映射到`target`值。而是，直接将*所有*未通过`@ValueMapping`注解做显式映射的值都转换为`target`值。\n\n### **集合映射**\n\n简单来说，使用 MapStruct 处理集合映射的方式与处理简单类型相同。\n\n我们创建一个简单的接口或抽象类并声明映射方法。 MapStruct 将根据我们的声明自动生成映射代码。 通常，生成的代码会遍历源集合，将每个元素转换为目标类型，并将每个转换后元素添加到目标集合中。\n\n- ##### **List 映射**\n\n我们先定义一个新的映射方法：\n\n```Plain%20Text\n@Mapper\npublic interface DoctorMapper {\n    List<DoctorDto> map(List<Doctor> doctor);\n}\n```\n\n生成的代码大致如下：\n\n```Plain%20Text\npublic class DoctorMapperImpl implements DoctorMapper {\n\n    @Override\n    public List<DoctorDto> map(List<Doctor> doctor) {\n        if ( doctor == null ) {\n            return null;\n        }\n\n        List<DoctorDto> list = new ArrayList<DoctorDto>( doctor.size() );\n        for ( Doctor doctor1 : doctor ) {\n            list.add( doctorToDoctorDto( doctor1 ) );\n        }\n\n        return list;\n    }\n\n    protected DoctorDto doctorToDoctorDto(Doctor doctor) {\n        if ( doctor == null ) {\n            return null;\n        }\n\n        DoctorDto doctorDto = new DoctorDto();\n\n        doctorDto.setId( doctor.getId() );\n        doctorDto.setName( doctor.getName() );\n        doctorDto.setSpecialization( doctor.getSpecialization() );\n\n        return doctorDto;\n    }\n}\n```\n\n可以看到，MapStruct 为我们自动生成了从`Doctor`到`DoctorDto`的映射方法。\n\n但是需要注意，如果我们在 DTO 中新增一个字段`fullName`，生成代码时会出现错误：\n\n```Plain%20Text\n警告: Unmapped target property: \"fullName\".\n```\n\n基本上，这意味着 MapStruct 在当前情况下无法为我们自动生成映射方法。因此，我们需要手动定义`Doctor`和`DoctorDto`之间的映射方法。具体参考之前的小节。\n\n- ##### **Set 和 Map 映射**\n\nSet 与 Map 型数据的处理方式与 List 相似。按照以下方式修改`DoctorMapper`：\n\n```Plain%20Text\n@Mapper\npublic interface DoctorMapper {\n\n    Set<DoctorDto> setConvert(Set<Doctor> doctor);\n\n    Map<String, DoctorDto> mapConvert(Map<String, Doctor> doctor);\n}\n```\n\n生成的最终实现代码如下：\n\n```Plain%20Text\npublic class DoctorMapperImpl implements DoctorMapper {\n\n    @Override\n    public Set<DoctorDto> setConvert(Set<Doctor> doctor) {\n        if ( doctor == null ) {\n            return null;\n        }\n\n        Set<DoctorDto> set = new HashSet<DoctorDto>( Math.max( (int) ( doctor.size() / .75f ) + 1, 16 ) );\n        for ( Doctor doctor1 : doctor ) {\n            set.add( doctorToDoctorDto( doctor1 ) );\n        }\n\n        return set;\n    }\n\n    @Override\n    public Map<String, DoctorDto> mapConvert(Map<String, Doctor> doctor) {\n        if ( doctor == null ) {\n            return null;\n        }\n\n        Map<String, DoctorDto> map = new HashMap<String, DoctorDto>( Math.max( (int) ( doctor.size() / .75f ) + 1, 16 ) );\n\n        for ( java.util.Map.Entry<String, Doctor> entry : doctor.entrySet() ) {\n            String key = entry.getKey();\n            DoctorDto value = doctorToDoctorDto( entry.getValue() );\n            map.put( key, value );\n        }\n\n        return map;\n    }\n\n    protected DoctorDto doctorToDoctorDto(Doctor doctor) {\n        if ( doctor == null ) {\n            return null;\n        }\n\n        DoctorDto doctorDto = new DoctorDto();\n\n        doctorDto.setId( doctor.getId() );\n        doctorDto.setName( doctor.getName() );\n        doctorDto.setSpecialization( doctor.getSpecialization() );\n\n        return doctorDto;\n    }\n}\n```\n\n与 List 映射类似，MapStruct 自动生成了`Doctor`转换为`DoctorDto`的映射方法。\n\n- ##### **集合映射策略**\n\n很多场景中，我们需要对具有父子关系的数据类型进行转换。通常来说，会有一个数据类型（父），其字段是另一个数据类型（子）的集合。\n\n对于这种情况，MapStruct 提供了一种方法来选择如何将子类型设置或添加到父类型中。具体来说，就是`@Mapper`注解中的`collectionMappingStrategy`属性，该属性可以取值为`ACCESSOR_ONLY`， `SETTER_PREFERRED`， `ADDER_PREFERRED` 或`TARGET_IMMUTABLE`。\n\n这些值分别表示不同的为子类型集合赋值的方式。默认值是`ACCESSOR_ONLY`，这意味着只能使用访问器来设置子集合。\n\n当父类型中的*Collection*字段`setter`方法不可用，但我们有一个子类型`add`方法时，这个选项就派上用场了；另一种有用的情况是父类型中的*Collection*字段是不可变的。\n\n我们新建一个类：\n\n```Plain%20Text\npublic class Hospital {\n    private List<Doctor> doctors;\n    // getters and setters or builder\n}\n```\n\n同时定义一个映射目标 DTO 类，同时定义子类型集合字段的 getter、setter 和 adder：\n\n```Plain%20Text\npublic class HospitalDto {\n\n    private List<DoctorDto> doctors;\n\n  // 子类型集合字段getter\n    public List<DoctorDto> getDoctors() {\n        return doctors;\n    }\n  // 子类型集合字段setter\n    public void setDoctors(List<DoctorDto> doctors) {\n        this.doctors = doctors;\n    }\n  // 子类型数据adder\n    public void addDoctor(DoctorDto doctorDTO) {\n        if (doctors == null) {\n            doctors = new ArrayList<>();\n        }\n\n        doctors.add(doctorDTO);\n    }\n}\n```\n\n创建对应的映射器：\n\n```Plain%20Text\n@Mapper(uses = DoctorMapper.class)\npublic interface HospitalMapper {\n    HospitalMapper INSTANCE = Mappers.getMapper(HospitalMapper.class);\n\n    HospitalDto toDto(Hospital hospital);\n}\n```\n\n生成的最终实现代码为：\n\n```Plain%20Text\npublic class HospitalMapperImpl implements HospitalMapper {\n\n    @Override\n    public HospitalDto toDto(Hospital hospital) {\n        if ( hospital == null ) {\n            return null;\n        }\n\n        HospitalDto hospitalDto = new HospitalDto();\n\n        hospitalDto.setDoctors( doctorListToDoctorDtoList( hospital.getDoctors() ) );\n\n        return hospitalDto;\n    }\n}\n```\n\n可以看到，在默认情况下采用的策略是`ACCESSOR_ONLY`，使用 setter 方法`setDoctors()`向`HospitalDto`对象中写入列表数据。\n\n相对的，如果使用 `ADDER_PREFERRED` 作为映射策略：\n\n```Plain%20Text\n@Mapper(collectionMappingStrategy = CollectionMappingStrategy.ADDER_PREFERRED,\n        uses = DoctorMapper.class)\npublic interface HospitalMapper {\n    HospitalMapper INSTANCE = Mappers.getMapper(HospitalMapper.class);\n\n    HospitalDto toDto(Hospital hospital);\n}\n```\n\n此时，会使用 adder 方法逐个将转换后的子类型 DTO 对象加入父类型的集合字段中。\n\n```Plain%20Text\npublic class CompanyMapperAdderPreferredImpl implements CompanyMapperAdderPreferred {\n\n    private final EmployeeMapper employeeMapper = Mappers.getMapper( EmployeeMapper.class );\n\n    @Override\n    public CompanyDTO map(Company company) {\n        if ( company == null ) {\n            return null;\n        }\n\n        CompanyDTO companyDTO = new CompanyDTO();\n\n        if ( company.getEmployees() != null ) {\n            for ( Employee employee : company.getEmployees() ) {\n                companyDTO.addEmployee( employeeMapper.map( employee ) );\n            }\n        }\n\n        return companyDTO;\n    }\n}\n```\n\n如果目标 DTO 中既没有`setter`方法也没有`adder`方法，会先通过`getter`方法获取子类型集合，再调用集合的对应接口添加子类型对象。\n\n可以在**[参考文档](https://link.zhihu.com/?target=https://mapstruct.org/documentation/stable/reference/html/#collection-mapping-strategies)**中看到不同类型的 DTO 定义（是否包含 setter 方法或 adder 方法），采用不同的映射策略时，所使用的添加子类型到集合中的方式。\n\n- ##### **目标集合实现类型**\n\nMapStruct 支持将集合接口作为映射方法的目标类型。\n\n在这种情况下，在生成的代码中会使用一些集合接口默认实现。 例如，上面的示例中，`List`的默认实现是`ArrayList`。\n\n常见接口及其对应的默认实现如下：\n\n无法复制加载中的内容\n\n你可以在**[参考文档](https://link.zhihu.com/?target=https://mapstruct.org/documentation/stable/reference/html/#implementation-types-for-collection-mappings)**中找到 MapStruct 支持的所有接口列表，以及每个接口对应的默认实现类型。\n\n## **进阶操作**\n\n### **依赖注入**\n\n到目前为止，我们一直在通过`getMapper()`方法访问生成的映射器：\n\n```Plain%20Text\nDoctorMapper INSTANCE = Mappers.getMapper(DoctorMapper.class);\n```\n\n但是，如果你使用的是 Spring，只需要简单修改映射器配置，就可以像常规依赖项一样注入映射器。\n\n修改 `DoctorMapper` 以支持 Spring 框架：\n\n```Plain%20Text\n@Mapper(componentModel = \"spring\")\npublic interface DoctorMapper {}\n```\n\n在`@Mapper`注解中添加`（componentModel = \"spring\"）`，是为了告诉 MapStruct，在生成映射器实现类时，我们希望它能支持通过 Spring 的依赖注入来创建。现在，就不需要在接口中添加 `INSTANCE` 字段了。\n\n这次生成的 `DoctorMapperImpl` 会带有 `@Component` 注解：\n\n```Plain%20Text\n@Component\npublic class DoctorMapperImpl implements DoctorMapper {}\n```\n\n只要被标记为`@Component`，Spring 就可以把它作为一个 bean 来处理，你就可以在其它类（如控制器）中通过`@Autowire`注解来使用它：\n\n```Plain%20Text\n@Controller\npublic class DoctorController() {\n    @Autowired\n    private DoctorMapper doctorMapper;\n}\n```\n\n如果你不使用 Spring, MapStruct 也支持**[Java CDI](https://link.zhihu.com/?target=https://docs.oracle.com/javaee/6/tutorial/doc/giwhl.html)**：\n\n```Plain%20Text\n@Mapper(componentModel = \"cdi\")\npublic interface DoctorMapper {}\n```\n\n### **添加默认值**\n\n`@Mapping` 注解有两个很实用的标志就是常量 `constant` 和默认值 `defaultValue` 。无论`source`如何取值，都将始终使用常量值； 如果`source`取值为`null`，则会使用默认值。\n\n修改一下 `DoctorMapper` ，添加一个 `constant` 和一个 `defaultValue` ：\n\n```Plain%20Text\n@Mapper(uses = {PatientMapper.class}, componentModel = \"spring\")\npublic interface DoctorMapper {\n    @Mapping(target = \"id\", constant = \"-1\")\n    @Mapping(source = \"doctor.patientList\", target = \"patientDtoList\")\n    @Mapping(source = \"doctor.specialty\", target = \"specialization\", defaultValue = \"Information Not Available\")\n    DoctorDto toDto(Doctor doctor);\n}\n```\n\n如果`specialty`不可用，我们会替换为`\"Information Not Available\"`字符串，此外，我们将`id`硬编码为`-1`。\n\n生成代码如下：\n\n```Plain%20Text\n@Component\npublic class DoctorMapperImpl implements DoctorMapper {\n\n    @Autowired\n    private PatientMapper patientMapper;\n\n    @Override\n    public DoctorDto toDto(Doctor doctor) {\n        if (doctor == null) {\n            return null;\n        }\n\n        DoctorDto doctorDto = new DoctorDto();\n\n        if (doctor.getSpecialty() != null) {\n            doctorDto.setSpecialization(doctor.getSpecialty());\n        }\n        else {\n            doctorDto.setSpecialization(\"Information Not Available\");\n        }\n        doctorDto.setPatientDtoList(patientListToPatientDtoList(doctor.getPatientList()));\n        doctorDto.setName(doctor.getName());\n\n        doctorDto.setId(-1);\n\n        return doctorDto;\n    }\n}\n```\n\n可以看到，如果 `doctor.getSpecialty()` 返回值为`null`，则将`specialization`设置为我们的默认信息。无论任何情况，都会对 `id`赋值，因为这是一个`constant`。\n\n### **添加表达式**\n\nMapStruct 甚至允许在`@Mapping`注解中输入 Java 表达式。你可以设置 `defaultExpression` （ `source` 取值为 `null`时生效），或者一个`expression`（类似常量，永久生效）。\n\n在 `Doctor` 和 `DoctorDto`两个类中都加了两个新属性，一个是 `String` 类型的 `externalId` ，另一个是`LocalDateTime`类型的 `appointment` ，两个类大致如下：\n\n```Plain%20Text\npublic class Doctor {\n\n    private int id;\n    private String name;\n    private String externalId;\n    private String specialty;\n    private LocalDateTime availability;\n    private List<Patient> patientList;\n    // getters and setters or builder\n}\n\npublic class DoctorDto {\n\n    private int id;\n    private String name;\n    private String externalId;\n    private String specialization;\n    private LocalDateTime availability;\n    private List<PatientDto> patientDtoList;\n    // getters and setters or builder\n}\n```\n\n修改 `DoctorMapper`：\n\n```Plain%20Text\n@Mapper(uses = {PatientMapper.class}, componentModel = \"spring\", imports = {LocalDateTime.class, UUID.class})\npublic interface DoctorMapper {\n\n    @Mapping(target = \"externalId\", expression = \"java(UUID.randomUUID().toString())\")\n    @Mapping(source = \"doctor.availability\", target = \"availability\", defaultExpression = \"java(LocalDateTime.now())\")\n    @Mapping(source = \"doctor.patientList\", target = \"patientDtoList\")\n    @Mapping(source = \"doctor.specialty\", target = \"specialization\")\n    DoctorDto toDtoWithExpression(Doctor doctor);\n}\n```\n\n可以看到，这里将 `externalId`的值设置为 `java(UUID.randomUUID().toString())` ，如果源对象中没有 `availability` 属性，则会把目标对象中的 `availability` 设置为一个新的 `LocalDateTime`对象。\n\n由于表达式只是字符串，我们必须在表达式中指定使用的类。但是这里的表达式并不是最终执行的代码，只是一个字母的文本值。因此，我们要在 `@Mapper` 中添加 `imports = {LocalDateTime.class, UUID.class}` 。\n\n### **添加自定义方法**\n\n到目前为止，我们一直使用的策略是添加一个“占位符”方法，并期望 MapStruct 能为我们实现它。其实我们还可以向接口中添加自定义的`default`方法，也可以通过`default`方法直接实现一个映射。然后我们可以通过实例直接调用该方法，没有任何问题。\n\n为此，我们创建一个 `DoctorPatientSummary`类，其中包含一个 `Doctor` 及其 `Patient`列表的汇总信息：\n\n```Plain%20Text\npublic class DoctorPatientSummary {\n    private int doctorId;\n    private int patientCount;\n    private String doctorName;\n    private String specialization;\n    private String institute;\n    private List<Integer> patientIds;\n    // getters and setters or builder\n}\n```\n\n接下来，我们在 `DoctorMapper`中添加一个`default`方法，该方法会将 `Doctor` 和 `Education` 对象转换为一个 `DoctorPatientSummary`:\n\n```Plain%20Text\n@Mapper\npublic interface DoctorMapper {\n\n    default DoctorPatientSummary toDoctorPatientSummary(Doctor doctor, Education education) {\n\n        return DoctorPatientSummary.builder()\n                .doctorId(doctor.getId())\n                .doctorName(doctor.getName())\n                .patientCount(doctor.getPatientList().size())\n        .patientIds(doctor.getPatientList()\n                     .stream()\n                      .map(Patient::getId)\n                     .collect(Collectors.toList()))\n              .institute(education.getInstitute())\n                .specialization(education.getDegreeName())\n                .build();\n    }\n}\n```\n\n这里使用了 Builder 模式创建`DoctorPatientSummary`对象。\n\n在 MapStruct 生成映射器实现类之后，你就可以使用这个实现方法，就像访问任何其它映射器方法一样：\n\n```Plain%20Text\nDoctorPatientSummary summary = doctorMapper.toDoctorPatientSummary(dotor, education);\n```\n\n### **创建自定义映射器**\n\n前面我们一直是通过接口来设计映射器功能，其实我们也可以通过一个带 `@Mapper` 的 `abstract` 类来实现一个映射器。MapStruct 也会为这个类创建一个实现，类似于创建一个接口实现。\n\n我们重写一下前面的示例，这一次，我们将它修改为一个抽象类：\n\n```Plain%20Text\n@Mapper\npublic abstract class DoctorCustomMapper {\n    public DoctorPatientSummary toDoctorPatientSummary(Doctor doctor, Education education) {\n\n        return DoctorPatientSummary.builder()\n                .doctorId(doctor.getId())\n                .doctorName(doctor.getName())\n                .patientCount(doctor.getPatientList().size())\n                .patientIds(doctor.getPatientList()\n                        .stream()\n                        .map(Patient::getId)\n                        .collect(Collectors.toList()))\n                .institute(education.getInstitute())\n                .specialization(education.getDegreeName())\n                .build();\n    }\n}\n```\n\n你可以用同样的方式使用这个映射器。由于限制较少，使用抽象类可以在创建自定义实现时给我们更多的控制和选择。另一个好处是可以添加`@BeforeMapping`和`@AfterMapping`方法。\n\n### **@BeforeMapping 和 @AfterMapping**\n\n为了进一步控制和定制化，我们可以定义 `@BeforeMapping` 和 `@AfterMapping`方法。显然，这两个方法是在每次映射之前和之后执行的。也就是说，在最终的实现代码中，会在两个对象真正映射之前和之后添加并执行这两个方法。\n\n可以在 `DoctorCustomMapper`中添加两个方法：\n\n```Plain%20Text\n@Mapper(uses = {PatientMapper.class}, componentModel = \"spring\")\npublic abstract class DoctorCustomMapper {\n\n    @BeforeMapping\n    protected void validate(Doctor doctor) {\n        if(doctor.getPatientList() == null){\n            doctor.setPatientList(new ArrayList<>());\n        }\n    }\n\n    @AfterMapping\n    protected void updateResult(@MappingTarget DoctorDto doctorDto) {\n        doctorDto.setName(doctorDto.getName().toUpperCase());\n        doctorDto.setDegree(doctorDto.getDegree().toUpperCase());\n        doctorDto.setSpecialization(doctorDto.getSpecialization().toUpperCase());\n    }\n\n    @Mapping(source = \"doctor.patientList\", target = \"patientDtoList\")\n    @Mapping(source = \"doctor.specialty\", target = \"specialization\")\n    public abstract DoctorDto toDoctorDto(Doctor doctor);\n}\n```\n\n基于该抽象类生成一个映射器实现类：\n\n```Plain%20Text\n@Component\npublic class DoctorCustomMapperImpl extends DoctorCustomMapper {\n\n    @Autowired\n    private PatientMapper patientMapper;\n\n    @Override\n    public DoctorDto toDoctorDto(Doctor doctor) {\n        validate(doctor);\n\n        if (doctor == null) {\n            return null;\n        }\n\n        DoctorDto doctorDto = new DoctorDto();\n\n        doctorDto.setPatientDtoList(patientListToPatientDtoList(doctor\n            .getPatientList()));\n        doctorDto.setSpecialization(doctor.getSpecialty());\n        doctorDto.setId(doctor.getId());\n        doctorDto.setName(doctor.getName());\n\n        updateResult(doctorDto);\n\n        return doctorDto;\n    }\n}\n```\n\n可以看到， `validate()` 方法会在 `DoctorDto` 对象实例化之前执行，而`updateResult()`方法会在映射结束之后执行。\n\n### **映射异常处理**\n\n异常处理是不可避免的，应用程序随时会产生异常状态。MapStruct 提供了对异常处理的支持，可以简化开发者的工作。\n\n考虑这样一个场景，我们想在 `Doctor` 映射为`DoctorDto`之前校验一下 `Doctor` 的数据。我们新建一个独立的 `Validator` 类进行校验：\n\n```Plain%20Text\npublic class Validator {\n    public int validateId(int id) throws ValidationException {\n        if(id == -1){\n            throw new ValidationException(\"Invalid value in ID\");\n        }\n        return id;\n    }\n}\n```\n\n我们修改一下 `DoctorMapper` 以使用 `Validator` 类，无需指定实现。跟之前一样， 在`@Mapper`使用的类列表中添加该类。我们还需要做的就是告诉 MapStruct 我们的 `toDto()` 会抛出 `throws ValidationException`：\n\n```Plain%20Text\n@Mapper(uses = {PatientMapper.class, Validator.class}, componentModel = \"spring\")\npublic interface DoctorMapper {\n\n    @Mapping(source = \"doctor.patientList\", target = \"patientDtoList\")\n    @Mapping(source = \"doctor.specialty\", target = \"specialization\")\n    DoctorDto toDto(Doctor doctor) throws ValidationException;\n}\n```\n\n最终生成的映射器代码如下：\n\n```Plain%20Text\n@Component\npublic class DoctorMapperImpl implements DoctorMapper {\n\n    @Autowired\n    private PatientMapper patientMapper;\n    @Autowired\n    private Validator validator;\n\n    @Override\n    public DoctorDto toDto(Doctor doctor) throws ValidationException {\n        if (doctor == null) {\n            return null;\n        }\n\n        DoctorDto doctorDto = new DoctorDto();\n\n        doctorDto.setPatientDtoList(patientListToPatientDtoList(doctor\n            .getPatientList()));\n        doctorDto.setSpecialization(doctor.getSpecialty());\n        doctorDto.setId(validator.validateId(doctor.getId()));\n        doctorDto.setName(doctor.getName());\n        doctorDto.setExternalId(doctor.getExternalId());\n        doctorDto.setAvailability(doctor.getAvailability());\n\n        return doctorDto;\n    }\n}\n```\n\nMapStruct 自动将`doctorDto`的`id`设置为`Validator`实例的方法返回值。它还在该方法签名中添加了一个 throws 子句。\n\n注意，如果映射前后的一对属性的类型与`Validator`中的方法出入参类型一致，那该字段映射时就会调用`Validator`中的方法，所以该方式请谨慎使用。\n\n### **映射配置**\n\nMapStruct 为编写映射器方法提供了一些非常有用的配置。多数情况下，如果我们已经定义了两个类型之间的映射方法，当我们要添加相同类型之间的另一个映射方法时，我们往往会直接复制已有方法的映射配置。\n\n其实我们不必手动复制这些注解，只需要简单的配置就可以创建一个相同/相似的映射方法。\n\n##### **继承配置**\n\n我们回顾一下“**[更新现有实例](https://zhuanlan.zhihu.com/p/368731266/edit#更新现有实例)**”，在该场景中，我们创建了一个映射器，根据 DoctorDto 对象的属性更新现有的 Doctor 对象的属性值：\n\n```Plain%20Text\n@Mapper(uses = {PatientMapper.class})\npublic interface DoctorMapper {\n\n    DoctorMapper INSTANCE = Mappers.getMapper(DoctorMapper.class);\n\n    @Mapping(source = \"doctorDto.patientDtoList\", target = \"patientList\")\n    @Mapping(source = \"doctorDto.specialization\", target = \"specialty\")\n    void updateModel(DoctorDto doctorDto, @MappingTarget Doctor doctor);\n}\n```\n\n假设我们还有另一个映射器，将 `DoctorDto`转换为 `Doctor` ：\n\n```Plain%20Text\n@Mapper(uses = {PatientMapper.class, Validator.class})\npublic interface DoctorMapper {\n\n    @Mapping(source = \"doctorDto.patientDtoList\", target = \"patientList\")\n    @Mapping(source = \"doctorDto.specialization\", target = \"specialty\")\n    Doctor toModel(DoctorDto doctorDto);\n}\n```\n\n这两个映射方法使用了相同的注解配置， `source`和 `target`都是相同的。其实我们可以使用`@InheritConfiguration`注释，从而避免这两个映射器方法的重复配置。\n\n如果对一个方法添加 `@InheritConfiguration` 注解，MapStruct 会检索其它的已配置方法，寻找可用于当前方法的注解配置。一般来说，这个注解都用于`mapping`方法后面的`update`方法，如下所示：\n\n```Plain%20Text\n@Mapper(uses = {PatientMapper.class, Validator.class}, componentModel = \"spring\")\npublic interface DoctorMapper {\n\n    @Mapping(source = \"doctorDto.specialization\", target = \"specialty\")\n    @Mapping(source = \"doctorDto.patientDtoList\", target = \"patientList\")\n    Doctor toModel(DoctorDto doctorDto);\n\n    @InheritConfiguration\n    void updateModel(DoctorDto doctorDto, @MappingTarget Doctor doctor);\n}\n```\n\n##### **继承逆向配置**\n\n还有另外一个类似的场景，就是编写映射函数将**_Model_** 转为 **_DTO_**，以及将 **_DTO_** 转为 **_Model_**。如下面的代码所示，我们必须在两个函数上添加相同的注释。\n\n```Plain%20Text\n@Mapper(componentModel = \"spring\")\npublic interface PatientMapper {\n\n    @Mapping(source = \"dateOfBirth\", target = \"dateOfBirth\", dateFormat = \"dd/MMM/yyyy\")\n    Patient toModel(PatientDto patientDto);\n\n    @Mapping(source = \"dateOfBirth\", target = \"dateOfBirth\", dateFormat = \"dd/MMM/yyyy\")\n    PatientDto toDto(Patient patient);\n}\n```\n\n两个方法的配置不会是完全相同的，实际上，它们应该是相反的。将 **Model** 转为 **_DTO_**，以及将 **_DTO_** 转为 **_Model_**——映射前后的字段相同，但是源属性字段与目标属性字段是相反的。\n\n我们可以在第二个方法上使用`@InheritInverseConfiguration`注解，避免写两遍映射配置：\n\n```Plain%20Text\n@Mapper(componentModel = \"spring\")\npublic interface PatientMapper {\n\n    @Mapping(source = \"dateOfBirth\", target = \"dateOfBirth\", dateFormat = \"dd/MMM/yyyy\")\n    Patient toModel(PatientDto patientDto);\n\n    @InheritInverseConfiguration\n    PatientDto toDto(Patient patient);\n}\n```\n\n这两个 Mapper 生成的代码是相同的。\n\n## **总结**\n\n在本文中，我们探讨了 MapStruct——一个用于创建映射器类的库。从基本映射到自定义方法和自定义映射器，此外， 我们还介绍了 MapStruct 提供的一些高级操作选项，包括依赖注入，数据类型映射、枚举映射和表达式使用。\n\nMapStruct 提供了一个功能强大的集成插件，可减少开发人员编写模板代码的工作量，使创建映射器的过程变得简单快捷。\n","tags":["技巧","开发工具"],"categories":["后端开发"]},{"title":"Git Flow 工作流","slug":"GitFlow工作流","url":"/2022/08/05/c7bea606.html","content":"\n## **Git Flow 简介**\n\n[Git Flow](http://nvie.com/posts/a-successful-git-branching-model/) 是构建在 Git 之上的一个组织软件开发活动的模型，是在 Git 之上构建的一项软件开发最佳实践。Git Flow 是一套使用 Git 进行源代码管理时的一套行为规范和简化部分 Git 操作的工具。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807173721.png)\n\n## **分支约定**\n\nGit Flow 有主分支和辅助分支两类分支。其中主分支用于组织与软件开发、部署相关的活动；辅助分支组织为了解决特定的问题而进行的各种开发活动。\n\n**主分支（长期分支）**\n\n- [master ](https://vanxhealth.feishu.cn/wiki/wikcnKl26BkARCg0YyaGTTYqbdg#JjEuXU)可执行版本记录分支，上面的每个节点都是发布到线上的一个版本，具体的版本号由 tag 确定\n- [develop ](https://vanxhealth.feishu.cn/wiki/wikcnKl26BkARCg0YyaGTTYqbdg#jmNw5a)代码开发分支，所有开发\n\n**辅助分支（短期分支）**\n\n- [feature ](https://vanxhealth.feishu.cn/wiki/wikcnKl26BkARCg0YyaGTTYqbdg#BglFMs)详细功能分支，每个功能分支应该尽可能的小（最好一天以内），开发完成之后尽快移入仓库中\n\n- [release ](https://vanxhealth.feishu.cn/wiki/wikcnKl26BkARCg0YyaGTTYqbdg#sUtR3F)测试版本发布分支，同时接收该版本的 bugfix，直到稳定之后再发布到 master，并合并到 develop 中。\n\n- [hotfix ](https://vanxhealth.feishu.cn/wiki/wikcnKl26BkARCg0YyaGTTYqbdg#Vq3QKh)紧急修复线上 bug 分支，直接从 master 的版本分出，同时最小版本号加 1。修复完成后发布一个最新版本，同时合并到 develop 中。\n\n- ### **主分支**\n\n主分支是所有开发活动的核心分支。所有的开发活动产生的输出物最终都会反映到主分支的代码中。主分支分为**master**分支和**develop**分支。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807173731.png)\n\n### master 分支\n\n- master 分支存放的是随时可供在生产环境中部署的稳定版本代码\n- master 分支保存官方发布版本历史，release tag 标识不同的发布版本\n- 一个项目只能有一个 master 分支\n- 仅在发布新的可供部署的代码时才更新 master 分支上的代码\n- 每次更新 master，都需对 master 添加指定格式的 tag，用于发布或回滚\n- master 分支是保护分支，不可直接 push 到远程仓 master 分支\n- master 分支代码只能被 release 分支或 hotfix 分支合并\n\n### develop 分支\n\n- develop 分支是保存当前最新开发成果的分支\n- 一个项目只能有一个 develop 分支\n- develop 分支衍生出各个 feature 分支\n- develop 分支是保护分支，不可直接 push 到远程仓库 develop 分支\n- develop 分支不能与 master 分支直接交互\n\n- ### **辅助分支**\n\n辅助分支是用于组织解决特定问题的各种软件开发活动的分支。辅助分支主要用于组织软件新功能的并行开发、简化新功能开发代码的跟踪、辅助完成版本发布工作以及对生产代码的缺陷进行紧急修复工作。这些分支与主分支不同，通常只会在有限的时间范围内存在。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807173734.png)\n\n**辅助分支包括**：\n\n- 用于开发新功能时所使用的`feature`分支\n- 用于辅助版本发布的`release`分支\n- 用于修正生产代码中的缺陷的`hotfix`分支\n\n以上这些分支都有固定的使用目的和分支操作限制。从单纯技术的角度说，这些分支与 Git 其他分支并 没有什么区别，但通过命名，我们定义了使用这些分支的方法。\n\n### feature 分支\n\n使用规范：\n\n- 命名规则：`feature/*`\n- `develop`分支的功能分支\n- feature 分支使用`develop`分支作为它们的父类分支\n- 以功能为单位从`develop`拉一个`feature`分支\n- 每个`feature`分支颗粒要尽量小，以利于快速迭代和避免冲突\n- 当其中一个 feature 分支完成后，它会合并回`develop`分支\n- 当一个功能因为各种原因不开发了或者放弃了，这个分支直接废弃不影响`develop`分支\n- feature 分支代码可以保存在开发者自己的代码库中而不强制提交到主代码库里\n- feature 分支只与 develop 分支交互，不能与 master 分支直接交互\n\n如有几个同事同时开发，需要分割成几个小功能，每个人都需要从`develop`中拉出一个`feature`分支，但是每个`feature`颗粒要尽量小，因为它需要我们能尽早`merge`回`develop`分支，否则冲突解决起来就没完没了。同时，当一个功能因为各种原因不开发了或者放弃了，这个分支直接废弃，不影响`develop`分支。\n\n### release 分支\n\n使用规范：\n\n- 命名规则：`release/*`，“\\*”以本次发布的版本号为标识\n- `release`分支主要用来为发布新版的测试、修复做准备\n- 当需要为发布新版做准备时，从 develop 衍生出一个`release`分支\n- `release`分支可以从`develop`分支上指定`commit`派生出\n- `release`分支测试通过后，合并到`master`分支并且给 master 标记一个版本号\n- `release`分支一旦建立就将独立，不可再从其他分支 pull 代码\n- 必须合并回`develop`分支和`master`分支\n\n`release`分支是为发布新的产品版本而设计的。在这个分支上的代码允许做小的缺陷修正、准备发布版本所需的各项说明信息（版本号、发布时间、编译时间等）。通过在`release`分支上进行这些工作可以让`develop`分支空闲出来以接受新的`feature`分支上的代码提交，进入新的软件开发迭代周期。\n\n当`develop`分支上的代码已经包含了所有即将发布的版本中所计划包含的软件功能，并且已通过所有测试时，我们就可以考虑准备创建`release`分支了。而所有在当前即将发布的版本之外的业务需求一定要确保不能混到`release`分支之内（避免由此引入一些不可控的系统缺陷）。\n\n成功的派生了`release`分支，并被赋予版本号之后，`develop`分支就可以为“下一个版本”服务了。所谓的“下一个版本”是在当前即将发布的版本之后发布的版本。版本号的命名可以依据项目定义的版本号命名规则进行。\n\n### hotfix 分支\n\n使用规范：\n\n- 命名规则：`hotfix/*`\n- `hotfix`分支用来快速给已发布产品修复 bug 或微调功能\n- 只能从`master`分支指定 tag 版本衍生出来\n- 一旦完成修复`bug`，必须合并回`master`分支和`develop`分支\n- `master`被合并后，应该被标记一个新的版本号\n- `hotfix`分支一旦建立就将独立，不可再从其他分支`pull`代码\n\n除了是计划外创建的以外，`hotfix`分支与`release`分支十分相似：都可以产生一个新的可供在生产环境部署的软件版本。\n\n当生产环境中的软件遇到了异常情况或者发现了严重到必须立即修复的软件缺陷的时候，就需要从`master`分支上指定的`TAG`版本派生`hotfix`分支来组织代码的紧急修复工作。\n\n这样做的显而易见的好处是不会打断正在进行的 develop 分支的开发工作，能够让团队中负责新功能开发的人与负责代码紧急修复的人并行的开展工作。\n\n## IDEA 安装 gitflow 插件\n\n### 安装\n\n前提你的电脑上需要安装了 git\n\n`idea -> file-settings -> Plugins -> marketplace`- 搜索 `Git Flow Integretion` 安装重启 `idea`\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807173738.png)\n\n点击`IDEA`右下角的`No flow`初始化分支\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807173742.png)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807173944.png)\n\n果出现 `Gitflow` 了，就表示完成了，可以使用\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807173948.png)\n\n初始化插件设置建议勾选的设置\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807174004.png)\n\n> 勾选配置说明：\n\n- Fetch from Origin （开启从远程拉取）\n\n- Push on finish feature（完成时自动推送）\n\n- Use custom tag commit message（使用自定义的打标签 commit message）\n\n### **各工作流的执行样例**\n\n#### 新功能开发 `feature`\n\n1. 点击 idea 右下角的 `Gitflow -> Start Feature -> 填写新需求的简单描述 — ok`\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807174052.png)\n\n2. 新生成的 `feature` 分支上编辑代码 -> 提交到本地（或者同时推送到远程）\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807174108.png)\n\n3. 新需求开发完成且提交到本地完成 -> 点击 `Finish Feature`\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807174120.png)\n\n4. 提测过程进行缺陷修改 -> 在该 `release` 分支上进行修改\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807174132.png)\n\n5. `Gitflow` 插件会自动将该 `release` 分支的代码合并到 `master` 和 `develop` 分支（本地和远程），并自动删除 `release` 分支，与此同时会自动触发打 `tag` 的操作\n\n**`tag` 即表示一个版本，也就是合并一个分支到 `master` 都需要打一个 tag。**\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807174217.png)\n\n6. 提测过程完成——由管理员操作执行点击`Finish Releasea`\n\n**注意：在提测未完成之前，严禁执行`Finish Releasea`！因为该操作会自动执行分支合并和删除的操作影响其他开发人员的工作**\n\n#### **常规缺陷修复** `bugfix`\n\n**本地自测 bug 修复**\n\n1. 点击 idea 右下角的 `Gitflow -> Start Bugfix -> 填写bug信息并选择需要修复的develop分支`\n\n以 `develop` 分支自测发现了 `bug`，现在要对其进行修复为例\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807174314.png)\n\n2. 在 `Bugfix` 分支上 `bug` 修复完成后 -> 点击 `Finish Bugfix` 推送修改到本地 `develop` 分支\n\n3. 将本地 `develop` 分支推送到远程\n\n**注意：**`release`**分支上的缺陷修复也可以按照该流程执行**\n\n#### 线上 bug 修复\n\n1. 修改线上 `bug` 的 `hotfix` 以 `master` 分支在运行时，出现了一个之前没有发现的 `bug`，现在要对其进行修复为例\n2. 点击 idea 右下角的 `Gitflow -> Start hotfix`\n3. 在 `hotfix` 分支上进行 `bug` 修复，提交到本地（可以一同推送到远程）\n4. 修复完成之后——点击 `Finish hotfix gitflow` 插件会自动将该 `hotfix` 分支的代码合并 `master` 和 `develop` 分支（本地和远程），并自动删除 `hotfix` 分支，与此同时会自动触发打 `tag` 的操作\n","tags":["Git","开发规范"],"categories":["DevOps"]},{"title":"Git 提交规约","slug":"Git提交规约","url":"/2022/08/02/8dc61f7f.html","content":"\n## 通用规约\n\n- **【强制】**开发环境的配置文件严禁提交到远程库（前后端都适用）\n\n```Bash\n# 本地修改配置文件之后不让git跟踪文件修改状态\n# git关闭跟踪文件修改提交\ngit update-index --assume-unchanged \"application-dev.yml\"\n# git打开跟踪文件修改提交\ngit update-index --no-assume-unchanged \"application-dev.yml\"\n```\n\n- **【强制】**必须设置 git 提交用户信息\n\n```Bash\n# git生成ssh密钥\nssh-keygen -t rsa -C \"xxx@vanxsoft.net\"\n# 查看git的配置\ngit config --list\n# 配置git用户信息，username必须为公司档案中文姓名，email必须为公司企业邮箱\ngit config --global user.name  \"username\"\ngit config --global user.email  \"email\"\n# 若出现中文乱码，请设置git的字符编码为utf-8\n```\n\n## 一、提交信息格式\n\n提交信息需保持统一的格式，每次提交的 commit message 必须包括 type、scope 和 subject 三部分。\n\n**组成部分：**\n\n主要分为下面三个部分： Header，Body，Footer。\n\n```HTML\n<type>(<scope>): <subject>\n// 空一行\n<body>\n// 空一行\n<footer>\n```\n\n下面详细解释下个个部分的含义。\n\n### 1. Header\n\nHeader 的部分只有一行,包括三个字段: type(必需), scope(可选), subject(必需)\n\n对应到 idea 插件上图的配置分别为 Header 部分的:\n\n| **type(必需)**    | **Type of change**    | **commit 类别**    |\n| ----------------- | --------------------- | ------------------ |\n| scope(可选)       | Scope of this change  | commint 影响的范围 |\n| **subject(必需)** | **Short description** | **简短的描述**     |\n\n1. ##### **type**\n\ntype 用于说明 commit 的类别，只允许使用下面标识\n\n- `feat`：新功能（feature）\n- `fix`：修补 bug\n- `docs`：文档（documentation）\n- `style`： 格式（不影响代码运行的变动,空格,格式化,等等）\n- `refactor`：重构（即不是新增功能，也不是修改 bug 的代码变动）\n- `perf`: 性能 (提高代码性能的改变)\n- `test`：增加测试或者修改测试\n- `build`: 影响构建系统或外部依赖项的更改(maven,gradle,npm 等等)\n- `ci`: 对 CI 配置文件和脚本的更改\n- `chore`：对非 src 和 test 目录的修改\n- `revert`: Revert a commit\n\n1. ##### **scope**\n\n`scope`用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。\n\n1. ##### **subject**\n\n`subject`是 commit 目的的简短描述，不超过 50 个字符。\n\n```SQL\n以动词开头，使用第一人称现在时，比如change，而不是changed或changes\n第一个字母小写\n结尾不加句号（.）\n```\n\n### 2. Body\n\nBody 部分是对本次 commit 的详细描述，可以分成多行。下面是一个范例。\n\n```XML\n如有必要，更详细的说明文本。包装它\n大概72个字左右。\n\n后面的段落在空行之后。\n\n-要点也可以\n-使用悬挂缩进\n```\n\n有一个注意点。\n\n（1）应该说明代码变动的动机，以及与以前行为的对比。\n\n### 3. Footer\n\nFooter 部分只用于两种情况。\n\n#### **（1）不兼容变动**\n\n如果当前代码与上一个版本不兼容，则 Footer 部分以`BREAKING CHANGE`开头，后面是对变动的描述、以及变动理由和迁移方法。\n\n#### **（2）关闭 Issue**\n\n> 这里填写 Jira 的 Issue ID，可以关联 Jira 问题\n\n> 这里的关闭 Issue 并不能改变 Jira Issue 的状态，Gitlab 与 Jira 的插件支持不稳定。但是可以将 Git Commit 关联到 Jira Issue\n\n如果当前 commit 针对某个 issue，那么可以在 Footer 部分关闭这个 issue 。\n\n```Nginx\nCloses #234\n```\n\n也可以一次关闭多个 issue 。\n\n```Apache\nCloses #123, #245, #992\n```\n\n最后一个完整的 `commit message` 示例如下：\n\n```HTTP\nfeature(流程管理): 流程管理\n\n-流程模型\n-人员分组\n-流程表单\n\nBREAKING CHANGE: 不兼容老版本\n\nCloses #101\n```\n\n## 二、提交信息生成方式\n\n### JetBrains 系列 IDE\n\n`JetBrains` 公司的 `IDEA`、`WebStrom` 可以安装 `Git Commit Message Plugins` 插件\n\n安装步骤如下：\n\n#### （1）安装 Git Commit Message Plugins 插件\n\n```\nFile -> Settings -> Plugins -> Marketplace -> 搜索 \"Git Commit Message Plugins\"\n```\n\n![image-20220807172600964](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807172601.png)\n\n#### （2）使用插件规范提交信息\n\n在 Commit 代码处，选择使用**Git Commit Message Plugins**插件，如下图所示\n\n![image-20220807172616778](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807172616.png)\n\n![image-20220807172624828](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807172624.png)\n\n### VS Code\n\n#### （1）安装插件\n\n扩展商店搜索 -> `git-commit-plugin` -> `安装`\n\n![image-20220807172714708](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807172714.png)\n\n#### （2）使用插件生成提交信息\n\n选择对应的部分进行填写，回车确认到下一步\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807171912.png)\n\n填写好提交信息之后正常提交即可\n\n### 命令行提交\n\n> 通过多个 -m 做到多行注释提交，每个 -m 代表一行\n\n通过多行注释提交命令，将上面说到的 `提交注释模板` 分块填写\n\n```Bash\ngit commit -m \"header\" -m \"body\" -m \"footer\"\n```\n\n例子如下：\n\n```Nginx\ngit commit -m \"feature(流程管理): 流程管理\" -m \"-流程模型\" -m \"Closes #101\"\n```\n\n### SoureTree\n\n直接在提交注释输入框内编辑注释信息即可（支持多行编辑）\n","tags":["Git","开发规范"],"categories":["DevOps"]},{"title":"Lombok 消除冗余代码","slug":"Lombok消除冗余代码","url":"/2022/08/01/e55146c8.html","content":"\n## **前言**\n\n`Lombok` 是一款 Java 开发插件，使得 `Java` 开发者可以通过其定义的一些注解来消除业务过程中冗余的代码，尤其是简单的 `Java` 模型对象（`POJO`）。而当我们如果在开发环境中使用 `Lombok` 开发插件后，可以省出重复构建，诸如 `hashCode` 和 `equals` 这样的方法以及各种业务对象模型的 `accessor` 和 `ToString` 等方法的大量时间。对于这些方法，它能够在编译源代码期间自动帮我们生产这些方法，并没有如反射那样降低程序的性能。\n\n可以用来帮助开发人员消除冗余的代码，对于一些简单的 `Java` 对象（`POJO`），它通过注释实现这一目的。\n\n## 实现原理\n\nLombok 的实现原理，基于 [JSR269(Pluggable Annotation Processing API)](https://jcp.org/en/jsr/detail?id=269) 规范，自定义编译器注解处理器，用于在 Javac 编译阶段时，扫描使用到 Lombok 定义的注解的类，进行自定义的代码生成。\n\n## 安装步骤\n\n在 IDEA 中，已经提供了 [IntelliJ Lombok plugin](https://plugins.jetbrains.com/plugin/6317-lombok) 插件，方便我们使用 Lombok。安装方式很简单，只需要在 IDEA Plugins 功能中，搜索 Lombok 关键字即可。如下图所示：\n\nIDEA 2020.3 版本以上已经内置 Lombok Plugin 插件，无需手动安装\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220807160143.png)\n\n## **Lombok 常用注解说明**\n\n| @NonNull           | 给方法参数增加这个注解会自动在方法内对该参数进行是否为空的校验，如果为空，则抛出 NPE （`NullPointerException`）                                                                                                                                                   |\n| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| @Cleanup           | 自动管理资源，用在局部变量之前，在当前变量范围内即将执行完毕退出之前会自动清理资源，自动生成 `try-finally`这样的代码来关闭流                                                                                                                                      |\n| @Getter/@Setter    | 用在属性上，再也不用自己手写 setter 和 getter 方法了，还可以指定访问范围                                                                                                                                                                                          |\n| @ToString          | 用在类上，可以自动覆写 toString 方法，当然还可以加其他参数，例如@ `ToString`(`exclude`=”`id`”)排除 id 属性，或者`@ToString`(`callSuper`=`true`,`includeFieldNames`=`true`)调用父类的 toString 方法，包含所有属性                                                  |\n| @EqualsAndHashCode | 用在类上，自动生成`equals`方法和`hashCode`方法                                                                                                                                                                                                                    |\n| @NoArgsConstructor | `@RequiredArgsConstructor` `and @AllArgsConstructor`：用在类上，自动生成无参构造和使用所有参数的构造函数以及把所有@NonNull 属性作为参数的构造函数，如果指定`staticName`= `“of”`参数，同时还会生成一个返回类对象的静态工厂方法，比使用构造函数方便很多             |\n| @Data              | 注解在类上，相当于同时使用了`@ToString`、`@EqualsAndHashCode`、`@Gette`r、`@Setter`和`@RequiredArgsConstrutor`这些注解，对于`POJO`类十分有用                                                                                                                      |\n| @Value             | 用在类上，是`@Data`的不可变形式，相当于为属性添加 final 声明，只提供`getter`方法，而不提供`setter`方法                                                                                                                                                            |\n| @Builder           | 用在类、构造器、方法上，为你提供复杂的`builder APIs`，让你可以像如下方式一样调用`Person.builder().name(\"Adam Savage\").city(\"San Francisco\").job(\"Mythbusters\").job(\"Unchained Reaction\").build();`更多说明参考`Builder`                                           |\n| @SneakyThrows      | 自动抛受检异常，而无需显式在方法上使用 throws 语句                                                                                                                                                                                                                |\n| @Synchronized      | 用在方法上，将方法声明为同步的，并自动加锁，而锁对象是一个私有的属性`$lock`或\\$`LOCK，`而`java`中的`synchronized`关键字锁对象是`this`，锁在`this`或者自己的类对象上存在副作用，就是你不能阻止非受控代码去锁 this 或者类对象，这可能会导致竞争条件或者其它线程错误 |\n| @Getter(lazy=true) | 可以替代经典的`Double Check Lock`样板代码                                                                                                                                                                                                                         |\n| @Log               | 根据不同的注解生成不同类型的`log`对象，但是实例名称都是`log`，有六种可选实现类                                                                                                                                                                                    |\n| val                | 用在局部变量前面，相当于将变量声明为 final                                                                                                                                                                                                                        |\n\n## **Lombok 代码示范**\n\n- ###### @Nonnull 为方法和构造函数的参数提供非空检查\n\n```TypeScript\npublic void notNullExample(@NonNull String string) {\n    string.length();\n}\n//=>相当于\npublic void notNullExample(String string) {\n    if (string != null) {\n        string.length();\n    } else {\n        throw new NullPointerException(\"null\");\n    }\n}\n```\n\n- ###### @Cleanup 自动释放资源\n\n```TypeScript\npublic static void main(String[] args) {\n    try {\n        @Cleanup InputStream inputStream = new FileInputStream(args[0]);\n    } catch (FileNotFoundException e) {\n        e.printStackTrace();\n    }\n    //=>相当于\n    InputStream inputStream = null;\n    try {\n        inputStream = new FileInputStream(args[0]);\n    } catch (FileNotFoundException e) {\n        e.printStackTrace();\n    } finally {\n        if (inputStream != null) {\n            try {\n                inputStream.close();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n- ###### @Getter/@Setter 对类的属性字段自动生成 Get/Set 方法\n\n```Java\n@Setter(AccessLevel.PUBLIC)\n@Getter(AccessLevel.PROTECTED)\nprivate int id;\nprivate String shap;\n```\n\n- ###### @ToString 为类生成一个 toString 方法\n\n```TypeScript\n@ToString(exclude = \"id\", callSuper = true, includeFieldNames = true)\npublic class LombokDemo {\n    private int id;\n    private String name;\n    private int age;\n    public static void main(String[] args) {\n        //输出LombokDemo(super=LombokDemo@48524010, name=null, age=0)\n        System.out.println(new LombokDemo());\n    }\n}\n```\n\n- ###### @EqualsAndHashCode 为类生成 equals 和 hasCode 方法\n\n```TypeScript\n@EqualsAndHashCode(exclude = {\"id\", \"shape\"}, callSuper = false)\npublic class LombokDemo {\n    private int id;\n    private String shap;\n}\n```\n\n- ###### @NoArgsConstructor，@RequiredArgsConstructor and @AllArgsConstructor，分别为类自动生成无参构造，指定参数构造器和包含所有参数构造器\n\n```TypeScript\n@NoArgsConstructor\n@RequiredArgsConstructor(staticName = \"of\")\n@AllArgsConstructor\npublic class LombokDemo {\n    @NonNull\n    private int id;\n    @NonNull\n    private String shap;\n    private int age;\n    public static void main(String[] args) {\n        new LombokDemo(1, \"circle\");\n        //使用静态工厂方法\n        LombokDemo.of(2, \"circle\");\n        //无参构造\n        new LombokDemo();\n        //包含所有参数\n        new LombokDemo(1, \"circle\", 2);\n    }\n}\n```\n\n- ###### @Data 在类上使用，相当于同时使用@ToString、@EqualsAndHashCode、@Getter、@Setter 和@RequiredArgsConstructor 这些注解\n\n```Java\n@Data\npublic class Menu {\n    private String shopId;\n    private String skuMenuId;\n    private String skuName;\n    private String normalizeSkuName;\n    private String dishMenuId;\n    private String dishName;\n    private String dishNum;\n    //默认阈值\n    private float thresHold = 0;\n    //新阈值\n    private float newThresHold = 0;\n    //总得分\n    private float totalScore = 0;\n}\n```\n\n- ###### @Value 为属性添加 final 声明\n\n```Java\n@Value\npublic class LombokDemo {\n    @NonNull\n    private int id;\n    @NonNull\n    private String shap;\n    private int age;\n    //相当于\n    private final int id;\n    public int getId() {\n        return this.id;\n    }\n    ...\n}\n```\n\n- ###### @Builder 提供构建值对象方式\n\n```TypeScript\n@Builder\npublic class BuilderExample {\n    private String name;\n    private int age;\n    @Singular\n    private Set<String> occupations;\n    public static void main(String[] args) {\n        BuilderExample test = BuilderExample.builder().age(11).name(\"test\").build();\n    }\n}\n```\n\n- ###### @SneakyThrows 自动抛受检异常\n\n```Java\nimport lombok.SneakyThrows;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.InputStream;\nimport java.io.UnsupportedEncodingException;\npublic class Test {\n    @SneakyThrows()\n    public void read() {\n        InputStream inputStream = new FileInputStream(\"\");\n    }\n    @SneakyThrows\n    public void write() {\n        throw new UnsupportedEncodingException();\n    }\n    //相当于\n    public void read() throws FileNotFoundException {\n        InputStream inputStream = new FileInputStream(\"\");\n    }\n    public void write() throws UnsupportedEncodingException {\n        throw new UnsupportedEncodingException();\n    }\n}\n```\n\n- ###### @Synchronized 将方法声明同步并自动加锁\n\n```TypeScript\npublic class SynchronizedDemo {\n    @Synchronized\n    public static void hello() {\n        System.out.println(\"world\");\n    }\n    //相当于\n    private static final Object $LOCK = new Object[0];\n    public static void hello() {\n        synchronized ($LOCK) {\n            System.out.println(\"world\");\n        }\n    }\n}\n```\n\n- ###### @Getter(lazy=true)可以替代经典的 Double check Lock 样板代码\n\n```Java\npublic class GetterLazyExample {\n    @Getter(lazy = true)\n    private final double[] cached = expensive();\n    private double[] expensive() {\n        double[] result = new double[1000000];\n        for (int i = 0; i < result.length; i++) {\n            result[i] = Math.asin(i);\n        }\n        return result;\n    }\n}\n\n// 相当于如下所示:\n\nimport java.util.concurrent.atomic.AtomicReference;\npublic class GetterLazyExample {\n    private final AtomicReference<java.lang.Object> cached = new AtomicReference<>();\n    public double[] getCached() {\n        java.lang.Object value = this.cached.get();\n        if (value == null) {\n            synchronized (this.cached) {\n                value = this.cached.get();\n                if (value == null) {\n                    final double[] actualValue = expensive();\n                    value = actualValue == null ? this.cached : actualValue;\n                    this.cached.set(value);\n                }\n            }\n        }\n        return (double[]) (value == this.cached ? null : value);\n    }\n    private double[] expensive() {\n        double[] result = new double[1000000];\n        for (int i = 0; i < result.length; i++) {\n            result[i] = Math.asin(i);\n        }\n        return result;\n    }\n}\n```\n\n- ###### @Log 根据不同的注解生成不同类型的 log 对象\n\n```Java\n@CommonsLog Creates log = org.apache.commons.logging.LogFactory.getLog(LogExample.class);\n@Log Creates log = java.util.logging.Logger.getLogger(LogExample.class.getName());\n@Log4j Creates log = org.apache.log4j.Logger.getLogger(LogExample.class);\n@Log4j2 Creates log = org.apache.logging.log4j.LogManager.getLogger(LogExample.class);\n@Slf4j Creates log = org.slf4j.LoggerFactory.getLogger(LogExample.class);\n@XSlf4j Creates log = org.slf4j.ext.XLoggerFactory.getXLogger(LogExample.class);\n```\n\n- ###### val 将变量声明 final 类型\n\n```Dart\npublic static void main(String[] args) {\n    val sets = new HashSet<String>();\n    val lists = new ArrayList<String>();\n    val maps = new HashMap<String, String>();\n    //=>相当于如下\n    final Set<String> sets2 = new HashSet<>();\n    final List<String> lists2 = new ArrayList<>();\n    final Map<String, String> maps2 = new HashMap<>();\n}\n```\n","tags":["技巧","开发工具"],"categories":["后端开发"]},{"title":"Floccus bookmark sync 自动同步书签","slug":"FloccusBookmarkSync自动同步书签","url":"/2022/06/19/6deb50f5.html","content":"\n## 前言\n\n本人平常工作生活中主要用到两款浏览器：Chrome、Edge。\n\nChrome 主要工作中开发调试页面情况下使用较多，Edge 装了比较多的插件，主要是生活中作为搜索工具、娱乐工具使用。\n\n同时用两个浏览器，最让我头疼的就是浏览器书签同步的问题，最近发现 [Floccus bookmarks sync](https://floccus.org/) 这款浏览器插件，搭配坚果云可以实现跨浏览器之间书签同步！\n\n## Floccus 介绍\n\nFloccus 是一款浏览器扩展，iOS 和 Android 应用程序，可在所有浏览器和设备上同步您的书签\n\n通过可选的自托管 Nextcloud 或 WebDAV 服务器，或通过 Google 云端硬盘进行可选的端到端加密\n\n## Floccus 搭配坚果云同步书签\n\nFloccus 支持 WebDAV、Nextcloud Bookmarks 和本地文件网盘同步，我这里采用的是 WebDAV 方案，配合坚果云实现。\n\n### 准备坚果云\n\n> 官网：[坚果云官网(jianguoyun.com)](https://www.jianguoyun.com/)\n\n登录坚果云官网，选择个人版（没有账号使用邮箱直接注册就行了）\n\n在同步文件夹根目录下创建一个文件夹，选择默认不同步到本地，需要同步到本地也可以，名字自定义即可，我这里是 floccus\n\n![image-20220619220802997](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619220803.png)\n\n然后上传一个 bookmarks.xbel 文件到刚才新建的文件夹里面，文件内容是：\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE xbel PUBLIC \"+//IDN python.org//DTD XML Bookmark Exchange Language 1.0//EN//XML\" \"http://pyxml.sourceforge.net/topics/dtds/xbel.dtd\">\n<xbel version=\"1.0\">\n<bookmark href=\"https://blog.kyire.site/\" id=\"1\"><title>Kyire の Blog | 记录美好生活</title></bookmark>\n</xbel>\n```\n\n接着在坚果云 `账户信息 -> 安全选项 -> 第三方应用管理 -> 创建一个 WebDAV 应用`，获取应用密码\n\n![image-20220619221328398](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619221328.png)\n\n### Floccus 插件安装和设置\n\n[Edge 扩展下载地址](https://microsoftedge.microsoft.com/addons/detail/floccus-bookmarks-sync/gjkddcofhiifldbllobcamllmanombji)、[Chrome 扩展下载地址](https://www.extfans.com/productivity/fnaicdffflnofjppbagibeoednhnbjhg/)\n\n安装好 Floccus 插件后，点击图标，新建账户：\n\n![image-20220619221912865](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619221912.png)\n\n选择 WebDAV 共享中的 XBEL 文件，点击继续\n\n![image-20220619221958514](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619221958.png)\n\n填写服务器地址（坚果云）、账号、应用密码\n\n> **这里的信息在坚果云第三方应用管理界面可以看到**\n\n![image-20220619222305268](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619222305.png)\n\n填写坚果云上的书签路径，`文件夹/bookmarks.xbel`，本地文件夹就选根路径\n\n![image-20220619222635483](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619222635.png)\n\n设置自动同步、同步间隔，选择同步策略等，按需配置即可\n\n![image-20220619222747381](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619222747.png)\n\n### 同步操作\n\n配置完成之后，点击扩展图标呼出面板，也可以**手动点击同步按钮**进行同步，同步完成之后，会**将本浏览器上的所有书签同步到坚果云**，然后你只需在另一个浏览器上再**将坚果云上的书签和本地的书签合并**，这样就实现了**跨浏览器之间的书签同步**！\n\n![image-20220619222835048](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619222835.png)\n","tags":["技巧","笔记"],"categories":["随笔小记"]},{"title":"Docker 安装 Nexus3 并搭建 Docker 私有镜像仓库","slug":"Docker安装Nexus3并搭建Docker私有镜像仓库","url":"/2022/06/17/79ad3306.html","content":"\n## 前言\n\nNexus 是 Sonatype 公司发布的一款仓库（Repository）管理软件，常用来搭建 Maven 私服，所以也有人将 Nexus 称为“Maven 仓库管理器”。\n\nNexus Repository 提供多种包格式的仓库：\n\n![image-20220617133124634](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220617133124.png)\n\n> 官方文档：https://help.sonatype.com/repomanager3\n\n## 安装部署\n\n这里采用 Docker 进行安装\n\n### 安装 nexus3\n\n```bash\ndocker run -itd \\\n--privileged=true --name=nexus3 \\\n-p 8081:8081 \\\n-p 8082:8082 \\\n-p 8083:8083 \\\n-p 8084:8084 \\\n-v /u01/cicd/nexus3/data:/nexus-data \\\nsonatype/nexus3:3.30.0\n```\n\n参数说明：\n\n`8081`：可以通过 http 访问 nexus 应用\n\n`8082`：docker(hosted)私有仓库，可以 pull 和 push\n\n`8083`：docker(proxy)代理远程仓库，只能 pull\n\n`8084`：docker(group)私有仓库和代理的组，只能 pull\n\n`-v`：建立容器与宿主机的连接，将容器中的数据持久化到宿主机上\n\n`/nexus-data`：容器内 nexus 存放数据的目录\n\n`/u01/cicd/nexus3/data`：宿主机映射容器内数据目录\n\n### 访问网页端\n\n容器启动成功后访问：http://192.168.88.236:8081/\n\n默认用户/密码：admin/admin123\n\n## 创建 Docker 镜像仓库\n\n`Repository -> Repositories -> Create repository`\n\n**repository 的类型**\n\n1. `hosted`，本地仓库，通常我们会部署自己的构件到这一类型的仓库。比如公司的第二方库。\n2. `proxy`，代理仓库，它们被用来代理远程的公共仓库，如 maven 中央仓库。\n3. `group`，仓库组，用来合并多个 hosted/proxy 仓库，当你的项目希望在多个 repository 使用资源时就不需要多次引用了，只需要引用一个 group 即可。\n\n![image-20220617134246522](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220617134246.png)\n\n### 创建 docker(hosted)类型的仓库\n\nhosted 类型的仓库主要用于将自己的镜像上传至私库。\n\n在创建镜像仓库的页面中，设置镜像仓库的相关信息（名称、HTTP 端口、是否允许匿名拉取镜像等）。\n\n**注意：这里设置的 HTTP 端口（8082）是后续拉取/推送镜像的端口**\n\n![image-20220617135103754](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220617135103.png)\n\n### 创建 docker(proxy)类型的仓库\n\nproxy 类型的仓库主要是用于代理中央镜像仓库，从外网将镜像拉取至本地仓库中。\n\n这里用的是阿里云的镜像地址，国内访问比较快。\n\n![image-20220617141027757](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220617141027.png)\n\n### 创建 docker(group)类型的仓库\n\n用于拉取镜像到本地使用，集成代理仓库和本地仓库的镜像。\n\n![image-20220617141322000](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220617141322.png)\n\n### 配置 Docker Realm\n\n将 Docker Bearer Token Realm 配置到右边，保存\n\n![image-20220617141707436](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220617141707.png)\n\n### 修改 docker 配置\n\n在 `/etc/docker/daemon.json` 文件中添加下面的内容：\n\n```bash\n$ vim /etc/docker/daemon.json\n{\n  \"insecure-registries\": [\"192.168.88.236:8082\",\"192.168.88.236:8084\"]\n}\n```\n\n- `8082`：`docker-hosted` 仓库端口\n- `8084`：`docker-group` 仓库端口\n\n重启 `docker` 服务\n\n```bash\n$ service docker restart\n\n# 查看是否生效\n$ docker info\nInsecure Registries:\n 192.168.88.236:8082\n 192.168.88.236:8084\n 127.0.0.0/8\n```\n\n### 上传/拉取镜像\n\n#### 登录私服\n\n```bash\n$ docker login -u admin -p wx123\\!@# 192.168.88.236:8082\nWARNING! Using --password via the CLI is insecure. Use --password-stdin.\nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded # 登录成功\n```\n\n#### 上传镜像\n\n```bash\n# 拉取 hello-wrold 镜像\n$ docker pull hello-world\nUsing default tag: latest\nlatest: Pulling from library/hello-world\n2db29710123e: Pull complete\nDigest: sha256:13e367d31ae85359f42d637adf6da428f76d75dc9afeb3c21faea0d976f5c651\nStatus: Downloaded newer image for hello-world:latest\ndocker.io/library/hello-world:latest\n# 创建 tag（仓库地址/镜像名称:TAG）\n$ docker tag hello-world 192.168.88.236:8082/myhello-world:1.0\n# push 镜像\n$ docker push 192.168.88.236:8082/myhello-world:1.0\nThe push refers to repository [192.168.88.236:8082/myhello-world]\ne07ee1baac5f: Pushed\n1.0: digest: sha256:f54a58bc1aac5ea1a25d796ae155dc228b3f0e11d046ae276b39c4bf2f13d8c4 size: 525\n```\n\n**上传私库成功！**\n\n![image-20220624120029872](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220624120037.png)\n\n#### 拉取镜像\n\n```bash\n$ docker pull 192.168.88.236:8082/myhello-world:1.0\n1.0: Pulling from myhello-world\nDigest: sha256:f54a58bc1aac5ea1a25d796ae155dc228b3f0e11d046ae276b39c4bf2f13d8c4\nStatus: Image is up to date for 192.168.88.236:8082/myhello-world:1.0\n192.168.88.236:8082/myhello-world:1.0\n```\n\n### 权限管理\n\n默认是使用 `admin` 用户登录的，权限太高，可以创建一个 `docker` 账号，并创建对应的角色，分配 `nx-repository-view-docker-*-*` 权限\n\n**创建角色**\n\n![image-20220624131513867](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220624131513.png)\n\n**创建用户**\n\n创建用户，并加入对应的角色组\n\n![image-20220624131705122](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220624131705.png)\n","tags":["Docker","容器"],"categories":["Linux"]},{"title":"使用 GitHub Actions 自动发布 Hexo 博客","slug":"GitHub-Actions自动发布Hexo博客","url":"/2022/06/16/47488464.html","content":"\n## GitHub Actions 简介\n\n`GitHub Actions` 是一个持续集成和持续交付 (`CI/CD`) 平台，可用于自动执行构建、测试和部署管道。 您可以创建工作流程来构建和测试存储库的每个拉取请求，或将合并的拉取请求部署到生产环境。\n\n`GitHub Actions` 不仅仅是 `DevOps`，还允许您在存储库中发生其他事件时运行工作流程。 例如，您可以运行工作流程，以便在有人在您的存储库中创建新问题时自动添加相应的标签。\n\n`GitHub Actions` 有一些自己的术语。\n\n（1）**workflow** （工作流程）：持续集成一次运行的过程，就是一个 workflow。\n\n（2）**job** （任务）：一个 workflow 由一个或多个 jobs 构成，含义是一次持续集成的运行，可以完成多个任务。\n\n（3）**step**（步骤）：每个 job 由多个 step 构成，一步步完成。\n\n（4）**action** （动作）：每个 step 可以依次执行一个或多个命令（action）。\n\n## 环境准备\n\n我的个人站点 [Kyire の Blog - 记录美好生活](https://blog.kyire.site/) 是通过 [Hexo](https://hexo.io/zh-cn/) 框架搭建的。\n\n> 搭建方法可参考：[Hexo+Gitee 搭建个人博客 | Kyire の Blog](https://blog.kyire.site/2021/02/06/8fe2b6a8.html)\n\n准备三个仓库：\n\n- 私有`Hexo`源码仓库（`Blog`）：博客文章以及`Hexo`源代码\n- `GitHub`公共静态页面仓库（`Kyire6.github.io`）：`Hexo`源码编译后生成的静态页面\n- `Gitee`公共静态页面仓库（`Kyire6`）：内容跟 `Kyire6.github.io` 一样，只是使用的服务不同\n\n自动部署的流程如下：\n\n![image-20220615223542331](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220615223549.png)\n\n## GitHub 密钥配置\n\n生成 `ssh密钥对`，用于部署静态文件，以及更新 `Gitee Pages` 服务：\n\n1. **生成密钥**\n\n执行如下命令生成 `ssh密钥对`，替换邮件地址为你的**GitHub 邮箱**地址：\n\n```bash\nssh-keygen -f hexo-deploy-key -t rsa -C \"username@example.com\"\n```\n\n命令执行后会生成两个文件：`hexo-deploy-key`（私钥） 和 `hexo-deploy-key.pub`（公钥）\n\n2. **将公钥添加到 Github Pages 仓库中**\n\n`Kyire6.github.io仓库 -> Settings -> Deploy keys -> Add deploy key`\n\n- `Title` 设置为 `HEXO_DEPLOY_PUB`\n- `Key` 填写 `hexo-deploy-key.pub` 文件内容\n- 勾选 `Allow write access` 选项\n\n![image-20220615231127446](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220615231127.png)\n\n3. **将私钥添加到博客源码仓库中**\n\n`Blog仓库 -> Settings -> Secrets -> Actions -> New repository secret`\n\n- `Name` 填写 `HEXO_DEPLOY_KEY`\n- `Value` 填写 `github-deploy-key` 文件内容\n\n![image-20220615231916597](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220615231916.png)\n\n4. **将 Gitee 账号密码添加到博客源码仓库中**\n\n`Blog仓库 -> Settings -> Secrets -> Actions -> New repository secret`\n\n- `Name` 填写 `GITEE_PASSWORD`\n- `Value` 填写 `Gitee账号的密码`\n\n![image-20220615233124815](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220615233124.png)\n\n## Gitee 密钥配置\n\n> 直接使用之前生成的密钥\n\n1. **将公钥添加到 Gitee Pages 仓库中**\n\n`Kyire6仓库 -> 管理 -> 部署公钥管理 -> 添加公钥`\n\n和 `GitHub` 一样需要对仓库有写权限，点击`【添加个人公钥】`\n\n![image-20220615232742168](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220615232742.png)\n\n- `标题` 设置为 `HEXO_DEPLOY_PUB`\n- `公钥` 填写 `hexo-deploy-key.pub` 文件内容\n\n![image-20220615232822304](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220615232822.png)\n\n## 配置 GitHub Actions\n\n在博客源码仓库（Blog）中，编写 `workflow` 文件\n\n在仓库的根目录下创建 `.github/workflow/deploy.yml` 文件，yaml 文件名可以自定义。\n\n下面是结合 [Hexo Action](https://github.com/marketplace/actions/hexo-action#🍌example-workflow---hexo-deploy)和[Gitee Pages Action ](https://github.com/marketplace/actions/gitee-pages-action)的 `workflow` 文件\n\n```yaml\nname: Hexo deploy\n\non:\n  push:\n    paths-ignore:\n      - 'source/_drafts/**'\n      - '.github/**'\njobs:\n  build:\n    runs-on: ubuntu-latest\n    name: A job to deploy blog.\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v1\n      with:\n        submodules: true\n\n    - name: Cache node modules\n      uses: actions/cache@v1\n      id: cache\n      with:\n        path: node_modules\n        key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}\n        restore-keys: |\n          ${{ runner.os }}-node-\n    - name: Install Dependencies\n      if: steps.cache.outputs.cache-hit != 'true'\n      run: npm ci\n\n    # Deploy hexo blog website.\n    - name: Deploy\n      id: deploy\n      uses: sma11black/hexo-action@v1.0.4\n      with:\n        # 用于访问 GitHub 静态页面仓库的部署密钥（私钥）。\n        deploy_key: ${{ secrets.HEXO_DEPLOY_KEY }}\n        # 用于部署的 github 帐户的用户名。\n        user_name: Kyire6\n        # 用于部署的 github 帐户的用户电子邮件。\n        user_email: kyire666@outlook.com\n        commit_msg: ${{ github.event.head_commit.message }}\n    - name: Get the output\n      run: |\n        echo \"${{ steps.deploy.outputs.notify }}\"\n  sync:\n    needs: build\n    runs-on: ubuntu-latest\n    steps:\n      - name: Sync to Gitee\n        uses: wearerequired/git-mirror-action@master\n        env:\n          # 用于访问 GitHub 静态页面仓库的部署密钥（私钥）。\n          SSH_PRIVATE_KEY: ${{ secrets.HEXO_DEPLOY_KEY }}\n        with:\n          # 源仓库\n          source-repo: git@github.com:Kyire6/Kyire6.github.io.git\n          # 目标仓库\n          destination-repo: git@gitee.com:Kyire6/Kyire6.git\n  reload-pages:\n    needs: sync\n    runs-on: ubuntu-latest\n    steps:\n      - name: Build Gitee Pages\n        uses: yanglbme/gitee-pages-action@main\n        with:\n          # Gitee登录用户名\n          gitee-username: Kyire6\n          # Gitee账号密码\n          gitee-password: ${{ secrets.GITEE_PASSWORD }}\n          # Gitee仓库名称，注意大小写\n          gitee-repo: Kyire6/Kyire6\n          # 仓库分支名，根据实际情况填写\n          branch: master\n```\n\n**部分字段解释：**\n\n1. `name`：workflow 名称\n\n2. `on`：触发 workflow 的事件\n\n   - `push`：push 事件\n   - `paths-ignore`：忽略指定的目录，也就是在忽略路径外的其它目录文件改动时才触发\n   - 还可以设置多种触发条件，比如支持 cron 语法实现定时触发，参考[这里](https://docs.github.com/cn/actions/reference/events-that-trigger-workflows)\n\n3. `jobs`：执行任务\n   - `build`：博客编译和发布，发布到 Github Pages\n   - `sync`：将更新后的 hiyongz.github.io 仓库同步到 Gitee\n   - `reload-pages`：自动更新 Pages，因为 Gitee Pages 不像 GitHub Pages 那样提交代码就自动更新。\n   - `runs-on`：运行环境，支持 windows，Ubuntu 和 macOS\n   - `steps`：指定每个 Job 的运行步骤\n   - `sma11black/hexo-action@v1.0.4`：博客构建发布，引用了 Hexo Action：\n   - `wearerequired/git-mirror-action@master`：仓库同步，引用了 git-mirror-action\n   - `yanglbme/gitee-pages-action@main`：自动更新 Gitee Pages，引用了 Gitee Pages Action\n\n> 参考资料：[GitHub Actions 的工作流程语法 - GitHub Docs](https://docs.github.com/cn/actions/using-workflows/workflow-syntax-for-github-actions)\n\n## 效果\n\n更新文章之后，提交博客源码到 `Blog` 仓库，满足 `GitHub Actions` 条件，触发 `deploy.yml` 中的编写的流水线：\n\n![image-20220615235619570](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220615235619.png)\n\n流水线运行成功，查看 `Kyire6.github.io` 和 Gitee 的 `Kyire6` 仓库可以发现都有更新（静态页面公共仓库），并且 `Gitee Pages` 服务也自动触发更新了，这样就通过 `GitHub Actions` 实现 `Hexo` 博客的自动发布。\n\n> **以后只需要将文章写好之后，push 到博客源码仓库后，触发流水线自动编译并部署，实现 CI/CD 操作，提升效率，避免重复的人工操作！**\n","tags":["笔记","Git","Hexo","GitHub"],"categories":["随笔小记"]},{"title":"Redis 集群部署案例设计","slug":"Redis集群部署案例","url":"/2022/06/06/11eee9b8.html","content":"\n## 面试题：1~2 亿条数据需要缓存，请问如何设计这个存储案例？\n\n单机单台 100%不可能，肯定是分布式存储，用 redis 如何落地？\n\n### 哈希取余分区\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606231141.png\" alt=\"image-20220606231134623\" style=\"zoom:50%;\" />\n\n2 亿条记录就是 2 亿个 k,v，我们单机不行必须要分布式多机，假设有 3 台机器构成一个集群，用户每次读写操作都是根据公式：\n\nhash(key) % N 个机器台数，计算出哈希值，用来决定数据映射到哪一个节点上。\n\n- 优点\n\n简单粗暴，直接有效，只需要预估好数据规划好节点，例如 3 台、8 台、10 台，就能保证一段时间的数据支撑。使用 Hash 算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡+分而治之的作用。\n\n- 缺点\n\n原来规划好的节点，进行扩容或者缩容就比较麻烦了，不管扩缩，每次数据变动导致节点有变动，映射关系需要重新进行计算，在服务器个数固定不变时没有问题，如果需要弹性扩容或故障停机的情况下，原来的取模公式就会发生变化：Hash(key)/3 会变成 Hash(key) /?。此时地址经过取余运算的结果将发生很大变化，根据公式获取的服务器也会变得不可控。某个 redis 机器宕机了，由于台数数量变化，会导致 hash 取余全部数据重新洗牌。\n\n### 一致性 Hash 算法分区\n\n> 一致性 Hash 算法背景\n>\n> 一致性哈希算法在 1997 年由麻省理工学院中提出的，设计目标是为了解决分布式缓存数据变动和映射问题，某个机器宕机了，分母数量改变了，自然取余数不 OK 了。\n\n1. 算法构建一致性哈希环\n\n一致性哈希环\n\n一致性哈希算法必然有个 hash 函数并按照算法产生 hash 值，这个算法的所有可能哈希值会构成一个全量集，这个集合可以成为一个 hash 空间[0,2^32-1]，这个是一个线性空间，但是在算法中，我们通过适当的逻辑控制将它首尾相连(0 = 2^32),这样让它逻辑上形成了一个环形空间。\n\n它也是按照使用取模的方法，前面笔记介绍的节点取模法是对节点（服务器）的数量进行取模。而一致性 Hash 算法是对 2^32 取模，简单来说，一致性 Hash 算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数 H 的值空间为 0-2^32-1（即哈希值是一个 32 位无符号整形），整个哈希环如下图：整个空间按顺时针方向组织，圆环的正上方的点代表 0，0 点右侧的第一个点代表 1，以此类推，2、3、4、……直到 2^32-1，也就是说 0 点左侧的第一个点代表 2^32-1， 0 和 2^32-1 在零点中方向重合，我们把这个由 2^32 个点组成的圆环称为 Hash 环。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606231532.png\" alt=\"image-20220606231532166\" style=\"zoom:50%;\" />\n\n2. 服务器 IP 节点映射\n\n节点映射\n\n将集群中各个 IP 节点映射到环上的某一个位置。将各个服务器使用 Hash 进行一个哈希，具体可以选择服务器的 IP 或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。假如 4 个节点 NodeA、B、C、D，经过 IP 地址的哈希函数计算(hash(ip))，使用 IP 地址哈希后在环空间的位置如下：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606231612.png\" alt=\"image-20220606231612002\" style=\"zoom:50%;\" />\n\n3. key 落到服务器的落键规则\n\n当我们需要存储一个 kv 键值对时，首先计算 key 的 hash 值，hash(key)，将这个 key 使用相同的函数 Hash 计算出哈希值并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器，并将该键值对存储在该节点上。\n\n如我们有 Object A、Object B、Object C、Object D 四个数据对象，经过哈希计算后，在环空间上的位置如下：根据一致性 Hash 算法，数据 A 会被定为到 Node A 上，B 被定为到 Node B 上，C 被定为到 Node C 上，D 被定为到 Node D 上。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606231644.png\" alt=\"image-20220606231644182\" style=\"zoom:50%;\" />\n\n- 优点\n\n**容错性**\n\n假设 Node C 宕机，可以看到此时对象 A、B、D 不会受到影响，只有 C 对象被重定位到 Node D。一般的，在一致性 Hash 算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。简单说，就是 C 挂了，受到影响的只是 B、C 之间的数据，并且这些数据会转移到 D 进行存储。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606231817.png\" alt=\"image-20220606231816969\" style=\"zoom:50%;\" />\n\n**扩展性**\n\n数据量增加了，需要增加一台节点 NodeX，X 的位置在 A 和 B 之间，那收到影响的也就是 A 到 X 之间的数据，重新把 A 到 X 的数据录入到 X 上即可，不会导致 hash 取余全部数据重新洗牌。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606231839.png\" alt=\"image-20220606231839770\" style=\"zoom:50%;\" />\n\n- 缺点\n\nHash 环的数据倾斜问题\n\n一致性 Hash 算法在服务**节点太少时**，容易因为节点分布不均匀而造成**数据倾斜**（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606231915.png\" alt=\"image-20220606231915547\" style=\"zoom:50%;\" />\n\n> **总结**\n>\n> 为了在节点数目发生改变时尽可能少的迁移数据\n>\n> 将所有的存储节点排列在收尾相接的 Hash 环上，每个 key 在计算 Hash 后会==顺时针==找到临近的存储节点存放。\n>\n> 而当有节点加入或退出时仅影响该节点在 Hash 环上==顺时针相邻的后续节点==。\n>\n> - **优点**\n>\n> 加入和删除节点只影响哈希环中顺时针方向的相邻的节点，对其他节点无影响。\n>\n> - **缺点**\n>\n> 数据的分布和节点的位置有关，因为这些节点不是均匀的分布在哈希环上的，所以数据在进行存储时达不到均匀分布的效果。\n\n### 哈希槽分区\n\n> ==为什么出现？==\n>\n> 解决一致性哈希算法出现的数据倾斜问题\n>\n> 哈希槽实质就是一个数组，数组[0,2^14 -1]形成 hash slot 空间。\n>\n> ==能干什么？==\n>\n> 解决均匀分配的问题，在数据和节点之间又加入了一层，把这层称为哈希槽（slot），用于管理数据和节点之间的关系，现在就相当于节点上放的是槽，槽里放的是数据。\n>\n> 槽解决的是粒度问题，相当于把粒度变大了，这样便于数据移动。\n>\n> 哈希解决的是映射问题，使用 key 的哈希值来计算所在的槽，便于数据分配。\n>\n> ==多少个哈希槽？==\n>\n> 一个集群只能有 16384 个槽，编号 0-16383（0-2^14-1）。这些槽会分配给集群中的所有主节点，分配策略没有要求。可以指定哪些编号的槽分配给哪个主节点。集群会记录节点和槽的对应关系。解决了节点和槽的关系后，接下来就需要对 key 求哈希值，然后对 16384 取余，余数是几 key 就落入对应的槽里。slot = CRC16(key) % 16384。以槽为单位移动数据，因为槽的数目是固定的，处理起来比较容易，这样数据移动问题就解决了。\n\n**哈希槽计算**\n\nRedis 集群中内置了 16384 个哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，也就是映射到某个节点上。如下代码，key 之 A 、B 在 Node2， key 之 C 落在 Node3 上。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606232459.png\" alt=\"image-20220606232459710\" style=\"zoom:50%;\" />\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606232446.png\" alt=\"image-20220606232446308\" style=\"zoom:50%;\" />\n","tags":["笔记","面试","Redis"],"categories":["中间件"]},{"title":"SpringBoot2 核心技术","slug":"SpringBoot2核心技术","url":"/2022/05/18/5862bae2.html","content":"\n## 基础入门\n\n### 1、Spring 生态圈\n\n> Spring 官网：https://spring.io\n\n**Spring 能做什么？**\n\n![image-20220515171609895](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220515171610.png)\n\n**Spring 的生态：**\n\n- web 开发\n- 数据访问\n- 安全控制\n- 分布式\n- 消息服务\n- 移动开发\n- 批处理\n- ...\n\n### 2、为什么使用 SpringBoot？\n\n> Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can “just run”.\n>\n> 能快速创建出生产级别的 Spring 应用。\n\n**SpringBoot 的优点：**\n\n- 创建独立 Spring 应用\n- 内嵌 web 服务器\n- 自动 starter 依赖，简化构建配置\n- 自动配置 Spring 以及第三方功能\n- 提供生产级别的监控、健康检查及外部化配置\n- 无代码生成、无需编写 XML\n- SpringBoot 是整合 Spring 技术栈的一站式框架\n- SpringBoot 是简化 Spring 技术栈的快速开发脚手架\n\n**SpringBoot 的缺点：**\n\n- 人称版本帝，社区活跃，迭代快，需要时刻关注版本变化\n- 封装太深，内部原理复杂，不容易精通\n\n### 3、时代背景\n\nSpringBoot 诞生的时代背景，为了解决什么样的应用场景？\n\n#### 3.1、微服务\n\n[James Lewis and Martin Fowler (2014)](https://martinfowler.com/articles/microservices.html) 提出微服务完整概念。\n\n> In short, the **microservice architectural style** is an approach to developing a single application as a **suite of small services**, each **running in its own process** and communicating with **lightweight** mechanisms, often an **HTTP** resource API. These services are **built around business capabilities** and **independently deployable** by fully **automated deployment** machinery. There is a **bare minimum of centralized management** of these services, which may be **written in different programming languages** and use different data storage technologies.-- [James Lewis and Martin Fowler (2014)](https://martinfowler.com/articles/microservices.html)\n\n**主要提出：**\n\n- 微服务是一种架构风格\n- 一个应用拆分为一组小型服务\n- 每个服务运行在自己的进程内，也就是可独立部署和升级\n- 服务之间使用轻量级 HTTP 交互\n- 服务围绕业务功能拆分\n- 可以由全自动部署机制独立部署\n- 去中心化，服务自治。服务可以使用不同的语言、不同的存储技术\n\n#### 3.2、分布式\n\n分布式架构，讲得是系统服务分布在多个物理隔离的节点上运行，统一对外提供服务。从用户层面来看，就是一组服务节点组成一个系统。\n\n**分布式有哪些困难：**\n\n- 远程调用\n- 服务发现\n- 负载均衡\n- 服务容错\n- 配置管理\n- 服务监控\n- 链路追踪\n- 日志管理\n- 任务调度\n- ...\n\n**分布式的解决方案：**\n\n==SpringBoot + SpringCloud==\n\n### 4、如何学习 SpringBoot？\n\n> 官方文档：https://docs.spring.io/spring-boot/docs/current/reference/html/\n>\n> 版本更新日志：https://github.com/spring-projects/spring-boot/wiki#release-notes\n\n### 5、SpringBoot 特点\n\n首先快速搭建一个`SpringBoot`应用\n\n#### 5.1、准备工作\n\n**系统要求**\n\n- [Java 8](https://www.java.com/) & 兼容 java14 .\n- Maven 3.3+\n- idea 2022.1\n\n##### maven 设置\n\n```xml\n<mirrors>\n    <mirror>\n        <id>nexus-aliyun</id>\n        <mirrorOf>central</mirrorOf>\n        <name>Nexus aliyun</name>\n        <url>http://maven.aliyun.com/nexus/content/groups/public</url>\n    </mirror>\n</mirrors>\n\n<profiles>\n    <profile>\n        <id>jdk-1.8</id>\n        <activation>\n            <activeByDefault>true</activeByDefault>\n            <jdk>1.8</jdk>\n        </activation>\n        <properties>\n            <maven.compiler.source>1.8</maven.compiler.source>\n            <maven.compiler.target>1.8</maven.compiler.target>\n            <maven.compiler.compilerVersion>1.8</maven.compiler.compilerVersion>\n        </properties>\n    </profile>\n</profiles>\n```\n\n##### 创建一个 maven 项目\n\n- 创建工程\n\n过程略，使用 idea 创建即可\n\n- 引入依赖\n\n```xml\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>2.6.7</version>\n</parent>\n\n\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n</dependencies>\n```\n\n- 创建主程序\n\n```java\n/**\n * 主程序类\n * @SpringBootApplication：这是一个SpringBoot应用\n */\n@SpringBootApplication\npublic class MainApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(MainApplication.class,args);\n    }\n}\n```\n\n- 编写接口\n\n```java\n@RestController\npublic class HelloController {\n\n\n    @RequestMapping(\"/hello\")\n    public String handle01(){\n        return \"Hello, Spring Boot 2!\";\n    }\n\n}\n```\n\n- 简化配置\n\n`application.properties`\n\n```\nserver.port=8888\n```\n\n- 测试\n\n运行启动类中的 main 方法，访问接口测试：localhost:8888/hello\n\n#### 5.2、依赖管理\n\n- **父项目做依赖管理**\n\n```xml\n<!-- 父项目 -->\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>2.6.7</version>\n</parent>\n\n<!-- spring-boot-starter-parent的父项目 -->\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-dependencies</artifactId>\n    <version>2.6.7</version>\n</parent>\n<!-- 几乎声明了所有开发中常用的依赖的版本号，自动版本仲裁机制 -->\n```\n\n- **开发导入 starter 场景启动器**\n\n官方支持的的 starter 列表：[Spring Boot Starters](https://docs.spring.io/spring-boot/docs/current/reference/html/using.html#using-boot-starter)\n\n`spring-boot-starter-*`：这个 `*` 代表的就是某种场景，引入场景启动器可以帮助我们简化开发，依赖管理\n\n第三方场景启动器：`*-spring-boot-starter`\n\n```\n<!-- 所有的场景启动器最底层的依赖 -->\n<dependency>\n  <groupId>org.springframework.boot</groupId>\n  <artifactId>spring-boot-starter</artifactId>\n  <version>2.6.7</version>\n  <scope>compile</scope>\n</dependency>\n```\n\n- **无需关注版本号，自动根据场景启动器版本仲裁（父项目）**\n\n  1. 引入依赖默认都可以不写版本\n  2. 引入非版本仲裁的 jar，要写版本号。\n\n- **可以修改默认版本号**\n  1. 查看 spring-boot-dependencies 里面规定当前依赖的版本 用的 key\n  2. 在当前项目里面重写配置\n\n```\n<properties>\n\t<mysql.version>5.1.43</mysql.version>\n</properties>\n```\n\n#### 5.3、自动配置\n\n`spring-boot-starter-web` 这个场景启动器会帮助我们做好很多配置\n\n- 自动配置好 Tomcat\n\n  - 引入 Tomcat 依赖\n  - 配置 Tomcat\n\n  ```xml\n  <dependency>\n      <groupId>org.springframework.boot</groupId>\n      <artifactId>spring-boot-starter-tomcat</artifactId>\n      <version>2.6.7</version>\n      <scope>compile</scope>\n  </dependency>\n  ```\n\n- 自动配好 SpringMVC\n\n- - 引入 SpringMVC 全套组件\n  - 自动配置好 SpringMVC 常用组件（功能）\n\n- 自动配好 Web 常用功能，如：字符编码问题\n  - SpringBoot 帮我们配置好了所有 web 开发的常用场景\n- 默认的包结构\n  - 主程序所在的包及其下面的所有子包里面的组件都会被扫描进来\n  - 无需以前的包扫描配置\n  - 想要改变扫描路径，@SpringBootApplication(scanBasePackages=\"com.vansys\")\n    - 或者使用@ComponentScan 指定扫描路径\n\n```\n@SpringBootApplication\n等同于\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\"com.vansys\")\n```\n\n- 各种配置拥有默认值\n  - 默认配置最终都是映射到某个类上，如：MultipartProperties\n  - 配置文件的值最终会绑定在每个类上，这个类会在容器中创建对象\n- 按需加载所有自动配置项\n  - 非常多的 starter\n  - 引入了哪些场景，相对应的场景才会开启\n  - SprongBoot 所有的自动配置功能都在 spring-boot-autoconfigure 包里面\n- ...\n\n### 6、容器功能\n\n#### 6.1、组件添加\n\n##### @Configuration\n\n- 基本使用\n\n- Full 模式与 Lite 模式\n\n  - 配置类组件之间无依赖关系用 Lite 模式，加速容器的启动过程，减少判断\n\n  - 配置类组件之间有依赖关系，方法会被调用得到之前的单实例组件，用 Full 模式\n\n```java\n#############################Configuration使用示例######################################\n/**\n * 1、配置类里面使用@Bean标注在方法上给容器注册组件，默认也是单实例的\n * 2、配置类本身也是组件\n * 3、proxyBeanMethods：代理bean的方法\n *      Full(proxyBeanMethods = true)、【保证每个@Bean方法被调用多少次返回的组件都是单实例的】\n *      Lite(proxyBeanMethods = false)【每个@Bean方法被调用多少次返回的组件都是新创建的】\n *      组件依赖必须使用Full模式默认。其他默认是否Lite模式\n */\n@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件\npublic class MyConfig {\n\n    /**\n     * Full:外部无论对配置类中的这个组件注册方法调用多少次获取的都是之前注册容器中的单实例对象\n     * @return\n     */\n    @Bean //给容器中添加组件。以方法名作为组件的id。返回类型就是组件类型。返回的值，就是组件在容器中的实例\n    public User user01(){\n        User zhangsan = new User(\"zhangsan\", 18);\n        //user组件依赖了Pet组件\n        zhangsan.setPet(tomcatPet());\n        return zhangsan;\n    }\n\n    @Bean(\"tom\")\n    public Pet tomcatPet(){\n        return new Pet(\"tomcat\");\n    }\n}\n\n\n#########################@Configuration测试代码如下###################################\n@SpringBootApplication\npublic class MainApplication {\n\n    public static void main(String[] args) {\n        //1、返回我们IOC容器\n        ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\n\n        //2、查看容器里面的组件\n        String[] names = run.getBeanDefinitionNames();\n        for (String name : names) {\n            System.out.println(name);\n        }\n\n        //3、从容器中获取组件\n\n        Pet tom01 = run.getBean(\"tom\", Pet.class);\n\n        Pet tom02 = run.getBean(\"tom\", Pet.class);\n\n        System.out.println(\"组件：\"+(tom01 == tom02));\n\n\n        //4、com.vansys.config.MyConfig$$EnhancerBySpringCGLIB$$51f1e1ca@1654a892\n        MyConfig bean = run.getBean(MyConfig.class);\n        System.out.println(bean);\n\n        //如果@Configuration(proxyBeanMethods = true)代理对象调用方法。SpringBoot总会检查这个组件是否在容器中有。\n        //保持组件单实例\n        User user = bean.user01();\n        User user1 = bean.user01();\n        System.out.println(user == user1);\n\n\n        User user01 = run.getBean(\"user01\", User.class);\n        Pet tom = run.getBean(\"tom\", Pet.class);\n\n        System.out.println(\"用户的宠物：\"+(user01.getPet() == tom));\n    }\n}\n\n```\n\n##### @Bean、@Component、@Controller、@Service、@Repository\n\n在类上使用这些这些注解也可以实现往容器里添加组件\n\n##### @ComponentScan、@Import\n\n```\n// 给容器中自动创建出这两个类型的组件、默认组件的名字就是全类名\n@Import({User.class, DBHelper.class})\n@Configuration(proxyBeanMethods = false) //告诉SpringBoot这是一个配置类 == 配置文件\npublic class MyConfig {\n\n}\n```\n\n##### @Conditional\n\n条件装配：满足@Conditional 指定的条件，则进行组件注入\n\n![image-20220515224340380](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220515224340.png)\n\n##### @ImportResource\n\n原生配置文件引入，可以引入一个 `beans.xml` 配置文件\n\n#### 6.2、配置绑定\n\n##### @Component + @ConfigurationProperties\n\n通过 `prefix` 匹配 `application.properties` 核心配置文件的配置，并指定注入到容器中\n\n```java\n/**\n * 只有在容器中的组件，才会拥有SpringBoot提供的强大功能\n */\n@Component\n@ConfigurationProperties(prefix = \"mycar\")\npublic class Car {\n\n    private String brand;\n    private Integer price;\n\n    public String getBrand() {\n        return brand;\n    }\n\n    public void setBrand(String brand) {\n        this.brand = brand;\n    }\n\n    public Integer getPrice() {\n        return price;\n    }\n\n    public void setPrice(Integer price) {\n        this.price = price;\n    }\n\n    @Override\n    public String toString() {\n        return \"Car{\" +\n                \"brand='\" + brand + '\\'' +\n                \", price=\" + price +\n                '}';\n    }\n}\n```\n\n##### @EnableConfigurationProperties + @ConfigurationProperties\n\n```java\n@EnableConfigurationProperties(Car.class)\n//1、开启Car配置绑定功能\n//2、把这个Car这个组件自动注册到容器中\npublic class MyConfig {\n}\n```\n\n> Spring 注解详解：https://www.bilibili.com/video/BV1gW411W7wy\n\n### 7、自动配置原理入门\n\n#### 7.1、引导加载自动配置类\n\n```java\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\n    excludeFilters = {@Filter(\n    type = FilterType.CUSTOM,\n    classes = {TypeExcludeFilter.class}\n), @Filter(\n    type = FilterType.CUSTOM,\n    classes = {AutoConfigurationExcludeFilter.class}\n)}\n)\npublic class MainApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(MainApplication.class,args);\n    }\n}\n```\n\n- SpringBootConfiguration\n  - @Configuration：表明当前是一个配置类\n- @ComponentScan\n\n  - 指定扫描哪些包下的组件\n\n- @EnableAutoConfiguration\n\n  ```java\n  @AutoConfigurationPackage\n  @Import({AutoConfigurationImportSelector.class})\n  public @interface EnableAutoConfiguration {\n      String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\";\n  \n      Class<?>[] exclude() default {};\n  \n      String[] excludeName() default {};\n  }\n  ```\n\n  - @AutoConfigurationPackage\n\n  自动配置包？指定了默认的包规则\n\n  ```java\n  //利用Registrar给容器中导入一系列组件\n  //将指定的一个包下的所有组件导入进来？MainApplication 所在包下。\n  @Import({AutoConfigurationPackages.Registrar.class})\n  public @interface AutoConfigurationPackage {\n      String[] basePackages() default {};\n  \n      Class<?>[] basePackageClasses() default {};\n  }\n  ```\n\n  - @Import(AutoConfigurationImportSelector.class)\n\n  ```\n  1、利用getAutoConfigurationEntry(annotationMetadata);给容器中批量导入一些组件\n  2、调用List<String> configurations = getCandidateConfigurations(annotationMetadata, attributes)获取到所有需要导入到容器中的配置类\n  3、利用工厂加载 Map<String, List<String>> loadSpringFactories(@Nullable ClassLoader classLoader)；得到所有的组件\n  4、从META-INF/spring.factories位置来加载一个文件。\n  \t默认扫描我们当前系统里面所有META-INF/spring.factories位置的文件\n      spring-boot-autoconfigure-2.6.7.RELEASE.jar包里面也有META-INF/spring.factories\n  ```\n\n![image-20220515232710021](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220515232710.png)\n\n> spring-boot-autoconfigure-2.6.7.RELEASE.jar/META-INF/spring.factories 文件里面写死了 spring-boot 一启动就要给容器中加载的所有配置类\n\n```\n# Auto Configure\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\norg.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\\norg.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\\norg.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\\norg.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\\norg.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\\norg.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.context.LifecycleAutoConfiguration,\\\norg.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\\norg.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\\norg.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRestClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.jdbc.JdbcRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.mongo.MongoReactiveDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.mongo.MongoReactiveRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.neo4j.Neo4jReactiveDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.neo4j.Neo4jReactiveRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.r2dbc.R2dbcDataAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.r2dbc.R2dbcRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\\norg.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\\norg.springframework.boot.autoconfigure.elasticsearch.ElasticsearchRestClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\\norg.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\\norg.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\\norg.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\\norg.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\\norg.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\\norg.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\\norg.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration,\\\norg.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration,\\\norg.springframework.boot.autoconfigure.influx.InfluxDbAutoConfiguration,\\\norg.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\\norg.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\\norg.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration,\\\norg.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\\norg.springframework.boot.autoconfigure.availability.ApplicationAvailabilityAutoConfiguration,\\\norg.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\\norg.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\\norg.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mongo.MongoReactiveAutoConfiguration,\\\norg.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\\norg.springframework.boot.autoconfigure.neo4j.Neo4jAutoConfiguration,\\\norg.springframework.boot.autoconfigure.netty.NettyAutoConfiguration,\\\norg.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\\norg.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration,\\\norg.springframework.boot.autoconfigure.r2dbc.R2dbcAutoConfiguration,\\\norg.springframework.boot.autoconfigure.r2dbc.R2dbcTransactionManagerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.rsocket.RSocketMessagingAutoConfiguration,\\\norg.springframework.boot.autoconfigure.rsocket.RSocketRequesterAutoConfiguration,\\\norg.springframework.boot.autoconfigure.rsocket.RSocketServerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.rsocket.RSocketStrategiesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.reactive.ReactiveSecurityAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.reactive.ReactiveUserDetailsServiceAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.rsocket.RSocketSecurityAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration,\\\norg.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\\norg.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.oauth2.client.reactive.ReactiveOAuth2ClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.security.oauth2.resource.reactive.ReactiveOAuth2ResourceServerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\\norg.springframework.boot.autoconfigure.sql.init.SqlInitializationAutoConfiguration,\\\norg.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration,\\\norg.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration,\\\norg.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\\norg.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\\norg.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\\norg.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.ReactiveMultipartAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.WebSessionIdResolverAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,\\\norg.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration,\\\norg.springframework.boot.autoconfigure.websocket.reactive.WebSocketReactiveAutoConfiguration,\\\norg.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration,\\\norg.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration,\\\norg.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration,\\\norg.springframework.boot.autoconfigure.webservices.client.WebServiceTemplateAutoConfiguration\n```\n\n#### 7.2、按需开启自动配置项\n\n`spring-boot-2.6.7.RELEASE` 版本默认提供了 133 个自动配置项，全为 `xxxAutoConfiguration` 的自动配置类，但是根据 Spring 的 `@Conditional` 注解，最终会按需配置。\n\n#### 7.3、修改默认配置\n\n```java\n//给容器中加入了文件上传解析器；\n@Bean\n//容器中有这个类型组件\n@ConditionalOnBean(MultipartResolver.class)\n//容器中没有这个名字 multipartResolver 的组件\n@ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME)\npublic MultipartResolver multipartResolver(MultipartResolver resolver) {\n    //给@Bean标注的方法传入了对象参数，这个参数的值就会从容器中找。\n    //SpringMVC multipartResolver。防止有些用户配置的文件上传解析器不符合规范\n    // Detect if the user has created a MultipartResolver but named it incorrectly\n    return resolver;\n}\n\n```\n\n==SpringBoot 默认会在底层配好所有的组件。但是如果用户自己配置了以用户的优先==\n\n```java\n@Bean\n@ConditionalOnMissingBean\npublic CharacterEncodingFilter characterEncodingFilter() {\n}\n```\n\n总结：\n\n- SpringBoot 先加载所有的自动配置类 xxxxxAutoConfiguration\n- 每个自动配置类按照条件进行生效，默认都会绑定配置文件指定的值。xxxxProperties 里面拿。xxxProperties 和配置文件进行了绑定\n- 生效的配置类就会给容器中装配很多组件\n- 只要容器中有这些组件，相当于这些功能就有了\n- 定制化配置\n\n- - 用户直接自己使用@Bean 替换底层的组件\n  - 用户去看这个组件是获取的配置文件什么值就去修改。\n\n> xxxxxAutoConfiguration ---> 组件 --->\\*\\* \\*\\*xxxxProperties 里面拿值 ----> application.properties\n\n## 核心功能\n\n### 1、配置文件\n\n#### 1.1、文件类型\n\n- properties\n\n同以前的 properties 用法\n\n- yaml\n\nYAML 是 `YAML Ain't Markup Language`（YAML 不是一种标记语言）的递归缩写。在开发的这种语言时，YAML 的意思其实是：`Yet Another Markup Language`（仍是一种标记语言）。\n\n非常适合用来做以数据为中心的配置文件\n\n**基本语法**\n\n- `key: value`；kv 之间有空格\n- 大小写敏感\n- 使用缩进表示层级关系\n- 缩进不允许使用 tab，只允许空格\n- 缩进的空格数不重要，只要相同层级的元素左对齐即可\n- `#` 表示注释\n- '' 与 \"\" 表示字符串内容，会被 转义/不转义\n\n**数据类型**\n\n- 字面量：单个的、不可再分的值。date、boolean、string、number、null\n\n```yaml\nk: v\n```\n\n- 对象：键值对的集合。map、hash、set、object\n\n```yaml\n行内写法：k: {k1:v1,k2:v2,k3:v3}\n#或\nk:\n  k1: v1\n  k2: v2\n  K3: v3\n```\n\n- 数组：一组按次序排列的值。array、list、queue\n\n```yaml\n行内写法：k: [v1,v2,v3]\n#或\nk:\n - v1\n - v2\n - v3\n```\n\n**示例**\n\n```java\n@Data\npublic class Person {\n\n\tprivate String userName;\n\tprivate Boolean boss;\n\tprivate Date birth;\n\tprivate Integer age;\n\tprivate Pet pet;\n\tprivate String[] interests;\n\tprivate List<String> animal;\n\tprivate Map<String, Object> score;\n\tprivate Set<Double> salarys;\n\tprivate Map<String, List<Pet>> allPets;\n}\n\n@Data\npublic class Pet {\n\tprivate String name;\n\tprivate Double weight;\n}\n```\n\n```yaml\n# yaml表示以上对象\nperson:\n  userName: zhangsan\n  boss: false\n  birth: 2019/12/12 20:12:33\n  age: 18\n  pet:\n    name: tomcat\n    weight: 23.4\n  interests: [篮球,游泳]\n  animal:\n    - jerry\n    - mario\n  score:\n    english:\n      first: 30\n      second: 40\n      third: 50\n    math: [131,140,148]\n    chinese: {first: 128,second: 136}\n  salarys: [3999,4999.98,5999.99]\n  allPets:\n    sick:\n      - {name: tom}\n      - {name: jerry,weight: 47}\n    health: [{name: mario,weight: 47}]\n```\n\n#### 1.2、配置提示\n\n==自定义的类和配置文件绑定一般没有提示==\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-configuration-processor</artifactId>\n    <optional>true</optional>\n</dependency>\n\n<!-- 如果在项目中使用 AspectJ，则需要确保注释处理器仅运行一次。 -->\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-compiler-plugin</artifactId>\n    <configuration>\n        <proc>none</proc>\n    </configuration>\n</plugin>\n```\n\n### 2、Web 开发\n\n#### 2.1、SpringMVC 自动配置概览\n\nSpring Boot provides auto-configuration for Spring MVC that **works well with most applications.(大多场景我们都无需自定义配置)**\n\nThe auto-configuration adds the following features on top of Spring’s defaults:\n\n- Inclusion of `ContentNegotiatingViewResolver` and `BeanNameViewResolver` beans.\n\n- - 内容协商视图解析器和 BeanName 视图解析器\n\n- Support for serving static resources, including support for WebJars (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-static-content))).\n\n- - 静态资源（包括 webjars）\n\n- Automatic registration of `Converter`, `GenericConverter`, and `Formatter` beans.\n\n- - 自动注册 `Converter，GenericConverter，Formatter`\n\n- Support for `HttpMessageConverters` (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-message-converters)).\n\n- - 支持 `HttpMessageConverters` （后来我们配合内容协商理解原理）\n\n- Automatic registration of `MessageCodesResolver` (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-message-codes)).\n\n- - 自动注册 `MessageCodesResolver` （国际化用）\n\n- Static `index.html` support.\n\n- - 静态 index.html 页支持\n\n- Custom `Favicon` support (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-favicon)).\n\n- - 自定义 `Favicon`\n\n- Automatic use of a `ConfigurableWebBindingInitializer` bean (covered [later in this document](https://docs.spring.io/spring-boot/docs/current/reference/html/spring-boot-features.html#boot-features-spring-mvc-web-binding-initializer)).\n\n- - 自动使用 `ConfigurableWebBindingInitializer` ，（DataBinder 负责将请求数据绑定到 JavaBean 上）\n\n> If you want to keep those Spring Boot MVC customizations and make more [MVC customizations](https://docs.spring.io/spring/docs/5.2.9.RELEASE/spring-framework-reference/web.html#mvc) (interceptors, formatters, view controllers, and other features), you can add your own `@Configuration` class of type `WebMvcConfigurer` but **without** `@EnableWebMvc`.\n>\n> **不用@EnableWebMvc 注解。使用** `@Configuration**` **+** `WebMvcConfigurer` **自定义规则**\n\n> If you want to provide custom instances of `RequestMappingHandlerMapping`, `RequestMappingHandlerAdapter`, or `ExceptionHandlerExceptionResolver`, and still keep the Spring Boot MVC customizations, you can declare a bean of type `WebMvcRegistrations` and use it to provide custom instances of those components.\n>\n> **声明** `WebMvcRegistrations` **改变默认底层组件**\n\n> If you want to take complete control of Spring MVC, you can add your own `@Configuration` annotated with `@EnableWebMvc`, or alternatively add your own `@Configuration`-annotated `DelegatingWebMvcConfiguration` as described in the Javadoc of `@EnableWebMvc`.\n>\n> **使用** ==@EnableWebMvc+@Configuration+DelegatingWebMvcConfiguration 全面接管 SpringMVC==\n","tags":["技巧","笔记","微服务"],"categories":["后端开发"]},{"title":"Nginx 从入门到实战","slug":"Nginx从入门到实战","url":"/2022/04/24/3db3af36.html","content":"\n## Nginx 的安装\n\n本文 Linux 环境基于 `centos7`\n\n### 版本区别\n\n常用版本分为四大阵营\n\n- Nginx 开源版 http://nginx.org/\n- Nginx plus 商业版 https://www.nginx.com\n- openresty http://openresty.org/cn/\n- Tengine http://tengine.taobao.org/\n\n### 编译安装\n\n这里下载的是 `nginx-1.21.6.tar.gz` ，解压后编译安装\n\n```bash\n# 解压\ntar zxvf nginx-1.21.6.tar.gz -C ./\ncd nginx-1.21.6\n# 执行配置脚本\n./configure --prefix=/usr/local/nginx\n# 安装\nmake && make install\n```\n\n### 如果出现警告或报错\n\n一般是缺少依赖的问题\n\n```bash\n# 安装gcc\nyum install -y gcc\n# 安装perl库\nyum install -y pcre pcre-devel\n# 安装zlib库\nyum install -y zlib zlib-devel\n# 重新执行安装\nmake && make install\n```\n\n### 安装成系统服务\n\n1. 创建服务脚本\n\n`vi /usr/lib/systemd/system/nginx.service`\n\n2. 服务脚本内容\n\n```\n[Unit]\nDescription=nginx - web server\nAfter=network.target remote-fs.target nss-lookup.target\n[Service]\nType=forking\nPIDFile=/usr/local/nginx/logs/nginx.pid\nExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf\nExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf\nExecReload=/usr/local/nginx/sbin/nginx -s reload\nExecStop=/usr/local/nginx/sbin/nginx -s stop\nExecQuit=/usr/local/nginx/sbin/nginx -s quit\nPrivateTmp=true\n[Install]\nWantedBy=multi-user.target\n```\n\n3. 重新加载系统服务\n\n`systemctl daemon-reload`\n\n4. 启动服务\n\n`systemctl start nginx.service`\n\n5. 开机自启\n\n`systemctl enable nginx.service`\n\n## Nginx 基础使用\n\n### 目录结构\n\n进入`Nginx`的主目录可以看到这些文件夹\n\n```\nclient_body_temp conf fastcgi_temp html logs proxy_temp sbin scgi_temp uwsgi_temp\n```\n\n其中这几个文件夹在刚安装时是没有的， 主要用来存放运行过程中的临时文件\n\n```\nclient_body_temp fastcgi_temp proxy_temp scgi_temp\n```\n\n- conf：用来存放配置文件\n- html：用来存放静态文件的默认目录 html、css 等\n- sbin：nginx 的主程序\n- logs：nginx 运行日志\n\n### 基本运行原理\n\n![image-20220424022053512](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220424022100.png)\n\n## Nginx 配置\n\n### 最小配置\n\n```\n#  默认为1，表示开启一个业务进程\nworker_processes  1;\n\nevents {\n\t# 单个业务进程可接受连接数\n    worker_connections  1024;\n}\n\n\nhttp {\n\t# 引入http mime类型\n    include       mime.types;\n    # 如果mime类型没匹配上，默认使用二进制流的方式传输。\n    default_type  application/octet-stream;\n\t使用linux的 sendfile(socket, file, len) 高效网络传输，也就是数据0拷贝。\n    sendfile        on;\n\n    keepalive_timeout  65;\n\n\t# 虚拟主机 vhost\n    server {\n    \t# 监听端口号\n        listen       80;\n        # 域名、主机名\n        server_name  localhost;\n\n\t\t# 匹配路径\n        location / {\n            root   html; # 文件根目录\n            index  index.html index.htm; # 默认页名称\n        }\n\n\t\t# 报错编码对应页面\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n\n}\n```\n\n### 虚拟主机\n\n原本一台服务器只能对应一个站点，通过虚拟主机技术可以虚拟化成多个站点同时对外提供服务\n\n**server_name 匹配规则**\n\n我们需要注意的是 `server_name` 匹配分先后顺序，写在前面的匹配上就不会继续往下匹配了。\n\n- 完整匹配\n\n可以在同一个 `server_name` 中配置多个域名\n\n```\nserver_name abc.com abc123.com;\n```\n\n- 通配符匹配\n\n可以通过 `*` 通配符来模糊匹配多个域名，可以在开始和结尾使用\n\n```\nserver_name *.abc.com abc.*\n```\n\n- 正则匹配\n\n```\nserver_name ~^[0-9]+\\.abc\\.com$\n```\n\n### 反向代理\n\n通过关键字 `proxy_pass` 关键字来指定一个服务器地址（ip/域名）\n\n```nginx\nlocation / {\n\tproxy_pass http://www.baidu.com/;\n}\n```\n\n#### 负载均衡\n\n- 基于反向代理的负载均衡配置\n\n```nginx\nupstream app {\n    server 192.168.88.102:80;\n    server 192.168.88.103:80;\n}\n\nlocation / {\n\tproxy_pass http://app;\n}\n```\n\n#### 负载均衡策略\n\n- **轮询**\n\n默认情况下使用轮询方式，逐一转发，这种方式适用于无状态请求\n\n- **权重（weight）**\n  - down：表示当前的主机暂时不参与负载\n  - weight：默认为 1，weight 越大，负载的权重就越大\n  - backup： 其它所有的非 backup 机器 down 或者忙的时候，请求 backup 机器\n\n指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况。\n\n```nginx\nupstream app {\n    server 192.168.88.102:80 weight=10 down;\n    server 192.168.88.103:80 weight=1;\n    server 127.0.0.1:8060 weight=1 backup;\n}\n```\n\n- **ip_hash**\n\n根据客户端的 ip 地址转发同一台服务器，可以保持回话\n\n- **least_conn**\n\n最少连接数访问\n\n- **url_hash**\n\n根据用户访问的 url 定向转发请求\n\n- **fair**\n\n根据后端服务器响应时间转发请求\n\n### 动静分离\n\n- 配置后端服务的反向代理\n\n```nginx\nlocation / {\n\tproxy_pass http://127.0.0.1:8080;\n}\n```\n\n- 配置前端静态资源\n\n```nginx\nlocation /css {\n    root /usr/local/nginx/static;\n    index index.html index.htm;\n}\n\nlocation /images {\n    root /usr/local/nginx/static;\n    index index.html index.htm;\n}\n\nlocation /js {\n    root /usr/local/nginx/static;\n    index index.html index.htm;\n}\n\n# 正则匹配\nlocation ~*/(css|img|js) {\n    root /usr/local/nginx/static;\n    index index.html index.htm;\n}\n```\n\n### location 配置规则\n\n#### location 前缀\n\n- / 通用匹配，任何请求都会匹配到\n\n- = 精准匹配，不是以指定模式开头\n\n- ~ 正则匹配，区分大小写\n\n- ~\\* 正则匹配，不区分大小写\n- ^~ 非正则匹配，匹配以指定模式开头的 location\n\n#### location 匹配规则\n\n- 多个正则 `location` 直接按书写顺序匹配，匹配成功后就不会往下匹配\n- 普通（非正则）`location` 会一直往下，直到找到匹配度最高的（最大前缀匹配）\n- 当普通 `location` 与正则 `location` 同时存在，如果正则匹配成功,则不会再执行普通匹配\n- 所有类型 `location` 存在时，`=匹配` > `^~匹配` > `正则匹配` > `普通（最大前缀匹配）`\n\n#### alias 与 root\n\n`root` 用来设置根目录，而 `alias` 在接受请求的时候在路径上不会加上 `location`\n\n```nginx\nlocation /css {\n    alias /usr/local/nginx/static/css;\n    index index.html index.htm;\n}\n```\n\n- alias 指定的目录是准确的，即 location 匹配访问的 path 目录下的文件直接是在 alias 目录下查找的；\n- root 指定 的目录是 location 匹配访问的 path 目录的上一级目录,这个 path 目录一定要是真实存在 root 指定目录下的；\n- 使用 alias 标签的目录块中不能使用 rewrite 的 break（具体原因不明）；另外，alias 指定的目录后面必须要加上\"/\"符 号！！\n- alias 虚拟目录配置中，location 匹配的 path 目录如果后面不带\"/\"，那么访问的 url 地址中这个 path 目录后 面加不加\"/\"不影响访问，访问时它会自动加上\"/\"； 但是如果 location 匹配的 path 目录后面加上\"/\"，那么访问的 url 地 址中这个 path 目录必须要加上\"/\"，访问时它不会自动加上\"/\"。如果不加上\"/\"，访问就会失败！\n- root 目录配置中，location 匹配的 path 目录后面带不带\"/\"，都不会影响访问。\n\n### URLRewrite\n\nrewirte 语法格式及参数语法：\n\n`rewrite` 是实现 URL 重写的关键指令，根据 `regex (正则表达式)` 部分内容，重定向到 `replacement`，结尾是 `flag` 标记。\n\n```\nrewrite   <regex>   <replacement>   [flag];\n关键字     正则       替代内容         flag标记\n```\n\n- **关键字**：其中关键字 `rewrite` 不能改变\n- **正则**：正则表达式语句进行规则匹配\n- **替代内容**：将正则匹配的内容替换成 `replacement`\n- **flag 标记**：`rewrite` 支持的 `flag` 标记\n\n> rewrite 参数的标签段位置：server、location、if\n\n**flag 标记说明：**\n\n- last：本条规则匹配完成后，继续向下匹配新的 location URI 规则\n- break：本条规则匹配完成即终止，不再匹配后面的任何规则\n- redirect：返回 302 临时重定向，浏览器地址会显示跳转后的 URL 地址\n- permanent：返回 301 永久重定向，浏览器地址栏会显示跳转后的 URL 地址\n\n### 防盗链配置\n\n```nginx\nvalid_referers none | blocked | server_names | strings ....;\n```\n\n- none：检测 `Referer` 头域不存在的情况\n- blocked：检测 `Referer` 头域的值被防火墙或者代理服务器删除或伪装的情况。这种情况该头域的值不以 `http://` 或 `https://` 开头\n- server_names：设置一个或多个 `URL` ，检测 `Referer` 头域的值是否是这些 `URL` 中的某一个。\n\n**使用 curl 测试**\n\n```\ncurl -I http://192.168.44.101/img/logo.png\n\n# -I 表示只显示响应的头信息\n```\n\n**带引用**\n\n```\ncurl -e \"http://baidu.com\" -I http://192.168.44.101/img/logo.png\n```\n\n### 高可用配置\n\n#### 安装 Keepalived\n\n- 编译安装\n\n下载地址：https://www.keepalived.org/download.html#\n\n```\n# 解压之后通过命令安装\n./configure\n\n# 如遇报错提示\nconfigure: error:\n!!! OpenSSL is not properly installed on your system. !!!\n!!! Can not include OpenSSL headers files. !!!\n\n# 安装依赖\nyum install openssl-devel\n```\n\n- yum 安装\n\n```\nyum install keepalived\n```\n\n#### 配置\n\n使用 `yum` 安装后的配置文件在 `/etc/keepalived/keepalived.conf`\n\n**最小配置**\n\n主机：\n\n```\n! Configuration File for keepalived\nglobal_defs {\n\trouter_id lb101\n}\nvrrp_instance vansys {\n    state MASTER\n    interface ens33\n    virtual_router_id 51\n    priority 100\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n    \t192.168.44.200\n    }\n}\n```\n\n从机：\n\n```\n! Configuration File for keepalived\nglobal_defs {\n\trouter_id lb100\n}\nvrrp_instance vansys {\n    state MASTER\n    interface ens33\n    virtual_router_id 51\n    priority 100\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n    \t192.168.44.200\n    }\n}\n```\n\n**启动服务**\n\n```\nsystemctl start keepalived\n```\n","tags":["技巧","笔记","Nginx"],"categories":["中间件"]},{"title":"Docker 容器-高级篇","slug":"Docker容器-高级篇","url":"/2022/04/07/289e2bff.html","content":"\n## Docker 复杂应用安装\n\n### MySQL 主从复制\n\n主从搭建步骤：\n\n- #### **新建主服务器容器实例 3307**\n\n```bash\ndocker run -p 3307:3306 --name mysql-master \\\n-v /mydata/mysql-master/log:/var/log/mysql \\\n-v /mydata/mysql-master/data:/var/lib/mysql \\\n-v /mydata/mysql-master/conf:/etc/mysql \\\n-e MYSQL_ROOT_PASSWORD=root  \\\n-d mysql:5.7\n```\n\n1. **进入/mydata/mysql-master/conf 目录下新建 my.cnf**\n\n```bash\n[root@88231 conf]# vim my.cnf\n[mysqld]\n## 设置server_id，同一局域网中需要唯一\nserver_id=101\n## 指定不需要同步的数据库名称\nbinlog-ignore-db=mysql\n## 开启二进制日志功能\nlog-bin=mall-mysql-bin\n## 设置二进制日志使用内存大小（事务）\nbinlog_cache_size=1M\n## 设置使用的二进制日志格式（mixed,statement,row）\nbinlog_format=mixed\n## 二进制日志过期清理时间。默认值为0，表示不自动清理。\nexpire_logs_days=7\n## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。\n## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致\nslave_skip_errors=1062\n```\n\n2. **修改完配置后重启 master 实例**\n\n```\n[root@88231 conf]# docker restart mysql-master\nmysql-master\n```\n\n3. **进入 mysql-master 容器**\n\n```\n[root@88231 conf]# docker exec -it mysql-master /bin/bash\nroot@c84fa378812d:/# mysql -uroot -p\nEnter password:\n```\n\n4. **master 容器实例内创建数据同步用户**\n\n```bash\nmysql> CREATE USER 'slave'@'%' IDENTIFIED BY '123456';\nQuery OK, 0 rows affected (0.01 sec)\n\nmysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n- #### 新建从服务器容器实例 3308\n\n```bash\ndocker run -p 3308:3306 --name mysql-slave \\\n-v /mydata/mysql-slave/log:/var/log/mysql \\\n-v /mydata/mysql-slave/data:/var/lib/mysql \\\n-v /mydata/mysql-slave/conf:/etc/mysql \\\n-e MYSQL_ROOT_PASSWORD=root  \\\n-d mysql:5.7\n```\n\n1. **进入/mydata/mysql-slave/conf 目录下新建 my.cnf**\n\n```bash\n[root@88231 conf]# vim my.cnf\n[mysqld]\n## 设置server_id，同一局域网中需要唯一\nserver_id=102\n## 指定不需要同步的数据库名称\nbinlog-ignore-db=mysql\n## 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用\nlog-bin=mall-mysql-slave1-bin\n## 设置二进制日志使用内存大小（事务）\nbinlog_cache_size=1M\n## 设置使用的二进制日志格式（mixed,statement,row）\nbinlog_format=mixed\n## 二进制日志过期清理时间。默认值为0，表示不自动清理。\nexpire_logs_days=7\n## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。\n## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致\nslave_skip_errors=1062\n## relay_log配置中继日志\nrelay_log=mall-mysql-relay-bin\n## log_slave_updates表示slave将复制事件写进自己的二进制日志\nlog_slave_updates=1\n## slave设置为只读（具有super权限的用户除外）\nread_only=1\n```\n\n2. **修改完配置后重启 slave 实例**\n\n```bash\n[root@88231 conf]# docker restart mysql-slave\nmysql-slave\n```\n\n3. **在主数据库中查看主从同步状态**\n\n```bash\nmysql> show master status;\n+-----------------------+----------+--------------+------------------+-------------------+\n| File                  | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+-----------------------+----------+--------------+------------------+-------------------+\n| mall-mysql-bin.000001 |      617 |              | mysql            |                   |\n+-----------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.01 sec)\n```\n\n4. **进入 mysql-slave 容器**\n\n```bash\n[root@88231 conf]# docker exec -it mysql-slave /bin/bash\nroot@820edd47f326:/# mysql -uroot -p\nEnter password:\n```\n\n5. **在从数据库中配置主从复制**\n\n```bash\nchange master to master_host='宿主机ip', master_user='slave', master_password='123456', master_port=3307, master_log_file='mall-mysql-bin.000001', master_log_pos=617, master_connect_retry=30;\n\nmysql> change master to master_host='192.168.88.231', master_user='slave', master_password='123456', master_port=3307, master_log_file='mall-mysql-bin.000001', master_log_pos=617, master_connect_retry=30;\nQuery OK, 0 rows affected, 2 warnings (0.15 sec)\n\n#主从复制命令参数说明\nmaster_host：主数据库的IP地址；\nmaster_port：主数据库的运行端口；\nmaster_user：在主数据库创建的用于同步数据的用户账号；\nmaster_password：在主数据库创建的用于同步数据的用户密码；\nmaster_log_file：指定从数据库要复制数据的日志文件，通过查看主数据的状态，获取File参数；\nmaster_log_pos：指定从数据库从哪个位置开始复制数据，通过查看主数据的状态，获取Position参数；\nmaster_connect_retry：连接失败重试的时间间隔，单位为秒。\n```\n\n6. **在从数据库中查看主从同步状态**\n\n```bash\nmysql> show slave status \\G;\n*************************** 1. row ***************************\n               Slave_IO_State:\n                  Master_Host: 192.168.88.231\n                  Master_User: slave\n                  Master_Port: 3307\n                Connect_Retry: 30\n              Master_Log_File: mall-mysql-bin.000001\n          Read_Master_Log_Pos: 617\n               Relay_Log_File: mall-mysql-relay-bin.000001\n                Relay_Log_Pos: 4\n        Relay_Master_Log_File: mall-mysql-bin.000001\n         # NO -- 还没开始\n             Slave_IO_Running: No\n            Slave_SQL_Running: No\n              Replicate_Do_DB:\n          Replicate_Ignore_DB:\n           Replicate_Do_Table:\n       Replicate_Ignore_Table:\n      Replicate_Wild_Do_Table:\n  Replicate_Wild_Ignore_Table:\n                   Last_Errno: 0\n                   Last_Error:\n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 617\n              Relay_Log_Space: 154\n              Until_Condition: None\n               Until_Log_File:\n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File:\n           Master_SSL_CA_Path:\n              Master_SSL_Cert:\n            Master_SSL_Cipher:\n               Master_SSL_Key:\n        Seconds_Behind_Master: NULL\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error:\n               Last_SQL_Errno: 0\n               Last_SQL_Error:\n  Replicate_Ignore_Server_Ids:\n             Master_Server_Id: 0\n                  Master_UUID:\n             Master_Info_File: /var/lib/mysql/master.info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State:\n           Master_Retry_Count: 86400\n                  Master_Bind:\n      Last_IO_Error_Timestamp:\n     Last_SQL_Error_Timestamp:\n               Master_SSL_Crl:\n           Master_SSL_Crlpath:\n           Retrieved_Gtid_Set:\n            Executed_Gtid_Set:\n                Auto_Position: 0\n         Replicate_Rewrite_DB:\n                 Channel_Name:\n           Master_TLS_Version:\n1 row in set (0.00 sec)\n```\n\n7. **在从数据库中开启主从同步**\n\n```bash\nmysql> start slave;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n8. **查看从数据库状态发现已经同步**\n\n```bash\nmysql> show slave status \\G;\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event\n                  Master_Host: 192.168.88.231\n                  Master_User: slave\n                  Master_Port: 3307\n                Connect_Retry: 30\n              Master_Log_File: mall-mysql-bin.000001\n          Read_Master_Log_Pos: 617\n               Relay_Log_File: mall-mysql-relay-bin.000002\n                Relay_Log_Pos: 325\n        Relay_Master_Log_File: mall-mysql-bin.000001\n           # Yes -- 已开始\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB:\n          Replicate_Ignore_DB:\n           Replicate_Do_Table:\n       Replicate_Ignore_Table:\n      Replicate_Wild_Do_Table:\n  Replicate_Wild_Ignore_Table:\n                   Last_Errno: 0\n                   Last_Error:\n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 617\n              Relay_Log_Space: 537\n              Until_Condition: None\n               Until_Log_File:\n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File:\n           Master_SSL_CA_Path:\n              Master_SSL_Cert:\n            Master_SSL_Cipher:\n               Master_SSL_Key:\n        Seconds_Behind_Master: 0\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error:\n               Last_SQL_Errno: 0\n               Last_SQL_Error:\n  Replicate_Ignore_Server_Ids:\n             Master_Server_Id: 101\n                  Master_UUID: 25cb5d93-e4df-11ec-86da-0242ac110003\n             Master_Info_File: /var/lib/mysql/master.info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n           Master_Retry_Count: 86400\n                  Master_Bind:\n      Last_IO_Error_Timestamp:\n     Last_SQL_Error_Timestamp:\n               Master_SSL_Crl:\n           Master_SSL_Crlpath:\n           Retrieved_Gtid_Set:\n            Executed_Gtid_Set:\n                Auto_Position: 0\n         Replicate_Rewrite_DB:\n                 Channel_Name:\n           Master_TLS_Version:\n1 row in set (0.00 sec)\n```\n\n9. **主从复制测试**\n\n```\n- 主机新建库-使用库-新建表-插入数据，ok\n- 从机使用库-查看记录，ok\n```\n\n### Redis 集群\n\n#### 搭建 Redis 集群\n\n> 3 主 3 从 redis 集群扩缩容配置案例架构说明\n>\n> https://www.processon.com/view/link/629e20255653bb03f2cc0a14\n\n1. **新建 6 个 docker 容器 redis 实例**\n\n```bash\ndocker run -d --name redis-node-1 --net host --privileged=true -v /data/redis/share/redis-node-1:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6381\n\ndocker run -d --name redis-node-2 --net host --privileged=true -v /data/redis/share/redis-node-2:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6382\n\ndocker run -d --name redis-node-3 --net host --privileged=true -v /data/redis/share/redis-node-3:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6383\n\ndocker run -d --name redis-node-4 --net host --privileged=true -v /data/redis/share/redis-node-4:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6384\n\ndocker run -d --name redis-node-5 --net host --privileged=true -v /data/redis/share/redis-node-5:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6385\n\ndocker run -d --name redis-node-6 --net host --privileged=true -v /data/redis/share/redis-node-6:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6386\n```\n\n==如果运行成功，效果如下：==\n\n![image-20220606234533562](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606234533.png)\n\n> 命令分步解释：\n>\n> - docker run：创建并运行 docker 容器实例\n>\n> - --name redis-node-6：容器名字\n>\n> - --net host：使用宿主机的 IP 和端口，默认\n>\n> - --privileged=true：获取宿主机 root 用户权限\n>\n> - -v /data/redis/share/redis-node-6:/data：容器卷，宿主机地址:docker 内部地址\n>\n> - redis:6.0.8：redis 镜像和版本号\n>\n> - --cluster-enabled yes：开启 redis 集群\n>\n> - --appendonly yes：开启持久化\n>\n> - --port 6386：redis 端口号\n\n2. **进入容器 redis-node-1 并为 6 台机器构建集群关系**\n\n```bash\n# 进入容器\n[root@88231 ~]# docker exec -it redis-node-1 /bin/bash\n\n# 构建主从关系\n# 注意，进入docker容器后才能执行一下命令，且注意自己的真实IP地址\nredis-cli --cluster create 192.168.88.231:6381 192.168.88.231:6382 192.168.88.231:6383 192.168.88.231:6384 192.168.88.231:6385 192.168.88.231:6386 --cluster-replicas 1\n# --cluster-replicas 1 表示为每个master创建一个slave节点\n```\n\n![image-20220606235150386](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606235150.png)\n\n![image-20220606235242475](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606235242.png)\n\n![image-20220606235332969](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220606235333.png)\n\n==一切 OK 的话，3 主 3 从搞定==\n\n3. **链接进入 6381 作为切入点，查看集群状态**\n\n```\nroot@88231:/data# redis-cli -p 6381\n127.0.0.1:6381> keys *\n127.0.0.1:6381> cluster info\n127.0.0.1:6381> cluster nodes\n```\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220607000338.png\" alt=\"image-20220607000338016\" style=\"zoom:50%;\" />\n\n![image-20220607000524306](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220607000524.png)\n\n#### 主从容错切换迁移\n\n##### 数据读写存储\n\n1. 启动 6 个 redis 构成的集群并通过 exec 进入\n2. 对 6381 新增两个 key\n3. 防止路由失效加参数 -c 并新增两个 key\n\n![image-20220609222228049](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609222235.png)\n\n![image-20220609222420357](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609222420.png)\n\n4. 查看集群信息\n\n```bash\nredis-cli --cluster check 192.168.88.231:6381\n```\n\n![image-20220609222613143](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609222613.png)\n\n##### 容错切换迁移\n\n1. 主 6381 和从机切换，先停止主机 6381\n2. 6381 主机停了，对应的真实从机上位\n3. 6381 作为 1 号主机分配的从机以实际情况为准，具体是几号机器就是几号\n4. 再次查看集群信息\n\n![image-20220609223136321](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609223136.png)\n\n> ==6381 宕机了，6385 上位成了新的 master==\n>\n> 备注：本次操作 6381 为主节点，对应的从节点是 6385，对应关系是随机的，每次操作以实际情况为准\n\n5. 启动 6381 节点\n\n```bash\ndocker start redis-node-1\n```\n\n![image-20220609224042839](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609224043.png)\n\n6. 再停 6385 节点\n\n```bash\ndocker stop redis-node-5\n```\n\n![image-20220609224750744](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609224750.png)\n\n7. 再启 6385 节点\n\n```bash\ndocker start redis-node-5\n```\n\n> ==发现主从节点又恢复之前的状态了==\n\n8. 查看集群状态\n\n```\nredis-cli --cluster check 自己IP:6381\n\n可以看到主节点分配的\n```\n\n![image-20220609230337692](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609230337.png)\n\n##### 主从扩容案例\n\n1. 新建 6387、6388 两个节点+新建后启动+查看是否是 8 节点\n\n```bash\ndocker run -d --name redis-node-7 --net host --privileged=true -v /data/redis/share/redis-node-7:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6387\n\ndocker run -d --name redis-node-8 --net host --privileged=true -v /data/redis/share/redis-node-8:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6388\n\ndocker ps\n```\n\n2. 进入 6387 容器实例内部\n\n```bash\ndocker exec -it redis-node-7 /bin/bash\n```\n\n3. 将新增的 6387 节点（空槽号）作为 master 节点加入集群\n\n```\nredis-cli --cluster add-node 自己实际IP地址:6387 自己实际IP地址:6381\nredis-cli --cluster add-node 192.168.88.231:6387 192.168.88.231:6381\n6387 就是将要作为master新增节点\n6381 就是原来集群节点里面的领路人，相当于6387拜拜6381的码头从而找到组织加入集群\n```\n\n![image-20220609231034192](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609231034.png)\n\n4. 检查集群情况第 1 次\n\n```\nredis-cli --cluster check 真实ip地址:6381\n\nredis-cli --cluster check 192.168.88.231:6381\n```\n\n![image-20220609231423755](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609231423.png)\n\n5. 重新分派槽号\n\n```\n重新分派槽号\n\n命令:redis-cli --cluster reshard IP地址:端口号\n\nredis-cli --cluster reshard 192.168.88.231:6381\n```\n\n![image-20220609232741435](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609232741.png)\n\n6. 检查集群情况第 2 次\n\n```bash\nredis-cli --cluster check 真实ip地址:6381\n\nredis-cli --cluster check 192.168.88.231:6381\n```\n\n![image-20220609233201196](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609233201.png)\n\n> ==槽号分派说明==\n>\n> 为什么 6387 是 3 个新的区间，以前的还是连续？\n>\n> 重新分配成本太高，所以前 3 家各自匀出来一部分，从 6381/6382/6383 三个旧节点分别匀出 1364 个坑位给新节点 6387\n\n![image-20220609233346240](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609233346.png)\n\n7. 为主节点 6387 分配从节点 6388\n\n```\n命令：redis-cli --cluster add-node ip:新slave端口 ip:新master端口 --cluster-slave --cluster-master-id 新主机节点ID\n\nredis-cli --cluster add-node 192.168.88.231:6388 192.168.88.231:6387 --cluster-slave --cluster-master-id 7206137ce4e66c0464fa0fa00472202ce5b16792\n-------这个是6387的编号，按照自己实际情况\n```\n\n![image-20220609233720722](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609233720.png)\n\n8. 检查集群第 3 次\n\n```\nredis-cli --cluster check 192.168.88.231:6382\n\n4 主 4 从\n```\n\n![image-20220609233902550](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220609233902.png)\n\n##### 主从缩容案例\n\n> 目的：6387 和 6388 下线\n\n1. 检查集群情况 - 获得 6388 的节点 ID\n\n```bash\nredis-cli --cluster check 192.168.88.231:6382\n```\n\n![image-20220610223609176](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220610223609.png)\n\n2. 将 6388 删除 从集群中将 4 号从节点 6388 删除\n\n```bash\n命令：redis-cli --cluster del-node ip:从机端口 从机6388节点ID\n\nredis-cli --cluster del-node 192.168.88.231:6388 1fedf6a6f9acfbdba6951a532cd2d68e4546898e\n```\n\n![image-20220610223709085](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220610223709.png)\n\n```bash\nredis-cli --cluster check 192.168.88.231:6382\n```\n\n==检查一下发现，6388 被删除了，只剩下七台机器了。==\n\n![image-20220610223900954](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220610223901.png)\n\n3. 将 6387 的槽号清空，重新分配，本例将清出来的槽号都给 6381\n\n```bash\nredis-cli --cluster reshard 192.168.88.231:6381\n```\n\n![image-20220610224116496](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220610224116.png)\n\n![image-20220610224657149](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220610224735.png)\n\n> 将 6387 节点的槽号都分配给 6381\n\n4. 检查集群情况\n\n```bash\nredis-cli --cluster check 192.168.88.231 6382\n\n4096 个槽位都指给 6381，它变成了 8192 个槽位，相当于全部都给 6381了\n```\n\n![image-20220610225027291](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220610225027.png)\n\n5. 删除 6387 节点\n\n```bash\n命令：redis-cli --cluster del-node ip:端口 6387节点ID\n\nredis-cli --cluster del-node 192.168.88.231:6387 7206137ce4e66c0464fa0fa00472202ce5b16792\n```\n\n![image-20220610225144956](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220610225145.png)\n\n6. 再次检查集群情况\n\n```bash\nredis-cli --cluster check 192.168.88.231 6382\n\n恢复之前的 3 主 3 从，缩容成功！\n```\n\n![image-20220610225344237](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220610225344.png)\n\n## DockerFile\n\n### Dockerfile 介绍\n\n`Dockerfile` 是用来构建 Docker 镜像的文本文件，是由一条条构建镜像所需的指令和参数构成的脚本。\n\n> 官网：https://docs.docker.com/engine/reference/builder/\n\n构建步骤：\n\n1. 编写一个 `Dockerfile` 文件\n2. `docker bulid` 构建为一个镜像\n3. `docker run` 运行镜像\n4. `docker push` 发布镜像（DockerHub. 阿里云镜像仓库）\n\n![image-20220611202748238](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220611202748.png)\n\n### Dockerfile 构建过程\n\n#### Dockerfile 基础知识\n\n1. 每个保留关键字（指令）都==必须是大写字母==且后面要跟随至少一个参数\n2. 指令按照从上到下，顺序执行\n3. `#` 表示注释\n4. 每条指令都会创建一个新的镜像层并对镜像进行提交\n\n![image-20211230224659329](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211230224706.png)\n\n#### Docker 执行 Dockerfile 的大致流程\n\n1. docker 从基础镜像运行一个容器\n2. 执行一条指令并对容器做出修改\n3. docker 再基于刚提交的镜像运行一个新容器\n4. 执行 Dockerfile 中的下一条指令知道所有指令都执行完成\n\n#### 总结\n\n从应用软件的角度看，`Dockerfile`、`Docker镜像`与`Docker容器`分别代表软件的三个不同阶段：\n\n- `Dockerfile`是软件的原材料\n- `Docker镜像`是软件的交付品\n- `Docker容器`则可以认为是软件镜像的运行态，也即依照镜像运行的容器实例\n\n==Dockerfile 面向开发，Docker 镜像成为交付标准，Docker 容器则涉及部署与运维，三者缺一不可，合力充当 Docker 体系的基石==\n\n![image-20220611204149366](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220611204149.png)\n\n1. Dockerfile，需要定义一个 Dockerfile，Dockerfile 定义了进程需要的一切东西。Dockerfile 涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计 namespace 的权限控制)等等;\n\n2. Docker 镜像，在用 Dockerfile 定义一个文件之后，docker build 时会产生一个 Docker 镜像，当运行 Docker 镜像时会真正开始提供服务;\n\n3. Docker 容器，容器是直接提供服务的。\n\n### DockerFile 的保留字指令\n\n- `FROM`：基础镜像，当前新镜像是基于哪个镜像的，指定一个已经存在的镜像作为模板，第一条必须是 FROM\n\n- `MAINTAINER`：镜像维护者的姓名和邮箱地址\n\n- `RUN`：容器构建时需要运行的命令，包含两种格式：\n\n  - shell 格式：\n\n  ![image-20220611204952312](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220611204952.png)\n\n  - exec 格式：\n\n  ![image-20220611205003786](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220611205003.png)\n\n  - `RUN` 是在 `docker build` 时运行\n\n- `EXPOSE`：当前容器对外暴露出的端口\n\n- `WORKDIR`：指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点\n\n- `USER`：指定该镜像以什么样的用户去执行，如果都不指定，默认是 root\n\n- `ENV`：用来在构建镜像过程中设置环境变量\n\n  - ```\n    ENV MY_PATH /usr/mytest\n    这个环境变量可以在后续的任何RUN指令中使用，这就如同在命令前面指定了环境变量前缀一样；\n    也可以在其它指令中直接使用这些环境变量，\n    \n    比如：WORKDIR $MY_PATH\n    ```\n\n- `ADD`：将宿主机目录下的文件拷贝进镜像且会自动处理 URL 和解压 tar 压缩包\n\n- `COPY`：类似 ADD，拷贝文件和目录到镜像中\n\n  - ```dockerfile\n    # 将从构建上下文目录中 <源路径> 的文件/目录复制到新的一层的镜像内的 <目标路径> 位置\n    \n    COPY src dest\n    COPY [\"src\", \"dest\"]\n    \n    # <src源路径>：源文件或者源目录\n    # <dest目标路径>：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。\n    ```\n\n- `VOLUME`：容器数据卷，用于数据保存和持久化工作\n\n- `CMD`：指定容器启动后的要干的事情\n\n  - ![image-20220611210408046](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220611210408.png)\n  - **注意：Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效，CMD 会被 docker run 之后的参数替换**\n  - 它和前面 `RUN` 命令的区别：\n    - `CMD` 是在 `docker run` 时运行\n    - `RUN` 是在 `docker build` 时运行\n\n- `ENTRYPOINT`：也是用来指定一个容器启动时要运行的命令\n\n  - 类似于 CMD 指令，**但是 ENTRYPOINT 不会被 docker run 后面的命令覆盖**， 而且这些命令行参数**会被当作参数送给 ENTRYPOINT 指令指定的程序**\n\n  - `ENTRYPOINT [\"<executeable>\",\"<param1>\",\"<param2>\"...]`\n    \n  - ENTRYPOINT 可以和 CMD 一起用，一般是**变参**才会使用 CMD，这里的 CMD 等于是在给 ENTRYPOINT 传参。当指定了 ENTRYPOINT 后，CMD 的含义就发生了变化，不再是直接运行其命令而是将 CMD 的内容作为参数传递给 ENTRYPOINT 指令，他两个组合会变成 `<ENTRYPOINT> \"<CMD>\"`\n\n  - **优点**：在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数\n\n  - **注意**：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效\n\n- 小总结\n\n  - ![image-20220618230538863](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220618230538.png)\n\n### 实战案例\n\n自定义镜像 ==> `mycentosjava8`\n\n**要求：**\n\n- Centos7 镜像具备 vim+ifconfig+jdk8\n- 准备 jdk8 的安装包（`jdk-8u251-linux-x64.tar.gz`）\n\n1. **准备编写 Dockerfile 文件**\n\n在 `/home` 目录下建一个 `myfile` 文件夹，并将 `jdk8` 的安装包放进去：\n\n![image-20220619202508648](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619202515.png)\n\n`Dockerfile` 文件内容如下：\n\n```dockerfile\nFROM centos:centos7\nMAINTAINER Kyire6<kyire666.outlook.com>\n\nENV MYPATH /usr/local\nWORKDIR $MYPATH\n\n#安装vim编辑器\nRUN yum -y install vim\n#安装ifconfig命令查看网络IP\nRUN yum -y install net-tools\n#安装java8及lib库\nRUN yum -y install glibc.i686\nRUN mkdir /usr/local/java\n#ADD 是相对路径jar,把jdk-8u251-linux-x64.tar.gz添加到容器中,安装包必须要和Dockerfile文件在同一位置\nADD jdk-8u251-linux-x64.tar.gz /usr/local/java/\n#配置java环境变量\nENV JAVA_HOME /usr/local/java/jdk1.8.0_251\nENV JRE_HOME $JAVA_HOME/jre\nENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH\nENV PATH $JAVA_HOME/bin:$PATH\n\nEXPOSE 80\n\nCMD echo $MYPATH\nCMD echo \"success--------------ok\"\nCMD /bin/bash\n```\n\n2. **执行构建命令**\n\n```bash\ndocker build -t 新镜像名:TAG .\n\n# 例如\ndocker build -t centosjava8:1.0 .\n```\n\n> **注意：命令要在 `Dockerfile` 的同级目录下执行，不要忘了命令结尾的 `.`**\n\n![image-20220619203258616](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619203258.png)\n\n![image-20220619204718396](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619204718.png)\n\n3. **运行容器**\n\n```bash\ndocker run -it centosjava8:1.0 /bin/bash\n```\n\n![image-20220619212100997](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619212101.png)\n\n### 虚悬镜像\n\n虚悬镜像就是仓库名、标签都是 `<none>` 的镜像，也称为 `dangling image`\n\n**用 Dockerfile 生成一个**\n\n```\n# 编写 Dockerfile 文件\nvim Dockerfile\nfrom ubuntu\nCMD echo 'action is success'\n\n# build 镜像\ndocker build .\n```\n\n![image-20220619214708171](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619214708.png)\n\n**查看虚悬镜像**\n\n```bash\ndocker images -f dangling=true\n```\n\n![image-20220619214819128](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619214819.png)\n\n**删除所有虚悬镜像**\n\n虚悬镜像已经失去存在价值，可以删除\n\n```bash\ndocker image prune\n```\n\n![image-20220619215102621](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220619215102.png)\n\n### 发布自己的镜像\n\n> DockerHub\n\n1. 地址 https://hub.docker.com/ 注册自己的账号！\n\n2. 确保这个账号可以登录\n\n3. 在服务器上提交自己的镜像\n\n   ```shell\n   [root@ouwen ~]# docker login --help\n\n   Usage:  docker login [OPTIONS] [SERVER]\n\n   Log in to a Docker registry.\n   If no server is specified, the default is defined by the daemon.\n\n   Options:\n     -p, --password string   Password\n         --password-stdin    Take the password from stdin\n     -u, --username string   Username\n   [root@ouwen ~]# docker login -u ouwen666\n   Password:\n   WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n   Configure a credential helper to remove this warning. See\n   https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\n   Login Succeeded\n   ```\n\n4. 使用 `docker login` 登录之后就可以提交镜像了\n\n   ```shell\n   # 1. 使用 docker tag 命令修改镜像版本\n   [root@ouwen ~]# docker tag 352abc3918b1 ouwen666/tomcat:1.0\n   # 2. 使用 docker push 命令提交镜像到 DockerHub\n   [root@ouwen ~]# docker push ouwen666/tomcat:1.0\n   ```\n\n   ![image-20220103135111272](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220103135111.png)\n\n   > 发现：提交的时候也是按照镜像的层级来的！\n\n> 阿里云镜像\n\n1. 登录阿里云\n\n2. 找到容器镜像服务\n\n3. 创建镜像仓库\n\n   ![image-20220103140835560](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220103140835.png)\n\n4. 浏览仓库信息\n\n   ![image-20220103140926596](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220103140926.png)\n\n### 总结\n\n![image-20220103142038290](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220103142038.png)\n\n## Docker 网络\n\n### `docker0` 网卡\n\ndocker 服务启动后，会产生一个名为 `docker0` 的虚拟网桥，使用 `ip addr` 查看本机 ip\n\n![image-20220103235821684](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220104001129.png)\n\n### docker 网络常用命令\n\n#### All 命令\n\n```bash\ndocker network --help\n```\n\n![image-20220625214854077](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220625214901.png)\n\n#### 查看网络\n\n```bash\ndocker network ls\n```\n\n![image-20220625215035376](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220625215035.png)\n\n#### 查看网络源数据\n\n```bash\ndocker network inspect xxx\n```\n\n![image-20220626002156711](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626002156.png)\n\n#### 创建网络\n\n```bash\ndocker network create xxx\n```\n\n#### 删除网络\n\n```bash\ndocker network rm xxx\n```\n\n![image-20220626002407749](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626002407.png)\n\n> **docker 网络能干嘛？**\n>\n> - 容器间的互联和通信以及端口映射\n> - 容器 IP 变动时可以通过服务名直接进行网络通信，进而不受到影响\n\n### 网络模式\n\n![image-20220626002547570](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626002547.png)\n\n- bridge 模式：使用 --network bridge 指定，默认使用 docker0\n- host 模式：使用 --network host 指定\n- none 模式：使用 --network none 指定\n- container 模式：使用 --network container:NAME 或者容器 ID 指定\n\n**容器实例内默认网络 IP 生产规则**\n\n1. 先启动两个 Ubuntu 容器实例\n\n![image-20220626002940194](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626002940.png)\n\n2. `docker inspect 容器 ID or 容器名字`\n\n![image-20220626003252589](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626003252.png)\n\n3. 关闭 u2 实例，新建 u3，查看 IP 变化\n\n![image-20220626003453087](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626003453.png)\n\n> 结论：\n>\n> **docker 容器内部的 IP 是有可能会发生变化的**\n\n#### bridge\n\nDocker 服务默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），该桥接网络的名称为 docker0，它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。Docker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信。\n\n```\n# 查看 bridge 网络的详细信息，并通过 grep 获取名称项\ndocker network inspect bridge | grep name\n```\n\n![image-20220626003931893](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626003931.png)\n\n```\nifconfig | grep docker\n```\n\n![image-20220626004014292](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626004014.png)\n\n> **说明：**\n>\n> 1. Docker 使用 Linux 桥接，在宿主机虚拟一个 Docker 容器网桥(docker0)，Docker 启动一个容器时会根据 Docker 网桥的网段分配给容器一个 IP 地址，称为 Container-IP，同时 Docker 网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的 Container-IP 直接通信\n>\n> 2. docker run 的时候，没有指定 network 的话默认使用的网桥模式就是 bridge，使用的就是 docker0。在宿主机 ifconfig,就可以看到 docker0 和自己 create 的 network(后面讲)eth0，eth1，eth2……代表网卡一，网卡二，网卡三……，lo 代表 127.0.0.1，即 localhost，inet addr 用来表示网卡的 IP 地址\n>\n> 3. 网桥 docker0 创建一对对等虚拟设备接口一个叫 veth，另一个叫 eth0，成对匹配\n>    1. 整个宿主机的网桥模式都是 docker0，类似一个交换机有一堆接口，每个接口叫 veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫 veth pair）\n>    2. 每个容器实例内部也有一块网卡，每个接口叫 eth0\n>    3. docker0 上面的每个 veth 匹配某个容器实例内部的 eth0，两两配对，一一匹配\n>\n> **通过上述，将宿主机上的所有容器都连接到这个内部网络上，两个容器在同一个网络下,会从这个网关下各自拿到分配的 ip，此时两个容器的网络是互通的。**\n\n![image-20220626004158705](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626004158.png)\n\n**两两匹配验证**\n\n```bash\ndocker run -d -p 8081:8080   --name tomcat81 billygoo/tomcat8-jdk8\n\ndocker run -d -p 8082:8080   --name tomcat82 billygoo/tomcat8-jdk8\n```\n\n![image-20220626004536998](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626004537.png)\n\n![image-20220626004743381](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626004743.png)\n\n#### host\n\n直接使用宿主机的 IP 地址与外界进行通信，不再需要额外进行 NAT 转换。\n\n> **说明：**\n>\n> 容器将不会获得一个独立的 Network Namespace， 而是和宿主机共用一个 Network Namespace。容器将不会虚拟出自己的网卡而是使用宿主机的 IP 和端口。\n\n![image-20220626004852511](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626004852.png)\n\n**验证**\n\n```bash\ndocker run -d -p 8083:8080 --network host --name tomcat83 billygoo/tomcat8-jdk8\n```\n\n![image-20220626005212574](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626005212.png)\n\n**问题：**\n\ndocker 容器启动时出现了警告\n\n**原因：**\n\ndocker 启动时指定 --network=host 或 -net=host，如果还指定了 -p 映射端口，那这个时候就会有此警告，并且通过-p 设置的参数将不会起到任何作用，端口号会以主机端口号为主，重复时则递增。\n\n**解决:**\n\n解决的办法就是使用 docker 的其他网络模式，例如 --network=bridge，这样就可以解决问题，或者直接无视...\n\n**正确做法：**\n\n```bash\ndocker run -d --network host --name tomcat83 billygoo/tomcat8-jdk8\n```\n\n这样就不会出现之前的警告了，查看容器实例内部：\n\n![image-20220626005512017](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626005512.png)\n\n> 没有设置-p 的端口映射了，如何访问启动的 tomcat83？\n>\n> http://宿主机IP:8080/\n>\n> **在 CentOS 里面用默认的火狐浏览器访问容器内的 tomcat83 看到访问成功，因为此时容器的 IP 借用主机的，所以容器共享宿主机网络 IP，这样的好处是外部主机与容器可以直接通信。**\n\n#### none\n\n在 none 模式下，并不为 Docker 容器进行任何网络配置。 也就是说，这个 Docker 容器没有网卡、IP、路由等信息，只有一个 lo，需要我们自己为 Docker 容器添加网卡、配置 IP 等。禁用网络功能，只有 lo 标识(就是 127.0.0.1 表示本地回环)\n\n**验证**\n\n```bash\ndocker run -d -p 8084:8080 --network none --name tomcat84 billygoo/tomcat8-jdk8\n```\n\n进入容器内部查看\n\n![image-20220626005846474](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626005846.png)\n\n在容器外部查看\n\n![image-20220626005935898](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626005936.png)\n\n#### container\n\n新建的容器和已经存在的一个容器共享一个网络 IP 配置而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。\n\n![image-20220626010017092](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626010017.png)\n\n**验证**\n\n```bash\ndocker run -d -p 8085:8080 --name tomcat85 billygoo/tomcat8-jdk8\n\ndocker run -d -p 8086:8080 --network container:tomcat85 --name tomcat86 billygoo/tomcat8-jdk8\n```\n\n运行结果：\n\n![image-20220626010148299](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626010148.png)\n\n相当于 tomcat86 和 tomcat85 公用同一个 ip 同一个端口，导致端口冲突！\n\n**换一个镜像进行验证**\n\n> Alpine 操作系统是一个面向安全的轻型 Linux 发行版\n>\n> Alpine Linux 是一款独立的、非商业的通用 Linux 发行版，专为追求安全性、简单性和资源效率的用户而设计。 可能很多人没听说过这个 Linux 发行版本，但是经常用 Docker 的朋友可能都用过，因为他小，简单，安全而著称，所以作为基础镜像是非常好的一个选择，可谓是麻雀虽小但五脏俱全，镜像非常小巧，不到 6M 的大小，所以特别适合容器打包。\n\n```bash\ndocker run -it --name alpine1  alpine /bin/sh\n\ndocker run -it --network container:alpine1 --name alpine2  alpine /bin/sh\n```\n\n![image-20220626010511330](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626010511.png)\n\n假如此时关闭 alpine1，再看看 alpin2\n\n![image-20220626010625716](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626010625.png)\n\n发现 `107: eth0@if108` 已经消失\n\n![image-20220626010751877](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626010751.png)\n\n### 自定义网络\n\n#### 过时的 link\n\n![image-20220626010828576](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626010828.png)\n\n#### 使用自定义网络的好处\n\n**before**\n\n```bash\ndocker run -d -p 8081:8080   --name tomcat81 billygoo/tomcat8-jdk8\ndocker run -d -p 8082:8080   --name tomcat82 billygoo/tomcat8-jdk8\n```\n\n启动成功使用 docker exec 进入到容器内部\n\n**按照 IP 地址 ping 是 OK 的**\n\n![image-20220626011951406](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626011951.png)\n\n但是无法按照服务名 ping\n\n![image-20220626012135798](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626012135.png)\n\n**after**\n\n自定义桥接网络，自定义网络默认使用的就是桥接网络 -- bridge\n\n1. 新建自定义网络\n\n![image-20220626012308361](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626012308.png)\n\n2. 新建容器并加入上一步新建的自定义网络\n\n```bash\ndocker run -d -p 8081:8080 --network my_network  --name tomcat81 billygoo/tomcat8-jdk8\n\ndocker run -d -p 8082:8080 --network my_network  --name tomcat82 billygoo/tomcat8-jdk8\n```\n\n3. 互相 ping 测试\n\n![image-20220626012536459](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626012536.png)\n\n> **结论**\n>\n> **_自定义网络本身就维护好了主机名和 ip 的对应关系（ip 和域名都能通）_**\n\n## Docker 平台架构图解\n\n### 整体说明\n\n从其架构和运行流程来看，Docker 是一个 C/S 模式的架构，后端是一个松耦合架构，众多模块各司其职。\n\nDocker 运行的基本流程为：\n\n1. 用户是使用 Docker Client 与 Docker Daemon 建立通信，并发送请求给后者。\n2. Docker Daemon 作为 Docker 架构中的主体部分，首先提供 Docker Server 的功能使其可以接受 Docker Client 的请求。\n3. Docker Engine 执行 Docker 内部的一系列工作，每一项工作都是以一个 Job 的形式的存在。\n4. Job 的运行过程中，当需要容器镜像时，则从 Docker Registry 中下载镜像，并通过镜像管理驱动 Graph driver 将下载镜像以 Graph 的形式存储。\n5. 当需要为 Docker 创建网络环境时，通过网络管理驱动 Network driver 创建并配置 Docker 容器网络环境。\n6. 当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 Execdriver 来完成。\n7. Libcontainer 是一项独立的容器管理包，Network driver 以及 Exec driver 都是通过 Libcontainer 来实现具体对容器进行的操作。\n\n### 整体架构\n\n![image-20220626012732507](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220626012732.png)\n\n## Docker Compose\n\n> 官方文档：https://docs.docker.com/compose/\n\n### 什么是 Docker Compose\n\n`Docker Compose` 是一个用于定义和运行多容器 `Docker` 应用程序的工具。使用 `Compose`，您可以使用 `YAML` 文件来配置应用程序的服务。然后，使用单个命令，从配置创建并启动所有服务\n\n使用 `Docker Compose` 基本上有以下三步：\n\n1. 使用 定义应用的环境，以便可以在任何位置重现它。`Dockerfile`\n2. 定义构成应用的服务，以便它们可以在隔离的环境中一起运行。`docker-compose.yml`\n3. 运行[Docker Compose](https://docs.docker.com/compose/cli-command/)将启动并运行整个应用。您也可以使用 docker-compose 二进制文件运行。` docker compose up``docker-compose up `\n\n`docker-compose.yml` 示例：\n\n```yaml\nversion: \"3.9\"  # optional since v1.27.0\nservices:\n  web:\n    build: .\n    ports:\n      - \"8000:5000\"\n    volumes:\n      - .:/code\n      - logvolume01:/var/log\n    links:\n      - redis\n  redis:\n    image: redis\nvolumes:\n  logvolume01: {}\n```\n\n### 安装 Docker Compose\n\n1. 下载\n\n```bash\n # 官网地址\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n\n # 国内镜像\nsudo curl -L \"https://get.daocloud.io/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n```\n\n![image-20220404124103270](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220404124103.png)\n\n2. 给 `docker-compose` 文件授可执行权限\n\n```bash\nsudo chmod +x /usr/local/bin/docker-compose\n```\n\n3. 测试安装是否成功\n\n```bash\ndocker-compose --version\n```\n\n4. 卸载 `docker-compose`\n\n```\nrm /usr/local/bin/docker-compose\n```\n\n![image-20220404124418121](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220404124418.png)\n\n### Compose 核心概念\n\n**一文件**\n\n`docker-compose.yml`\n\n**两要素**\n\n- 服务（service)\n\n一个个应用容器实例，比如订单微服务、库存微服务、mysql 容器、nginx 容器或者 redis 容器\n\n- 工程（project）\n\n由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义\n\n### Compose 使用的三个步骤\n\n1. 编写 Dockerfile 定义各个微服务应用并构建出对应的镜像文件\n2. 使用 docker-compose.yml 定义一个完整业务单元，安排好整体应用中的各个容器服务\n3. 最后，执行 docker-compose up 命令 来启动并运行整个应用程序，完成一键部署上线\n\n### Compose 常用命令\n\n**查看帮助信息**\n\n```bash\ndocker-compose -h|help\n```\n\n**命令选项**\n\n- -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定；\n- -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名；\n- –x-networking 使用 Docker 的可拔插网络后端特性；\n- –x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge；\n- –verbose 输出更多调试信息；\n- -v, --version 打印版本并退出；\n- -H, --host HOST，远程操作 docker，被操作的 docker 需要开放 2375 端口\n\n**常用命令**\n\n- **up**：启动所有 docker-compose 服务\n\n```bash\ndocker-compose up\n# 启动所有docker-compose服务并后台运行\ndocker-compose up -d\n```\n\n- **down**：停止并删除容器、网络、卷\n\n```bash\ndocker-compose down\n```\n\n- **exec**：进入容器实例内部\n\n```bash\ndocker-compose exec docker-compose.yml文件中写的服务id /bin/bash\n```\n\n- **ps**：展示当前 docker-compose 编排过的运行的所有容器\n\n```bash\ndocker-compose ps\n```\n\n- **top**：展示当前 docker-compose 编排过的容器进程\n\n```bash\ndocker-compose top\n```\n\n- **logs**：查看容器输出日志\n\n```bash\ndocker-compose logs yml里面的服务id\n```\n\n- **build**：构建或者重新构建服务\n\n```bash\ndocker-compose build\n```\n\n- **start**：启动服务\n\n```bash\ndocker-compose start yml里面的服务id\n```\n\n- **stop**：停止服务\n\n```bash\ndocker-compose stop yml里面的服务id\n```\n\n- **restart**：重启服务\n\n```bash\ndocker-compose restart yml里面的服务id\n```\n\n- **config**：检查配置\n\n```bash\ndocker-compose config\n\n# 有问题才输出\ndocker-compose config -q\n```\n\n- **scale**：设置指定服务运行容器的个数，以 `service=num` 形式指定\n\n```bash\ndocker-compose scale yml里面的服务id=实例个数\n```\n\n### docker-compose.yml 文件规则\n\n官网地址：https://docs.docker.com/compose/compose-file/compose-file-v3/\n\n- **version**：指定 docker-compose.yml 文件的写法格式\n- **services**：服务，多个容器集合\n- **build**：配置构建时，Compose 会利用它自动构建镜像，该值可以是一个路径，也可以是一个对象，用于指定 Dockerfile 参数\n\n```yaml\nbuild: ./dir\n---------------\nbuild:\n    context: ./dir\n    dockerfile: Dockerfile\n    args:\n        buildno: 1\n```\n\n- **command**：覆盖容器启动后默认执行的命令\n\n```yaml\ncommand: bundle exec thin -p 3000\n----------------------------------\ncommand: [bundle,exec,thin,-p,3000]\n```\n\n- **dns**：配置 dns 服务器，可以是一个值或列表\n\n```yaml\ndns: 8.8.8.8\n------------\ndns:\n    - 8.8.8.8\n    - 9.9.9.9\n```\n\n- **dns_search**：配置 DNS 搜索域，可以是一个值或列表\n\n```yaml\ndns_search: example.com\n------------------------\ndns_search:\n    - dc1.example.com\n    - dc2.example.com\n```\n\n- **environment**：环境变量配置，可以用数组或字典两种方式\n\n```yaml\nenvironment:\n    RACK_ENV: development\n    SHOW: 'ture'\n-------------------------\nenvironment:\n    - RACK_ENV=development\n    - SHOW=ture\n```\n\n- **env_file**：从文件中获取环境变量，可以指定一个文件路径或路径列表，其优先级低于 environment 指定的环境变量\n\n```yaml\nenv_file: .env\n---------------\nenv_file:\n    - ./common.env\n```\n\n- **expose**：暴露端口，只将端口暴露给连接的服务，而不暴露给主机\n\n```yaml\nexpose:\n    - \"3000\"\n    - \"8000\"\n```\n\n- **image**：指定服务所使用的镜像\n\n```yaml\nimage: java\n```\n\n- **network_mode**：设置网络模式\n\n```yaml\nnetwork_mode: \"bridge\"\nnetwork_mode: \"host\"\nnetwork_mode: \"none\"\nnetwork_mode: \"service:[service name]\"\nnetwork_mode: \"container:[container name/id]\"\n```\n\n- **ports**：对外暴露的端口定义，和 expose 对应\n\n```yaml\nports:   # 暴露端口信息  - \"宿主机端口:容器暴露端口\"\n- \"8763:8763\"\n- \"8763:8763\"\n```\n\n- **links**：将指定容器连接到当前连接，可以设置别名，避免 ip 方式导致的容器重启动态改变的无法连接情况\n\n```yaml\nlinks:    # 指定服务名称:别名\n    - docker-compose-eureka-server:compose-eureka\n```\n\n- **volumes**：卷挂载路径\n\n```yaml\nvolumes:\n  - /lib\n  - /var\n```\n\n## Docker 轻量级可视化工具 Portainer\n\nPortainer 是一款轻量级的应用，它提供了图形化界面，用于方便地管理 Docker 环境，包括单机环境和集群环境。\n\ndocker 命令安装\n\n```bash\n# 官方版本\ndocker run -d -p 8000:8000 -p 9010:9000 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer\n\n# 中文版本\ndocker run -d --restart=always --name=\"portainer\" -p 9010:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data 6053537/portainer-ce\n\n# EE 商业版本（public 为中文汉化资源）\ndocker run -d -p 8000:8000 -p 9010:9000 -p 9443:9443 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /u01/portainer/portainer_data:/data -v /u01/portainer/public:/public portainer/portainer-ee:2.10.0\n```\n\n第一次登录需要创建 admin 用户，访问地址：`xxx.xxx.xxx.xxx:9010`\n\n![image-20211218203604987](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218203605.png)\n\n选择 local 选项卡后本地 docker 详细信息展示\n\n![image-20211218203652466](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218203652.png)\n\n管理本地环境\n\n![image-20211218203840461](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218203840.png)\n\n## Docker Swarm\n\n> 官方文档：https://docs.docker.com/engine/swarm/\n\n### 什么是 Docker Swarm\n\nSwarm 是 [Docker](https://www.docker.com/) 官方提供的一款集群管理工具，其主要作用是把若干台 Docker 主机抽象为一个整体，并且通过一个入口统一管理这些 Docker 主机上的各种 Docker 资源。\n\nDocker Swarm 和 Docker Compose 一样，都是 Docker 官方容器编排项目，但不同的是，Docker Compose 是一个在单个服务器或主机上创建多个容器的工具，而 Docker Swarm 则可以在多个服务器或主机上创建容器集群服务。\n\n### Docker Swarm 架构图\n\n![image-20220405181654649](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220405181654.png)\n\n上图可以看出，Swarm 是典型的 master-slave 结构，通过发现服务来选举 manager。manager 是中心管理节点，各个 node 上运行 agent 接受 manager 的统一管理，集群会自动通过 Raft 协议分布式选举出 manager 节点，无需额外的发现服务支持，避免了单点的瓶颈问题，同时也内置了 DNS 的负载均衡和对外部负载均衡机制的集成支持。\n\n### Swarm 关键概念\n\n- **Swarm（群）**\n\n嵌入在 Docker 引擎中的集群管理和编排功能是使用[swarmkit 构建的](https://github.com/docker/swarmkit/)。`Swarmkit` 是一个单独的项目，它实现了 Docker 的编排层并直接在 Docker 中使用。\n\n一个 swarm 由多个 Docker 主机组成，它们以**swarm 模式**运行并充当管理器（管理成员资格和委托）和工作人员（运行 [swarm 服务](https://docs.docker.com/engine/swarm/key-concepts/#services-and-tasks)）。给定的 Docker 主机可以是管理员、工作人员或同时执行这两种角色。创建服务时，您需要定义其最佳状态（副本数量、可用的网络和存储资源、服务向外界公开的端口等等）。Docker 致力于维护所需的状态。例如，如果一个工作节点变得不可用，Docker 会将该节点的任务安排在其他节点上。*任务*是一个 正在运行的容器，它是一个集群服务的一部分，由一个集群管理器管理，而不是一个独立的容器。\n\nswarm 服务相对于独立容器的主要优势之一是您可以修改服务的配置，包括它所连接的网络和卷，而无需手动重新启动服务。Docker 将更新配置，停止具有过期配置的服务任务，并创建与所需配置匹配的新任务。\n\n当 Docker 在 swarm 模式下运行时，您仍然可以在任何参与 swarm 的 Docker 主机以及 swarm 服务上运行独立容器。独立容器和 swarm 服务之间的一个关键区别在于，只有 `swarm manager` 可以管理 swarm，而独立容器可以在任何守护进程上启动。Docker 守护进程可以作为管理者、工作者或两者兼而有之。\n\n就像您可以使用[Docker Compose](https://docs.docker.com/compose/)定义和运行容器一样，您可以定义和运行[Swarm 服务](https://docs.docker.com/engine/swarm/services/)堆栈。\n\n- **Node（节点）**\n\n**节点**是参与 swarm 的 Docker 引擎的一个实例。您也可以将其视为 Docker 节点。您可以在单个物理计算机或云服务器上运行一个或多个节点，但生产群部署通常包括分布在多个物理和云计算机上的 Docker 节点。\n\n要将应用程序部署到 swarm，您需要向 **管理器节点**提交服务定义。管理节点将称为 [任务](https://docs.docker.com/engine/swarm/key-concepts/#services-and-tasks)的工作单元分派给工作节点。\n\n管理器节点还执行维护集群所需状态所需的编排和集群管理功能。管理器节点选举一个领导者来执行编排任务。\n\n**工作节点**接收并执行从管理节点分派的任务。默认情况下，管理器节点也将服务作为工作节点运行，但您可以将它们配置为专门运行管理器任务并成为仅管理器节点。代理在每个工作节点上运行并报告分配给它的任务。`worker` 节点将其分配的任务的当前状态通知给 `manager` 节点，以便 `manager` 可以保持每个 `worker` 的期望状态。\n\n- **Service（服务）**\n\n**服务**是要在管理节点或工作节点上执行的任务的定义。它是 swarm 系统的**中心结构**，也是用户与 swarm 交互的主要根源。\n\n创建服务时，您需要指定要使用的容器映像以及在运行的容器中执行的命令。\n\n在**复制服务**模型中，群管理器根据您在所需状态中设置的规模在节点之间分配特定数量的副本任务。\n\n对于**全局服务**，swarm 在集群中的每个可用节点上为服务运行一个任务。\n\n- **Task（任务）**\n\n一个**任务**携带一个 Docker 容器和在容器内运行的命令。它是 swarm 的**原子调度单元**。Manager 节点根据服务规模中设置的副本数将任务分配给工作节点。一旦任务被分配给一个节点，它就不能移动到另一个节点。它只能在分配的节点上运行或失败。\n\n- **Load balancing（负载均衡）**\n\nswarm 管理器使用**入口负载平衡**将您希望在外部提供给 swarm 的服务公开。swarm manager 可以自动为服务分配一个**PublishedPort**，或者您可以为该服务配置一个 PublishedPort。您可以指定任何未使用的端口。如果不指定端口，swarm manager 会为服务分配一个 `30000-32767` 范围内的端口。\n\n外部组件（例如云负载均衡器）可以访问集群中任何节点的 PublishedPort 上的服务，无论该节点当前是否正在运行该服务的任务。swarm 中的所有节点将入口连接路由到正在运行的任务实例。\n\nSwarm 模式有一个内部 `DNS` 组件，它自动为 swarm 中的每个服务分配一个 DNS 条目。swarm manager 使用**内部负载平衡**根据服务的 DNS 名称在集群内的服务之间分配请求。\n\n### Swarm 工作原理\n\n#### 节点如何工作\n\nSwarm 集群由管理节点（Manager）和工作节点（Work）构成。\n\n![image-20220716220722605](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220716220722.png)\n\n##### 管理节点\n\nManager 节点处理集群管理任务：\n\n- 维护集群状态\n- 调度服务\n- 服务群模式[HTTP API 端点](https://docs.docker.com/engine/api/)\n\n使用[Raft](https://raft.github.io/raft.pdf)实现，管理器维护整个 swarm 和在其上运行的所有服务的一致内部状态。出于测试目的，可以使用单个管理器运行 swarm。如果单管理器集群中的管理器发生故障，您的服务将继续运行，但您需要创建一个新集群才能恢复。\n\n为了利用 swarm 模式的容错特性，Docker 建议您根据组织的高可用性要求实现奇数个节点。当您有多个管理器时，您可以从管理器节点的故障中恢复而无需停机。\n\n- 一个三管理器群最多可以容忍一名管理器的损失。\n- 一个五管理器群最多可以同时丢失两个管理器节点。\n- 一个`N`管理器集群最多可以容忍丢失 `(N-1)/2`管理器。\n- Docker 建议一个 swarm 最多使用七个管理器节点。\n\n> **重要提示**：添加更多管理器并不意味着增加可扩展性或提高性能。一般来说，情况正好相反。\n\n##### 工作节点\n\n工作节点也是 Docker 引擎的实例，其唯一目的是执行容器。Worker 节点不参与 Raft 分布式状态，不做调度决策，也不服务于 swarm 模式的 HTTP API。\n\n您可以创建一个由一个管理器节点组成的集群，但如果没有至少一个管理器节点，您就不能拥有一个工作程序节点。默认情况下，所有 manager 也是 worker。在单个管理节点集群中，您可以运行类似 `docker service create` 的命令，并且调度程序将所有任务放在本地引擎上。\n\n要防止调度程序将任务放置在多节点集群中的管理器节点上，请将管理器节点的可用性设置为 `Drain`。调度器优雅地停止 `Drain` 模式节点上的任务，并在一个 `Active` 节点上调度任务。调度程序不会将新任务分配给 `Drain` 可用的节点。\n\n请参阅[docker node update](https://docs.docker.com/engine/reference/commandline/node_update/) 命令行参考以了解如何更改节点可用性。\n\n#### 服务如何运作\n\n要在 Docker 引擎处于 swarm 模式时部署应用程序映像，您需要创建一个服务。通常，服务是某个更大应用程序上下文中微服务的映像。服务的示例可能包括 HTTP 服务器、数据库或您希望在分布式环境中运行的任何其他类型的可执行程序。\n\n创建服务时，您需要指定要使用的容器映像以及在运行的容器中执行的命令。您还可以定义服务的选项，包括：\n\n- swarm 使服务在 swarm 外部可用的端口\n- 服务连接到集群中的其他服务的覆盖网络\n- CPU 和内存限制和预留\n- 滚动更新策略\n- 在 swarm 中运行的图像的副本数\n\n##### 服务、任务和容器\n\n当您将服务部署到 swarm 时，swarm manager 接受您的服务定义作为服务的所需状态。然后，它将集群中的节点上的服务安排为一个或多个副本任务。这些任务在 swarm 中的节点上彼此独立运行。\n\n例如，假设您想在 nginx 的三个实例之间进行负载平衡。下图显示了具有三个副本的 nginx 服务。nginx 的三个实例中的每一个都是 swarm 中的一个任务。\n\n![image-20220717111642619](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220717111642.png)\n\n容器是一个独立的进程。在 swarm 模式模型中，每个任务只调用一个容器。任务类似于调度程序放置容器的“槽”。一旦容器处于活动状态，调度程序就会识别出任务处于运行状态。如果容器未通过健康检查或终止，则任务终止。\n\n##### 任务和调度\n\n任务是 swarm 中调度的原子单元。当您通过创建或更新服务来声明所需的服务状态时，编排器通过调度任务来实现所需的状态。例如，您定义了一个服务，该服务指示协调器始终保持三个 HTTP 侦听器实例运行。编排器通过创建三个任务来响应。每个任务都是调度程序通过生成容器来填充的槽。容器是任务的实例化。如果 HTTP 侦听器任务随后未能通过其健康检查或崩溃，编排器将创建一个新的副本任务来生成一个新容器。\n\n任务是一种单向机制。它通过一系列状态单调地进行：分配、准备、运行等。如果任务失败，编排器将删除任务及其容器，然后根据服务指定的所需状态创建一个新任务来替换它。\n\nDocker swarm 模式的底层逻辑是一个通用的调度器和编排器。服务和任务抽象本身并不知道它们实现的容器。假设您可以实现其他类型的任务，例如虚拟机任务或非容器化流程任务。调度器和编排器不知道任务的类型。但是，当前版本的 Docker 只支持容器任务。\n\n下图显示了 swarm 模式如何接受服务创建请求并将任务调度到工作节点。\n\n![image-20220717231629076](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220717231629.png)\n\n##### 待办服务（pending）\n\n一个服务可以这样配置，使得当前在 swarm 中的任何节点都不能运行它的任务。在这种情况下，服务保持状态`pending`。以下是服务可能保持状态的几个示例`pending`。\n\n> **注意**：如果您的唯一目的是阻止部署服务，请将服务缩放到 0，而不是尝试将其配置为保留在`pending`.\n\n- 如果所有节点都已暂停或耗尽，并且您创建了一项服务，则该服务将处于挂起状态，直到节点可用为止。实际上，第一个可用的节点会获得所有任务，因此这在生产环境中不是一件好事。\n- 您可以为服务保留特定数量的内存。如果 swarm 中没有节点具有所需的内存量，则服务将保持挂起状态，直到可以运行其任务的节点可用。如果您指定一个非常大的值，例如 500 GB，则该任务将永远保持挂起状态，除非您确实有一个可以满足它的节点。\n- 您可以对服务施加放置约束，并且这些约束可能无法在给定时间得到遵守。\n\n这种行为说明您的任务的要求和配置与当前的 swarm 状态并没有紧密联系。作为 swarm 的管理员，您声明了您的 swarm 所需的状态，并且管理器与 swarm 中的节点一起创建该状态。您不需要对 swarm 上的任务进行微观管理。\n\n##### 部署模式\n\n有两种类型的服务部署，复制的（`replicated`）和全局的（`global`）。\n\n对于复制服务，您指定要运行的相同任务的数量。例如，您决定部署具有三个副本的 HTTP 服务，每个副本提供相同的内容。\n\n全局服务是在每个节点上运行一个任务的服务。没有预先指定的任务数量。每次将节点添加到 swarm 时，编排器都会创建一个任务，调度器会将任务分配给新节点。全局服务的良好候选者是监控代理、防病毒扫描程序或您希望在集群中的每个节点上运行的其他类型的容器。\n\n下图显示了黄色的三服务副本和灰色的全局服务。\n\n![image-20220717232121078](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220717232121.png)\n\n#### Swarm 任务状态\n\nDocker 允许创建可以启动任务的服务。服务是对所需状态的描述，而任务完成工作。工作按以下顺序安排在 swarm 节点上：\n\n1. 通过使用创建服务`docker service create`。\n2. 请求转到 Docker 管理器节点。\n3. Docker 管理器节点安排服务在特定节点上运行。\n4. 每个服务可以启动多个任务。\n5. 每个任务都有一个生命周期，其状态包括 `NEW`、`PENDING` 和 `COMPLETE`。\n\n任务是运行一次即可完成的执行单元。当一个任务停止时，它不会再次执行，但一个新的任务可能会取代它。\n\n任务通过多个状态前进，直到它们完成或失败。任务在 `NEW` 状态中初始化。任务通过多个状态向前推进，并且其状态不会后退。例如，任务永远不会从 `COMPLETE` 到 `RUNNING`。\n\n任务按以下顺序通过状态：\n\n| 任务状态    | 描述                                                                   |\n| :---------- | :--------------------------------------------------------------------- |\n| `NEW`       | 任务已初始化。                                                         |\n| `PENDING`   | 分配了任务的资源。                                                     |\n| `ASSIGNED`  | Docker 将任务分配给节点。                                              |\n| `ACCEPTED`  | 该任务已被工作节点接受。如果工作节点拒绝任务，则状态更改为`REJECTED`。 |\n| `PREPARING` | Docker 正在准备任务。                                                  |\n| `STARTING`  | Docker 正在启动任务。                                                  |\n| `RUNNING`   | 任务正在执行。                                                         |\n| `COMPLETE`  | 任务退出，没有错误代码。                                               |\n| `FAILED`    | 任务以错误代码退出。                                                   |\n| `SHUTDOWN`  | Docker 请求关闭任务。                                                  |\n| `REJECTED`  | 工作节点拒绝了该任务。                                                 |\n| `ORPHANED`  | 节点关闭时间过长。                                                     |\n| `REMOVE`    | 该任务不是终端，但相关服务已被删除或缩小。                             |\n\n> **查看任务状态**\n>\n> 运行 docker service ps <service-name>以获取任务的状态。该 `CURRENT STATE` 字段显示任务的状态以及它在那里的时间。\n\n### 常用命令\n\n#### 创建 Swarm\n\n1. 运行以下命令来创建一个新的 swarm：\n\n```bash\n$ docker swarm init --advertise-addr <MANAGER-IP>\n```\n\n2. 例如：\n\n```bash\n$ docker swarm init --advertise-addr 192.168.88.230\nSwarm initialized: current node (uo7m7w01d5wfdjt0qn9m3aau4) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-63d99h3uln0k8qfne7w39qt6f1tv4yddvevyzwh3uzhhfl73wf-3abelxhlyvhm54klavpbr06r5 192.168.88.230:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n```\n\n> 该 `--advertise-addr` 标志将管理节点配置为将其地址发布为 `192.168.88.230`。 swarm 中的其他节点必须能够访问该 IP 地址的 manager。\n>\n> 输出包括将新节点加入 swarm 的命令。根据 `--token` 标志的值，节点将作为 manager 或 worker 加入。\n\n3. 运行`docker info`查看 swarm 的当前状态：\n\n```bash\n$ docker info\n Containers: 3\n  Running: 3\n  Paused: 0\n  Stopped: 0\n Images: 4\n ...snip...\n Swarm: active\n  NodeID: uo7m7w01d5wfdjt0qn9m3aau4\n  Is Manager: true\n  ClusterID: ym3kr78wgx258lawn3iclgxwq\n  Managers: 1\n  Nodes: 3\n  ...snip...\n```\n\n4. 运行`docker node ls`命令查看节点信息：\n\n```bash\n$ docker node ls\nID                            HOSTNAME   STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION\nuo7m7w01d5wfdjt0qn9m3aau4 *   88230      Ready     Active         Leader           20.10.13\np4tlkfxa4d2ne1diq0mtlifs9     88233      Ready     Active                          20.10.17\noawv9cs597brq8h5hzis3ynlc     88237      Ready     Active                          20.10.17\n```\n\n#### 将节点添加到 Swarm\n\n当你创建了一个带有管理节点的 swarm 时，你就可以添加工作节点了。\n\n1. 运行创建 Swarm 中 `docker swarm init` 步骤生成的命令，以创建一个加入现有 swarm 的工作节点：\n\n```bash\n$ docker swarm join --token SWMTKN-1-63d99h3uln0k8qfne7w39qt6f1tv4yddvevyzwh3uzhhfl73wf-3abelxhlyvhm54klavpbr06r5 192.168.88.230:2377\n```\n\n2. 如果没有可用的命令，可以在管理节点上运行以下命令来生成工作节点的加入命令：\n\n```bash\n$ docker swarm join-token worker\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-63d99h3uln0k8qfne7w39qt6f1tv4yddvevyzwh3uzhhfl73wf-3abelxhlyvhm54klavpbr06r5 192.168.88.230:2377\n```\n\n3. 生成管理节点的加入命令：\n\n```bash\n$ docker swarm join-token manager\nTo add a manager to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-63d99h3uln0k8qfne7w39qt6f1tv4yddvevyzwh3uzhhfl73wf-0so9mhkgy8btr579ho4pfza9n 192.168.88.230:2377\n```\n\n#### 删除节点\n\n先在要删除的节点上运行：\n\n```bash\ndocker swarm leave\n```\n\n在 `manage` 节点上运行：\n\n```bash\ndocker node rm NODE \n```\n\n#### 节点提升\n\n**用法**\n\n```bash\ndocker node promote NODE [NODE...]\n```\n\n**说明**\n\n将节点提升为 `manager`。该命令只能在 `manage node` 上执行。\n\n> **笔记**\n>\n> 这是一个集群管理命令，必须在 swarm manager 节点上执行。\n\n#### 节点降级\n\n**用法**\n\n```bash\ndocker node demote NODE [NODE...]\n```\n\n**说明**\n\n降级现有 `manager`，使其不再是 `manager`。\n\n> **笔记**\n>\n> 这是一个集群管理命令，必须在 swarm manager 节点上执行。\n\n#### 部署服务\n\n1. 在管理节点上运行以下命令：\n\n```bash\n$ docker service create --replicas 1 --name helloworld alpine ping docker.com\nktcjndh4nj4nbwp461idnob0y\n```\n\n- 该 `docker service create` 命令创建服务。\n- 该 `--name` 标志命名服务 `helloworld`。\n- 该 `--replicas` 标志指定 1 个正在运行的实例的所需状态。\n- 参数 `alpine ping docker.com` 将服务定义为执行命令的 Alpine Linux 容器 `ping docker.com`。\n\n2. 运行 `docker service ls` 查看正在运行的服务列表：\n\n```bash\n$ docker service ls\nID             NAME         MODE         REPLICAS   IMAGE           PORTS\nktcjndh4nj4n   helloworld   replicated   1/1        alpine:latest\n```\n\n#### 检查服务\n\n将服务部署到 swarm 后，可以使用 `Docker CLI` 查看有关在 swarm 中运行的服务的详细信息。\n\n1. 运行 `docker service inspect --pretty <SERVICE-ID>` 以易于阅读的格式显示有关服务的详细信息。\n\n```\n$ docker service inspect --pretty helloworld\n\nID:\t\tktcjndh4nj4nbwp461idnob0y\nName:\t\thelloworld\nService Mode:\tReplicated\n Replicas:\t1\nPlacement:\nContainerSpec:\n Image:\t\talpine\n Args:\t\tping docker.com\n Init:\t\tfalse\nResources:\nEndpoint Mode:\tvip\n```\n\n> **提示**：要以 json 格式返回服务详细信息，请运行不带 `--pretty` 标志的相同命令。\n\n```bash\n$ docker service inspect helloworld\n[\n    {\n        \"ID\": \"ktcjndh4nj4nbwp461idnob0y\",\n        \"Version\": {\n            \"Index\": 28\n        },\n        \"CreatedAt\": \"2022-04-05T15:00:31.72873489Z\",\n        \"UpdatedAt\": \"2022-04-05T15:00:31.72873489Z\",\n        \"Spec\": {\n            \"Name\": \"helloworld\",\n            \"Labels\": {},\n            \"TaskTemplate\": {\n                \"ContainerSpec\": {\n                    \"Image\": \"alpine\",\n                    \"Args\": [\n                        \"ping\",\n                        \"docker.com\"\n                    ],\n                    \"Init\": false,\n                    \"StopGracePeriod\": 10000000000,\n                    \"DNSConfig\": {},\n                    \"Isolation\": \"default\"\n                },\n                \"Resources\": {\n                    \"Limits\": {},\n                    \"Reservations\": {}\n                },\n                \"RestartPolicy\": {\n                    \"Condition\": \"any\",\n                    \"Delay\": 5000000000,\n                    \"MaxAttempts\": 0\n                },\n                \"Placement\": {},\n                \"ForceUpdate\": 0,\n                \"Runtime\": \"container\"\n            },\n            \"Mode\": {\n                \"Replicated\": {\n                    \"Replicas\": 1\n                }\n            },\n            \"EndpointSpec\": {\n                \"Mode\": \"vip\"\n            }\n        },\n        \"Endpoint\": {\n            \"Spec\": {}\n        }\n    }\n]\n```\n\n2. 运行 `docker service ps <SERVICE-ID>` 查看哪些节点正在运行该服务：\n\n```bash\n$ docker service ps helloworld\nID             NAME           IMAGE           NODE      DESIRED STATE   CURRENT STATE            ERROR     PORTS\n3s1myvuaoc0k   helloworld.1.3s1myvuaoc0kdvlaz4fgz3usk   alpine:latest   8886      Running         Running 31 minutes ago\n```\n\n在这种情况下，服务的一个实例正在节点 `helloworld` 上运行 。`8886` 您可能会看到该服务在您的管理器节点上运行。默认情况下，swarm 中的管理节点可以像工作节点一样执行任务。\n\nSwarm 还向您显示服务任务的 `DESIRED STATE` 和 `CURRENT STATE`，以便您可以查看任务是否根据服务定义运行。\n\n3. 在运行 `docker ps` 任务的节点上运行以查看有关任务容器的详细信息。\n\n> **提示**：如果`helloworld`在管理节点以外的节点上运行，则必须 ssh 到该节点。\n\n```bash\n$ docker ps\nCONTAINER ID   IMAGE           COMMAND             CREATED          STATUS          PORTS     NAMES\n3128610843c3   alpine:latest   \"ping docker.com\"   38 minutes ago   Up 38 minutes    helloworld.1.3s1myvuaoc0kdvlaz4fgz3usk\n```\n\n#### 扩展服务\n\n将服务部署到 swarm 后，您就可以使用 `Docker CLI` 扩展服务中的容器数量了。在服务中运行的容器称为“任务”。\n\n1. 运行以下命令以更改在 swarm 中运行的服务的所需状态\n\n```bash\n$ docker service scale <SERVICE-ID>=<NUMBER-OF-TASKS>\n```\n\n例如：\n\n```bash\n$ docker service scale helloworld=5\nhellworld scaled to 5\n```\n\n2. 运行 `docker service ps <SERVICE-ID>` 查看更新的任务列表：\n\n```bash\n$ docker service ps helloworld\nID             NAME           IMAGE           NODE      DESIRED STATE   CURRENT STATE                ERROR     PORTS\n3s1myvuaoc0k   helloworld.1   alpine:latest   8886      Running         Running 43 minutes ago\nsub0vfkz17t1   helloworld.2   alpine:latest   88235     Running         Running 53 seconds ago\nqiiwkq8eaw4c   helloworld.3   alpine:latest   88236     Running         Running about a minute ago\n272jo44c63qd   helloworld.4   alpine:latest   88236     Running         Running about a minute ago\nvx61pv6vzm9y   helloworld.5   alpine:latest   8886      Running         Running 2 minutes ago\n```\n\n您可以看到 swarm 创建了 4 个新任务以扩展到总共 5 个正在运行的 Alpine Linux 实例。任务分布在 swarm 的三个节点之间。\n\n#### 删除服务\n\n1. 运行 `docker service rm helloworld` 以删除 `helloworld` 服务。\n\n```bash\n$ docker service rm helloworld\nhelloworld\n```\n\n#### 应用滚动更新\n\n1. 将您的 Redis 标签部署到 swarm 并为 swarm 配置 10 秒的更新延迟。请注意，以下示例显示了较旧的 Redis 标记：\n\n```bash\n$ docker service create \\\n  --replicas 3 \\\n  --name redis \\\n  --update-delay 10s \\\n  redis:3.0.6\npvud31bgvl7e5ljf6xuxcn7dh\n```\n\n您在服务部署时配置滚动更新策略。\n\n该 `--update-delay` 标志配置更新服务任务或任务集之间的时间延迟。您可以将时间描述 `T` 为秒数 `Ts`、分钟数 `Tm` 或小时数的组合 `Th`。所以 `10m30s` 表示延迟 10 分 30 秒。\n\n默认情况下，调度程序一次更新 1 个任务。您可以传递该 `--update-parallelism` 标志来配置调度程序同时更新的最大服务任务数。\n\n默认情况下，当单个任务的更新返回状态为 时 `RUNNING`，调度程序会安排另一个任务进行更新，直到所有任务都更新完毕。如果在更新期间的任何时间任务返回 `FAILED`，调度程序会暂停更新。您可以使用或 的 `--update-failure-action` 标志来控制行为 。`docker service create` `docker service update`\n\n2. 检查`redis`服务：\n\n```bash\n$ docker service inspect --pretty redis\n\nID:\t\tpvud31bgvl7e5ljf6xuxcn7dh\nName:\t\tredis\nService Mode:\tReplicated\n Replicas:\t3\nPlacement:\nUpdateConfig:\n Parallelism:\t1\n Delay:\t\t10s\nContainerSpec:\n Image:\t\tredis:3.0.6\n Init:\t\tfalse\nResources:\nEndpoint Mode:\tvip\n```\n\n3. 现在您可以更新 `redis`， swarm manager 根据 `UpdateConfig` 策略将更新应用到节点：\n\n```bash\n$ docker service update --image redis:3.0.7 redis\nredis\n```\n\n默认情况下，调度程序按如下方式应用滚动更新：\n\n- 停止第一个任务。\n- 为已停止的任务安排更新。\n- 启动更新任务的容器。\n- 如果一个任务的更新返回`RUNNING`，等待指定的延迟时间然后开始下一个任务。\n- 如果在更新期间的任何时间，任务返回`FAILED`，则暂停更新。\n\n4. 运行 `docker service inspect --pretty redis` 以查看处于所需状态的新图像：\n\n```bash\n$ docker service inspect --pretty redis\n\nID:\t\tpvud31bgvl7e5ljf6xuxcn7dh\nName:\t\tredis\nService Mode:\tReplicated\n Replicas:\t3\nPlacement:\nUpdateConfig:\n Parallelism:\t1\n Delay:\t\t10s\nContainerSpec:\n Image:\t\tredis:3.0.7\n Init:\t\tfalse\nResources:\nEndpoint Mode:\tvip\n```\n\n5. 运行 `docker service ps <SERVICE-ID>` 以观看滚动更新：\n\n```bash\n$ docker service ps redis\nID             NAME          IMAGE         NODE      DESIRED STATE   CURRENT STATE            ERROR     PORTS\ns3uwdrtssguv   redis.1       redis:3.0.7   88236     Running         Running 3 minutes ago\n9nav9b094si0    \\_ redis.1   redis:3.0.6   88236     Shutdown        Shutdown 5 minutes ago\ntdy6tqfhweo4   redis.2       redis:3.0.7   88235     Running         Running 2 minutes ago\nt9vr0kt1h8av    \\_ redis.2   redis:3.0.6   88235     Shutdown        Shutdown 3 minutes ago\nxjc6v95dayhv   redis.3       redis:3.0.7   8886      Running         Running 3 minutes ago\nbiy701m9tvat    \\_ redis.3   redis:3.0.6   8886      Shutdown        Shutdown 4 minutes ago\n```\n\n#### 排空一个节点\n\n有时，例如计划的维护时间，您需要将节点设置为 `DRAIN` 可用。`DRAIN` 可用性阻止节点从集群管理器接收新任务。这也意味着管理器停止在节点上运行的任务，并在可用的节点上启动副本任务 `ACTIVE`。\n\n> **重要**：将节点设置为 `DRAIN` 不会从该节点删除独立容器，例如使用 Docker 引擎 API 创建的 `docker run` 容器 `docker-compose up`。一个节点的状态，包括 `DRAIN`，只影响节点调度 swarm 服务工作负载的能力。\n\n1. 运行 `docker node update --availability drain <NODE-ID>` 以排空已分配任务的节点：\n\n```bash\n$ docker node update --availability drain worker1\nwork1\n```\n\n2. 检查节点其可用性：\n\n```bash\n$ docker node inspect --pretty worker1\n```\n\n`AVAILABILITY` 属性值为 `Drain`\n\n## Docker Stack\n\n### deploy\n\n指定与服务的部署和运行有关的配置。只在 swarm 模式下才会有用。\n\n```\nversion: \"3.7\"\nservices:\n  redis:\n    image: redis:alpine\n    deploy:\nsssssssss\n      endpoint_mode: dnsrr\n      labels:\n        description: \"This redis service label\"\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 50M\n        reservations:\n          cpus: '0.25'\n          memory: 20M\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 120s\n```\n\n可以选参数：\n\n**endpoint_mode**：访问集群服务的方式。\n\n```\nendpoint_mode: vip\n# Docker 集群服务一个对外的虚拟 ip。所有的请求都会通过这个虚拟 ip 到达集群服务内部的机器。\nendpoint_mode: dnsrr\n# DNS 轮询（DNSRR）。所有的请求会自动轮询获取到集群 ip 列表中的一个 ip 地址。\n```\n\n**labels**：在服务上设置标签。可以用容器上的 labels（跟 deploy 同级的配置） 覆盖 deploy 下的 labels。\n\n**mode**：指定服务提供的模式。\n\n- **replicated**：复制服务，复制指定服务到集群的机器上。\n\n- **global**：全局服务，服务将部署至集群的每个节点。\n\n- 图解：下图中黄色的方块是 replicated 模式的运行情况，灰色方块是 global 模式的运行情况。\n\n  ![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220713152904.png)\n\n**replicas：mode** 为 replicated 时，需要使用此参数配置具体运行的节点数量。\n\n**resources**：配置服务器资源使用的限制，例如上例子，配置 redis 集群运行需要的 cpu 的百分比 和 内存的占用。避免占用资源过高出现异常。\n\n**restart_policy**：配置如何在退出容器时重新启动容器。\n\n- condition：可选 none，on-failure 或者 any（默认值：any）。\n- delay：设置多久之后重启（默认值：0）。\n- max_attempts：尝试重新启动容器的次数，超出次数，则不再尝试（默认值：一直重试）。\n- window：设置容器重启超时时间（默认值：0）。\n\n**rollback_config**：配置在更新失败的情况下应如何回滚服务。\n\n- parallelism：一次要回滚的容器数。如果设置为 0，则所有容器将同时回滚。\n- delay：每个容器组回滚之间等待的时间（默认为 0s）。\n- failure_action：如果回滚失败，该怎么办。其中一个 continue 或者 pause（默认 pause）。\n- monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为 0s）。\n- max_failure_ratio：在回滚期间可以容忍的故障率（默认为 0）。\n- order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认 stop-first ）。\n\n**update_config**：配置应如何更新服务，对于配置滚动更新很有用。\n\n- parallelism：一次更新的容器数。\n- delay：在更新一组容器之间等待的时间。\n- failure_action：如果更新失败，该怎么办。其中一个 continue，rollback 或者 pause （默认：pause）。\n- monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为 0s）。\n- max_failure_ratio：在更新过程中可以容忍的故障率。\n- order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认 stop-first）。\n\n**注**：仅支持 V3.4 及更高版本。\n","tags":["Docker","容器"],"categories":["Linux"]},{"title":"错误码及全局异常处理","slug":"错误码及全局异常处理","url":"/2022/04/07/816ad4bd.html","content":"\n## 写在前面\n\n在软件开发过程中，不可避免的是需要处理各种异常，在 Java 中，处理异常的方式一般就是采用`try{...}catch{...}finally{...}`代码块。在业务系统中，可能会有大量的异常处理代码块，这样不仅有大量的冗余代码，而且还影响代码的可读性。比较下面两张图：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220328132128.png\" alt=\"image-20220328132128521\" style=\"zoom:67%;\" />\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220328132228.png\" alt=\"image-20220328132228437\" style=\"zoom:67%;\" />\n\n可以看到，明显第二种的代码简洁，可读性高！此处的代码是在 Controller 层中的，在 Service 层中会有更多的异常处理代码块。\n\n那么我们应该如何优雅的进行异常处理呢？\n\n## 什么是统一异常处理\n\n在 Spring 里，我们可以使用@ControllerAdvice 来处理一些全局性的东西，最常见的是结合@ExceptionHandler 注解用于全局异常的处理。\n\n@ControllerAdvice 是在类上声明的注解，其用法主要有三点：\n\n- `@ExceptionHandler`注解标注的方法：用于捕获 Controller 中抛出的不同类型的异常，从而达到异常全局处理的目的\n- `@InitBinder`注解标注的方法：用于请求中注册自定义参数的解析，从而达到自定义请求参数格式的目的\n- `@ModelAttribute`注解标注的方法：表示此方法会在执行目标 Controller 方法之前执行\n\n跟异常处理有关的只有`@ExceptionHandler`注解，从字面意思上理解，就是`异常处理器`的意思，其实际作用也正是如此：若在某个`Controller`类定义一个异常处理方法，并在方法上添加该注解，那么当出现指定的异常时，会执行该处理异常的方法，其可以使用`SpringMVC`提供的数据绑定，比如接受一个当前抛出的`Throwable`对象。\n\n但是，这样一来，就必须在每一个`Controller`类都定义一套这样的异常处理方法，因为异常可以是各种各样。这样一来，就会造成大量的冗余代码，而且若需要新增一种异常的处理逻辑，就必须修改所有`Controller`类了，很不优雅。\n\n当然你可能会说，那就定义个类似`BaseController`的基类，这样总行了吧。\n\n这种做法虽然没错，但仍不尽善尽美，因为这样的代码有一定的侵入性和耦合性。简简单单的`Controller`，我为啥非得继承这样一个类呢，万一已经继承其他基类了呢。大家都知道`Java`只能继承一个类。\n\n那有没有一种方案，既不需要跟`Controller`耦合，也可以将定义的 **异常处理器** 应用到所有控制器呢？所以注解`@ControllerAdvice`出现了，简单的说，该注解可以把异常处理器应用到所有控制器，而不是单个控制器。借助该注解，我们可以实现：在独立的某个地方，比如单独一个类，定义一套对各种异常的处理机制，然后在类的签名加上注解`@ControllerAdvice`，统一对 `不同阶段的`、`不同异常` 进行处理。这就是统一异常处理的原理。\n\n> 注意到上面对异常按阶段进行分类，大体可以分成：进入`Controller`前的异常 和 `Service` 层异常，具体可以参考下图：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220328135114.png\" alt=\"image-20220328135114123\" style=\"zoom:67%;\" />\n\n## 统一异常处理实战\n\n通过全局统一的异常处理将自定义的错误码以 json 的格式返回给前端。\n\n### 统一返回结果类\n\n```\npackage org.jeecg.common.api.vo;\n\nimport com.fasterxml.jackson.annotation.JsonIgnore;\nimport io.swagger.annotations.ApiModel;\nimport io.swagger.annotations.ApiModelProperty;\nimport lombok.Data;\nimport org.jeecg.common.constant.CommonConstant;\nimport org.jeecg.common.constant.enums.ErrorCodeEnum;\n\nimport java.io.Serializable;\n\n/**\n * @description: 接口返回对象 -更新\n * @author: luo_Jj\n * @date: 2022/3/24 17:58\n */\n@Data\n@ApiModel(value=\"接口返回对象\", description=\"接口返回对象\")\npublic class Result<T> implements Serializable {\n\n\tprivate static final long serialVersionUID = 1L;\n\n\t/**\n\t * 成功标志\n\t */\n\t@ApiModelProperty(value = \"成功标志\")\n\tprivate boolean success = true;\n\n\t/**\n\t * 返回处理消息\n\t */\n\t@ApiModelProperty(value = \"返回处理消息\")\n\tprivate String message = \"\";\n\n\t/**\n\t * 返回代码\n\t */\n\t@ApiModelProperty(value = \"返回代码\")\n\tprivate String code = \"000000\";\n\n\t/**\n\t * 返回数据对象 data\n\t */\n\t@ApiModelProperty(value = \"返回数据对象\")\n\tprivate T result;\n\n\t/**\n\t * 时间戳\n\t */\n\t@ApiModelProperty(value = \"时间戳\")\n\tprivate long timestamp = System.currentTimeMillis();\n\n\tpublic Result() {\n\t}\n\n\tpublic Result(String code,String message) {\n\t\tthis.code = code;\n\t\tthis.message = message;\n\t}\n\n\tpublic Result<T> success(String message) {\n\t\tthis.message = message;\n\t\tthis.code = CommonConstant.SC_OK_200;\n\t\tthis.success = true;\n\t\treturn this;\n\t}\n\n\tpublic static<T> Result<T> OK() {\n\t\tResult<T> r = new Result<T>();\n\t\tr.setSuccess(true);\n\t\tr.setCode(CommonConstant.SC_OK_200);\n\t\treturn r;\n\t}\n\n\tpublic static<T> Result<T> OK(T data) {\n\t\tResult<T> r = new Result<T>();\n\t\tr.setSuccess(true);\n\t\tr.setCode(CommonConstant.SC_OK_200);\n\t\tr.setResult(data);\n\t\treturn r;\n\t}\n\n\tpublic static<T> Result<T> OK(String msg, T data) {\n\t\tResult<T> r = new Result<T>();\n\t\tr.setSuccess(true);\n\t\tr.setCode(CommonConstant.SC_OK_200);\n\t\tr.setMessage(msg);\n\t\tr.setResult(data);\n\t\treturn r;\n\t}\n\n\tpublic static<T> Result<T> error(String msg, T data) {\n\t\tResult<T> r = new Result<T>();\n\t\tr.setSuccess(false);\n\t\tr.setCode(CommonConstant.SC_INTERNAL_SERVER_ERROR_500);\n\t\tr.setMessage(msg);\n\t\tr.setResult(data);\n\t\treturn r;\n\t}\n\n\tpublic static<T> Result<T> error(String msg) {\n\t\treturn error(CommonConstant.SC_INTERNAL_SERVER_ERROR_500, msg);\n\t}\n\n\t/**\n\t* @description: 传递一个错误码枚举\n\t* @author: luo_jj\n\t* @date: 2022/3/28 14:55\n\t* @param errorCodeEnum:\n\t* @return: org.jeecg.common.api.vo.Result<T>\n\t*/\n\tpublic static<T> Result<T> error(ErrorCodeEnum errorCodeEnum) {\n\t\treturn error(errorCodeEnum.getCode(), errorCodeEnum.getMessage());\n\t}\n\n\tpublic static<T> Result<T> error(String code, String msg) {\n\t\tResult<T> r = new Result<T>();\n\t\tr.setCode(code);\n\t\tr.setMessage(msg);\n\t\tr.setSuccess(false);\n\t\treturn r;\n\t}\n\n\tpublic Result<T> error500(String message) {\n\t\tthis.message = message;\n\t\tthis.code = CommonConstant.SC_INTERNAL_SERVER_ERROR_500;\n\t\tthis.success = false;\n\t\treturn this;\n\t}\n\n}\n```\n\n### 错误码枚举类\n\n需要定义一个枚举类，包含所有的自定义的结果码：\n\n```\npackage org.jeecg.common.constant.enums;\n\nimport lombok.AllArgsConstructor;\nimport lombok.Getter;\nimport lombok.NoArgsConstructor;\n\n/**\n * @description: 错误码枚举\n * @author: luo_jj\n * @date: 2022年03月24日 17:15\n */\n@Getter\n@AllArgsConstructor\n@NoArgsConstructor\npublic enum ResultCodeEnum {\n    /*\n    * 错误产生来源分为 A/B/C\n    * A 表示错误来源于用户，比如参数错误，用户安装版本过低，用户支付超时等问题；\n    * B 表示错误来源于当前系统，往往是业务逻辑出错，或程序健壮性差等问题；\n    * C 表示错误来源于第三方服务，比如 CDN 服务出错，消息投递超时等问题；\n    * 四位数字编号从 0001 到 9999，大类之间的步长间距预留 100\n    *\n    * 错误码分为一级宏观错误码、二级宏观错误码、三级宏观错误码。\n    * 调用第三方服务出错是一级，中间件错误是二级，消息服务出错是三级。\n    * 说明：在无法更加具体确定的错误场景中，可以直接使用一级宏观错误码，分别是：A0001（用户端错误）、B0001（系统执行出错）、C0001（调用第三方服务出错）。\n    * 错误码表：http://192.168.88.211:8090/pages/viewpage.action?pageId=5473234\n    */\n\n    /*一切ok*/\n    SUCCESS_ERROR(\"000000\",\"成功\"),\n\n    /*用户端错误码*/\n    CLIENT_ERROR(\"A0001\",\"用户端错误\"),\n\n    /*服务端错误码*/\n    SYSTEM_ERROR(\"B0001\",\"系统执行出错\"),\n\n    /*第三方服务错误码*/\n    TPA_ERROR(\"C0001\",\"调用第三方服务出错\");\n\n    /** 错误码 */\n    private String code;\n\n    /** 错误描述 */\n    private String message;\n\n}\n```\n\n### 自定义业务异常类\n\n自定义一个业务异常类，以后和业务有关的异常通通抛出这个异常类，只需将定义好的错误枚举传入即可。\n\n```\npackage org.jeecg.common.exception;\n\nimport lombok.Getter;\nimport lombok.Setter;\nimport org.jeecg.common.constant.enums.ResultCodeEnum;\n\n/**\n* @description: 万序自定义异常\n* @author: luo_Jj\n* @date: 2022/3/24 18:15\n*/\n@Getter\n@Setter\npublic class VanxSoftException extends RuntimeException {\n\tprivate static final long serialVersionUID = 1L;\n\n\tprivate ResultCodeEnum resultCodeEnum;\n\n\tpublic VanxSoftException(ResultCodeEnum resultCodeEnum){\n\t\tsuper(resultCodeEnum.getMessage());\n\t\tthis.resultCodeEnum = resultCodeEnum;\n\t}\n}\n```\n\n### 全局异常处理类\n\n定义一个全局异常处理类\n\n1. 通过 `@RestControllerAdvice` 指定该类为 `Controller` 增强类并返回 `json` 到前端\n2. 通过 `@ExceptionHandler` 自定义捕获的异常类型\n\n```\npackage org.jeecg.common.exception;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.apache.shiro.authz.AuthorizationException;\nimport org.apache.shiro.authz.UnauthorizedException;\nimport org.jeecg.common.api.vo.Result;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.dao.DataIntegrityViolationException;\nimport org.springframework.dao.DuplicateKeyException;\nimport org.springframework.data.redis.connection.PoolException;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.web.HttpRequestMethodNotSupportedException;\nimport org.springframework.web.bind.annotation.ExceptionHandler;\nimport org.springframework.web.bind.annotation.ResponseStatus;\nimport org.springframework.web.bind.annotation.RestControllerAdvice;\nimport org.springframework.web.multipart.MaxUploadSizeExceededException;\nimport org.springframework.web.servlet.NoHandlerFoundException;\n\n/**\n * 异常处理器\n *\n * @Author scott\n * @Date 2019\n */\n@RestControllerAdvice\n@Slf4j\npublic class JeecgBootExceptionHandler {\n    @Value(\"${spring.servlet.multipart.max-file-size}\")\n    private String maxFileSize;\n\n    /**\n     * 处理自定义异常\n     */\n    @ExceptionHandler(JeecgBootException.class)\n    public Result<?> handleJeecgBootException(JeecgBootException e) {\n        log.error(e.getMessage(), e);\n        return Result.error(e.getMessage());\n    }\n\n    /**\n     * 处理自定义异常\n     */\n    @ExceptionHandler(JeecgBoot401Exception.class)\n    @ResponseStatus(HttpStatus.UNAUTHORIZED)\n    public Result<?> handleJeecgBoot401Exception(JeecgBoot401Exception e) {\n        log.error(e.getMessage(), e);\n        return new Result(\"401\", e.getMessage());\n    }\n\n    /**\n    * @description: 处理自定义异常-万序系统异常\n    * @author: luo_jj\n    * @date: 2022/3/25 11:33\n    * @param e:\n    * @return: org.jeecg.common.api.vo.Result<?>\n    */\n    @ExceptionHandler(VanxSoftException.class)\n    public Result<?> handleVanxSoftException(VanxSoftException e) {\n        log.error(e.getMessage(), e);\n        return Result.error(e.getResultCodeEnum());\n    }\n\n    @ExceptionHandler(NoHandlerFoundException.class)\n    public Result<?> handlerNoFoundException(Exception e) {\n        log.error(e.getMessage(), e);\n        return Result.error(\"404\", \"路径不存在，请检查路径是否正确\");\n    }\n\n    @ExceptionHandler(DuplicateKeyException.class)\n    public Result<?> handleDuplicateKeyException(DuplicateKeyException e) {\n        log.error(e.getMessage(), e);\n        return Result.error(\"数据库中已存在该记录\");\n    }\n\n    @ExceptionHandler({UnauthorizedException.class, AuthorizationException.class})\n    public Result<?> handleAuthorizationException(AuthorizationException e) {\n        log.error(e.getMessage(), e);\n        return Result.noauth(\"没有权限，请联系管理员授权\");\n    }\n\n    @ExceptionHandler(Exception.class)\n    public Result<?> handleException(Exception e) {\n        log.error(e.getMessage(), e);\n        return Result.error(\"操作失败，\" + e.getMessage());\n    }\n\n    /**\n     * @param e\n     * @return\n     * @Author 政辉\n     */\n    @ExceptionHandler(HttpRequestMethodNotSupportedException.class)\n    public Result<?> handleHttpRequestMethodNotSupportedException(HttpRequestMethodNotSupportedException e) {\n        StringBuffer sb = new StringBuffer();\n        sb.append(\"不支持\");\n        sb.append(e.getMethod());\n        sb.append(\"请求方法，\");\n        sb.append(\"支持以下\");\n        String[] methods = e.getSupportedMethods();\n        if (methods != null) {\n            for (String str : methods) {\n                sb.append(str);\n                sb.append(\"、\");\n            }\n        }\n        log.error(sb.toString(), e);\n        return Result.error(\"405\", sb.toString());\n    }\n\n    /**\n     * spring默认上传大小100MB 超出大小捕获异常MaxUploadSizeExceededException\n     */\n    @ExceptionHandler(MaxUploadSizeExceededException.class)\n    public Result<?> handleMaxUploadSizeExceededException(MaxUploadSizeExceededException e) {\n        log.error(e.getMessage(), e);\n        return Result.error(String.format(\"文件大小超出%s限制, 请压缩或降低文件质量! \", maxFileSize));\n    }\n\n    @ExceptionHandler(DataIntegrityViolationException.class)\n    public Result<?> handleDataIntegrityViolationException(DataIntegrityViolationException e) {\n        log.error(e.getMessage(), e);\n        return Result.error(\"字段太长,超出数据库字段的长度\");\n    }\n\n    @ExceptionHandler(PoolException.class)\n    public Result<?> handlePoolException(PoolException e) {\n        log.error(e.getMessage(), e);\n        return Result.error(\"Redis 连接异常!\");\n    }\n\n}\n```\n\n## 测试\n\n### 编写 TestController 测试\n\n```\npackage org.jeecg.modules.exception.controller;\n\nimport com.alibaba.fastjson.JSONObject;\nimport io.swagger.annotations.Api;\nimport io.swagger.annotations.ApiOperation;\nimport lombok.extern.slf4j.Slf4j;\nimport org.jeecg.common.api.vo.Result;\nimport org.jeecg.common.constant.enums.ResultCodeEnum;\nimport org.jeecg.common.exception.VanxSoftException;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestMethod;\nimport org.springframework.web.bind.annotation.RestController;\n\n/**\n * @description: 全局异常处理\n * @author: luo_jj\n * @date: 2022年03月24日 17:45\n */\n@RestController\n@RequestMapping(\"/exception\")\n@Api(tags=\"全局异常处理\")\n@Slf4j\npublic class ExceptionController {\n\n    @ApiOperation(\"测试请求\")\n    @RequestMapping(value = \"/test\", method = RequestMethod.POST)\n    public Result<JSONObject> testClientError(){\n        throw new VanxSoftException(ResultCodeEnum.SYSTEM_ERROR);\n    }\n}\n```\n\n![image-20220328151505665](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220328151505.png)\n","tags":["技巧","笔记"],"categories":["后端开发"]},{"title":"持续集成工具之 Jenkins","slug":"持续集成工具之Jenkins","url":"/2022/04/03/1509bf9.html","content":"\n## 持续集成及 Jenkins 介绍\n\n### 软件开发生命周期\n\n软件开发生命周期又叫做**SDLC**（Software Development Life Cycle），它是集合了计划、开发、测试 和部署过程的集合。如下图所示 ：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309153101.png\" alt=\"image-20220309153101326\" style=\"zoom:67%;\" />\n\n- 需求分析\n\n这是生命周期的第一阶段，根据项目需求，团队执行一个可行性计划的分析。项目需求可能是公司内部 或者客户提出的。这阶段主要是对信息的收集，也有可能是对现有项目的改善和重新做一个新的项目。 还要分析项目的预算多长，可以从哪方面受益及布局，这也是项目创建的目标。\n\n- 设计\n\n第二阶段就是设计阶段，系统架构和满意状态（就是要做成什么样子，有什么功能），和创建一个项目 计划。计划可以使用图表，布局设计或者文者的方式呈现。\n\n- 实现\n\n第三阶段就是实现阶段，项目经理创建和分配工作给开者，开发者根据任务和在设计阶段定义的目标进 行开发代码。依据项目的大小和复杂程度，可以需要数月或更长时间才能完成。\n\n- 测试\n\n测试人员进行代码测试 ，包括功能测试、代码测试、压力测试等。\n\n- 进化\n\n最后进阶段就是对产品不断的进化改进和维护阶段，根据用户的使用情况，可能需要对某功能进行修 改，bug 修复，功能增加等。\n\n### 软件开发瀑布模型\n\n瀑布模型是最著名和最常使用的软件开发模型。瀑布模型就是一系列的软件开发过程。它是由制造业繁 衍出来的。一个高度化的结构流程在一个方向上流动，有点像生产线一样。在瀑布模型创建之初，没有 其它开发的模型，有很多东西全靠开发人员去猜测，去开发。这样的模型仅适用于那些简单的软件开发，但是已经不适合现在的开发了。\n\n下图对软件开发模型的一个阐述。\n\n![image-20220309154059145](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309154059.png)\n\n| 优势                                       | 劣势                                                                                   |\n| ------------------------------------------ | -------------------------------------------------------------------------------------- |\n| 简单易用和理解                             | 各个阶段的划分完全固定，阶段之间产生大量的文档，极大地增加了工作量。                   |\n| 当前一阶段完成后，您只需要去关注后续阶段。 | 由于开发模型是线性的，用户只有等到整个过程的末期才能见到开发成果，从而增加了开发风险。 |\n| 为项目提供了按阶段划分的检查节点           | 瀑布模型的突出缺点是不适应用户需求的变化。                                             |\n\n### 软件的敏捷开发\n\n#### 什么是敏捷开发？\n\n敏捷开发（Agile Development）的核心是迭代开发（Iterative Development）与 增量开发（Incremental Development）。\n\n- **何为迭代开发**？\n\n对于大型软件项目，传统的开发方式是采用一个大周期（比如一年）进行开发，整个过程就是一次“大开发”；迭代开发的方式则不一样，它将开发过程拆分成多个小周期，即一次“大开发”变成多次“小开发”，每次小开发都是同样的流程，所以看上去就好像重复在做同样的步骤。\n\n- **何为增量开发**？\n\n软件的每个版本，都会新增一个用户可以感知的完整功能。也就是说，按照新增功能来划分迭代。\n\n#### 敏捷开发如何迭代？\n\n虽然敏捷开发将软件开发分成多个迭代，但是也要求，每次迭代都是一个完整的软件开发周期，必须按照软件工程的方法论，进行正规的流程管理。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309154857.png\" alt=\"image-20220309154857660\" style=\"zoom:67%;\" />\n\n#### 敏捷开发有什么好处？\n\n- **早期交付**\n\n敏捷开发的第一个好处，就是早期交付，从而大大降低成本。\n\n- **降低风险**\n\n敏捷开发的第二个好处是，及时了解市场需求，降低产品不适用的风险。\n\n### 什么是持续集成？\n\n持续集成（Continuous integration，简称 CI）指的是，频繁地（一天多次）将代码集成到主干。\n\n**持续集成的目的，就是让产品可以快速迭代，同时还能保持高质量。**它的核心措施是，代码集成到主干之前，必须通过自动化测试。只要有一个测试用例失败，就不能集成。\n\n通过持续集成，团队可以快速的从一个功能到另一个功能，简而言之，敏捷软件开发很大一部分都要归功于持续集成。\n\n**持续集成的流程**\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309155459.png\" alt=\"image-20220309155459830\" style=\"zoom: 80%;\" />\n\n根据持续集成的设计，代码从提交到生产，整个过程有以下几步。\n\n- 提交\n\n流程的第一步，是开发者向代码仓库提交代码。所有后面的步骤都始于本地代码的一次提交（commit）。\n\n- 测试（第一轮）\n\n代码仓库对 commit 操作配置了钩子（hook），只要提交代码或者合并进主干，就会跑自动化测试。\n\n- 构建\n\n通过第一轮测试，代码就可以合并进主干，就算可以交付了。\n\n交付后，就先进行构建（build），再进入第二轮测试。所谓构建，指的是将源码转换为可以运行的实际代码，比如安装依赖，配置各种资源（样式表、JS 脚本、图片）等等。\n\n- 测试（第二轮）\n\n构建完成，就要进行第二轮测试。如果第一轮已经涵盖了所有测试内容，第二轮可以省略，当然，这时构建步骤也要移到第一轮测试前面。\n\n- 部署\n\n过了第二轮测试，当前代码就是一个可以直接部署的版本（artifact）。将这个版本的所有文件打包（ tar filename.tar \\* ）存档，发到生产服务器。\n\n- 回滚\n\n一旦当前版本发生问题，就要回滚到上一个版本的构建结果。最简单的做法就是修改一下符号链接，指 向上一个版本的目录。\n\n### 持续集成的组成要素\n\n- 一个自动构建过程，从检出代码、编译构建、运行测试、结果记录、测试统计等都是自动完成的，无需人工干预。\n- 一个代码存储库，即需要版本控制软件来保障代码的可维护性，同时作为构建过程的素材库，一般使用 SVN 或 Git。\n- 一个持续集成服务器， Jenkins 就是一个配置简单和使用方便的持续集成服务器。\n\n![image-20220309165502124](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309165502.png)\n\n### 持续集成的好处\n\n1. 降低风险，由于持续集成不断去构建，编译和测试，可以很早期发现问题，所以修复的代价就少；\n2. 对系统健康持续检查，减少发布风险带来的问题；\n3. 减少重复性工作；\n4. 持续部署，提供可部署单元包；\n5. 持续交付可供使用的版本；\n6. 增强团队信心；\n\n### Jenkins 介绍\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309165729.png\" alt=\"image-20220309165729929\" style=\"zoom:67%;\" />\n\nJenkins 是一款流行的开源持续集成（Continuous Integration）工具，广泛用于项目开发，具有自动 化构建、测试和部署等功能。官网：[Jenkins](https://www.jenkins.io/)。\n\n**Jenkins 的特征：**\n\n- 开源的 Java 语言开发持续集成工具，支持持续集成，持续部署。\n- 易于安装部署配置：可通过 yum 安装,或下载 war 包以及通过 docker 容器等快速实现安装部署，可方便 web 界面配置管理。\n- 消息通知及测试报告：集成 RSS/E-mail 通过 RSS 发布构建结果或当构建完成时通过 e-mail 通知，生成 JUnit/TestNG 测试报告。\n- 分布式构建：支持 Jenkins 能够让多台计算机一起构建/测试。\n- 文件识别：Jenkins 能够跟踪哪次构建生成哪些 jar，哪次构建使用哪个版本的 jar 等。\n- 丰富的插件支持：支持扩展插件，你可以开发适合自己团队使用的工具，如 git，svn，maven，docker 等。\n\n## Jenkins 安装与配置\n\n### 安装 Jenkins\n\n> [Jenkins 官方安装文档](https://www.jenkins.io/zh/doc/book/installing/)\n\n**Docker 安装 Jenkins（推荐）**\n\n- Docker 安装与配置\n\n  ```bash\n  # 1、卸载旧的版本\n  yum remove docker \\\n                    docker-client \\\n                    docker-client-latest \\\n                    docker-common \\\n                    docker-latest \\\n                    docker-latest-logrotate \\\n                    docker-logrotate \\\n                    docker-engine\n\n  # 2、需要的安装包\n  yum install -y yum-utils\n\n  # 3、设置镜像的仓库\n  yum-config-manager \\\n      --add-repo \\\n      https://download.docker.com/linux/centos/docker-ce.repo # 默认是国外的，十分慢！\n  # 建议使用阿里云的镜像地址\n  yum-config-manager \\\n      --add-repo \\\n      https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n  # 更新yum软件包索引\n  yum makecache fast\n\n  # 4、安装docker相关的 docker-ce 社区版 ee 企业版\n  yum install docker-ce docker-ce-cli containerd.io\n\n  # 5、启动docker\n  systemctl start docker\n\n  # 6、使用docker version查看是否安装成功\n  ```\n\n- 使用 Docker 安装 Jenkins\n\n  ```\n  # 使用命令直接安装\n  docker run -d --name jenkins --restart always \\\n  --user root -p 8180:8080 -p 51000:50000 \\\n  -v /var/jenkins_home:/var/jenkins_home \\\n  -v /opt/maven/apache-maven-3.6.3:/opt/maven/apache-maven-3.6.3 \\\n  -v /usr/local/java/jdk1.8.0_251:/usr/local/java/jdk1.8.0_251 \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkinsci/blueocean\n  ```\n\n**War 安装 Jenkins**\n\n- 获取 Jenkins 安装包\n\n下载页面：https://jenkins.io/zh/download/\n\n安装文件：jenkins.war\n\n```\n1、将最新的稳定Jenkins WAR包 下载到您计算机上的相应目录。\n\n2、在下载的目录内打开一个终端/命令提示符窗口到。\n\n3、运行命令java -jar jenkins.war\n\n4、浏览http://localhost:8080并等到*Unlock Jenkins*页面出现。\n\n5、继续使用Post-installation setup wizard后面步骤设置向导。\n```\n\n**解锁 Jenkins**\n\n![image-20220309174609417](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309174609.png)\n\n获取并输入 admin 账户密码（我这里是 docker 安装的，目录是映射到指定位置的，密码实际存放路径以提示为主）\n\n`cat /var/jenkins_home/secrets/initialAdminPassword`\n\n**跳过插件安装**\n\n因为 Jenkins 插件需要连接默认官网下载，速度非常慢，而且容易安装失败，所以我们暂时先跳过插件安装。\n\n![image-20220309174531892](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309174531.png)\n\n![image-20220309174831016](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309174831.png)\n\n**添加一个管理员账户，并进入 Jenkins 后台**\n\n![image-20220309174953956](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309174954.png)\n\n**保存并完成**\n\n![image-20220309175748708](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309175748.png)\n\n**开始使用 Jenkins**\n\n![image-20220309175816074](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309175816.png)\n\n![image-20220309175908276](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309175908.png)\n\n### Jenkins 插件管理\n\nJenkins 本身不提供很多功能，我们可以通过使用插件来满足我们的使用。例如从 Gitlab 拉取代码，使用 Maven 构建项目等功能需要依靠插件完成。接下来演示如何下载插件。\n\n**修改 Jenkins 插件下载地址**\n\nJenkins 国外官方插件地址下载速度非常慢，所以可以修改为国内插件地址：\n\n`Jenkins -> Manage Jenkins -> Manage Plugins，点击Available`\n\n![image-20220309180153473](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309180153.png)\n\n这样做是为了把 Jenkins 官方的插件列表下载到本地，接着修改地址文件，替换为国内插件地址：\n\n```\n# 进入配置目录 （目录视情况而定，安装的jenkins_home下）\ncd /var/jenkins_home/updates\n\n# 执行命令\nsed -i 's/http:\\/\\/updates.jenkins\u0002ci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g' default.json && sed -i 's/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g' default.json\n```\n\n最后，Manage Plugins 点击 Advanced，把 Update Site 改为国内插件下载地址\n\n![image-20220309180807037](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309180807.png)\n\nSumbit 后，在浏览器输入： http://120.78.204.65:8180/restart ，重启 Jenkins。\n\n**下载中文汉化插件**\n\n`Jenkins -> Manage Jenkins -> Manage Plugins，点击Available，搜索\"Chinese\"`\n\n![image-20220309181055822](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181055.png)\n\n完成后如下图所示：\n\n![image-20220309181122066](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181122.png)\n\n重启 Jenkins 之后，就看到 Jenkins 汉化了！（PS：某些菜单可能会汉化失败）\n\n![image-20220309181408200](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181408.png)\n\n### Jenkins 用户权限管理\n\n我们可以利用`Role-based Authorization Strategy`插件来管理 Jenkins 用户权限\n\n**安装 Role-based Authorization Strategy 插件**\n\n![image-20220309181600238](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181600.png)\n\n**开启权限全局安全配置**\n\n![image-20220309181914873](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181914.png)\n\n授权策略切换为\"Role-Based Strategy\"，保存\n\n![image-20220309181940124](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181940.png)\n\n**创建角色**\n\n在系统管理页面进入 Manage and Assign Roles\n\n![image-20220309182209559](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182209.png)\n\n点击\"Manage Roles\"\n\n![image-20220309182301430](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182301.png)\n\n![image-20220309182435102](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182435.png)\n\n`Global roles（全局角色）`：管理员等高级用户可以创建基于全局的角色\n\n`Item roles（项目角色）`： 针对某个或者某些项目的角色\n\n`Node roles（节点角色）`：节点相关的权限\n\n我们添加以下三个角色：\n\n- baseRole：该角色为全局角色。这个角色需要绑定 Overall 下面的 Read 权限，是为了给所有用户绑定最基本的 Jenkins 访问权限。注意：如果不给后续用户绑定这个角色，会报错误：`用户名 is missing the Overall/Read permission`\n- role1：该角色为项目角色。使用正则表达式绑定\"vx-chx.\\*\"，意思是只能操作 vx-chx 开头的项目。\n- role2：该角色为项目角色。使用正则表达式绑定\"vx-phm.\\*\"，意思是只能操作 vx-phm 开头的项目。\n\n![image-20220309182812353](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182812.png)\n\n保存\n\n**创建用户**\n\n在系统管理页面进入 Manage Users\n\n![image-20220309182917026](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182917.png)\n\n![image-20220309183107565](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309183107.png)\n\n分别创建两个用户：vxchx 和 vxphm\n\n![image-20220309183223041](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309183223.png)\n\n**给用户分配角色**\n\n系统管理页面进入 Manage and Assign Roles，点击 Assign Roles\n\n绑定规则如下：\n\n- vxchx 用户分别绑定 baseRole 和 role1 角色\n\n- vxphm 用户分别绑定 baseRole 和 role2 角色\n\n  ![image-20220309183455591](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309183455.png)\n\n保存\n\n**创建项目测试权限**\n\n以 admin 管理员账户创建两个项目，分别为 vx-chx-test 和 vx-phm-test\n\n结果为： vxchx 用户登录，只能看到 vx-chx-test 项目 vxphm 用户登录，只能看到 vx-phm-test 项目\n\n### Jenkins 凭证管理\n\n凭据可以用来存储需要密文保护的数据库密码、Gitlab 密码信息、Docker 私有仓库密码等，以便 Jenkins 可以和这些第三方的应用进行交互。\n\n**安装 Credentials Binding 插件**\n\n要在 Jenkins 使用凭证管理功能，需要安装`Credentials Binding`插件\n\n> 注：新版本已经默认安装了此插件，这里无需另外再安装了\n\n系统管理中选择 `Manage Credentials`\n\n![image-20220309184117479](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309184117.png)\n\n可以添加的凭证有 5 种：\n\n![image-20220309184218399](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309184218.png)\n\n- Username with password：用户名和密码\n- SSH Username with private key： 使用 SSH 用户和密钥\n- Secret file：需要保密的文本文件，使用时 Jenkins 会将文件复制到一个临时目录中，再将文件路径 设置到一个变量中，等构建结束后，所复制的 Secret file 就会被删除。\n- GitHub App：GitHub 的 API 令牌\n- Secret text：需要保存的一个加密的文本串，如钉钉机器人或 Github 的 api token\n- Certificate：通过上传证书文件的方式\n\n常用的凭证类型有：**Username with password（用户密码）**和 **SSH Username with private key（SSH 密钥）**\n\n接下来以使用 Git 工具到 Gitlab 拉取项目源码为例，演示 Jenkins 的如何管理 Gitlab 的凭证。\n\n**安装 Git 插件和 Git 工具**\n\n为了让 Jenkins 支持从 Gitlab 拉取源码，需要安装 Git 插件以及在服务器上安装 Git 工具。\n\nGit 插件安装：\n\n![image-20220310094712046](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310094719.png)\n\n服务器上安装 Git 工具（以 CentOS7 为例）：\n\n```bash\n# 安装\nyum install git -y\n# 安装后查看版本\ngit --version\n```\n\n**用户密码类型**\n\n1）创建凭据\n\n`Jenkins -> 凭证 -> 系统 -> 全局凭据 -> 添加凭据`\n\n![image-20220310095750604](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310095750.png)\n\n选择\"Username with password\"，输入 Gitlab 的用户名和密码，点击\"确定\"。\n\n![image-20220310100359012](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310100359.png)\n\n**SSH 密钥类型**\n\nSSH 免密登录示意图\n\n![image-20220310100539140](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310100539.png)\n\n1）使用 root 用户生成公钥和私钥\n\n`ssh-keygen -t rsa`\n\n在/root/.ssh/目录保存了公钥和使用\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310101013.png\" alt=\"image-20220310101013313\" style=\"zoom:67%;\" />\n\nid_rsa：私钥文件\n\nid_rsa.pub：公钥文件\n\n2）把生成的公钥放在 Gitlab 中\n\n`登录gitlab -> 点击头像 -> Settings -> SSH Keys`\n\n复制刚才 id_rsa.pub 文件的内容到这里，点击\"Add Key\"\n\n![image-20220310101538008](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310101538.png)\n\n3）在 Jenkins 中添加凭证，配置私钥\n\n在 Jenkins 添加一个新的凭证，类型为\"SSH Username with private key\"，把刚才生成私有文件内容复制过来\n\n![image-20220310102203814](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310102203.png)\n\n![image-20220310102427213](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310102427.png)\n\n### Jenkins 关联 JDK 和 Maven\n\n**关联 JDK**\n\n`Jenkins -> 系统管理 -> 全局工具配置 -> JDK -> 新增JDK，配置如下：`\n\n![image-20220310102744563](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310102744.png)\n\n**关联 Maven**\n\n`Jenkins -> 系统管理 -> 全局工具配置 -> Maven -> 新增Maven，配置如下：`\n\n![image-20220310102835922](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310102836.png)\n\n### **添加 Jenkins 全局变量**\n\n`Jenkins -> 系统管理 -> 全局属性 -> 添加三个环境变量，配置如下：`\n\n![image-20220310103241974](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310103242.png)\n\n### Jenkins 关闭跨站请求伪造保护\n\n- Docker 容器运行\n\n```\n# 1、进入运行的容器\ndocker exec -u root -it 你的Jenkins容器名称或者容器id bash\n\n# 2、输入命令，编辑jenkins启动配置文件\nvi /usr/local/bin/jenkins.sh\n\n# 3、在图中标记处，加入以下配置\n-Dhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION=true\n\n# 4、重启容器\ndocker restart jenkins\n```\n\n![image-20220312001020531](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220312001027.png)\n\n## Jenkins 构建 Maven 项目\n\n> 构建方式均采用 Jar 包方式，War 方式参考[WAR 部署方案 · JeecgBoot 开发文档](http://doc.jeecg.com/2043887)\n\n### Jenkins 项目构建类型\n\nJenkins 中自动构建项目的类型有很多，常用的有以下三种：\n\n- 自由风格软件项目（FreeStyle Project）\n- Maven 项目（Maven Project）\n- 流水线项目（Pipeline Project）\n\n每种类型的构建其实都可以完成一样的构建过程与结果，只是在操作方式、灵活度等方面有所区别，在实际开发中可以根据自己的需求和习惯来选择。（PS：个人推荐使用流水线类型，因为灵活度非常高）\n\n### 自由风格项目构建\n\n下面演示创建一个自由风格项目来完成项目的集成过程：\n\n`拉取代码 -> 编译 -> 打包 -> 部署`\n\n**拉取代码**\n\n1）创建项目\n\n![image-20220310112707895](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310112707.png)\n\n2）源码管理，从 Gitlab 拉取代码\n\n![image-20220310112815147](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310112815.png)\n\n**编译打包**\n\n`构建 -> 添加构建步骤 -> 执行shell`\n\n```bash\necho \"开始编译和打包\"\nmvn clean package\necho \"编译和打包结束\"\n```\n\n![image-20220310112952936](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310112952.png)\n\n**部署**\n\n把项目部署到远程的服务器上，并启动\n\n1）安装`Publish Over SSH`插件\n\nJenkins 本身无法实现远程部署到服务器上的功能，需要安装`Publish Over SSH`插件实现\n\n![image-20220310113332137](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310113332.png)\n\n2）配置`Publish over SSH`，添加 SSH 服务器\n\n`打开系统管理 -> 系统配置 -> 拉到底部，选择Publish over SSH区域选择新增`\n\n![image-20220310114012322](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310114012.png)\n\n`点击高级 -> 填写服务器密码`（也可选择 ssh 验证，在 Jenkins 中配置本机私钥，将公钥发送到目标机器，即可完成无密码登录）\n\n`发送命令：ssh-copy-id -i /root/.ssh/id_rsa.pub root@192.168.xxx.xxx`\n\n![image-20220310114702171](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310114702.png)\n\n- Passphrase： 密码（目标机器的密码）\n- Path to key：key 文件（私钥）的路径\n- SSH Server Name： 标识的名字（随便你取什么）\n- Hostname： 需要连接 ssh 的主机名或 ip 地址，此处填写应用服务器 IP（建议 ip）\n- Username： 用户名\n- Remote Directory： 远程目录(要发布的目录,比如/usr/local/tomcat/webapps/)\n\n3）添加构建步骤\n\n![image-20220310115055853](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310115055.png)\n\n![image-20220310115245384](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310115245.png)\n\n```\n# 脚本参考\nsource /etc/profile\n\ncd /apps\nps -ef|grep jeecg-boot-module-system-3.1.0.jar|grep -v grep|awk '{print $2}'|xargs kill -s 9\nBUILD_ID=dontKillMe\nnohup java -jar jeecg-boot-module-system-3.1.0.jar > jeecg-boot-module-system-3.1.0.log 2>&1 &\n```\n\n4）点击\"立即构建\"，开始构建过程\n\n![image-20220310115628609](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310115628.png)\n\n5）构建成功，并自动化部署，访问测试！\n\n### Maven 项目构建\n\n1）安装 Maven Integration Plugin（高版本的 Jenkins 已预装了此插件）\n\n![image-20220310135008339](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310135008.png)\n\n2）创建 Maven 项目\n\n![image-20220310135103444](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310135103.png)\n\n3）配置项目\n\n拉取代码和远程部署的过程和自由风格项目一样，只是\"构建\"部分不同\n\n![image-20220310135300799](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310135300.png)\n\n### Pipeline 流水线项目构建(\\*)\n\n#### Pipeline 简介\n\n**1）概念**\n\nPipeline，简单来说，就是一套运行在 Jenkins 上的工作流框架，将原来独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂流程编排和可视化的工作。\n\n**2）使用 Pipeline 有以下好处（来自翻译自官方文档）：**\n\n代码：Pipeline 以代码的形式实现，通常被检入源代码控制，使团队能够编辑，审查和迭代其传送流 程。持久：无论是计划内的还是计划外的服务器重启。Pipeline 都是可恢复的。可停止：Pipeline 可接 收交互式输入，以确定是否继续执行 Pipeline。多功能：Pipeline 支持现实世界中复杂的持续交付要求。它支持 fork/join、循环执行，并行执行任务的功能。可扩展：Pipeline 插件支持其 DSL 的自定义扩展，以及与其他插件集成的多个选项。\n\n**3）如何创建 Jenkins Pipeline 呢？**\n\n- Pipeline 脚本是由**Groovy**语言实现的，但是我们没必要单独去学习 Groovy\n- Pipeline 支持两种语法：**Declarative**(声明式)和**Scripted Pipeline**(脚本式)语法\n- Pipeline 也有两种创建方法：可以直接在 Jenkins 的 Web UI 界面中输入脚本；也可以通过创建一个 Jenkinsfile 脚本文件放入项目源码库中（一般我们都推荐在 Jenkins 中直接从源代码控制(SCM)中直接载入 Jenkinsfile Pipeline 这种方法）。\n\n#### Pipeline 语法快速入门\n\n**1）Declarative 声明式-Pipeline**\n\n创建一个流水线项目\n\n![image-20220310154144897](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310154144.png)\n\n`流水线 -> 选择HelloWorld模板`\n\n![image-20220310154618000](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310154618.png)\n\n生成的内容如下：\n\n```groovy\npipeline {\n    agent any\n\n    stages {\n        stage('Hello') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n```\n\n- **stages：**代表整个流水线的所有执行阶段。通常 stages 只有 1 个，里面包含多个 stage\n\n- **stage：**代表流水线中的某个阶段，可能出现 n 个。一般分为拉取代码，编译构建，部署等阶段。\n\n- **steps：**代表一个阶段内需要执行的逻辑。steps 里面是 shell 脚本，git 拉取代码，ssh 远程发布等任意内容。\n\n编写一个简单声明式的 Pipeline：\n\n```groovy\npipeline {\n    agent any\n    stages {\n        stage('拉取代码') {\n            steps {\n            \techo '拉取代码'\n            }\n        }\n        stage('编译构建') {\n            steps {\n            \techo '编译构建'\n            }\n        }\n        stage('项目部署') {\n            steps {\n            \techo '项目部署'\n            }\n        }\n    }\n}\n```\n\n点击构建，进入`Blue Ocean`可以看到整个构建过程\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310155756.png\" alt=\"image-20220310155756052\" style=\"zoom: 150%;\" />\n\n**2）Scripted Pipeline 脚本式-Pipeline**\n\n创建项目\n\n![image-20220310155938728](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310155938.png)\n\n选择 `Scripted Pipeline\"`\n\n![image-20220310160044398](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310160044.png)\n\n```groovy\nnode {\n    def mvnHome\n    stage('Preparation') { // for display purposes\n\n    }\n    stage('Build') {\n\n    }\n    stage('Results') {\n\n    }\n}\n```\n\n- Node：节点，一个 Node 就是一个 Jenkins 节点，Master 或者 Agent，是执行 Step 的具体运行环境，后续讲到 Jenkins 的 Master-Slave 架构的时候用到。\n- Stage：阶段，一个 Pipeline 可以划分为若干个 Stage，每个 Stage 代表一组操作，比如： Build、Test、Deploy，Stage 是一个逻辑分组的概念。\n- Step：步骤，Step 是最基本的操作单元，可以是打印一句话，也可以是构建一个 Docker 镜像， 由各类 Jenkins 插件提供，比如命令：sh ‘make’，就相当于我们平时 shell 终端中执行 make 命令 一样。\n\n编写一个简单的脚本式 Pipeline\n\n```\nnode {\n    def mvnHome\n    stage('拉取代码') { // for display purposes\n    \techo '拉取代码'\n    }\n    stage('编译构建') {\n    \techo '编译构建'\n    }\n    stage('项目部署') {\n    \techo '项目部署'\n    }\n}\n```\n\n构建结果和声明式一样！\n\n**Pipeline Script from SCM**\n\n刚才我们都是直接在 Jenkins 的 UI 界面编写 Pipeline 代码，这样不方便脚本维护，建议把 Pipeline 脚本放在项目中（一起进行版本控制）\n\n**1）在项目根目录建立 Jenkinsfile 文件，把内容复制到该文件中**\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310163924.png\" alt=\"image-20220310163924603\" style=\"zoom:67%;\" />\n\n把 Jenkinsfile 上传到 Gitlab\n\n**2）在项目中引用该文件**\n\n![image-20220310164207097](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310164207.png)\n\n![image-20220310164225747](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310164225.png)\n\n### Jenkinsfile\n\n#### Jenkinsfile 环境变量\n\n| 环境变量                       | 说明                                                                              |\n| ------------------------------ | --------------------------------------------------------------------------------- |\n| BRANCH_NAME                    | 在 multibranch 项目中，BRANCH_NAME 用于标明构建分支的名称。                       |\n| CHANGE_ID                      | 在 multibranch 的项目中，相较于特定的变更请求，用于标明变更 ID，比如 Pull Request |\n| CHANGE_URL                     | 在 multibranch 的项目中，相较于特定的变更请求，用于标明变更的 URL                 |\n| CHANGE_TITLE                   | 在 multibranch 的项目中，相较于特定的变更请求，用于标明变更的标题                 |\n| CHANGE_AUTHOR                  | 在 multibranch 的项目中，相较于特定的变更请求，用于标明提交变更的人员的名称       |\n| CHANGE_AUTHOR_DISPLAY_NAME     | 在 multibranch 的项目中，相较于特定的变更请求，用于标明提交变更的人员的显示名称   |\n| CHANGE_AUTHOR_EMAIL            | 在 multibranch 的项目中，相较于特定的变更请求，用于标明提交变更的人员的邮件地址   |\n| CHANGE_TARGET                  | 在 multibranch 的项目中，相较于特定的变更请求，用于合并后的分支信息等             |\n| BUILD_NUMBER                   | 当前的构建编号                                                                    |\n| BUILD_ID                       | 在 1.597 版本后引进，表示当前构建 ID                                              |\n| BUILD_DISPLAY_NAME             | 当前构建的显示信息                                                                |\n| JOB_NAME                       | 构建 Job 的全称，包含项目信息                                                     |\n| JOB_BASE_NAME                  | 除去项目信息的 Job 名称                                                           |\n| BUILD_TAG                      | 构建标签                                                                          |\n| EXECUTOR_NUMBER                | 执行器编号，用于标识构建器的不同编号                                              |\n| NODE_NAME                      | 构建节点的名称                                                                    |\n| NODE_LABELS                    | 节点标签                                                                          |\n| WORKSPACE                      | 构建时使用的工作空间的绝对路径                                                    |\n| JENKINS_HOME                   | JENKINS 根目录的绝对路径                                                          |\n| JENKINS_URL                    | Jenkins 的 URL 信息                                                               |\n| BUILD_URL                      | 构建的 URL 信息                                                                   |\n| JOB_URL                        | 构建 Job 的 URL 信息                                                              |\n| GIT_COMMIT                     | git 提交的 hash 码                                                                |\n| GIT_PREVIOUS_COMMIT            | 当前分支上次提交的 hash 码                                                        |\n| GIT_PREVIOUS_SUCCESSFUL_COMMIT | 当前分支上次成功构建时提交的 hash 码                                              |\n| GIT_BRANCH                     | 远程分支名称                                                                      |\n| GIT_LOCAL_BRANCH               | 本地分支名称                                                                      |\n| GIT_URL                        | 远程 URL 地址                                                                     |\n| GIT_COMMITTER_NAME             | Git 提交者的名称                                                                  |\n| GIT_AUTHOR_NAME                | Git Author 的名称                                                                 |\n| GIT_COMMITTER_EMAIL            | Git 提交者的 email 地址                                                           |\n| GIT_AUTHOR_EMAIL               | Git Author 的 email 地址                                                          |\n| MERCURIAL_REVISION             | Mercurial 的版本 ID 信息                                                          |\n| MERCURIAL_REVISION_SHORT       | Mercurial 的版本 ID 缩写                                                          |\n| MERCURIAL_REVISION_NUMBER      | Mercurial 的版本号信息                                                            |\n| MERCURIAL_REVISION_BRANCH      | 分支版本信息                                                                      |\n| MERCURIAL_REPOSITORY_URL       | 仓库 URL 信息                                                                     |\n| SVN_REVISION                   | Subversion 的当前版本信息                                                         |\n| SVN_URL                        | 当前工作空间中被 checkout 的 Subversion 工程的 URL 地址信息                       |\n\n### 常用的构建触发器\n\nJenkins 内置 4 种构建触发器：\n\n- 触发远程构建\n- 其他工程构建后触发（Build after other projects are build）\n- 定时构建（Build periodically）\n- 轮询 SCM（Poll SCM）\n- GitHub 钩子触发的 GIT SCM 轮询（GitHub hook trigger for GITScm polling）\n\n**触发远程构建**\n\n![image-20220310164928630](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310164928.png)\n\n触发构建 url：http://192.168.88.86:8180/job/vx-phm/build?token=abcabc\n\n**其他工程构建后触发**\n\n1）创建 pre_job 流水线工程\n\n![image-20220310170454942](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310170455.png)\n\n2）配置需要触发的工程\n\n![image-20220310170935519](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310170935.png)\n\n**定时构建**\n\n![image-20220310171234011](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310171234.png)\n\n定时字符串从左往右分别为： 分 时 日 月 周\n\n一些定时表达式的例子：\n\n```\n每30分钟构建一次：H代表形参 H/30 * * * * 10:02 10:32\n\n每2个小时构建一次: H H/2 * * *\n\n每天的8点，12点，22点，一天构建3次： (多个时间点中间用逗号隔开) 0 8,12,22 * * *\n\n每天中午12点定时构建一次 H 12 * * *\n\n每天下午18点定时构建一次 H 18 * * *\n\n在每个小时的前半个小时内的每10分钟 H(0-29)/10 * * * *\n\n每两小时一次，每个工作日上午9点到下午5点(也许是上午10:38，下午12:38，下午2:38，下午\n4:38) H H(9-16)/2 * * 1-5\n```\n\n**轮询 SCM**\n\n轮询 SCM，是指定时扫描本地代码仓库的代码是否有变更，如果代码有变更就触发项目构建。\n\n![image-20220310171348558](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310171348.png)\n\n注意：此构建触发器，Jenkins 会定时扫描本地整个项目的代码，增大系统的开销，不建议使用。\n\n### Git Hook 自动触发构建(\\*)\n\n刚才我们看到在 Jenkins 的内置构建触发器中，轮询 SCM 可以实现 Gitlab 代码更新，项目自动构建，但是该方案的性能不佳。那有没有更好的方案呢？有的。就是利用 Gitlab 的 webhook 实现代码 push 到仓库，立即触发项目自动构建。\n\n**安装 Gitlab Hook 插件**\n\n需要安装两个插件：\n\nGitlab Hook 和 Gitlab\n\n![image-20220310172047813](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310172047.png)\n\n**Jenkins 设置自动构建**\n\n![image-20220310172445870](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310172445.png)\n\n等会需要把生成的 webhook URL 配置到 Gitlab 中。\n\n**Gitlab 配置 webhook**\n\n1）开启 webhook 功能\n\n`使用root账户登录到后台，点击Admin Area -> Settings -> Network`\n\n`勾选\"Allow requests to the local network from web hooks and services\"`\n\n![image-20220310172805087](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310172805.png)\n\n2）在项目中添加 webhook\n\n`点击项目 -> Settings -> Webhooks`\n\n![image-20220310173325550](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310173325.png)\n\n注意：以下设置必须完成，否则会报错！\n\n`系统管理 -> 系统配置`\n\n![image-20220310173704682](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310173704.png)\n","tags":["笔记","持续集成"],"categories":["DevOps"]},{"title":"常用编程环境与开发工具安装手册","slug":"常用编程环境与开发工具安装手册","url":"/2022/04/02/2f74bb89.html","content":"\n> **安装目录示分区大小而定，不可盲目复制命令进行安装！**\n\n## 安装 Docker 容器服务\n\n### CentOS 安装\n\n```bash\n# 1. 卸载旧的版本\nsudo yum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-engine\n\n# 2. 安装yum-utils包（提供 yum-config-manager 程序）\nsudo yum install -y yum-utils\n\n# 3. 设置镜像的仓库\nyum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo # 默认是国外的，十分慢！\n# 建议使用阿里云的镜像地址\nyum-config-manager \\\n    --add-repo \\\n    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n# 更新yum软件包索引\nyum makecache fast\n\n# 4. 安装docker相关的 docker-ce docker-compose （默认为最新版）\nsudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y\n\n# 5. 安装指定版本\nsudo yum install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io docker-compose-plugin -y\nsudo yum install docker-ce-20.10.13 docker-ce-cli-20.10.13 containerd.io docker-compose-plugin -y\n\n# 6. 启动docker\nsystemctl start docker\nsystemctl enable docker\n\n# 7. 使用docker version查看是否安装成功\ndocker version\n```\n\n### Ubuntu 安装\n\n```bash\n# 1. 卸载旧的版本\nsudo apt-get remove docker docker-engine docker.io containerd runc\n\n# 2. 更新软件包索引并安装软件包，以允许通过 HTTPS 使用存储库：aptapt\nsudo apt-get update\n\nsudo apt-get install \\\n    apt-transport-https \\\n    ca-certificates \\\n    curl \\\n    gnupg-agent\n\n# 3. 添加 Docker 的官方 GPG 密钥：\nsudo curl -fsSL http://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n# 4. 设置存储库\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] http://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n  \n# 如果您使用 Ubuntu 衍生发行版，例如 Linux Mint，则可能需要使用 UBUNTU_CODENAME 而不是 VERSION_CODENAME\n\n# 5. 更新包索引，并安装最新版本的 Docker 引擎、容器和 Docker Compose\nsudo apt-get update\n\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\n# 安装指定版本\nsudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io docker-compose-plugin\n\n# 先列出存储库中的可用版本\napt-cache madison docker-ce\n docker-ce | 5:20.10.18~3-0~ubuntu-focal | https://download.docker.com/linux/ubuntu focal/stable amd64 Packages\n docker-ce | 5:20.10.17~3-0~ubuntu-focal | https://download.docker.com/linux/ubuntu focal/stable amd64 Packages\n docker-ce | 5:20.10.16~3-0~ubuntu-focal | https://download.docker.com/linux/ubuntu focal/stable amd64 Packages\n \n# 取出其中的版本号，例如：5:20.10.17~3-0~ubuntu-focal\nsudo apt-get install docker-ce=5:20.10.17~3-0~ubuntu-focal docker-ce-cli=5:20.10.17~3-0~ubuntu-focal containerd.io docker-compose-plugin\n\n\n# 6. 启动docker\nsystemctl start docker\nsystemctl enable docker\n\n# 7. 使用docker version查看是否安装成功\n```\n\n### DockerHub 国内网络无法访问，如何下载镜像文件，离线导入\n\n[使用 Github Action 构建 docker 镜像](https://wkdaily.cpolar.cn/archives/gc)\n\n## 安装 MiniKube 单机 K8S 服务\n\n> **安装环境：CentOS 8**\n\n### 安装 kubectl\n\n> [安装工具 | Kubernetes](https://kubernetes.io/zh-cn/docs/tasks/tools/)\n\n### 安装 MiniKube\n\n> [minikube start | minikube 中文](https://minikube.kubernetes.ac.cn/docs/start/?arch=%2Fwindows%2Fx86-64%2Fstable%2F.exe+download)\n\n常用命令：\n\n```bash\n# 启动 minikube\nminikube start --driver='docker' --cache-images=true  --kubernetes-version='v1.31.0' --registry-mirror='https://hub.geekery.cn' --base-image='registry.cn-hangzhou.aliyuncs.com/google_containers/kicbase:v0.0.45' --listen-address=0.0.0.0 --force\n\n# 开启 dashboard\nminikube dashboard\n# 启动端口转发，提供 dashboard 供外部访问\nkubectl port-forward -n kubernetes-dashboard svc/kubernetes-dashboard 8080:80 --address 0.0.0.0\n\n# 开启 nginx ingress controller 插件\n# 1.手动加载国内镜像\nminikube image load registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.12.0-beta.0\nminikube image load registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.4.4\n# 2.开启插件\nminikube addons enable ingress --images=\"KubeWebhookCertgenCreate=registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.4.4,KubeWebhookCertgenPatch=registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.4.4,IngressController=google_containers/nginx-ingress-controller:v1.12.0-beta.0\" --registries=\"IngressController=registry.cn-hangzhou.aliyuncs.com\"\n\n# 发布应用\n# 前提\n# 创建 nfs 共享文件夹，供 pod 内的容器访问\n# 后端\n# 1.导入打包好的后端应用 docker 镜像\n# 设置 Minikube 的 Docker 环境\neval $(minikube -p minikube docker-env)\n# 导入镜像到 Minikube\ndocker load -i vxtcip-boot-v1.0.0.tar\n# 2.编写 deployment 配置文件（yaml）\n# 略...\n# 3.部署 deployment\nkubectl apply -f *-deployment.yaml\n# 重启 deployment\nkubectl rollout restart -n ${namespace-name} deployment ${deployment-name}\n# 删除 deployment\nkubectl delete -n ${namespace-name} deployment ${deployment-name}\n```\n\n## 安装 Kubernetes 集群和 KubeSphere\n\n> 官方文档: [在 Linux 上安装 Kubernetes 和 KubeSphere](https://www.kubesphere.io/zh/docs/v4.1/03-installation-and-upgrade/02-install-kubesphere/02-install-kubernetes-and-kubesphere/)\n>\n> 参考博客：[33 张高清大图，带你玩转 KubeSphere 4.1.2 部署与扩展组件安装](https://www.kubesphere.io/zh/blogs/kubesphere-4.1.2-deployment-and-extension-installation/#23-部署-k8s-集群)\n\n### 前置条件\n\n#### 安装 Ansible 自动化运维工具（用于批量执行脚本/命令）\n\n参考本文《Ansible 安装与配置》\n\n#### 操作系统基础配置\n\n可使用 Ansible 批量在集群机器上执行\n\n```bash\n# 配置主机名(每台机器都需要配置，按照不同的 hostname 执行)\nhostnamectl set-hostname k8s-control-1\n# 配置DNS(已配置则忽略)\nansible k8s -m shell -a 'echo \"nameserver 114.114.114.114\" > /etc/resolv.conf'\n# 配置服务器时区\nansible k8s -m shell -a 'timedatectl set-timezone Asia/Shanghai'\n# 配置时间同步\n# - 安装 chrony 作为时间同步软件\nansible k8s -m shell -a 'yum install chrony -y'\n# - 编辑配置文件 /etc/chrony.conf，修改 ntp 服务器配置\nansible k8s -m shell -a \"sed -i 's/^pool pool.*/pool cn.pool.ntp.org iburst/g' /etc/chrony.conf\"\n# - 重启并设置 chrony 服务开机自启动\nansible k8s -m shell -a 'systemctl enable chronyd --now'\n# - 验证 chrony 同步状态\nansible k8s -m shell -a 'chronyc sourcestats -v'\n# 关闭系统防火墙\nansible k8s -m shell -a 'systemctl stop firewalld && systemctl disable firewalld'\n# 禁用 SELinux\nansible k8s -m shell -a \"sed -i 's/^SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config\"\n# 安装必须依赖\nansible k8s -m shell -a 'yum install curl socat conntrack ebtables ipset ipvsadm -y'\n```\n\n#### 磁盘配置\n\n每台服务器新增一块数据盘 **/dev/sdb**，用于 **Containerd** 和 **Kubernetes Pod** 的持久化存储\n\n为了满足用户在上线后数据盘容量不足时，可以实现动态扩容的需求。本文采用了 LVM 的方式配置磁盘\n\n##### 使用 LVM 配置硬盘，并挂载到数据目录\n\n```bash\n# 创建 PV\npvcreate /dev/sdb\n# 创建 VG\nvgcreate data /dev/sdb\n# 创建 LV（使用所有空间，VG 名字为 data，LV 名字为 lvdata）\nlvcreate -l 100%VG data -n lvdata、\n# 格式化磁盘\nmkfs.xfs /dev/mapper/data-lvdata\n# 手工挂载\nmkdir /u01\nmount /dev/mapper/data-lvdata /u01/\n# 开机自动挂载\ntail -1 /etc/mtab >> /etc/fstab\n# 创建 OpenEBS 本地数据根目录\nmkdir -p /u01/openebs/local\n# 创建 Containerd 数据目录\nmkdir -p /u01/containerd\n# 创建 Containerd 数据目录软连接\nln -s /u01/containerd /var/lib/containerd\n```\n\n### 部署 Kubernetes 集群\n\n使用 KubeSphere 出品的 KubeKey 工具，可以根据配置文件一键部署 K8S 高可用集群\n\n选择一台 control 节点作为部署节点，执行下面的操作\n\n#### 下载 KubeKey\n\n- 下载最新版的 KubeKey（**v3.1.7**）\n\n  ```bash\n  mkdir /u01/kubekey\n  \n  cd /u01/kubekey\n  \n  # 选择中文区下载(访问 GitHub 受限时使用)\n  export KKZONE=cn\n  curl -sfL https://get-kk.kubesphere.io | sh -\n  ```\n\n- 查看 KubeKey 支持的 Kubernetes 版本列表\n\n  ```bash\n  ./kk version --show-supported-k8s\n  ```\n\n  选择稳定且兼容性高的较新版本，本文选择的是 **v1.28.15**\n\n#### 创建 Kubernetes 集群部署配置\n\n1. 创建集群配置文件\n\n   ```bash\n   ./kk create config -f ksp-k8s-v12815.yaml --with-kubernetes v1.28.15\n   ```\n\n2. 修改配置文件\n\n本文采用 3 个节点同时作为 control-plane、etcd 和 worker 节点\n\n请使用编辑器，编辑配置文件 `ksp-k8s-v12815.yaml`，修改 **kind: Cluster** 小节中 hosts 和 roleGroups 等信息，修改说明如下：\n\n- hosts：指定节点的 IP、ssh 用户、ssh 密码\n- roleGroups：指定 3 个 etcd、control-plane 节点，并复用为 worker 节点\n- internalLoadbalancer： 启用内置的 HAProxy 负载均衡器\n- domain：自定义域名 **lb.opsxlab.cn**，没特殊需求可使用默认值 **lb.kubesphere.local**\n- clusterName：自定义 **opsxlab.cn**，没特殊需求可使用默认值 **cluster.local**\n- autoRenewCerts：该参数可以实现证书到期自动续期，默认为 **true**\n- containerManager：容器运行时使用 **containerd**\n- storage.openebs.basePath：**默认没有，新增配置**，指定 openebs 默认存储路径为 **/data/openebs/local**\n- registry.privateRegistry：**可选配置，** 解决 Docker 官方镜像不可用的问题\n- registry.namespaceOverride： **可选配置，** 解决 Docker 官方镜像不可用的问题\n\n修改后的完整示例如下：\n\n```yaml\napiVersion: kubekey.kubesphere.io/v1alpha2\nkind: Cluster\nmetadata:\n  name: vansys\nspec:\n  hosts:\n  - {name: k8s-control-1, address: 192.168.99.101, internalAddress: 192.168.99.101, user: root, password: \"xxx\"}\n  - {name: k8s-control-2, address: 192.168.99.102, internalAddress: 192.168.99.102, user: root, password: \"xxx\"}\n  - {name: k8s-control-3, address: 192.168.99.103, internalAddress: 192.168.99.103, user: root, password: \"xxx\"}\n  roleGroups:\n    etcd:\n    - k8s-control-1\n    - k8s-control-2\n    - k8s-control-3\n    control-plane: \n    - k8s-control-1\n    - k8s-control-2\n    - k8s-control-3\n    worker:\n    - k8s-control-1\n    - k8s-control-2\n    - k8s-control-3\n  controlPlaneEndpoint:\n    domain: lb.kubesphere.local\n    address: \"\"\n    port: 6443\n  kubernetes:\n    version: v1.28.15\n    clusterName: cluster.local\n    autoRenewCerts: true\n    containerManager: containerd\n  etcd:\n    type: kubekey\n  network:\n    plugin: calico\n    kubePodsCIDR: 10.233.64.0/18\n    kubeServiceCIDR: 10.233.0.0/18\n    enableMultusCNI: false\n  storage:\n    openebs:\n      basePath: /u01/openebs/local\n  registry:\n    # 使用 KubeSphere 在阿里云的镜像仓库，避免国内拉不下镜像的问题\n    privateRegistry: \"registry.cn-beijing.aliyuncs.com\" \n    namespaceOverride: \"kubesphereio\"\n    registryMirrors: []\n    insecureRegistries: []\n  addons: []\n```\n\n#### 部署 Kubernetes 集群\n\n使用上面创建的配置文件，执行下面的命令，创建 K8S 集群\n\n```bash\nexport KKZONE=cn\n./kk create cluster -f ksp-k8s-v12815.yaml\n```\n\n命令执行后，首先 **Kubekey** 会检查部署 K8S 的依赖及其他详细要求。通过检查后，系统将提示您确认安装。输入 **yes** 并按 **ENTER** 继续部署\n\n部署完成需要大约 10-20 分钟左右，具体需要看网速跟机器配置，若部署成功，会在终端显示如下信息：\n\n```bash\n20:10:23 CST Pipeline[CreateClusterPipeline] execute successfully\nInstallation is complete.\n\nPlease check the result using the command:\n\n        kubectl get pod -A\n```\n\n#### 验证 Kubernetes 集群状态\n\n在 control-1 控制节点使用 kubectl 命令验证\n\n```bash\n# 查看集群节点信息\nkubectl get nodes -o wide\n# 查看 Pod 信息\nkubectl get pods -A -o wide\n# 查看 Image 列表\ncrictl images ls\n```\n\n#### 问题记录\n\n安装 Kubernetes 时出现如下日志，且 kubeadm 初始化集群超时\n\n```\ndetected that the sandbox image \"registry.k8s.io/pause:3.8\" of the container runtime is inconsistent with that used by kubeadm. It is recommended that using \"registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.9\" as the CRI sandbox image\n```\n\n问题原因：containerd 配置的 sandbox image 跟 kubeadm 配置的不一致\n\n解决办法：将 `/etc/containerd/config.toml` 配置文件中的 sandbox_image 修改为 KubeKey 创建集群的配置文件中 `privateRegistry` 仓库的镜像，保持跟 kubeadm 的一致\n\n```toml\n  [plugins.\"io.containerd.grpc.v1.cri\"]\n    sandbox_image = \"registry.cn-beijing.aliyuncs.com/kubesphereio/pause:3.9\"\n```\n\n## Redis 缓存服务安装部署\n\n这里下载的是 `redis-5.0.8.tar.gz` 安装包，并将其直接放在了 `opt` ⽬ 录下\n\n### 解压安装包\n\n1、在 `/usr/local/` 下创建 `redis` ⽂ 件夹并进 ⼊\n\n```bash\ncd /usr/local/\nmkdir redis\ncd redis\n```\n\n2、将 `Redis` 安装包解压到 `/usr/local/redis` 中即可\n\n```bash\ntar zxvf /opt/redis-5.0.8.tar.gz -C ./\n```\n\n解压完之后， `/usr/local/redis` ⽬ 录中会出现 ⼀ 个 `redis-5.0.8.tar.gz` 的 ⽬ 录\n\n### 编译并安装\n\n```bash\ncd redis-5.0.8/\nmake && make install\n```\n\n### 将 Redis 安装为系统服务并后台启动\n\n进入 `utils` 目录，并执行如下脚本即可：\n\n```bash\ncd utils/\n./install_server.sh\n```\n\n此处我全部选择默认配置，有需要可以按需选择\n\n![image-20220401194430903](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220401194438.png)\n\n### 查看 Redis 服务启动情况\n\n直接执行如下命令来查看 Redis 的启动结果：\n\n```bash\nsystemctl status redis_6379.service\n\n# 扩展\n启动：systemctl start redis_6379.service\n停止：systemctl stop redis_6379.service\n重启：systemctl restart redis_6379.service\n```\n\n![image-20220401194604551](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220401194604.png)\n\n### 启动 Redis 客户端并测试\n\n启动自带的 `redis-cli` 客户端，测试通过：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220401194833.png\" alt=\"image-20220401194833905\" style=\"zoom:50%;\" />\n\n但是此时只能在本地访问，无法远程连接，因此还需要做部分设置\n\n### 运行远程连接\n\n编辑 `redis` 配置文件\n\n```bash\nvim /etc/redis/6379.conf\n```\n\n将 `bind 127.0.0.1` 修改为 `0.0.0.0`\n\n![image-20220401195240594](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220401195240.png)\n\n保存然后重启 `Redis` 服务即可：\n\n```bash\nsystemctl restart redis_6379.service\n```\n\n### 设置访问密码\n\n编辑 `redis` 配置文件\n\n```bash\nvim /etc/redis/6379.conf\n```\n\n找到如下内容：\n\n```\n#requirepass foobared\n```\n\n去掉注释，将 `foobared` 修改为自己想要的密码，保存即可。\n\n```\nrequirepass 123456\n```\n\n保存然后重启 `Redis` 服务即可：\n\n```bash\nsystemctl restart redis_6379.service\n```\n\n这样后续的访问需要先输入密码认证通过：\n\n![image-20220401195615345](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220401195615.png)\n\n## WEB 服务器 Nginx 安装部署\n\n这 ⾥ 下载的是 `nginx-1.17.10.tar.gz` 安装包，并将其直接放在了 `opt` ⽬ 录下\n\n### 解压安装包\n\n1、在 `/usr/local/` 下创建 `nginx` ⽂ 件夹并进 ⼊\n\n```bash\ncd /usr/local/\nmkdir nginx\ncd nginx\n```\n\n2、将 `Nginx` 安装包解压到 `/usr/local/nginx` 中即可\n\n```\ntar zxvf /opt/nginx-1.17.10.tar.gz -C ./\n```\n\n解压完之后， `/usr/local/nginx` ⽬ 录中会出现 ⼀ 个 `nginx-1.17.10` 的 ⽬ 录\n\n### 预先安装额外的依赖\n\n```bash\nyum -y install pcre-devel openssl openssl-devel gcc gcc-c++ autoconf automake make\n```\n\n### 编译安装 Nginx\n\n```bash\ncd nginx-1.17.10\n# 使用 --prefix= 可以指定目录安装\n./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module\nmake && make install\n```\n\n安装完成后，Nginx 的可执 ⾏⽂ 件位置位于\n\n```bash\n/usr/local/nginx/sbin/nginx\n```\n\n### 启动 Nginx\n\n直接执 ⾏ 如下命令即可：\n\n```\n/usr/local/nginx/sbin/nginx\n```\n\n如果想停 ⽌ Nginx 服务，可执 ⾏：\n\n```\n/usr/local/nginx/sbin/nginx -s stop\n```\n\n如果修改了配置 ⽂ 件后想重新加载 Nginx，可执 ⾏：\n\n```\n/usr/local/nginx/sbin/nginx -s reload\n```\n\n注意其配置 ⽂ 件位于：\n\n```\n/usr/local/nginx/conf/nginx.conf\n```\n\n### Centos6.9 注册为系统服务，并开机自启\n\n首先，在 linux 系统的/etc/init.d/目录下创建 nginx 文件，使用如下命令：\n\n`vi /etc/init.d/nginx`\n\n```sh\n#!/bin/sh\n#\n# nginx - this script starts and stops the nginx daemon\n#\n# chkconfig:   - 85 15\n# description:  NGINX is an HTTP(S) server, HTTP(S) reverse \\\n#               proxy and IMAP/POP3 proxy server\n# processname: nginx\n# config:      /etc/nginx/nginx.conf\n# config:      /etc/sysconfig/nginx\n# pidfile:     /var/run/nginx.pid\n# Source function library.\n. /etc/rc.d/init.d/functions\n# Source networking configuration.\n. /etc/sysconfig/network\n# Check that networking is up.\n[ \"$NETWORKING\" = \"no\" ] && exit 0\n# 这里根据实际安装位置修改\nnginx=\"/usr/local/nginx/sbin/nginx\"\nprog=$(basename $nginx)\n# 这里根据实际配置文件位置修改\nNGINX_CONF_FILE=\"/usr/local/nginx/conf\"\n[ -f /etc/sysconfig/nginx ] && . /etc/sysconfig/nginx\nlockfile=/var/lock/subsys/nginx\nmake_dirs() {\n   # make required directories\n   user=`$nginx -V 2>&1 | grep \"configure arguments:\" | sed 's/[^*]*--user=\\([^ ]*\\).*/\\1/g' -`\n   if [ -z \"`grep $user /etc/passwd`\" ]; then\n       useradd -M -s /bin/nologin $user\n   fi\n   options=`$nginx -V 2>&1 | grep 'configure arguments:'`\n   for opt in $options; do\n       if [ `echo $opt | grep '.*-temp-path'` ]; then\n           value=`echo $opt | cut -d \"=\" -f 2`\n           if [ ! -d \"$value\" ]; then\n               # echo \"creating\" $value\n               mkdir -p $value && chown -R $user $value\n           fi\n       fi\n   done\n}\nstart() {\n    [ -x $nginx ] || exit 5\n    [ -f $NGINX_CONF_FILE ] || exit 6\n    make_dirs\n    echo -n $\"Starting $prog: \"\n    daemon $nginx -c $NGINX_CONF_FILE\n    retval=$?\n    echo\n    [ $retval -eq 0 ] && touch $lockfile\n    return $retval\n}\nstop() {\n    echo -n $\"Stopping $prog: \"\n    killproc $prog -QUIT\n    retval=$?\n    echo\n    [ $retval -eq 0 ] && rm -f $lockfile\n    return $retval\n}\nrestart() {\n    configtest || return $?\n    stop\n    sleep 1\n    start\n}\nreload() {\n    configtest || return $?\n    echo -n $\"Reloading $prog: \"\n    killproc $nginx -HUP\n    RETVAL=$?\n    echo\n}\nforce_reload() {\n    restart\n}\nconfigtest() {\n  $nginx -t -c $NGINX_CONF_FILE\n}\nrh_status() {\n    status $prog\n}\nrh_status_q() {\n    rh_status >/dev/null 2>&1\n}\ncase \"$1\" in\n    start)\n        rh_status_q && exit 0\n        $1\n        ;;\n    stop)\n        rh_status_q || exit 0\n        $1\n        ;;\n    restart|configtest)\n        $1\n        ;;\n    reload)\n        rh_status_q || exit 7\n        $1\n        ;;\n    force-reload)\n        force_reload\n        ;;\n    status)\n        rh_status\n        ;;\n    condrestart|try-restart)\n        rh_status_q || exit 0\n            ;;\n    *)\n        echo $\"Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}\"\n        exit 2\nesac\n```\n\n保存脚本文件，并修改权限：\n\n```bash\n# 修改文件权限\nchmod a+x /etc/init.d/nginx\n# 添加为系统服务\nchkconfig --add /etc/init.d/nginx\n# 服务启动/停止命令\nservice nginx start\nservice nginx stop\n# 设置终端模式开机启动\nchkconfig nginx on\n```\n\n### CentOS7 注册为系统服务，并开机自启\n\n在系统中创建服务脚本，命令如下：\n\n`vi /usr/lib/systemd/system/nginx.service`\n\n```\n[Unit]\nDescription=nginx - web server\nAfter=network.target remote-fs.target nss-lookup.target\n[Service]\nType=forking\nPIDFile=/usr/local/nginx/logs/nginx.pid\nExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf\nExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf\nExecReload=/usr/local/nginx/sbin/nginx -s reload\nExecStop=/usr/local/nginx/sbin/nginx -s stop\nExecQuit=/usr/local/nginx/sbin/nginx -s quit\nPrivateTmp=true\n[Install]\nWantedBy=multi-user.target\n```\n\n重新加载系统服务，并设置开机自启\n\n```bash\n# 重新加载系统服务\nsystemctl daemon-reload\n# 启动服务\nsystemctl start nginx.service\n# 开机自启\nsystemctl enable nginx.service\n```\n\n## JDK（Java 环境）安装\n\n> 注意：这 ⾥ 安装的是 Oracle JDK\n\n### 准备 JDK 安装包\n\n我这里下载的是 `jdk-8u251-linux-x64.tar.gz` 安装包，并将其放在了 `/opt` 目录下\n\n### 卸载已有的 OPENJDK（如果有）\n\n如果系统 ⾃ 带有 `OpenJDK`，可以按照如下步骤提前卸载之。\n\n```bash\nrpm -qa | grep java\n```\n\n![image-20220308132559705](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220308133517.png)\n\n接下来可以将 `java` 开头的安装包均卸载即可：\n\n```bash\nyum -y remove java-1.7.0-openjdk-1.7.0.141-2.6.10.5.el7.x86_64\nyum -y remove java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64\n... 省略 ...\n```\n\n### 创建目录并解压\n\n1、在 `/usr/local/` 下创建 `java` 文件夹并进入\n\n```bash\ncd /usr/local/\nmkdir java\ncd java\n```\n\n2、将上 ⾯ 准备好的 JDK 安装包解压到 /usr/local/java 中即可\n\n```\ntar -zxvf /opt/jdk-8u251-linux-x64.tar.gz -C ./\n```\n\n解压完之后， /usr/local/java ⽬ 录中会出现 ⼀ 个 jdk1.8.0_251 的 ⽬ 录\n\n### 配置 JDK 环境变量\n\n编辑 `/etc/profile` 文件，在文件尾部加入如下 `JDK` 环境配置即可\n\n```\nJAVA_HOME=/usr/local/java/jdk1.8.0_251\nCLASSPATH=$JAVA_HOME/lib/\nPATH=$PATH:$JAVA_HOME/bin\nexport PATH JAVA_HOME CLASSPATH\n```\n\n然后执 ⾏ 如下命令让环境变量 ⽣ 效\n\n```\nsource /etc/profile\n```\n\n### 验证 JDK 安装结果\n\n输入如下命令即可检查安装结果：\n\n```\njava -version\n\njavac\n```\n\n![image-20220308153602981](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220308153603.png)\n\n## Maven 项目构建和管理工具安装\n\n### 准备 MAVEN 安装包并解压\n\n这 ⾥ 下载的是 `apache-maven-3.6.3-bin.tar.gz` 安装包，并将其放置于提前创建好的 `/usr/local/maven` ⽬ 录下。\n\n执 ⾏ 命令解压之：\n\n```bash\ntar -zxvf /opt/apache-maven-3.6.3-bin.tar.gz -C ./\n```\n\n即可在当前 ⽬ 录得到 /usr/local/maven/apache-maven-3.6.3 ⽬ 录\n\n### 配置 MAVEN 加速镜像源\n\n这 ⾥ 配置的是阿 ⾥ 云的 maven 镜像源。\n\n编辑修改 `/usr/local/maven/apache-maven-3.6.3/conf/settings.xml` ⽂ 件，在 `<mirrors></mirrors>` 标签对 ⾥ 添加如下内容即可：\n\n```xml\n<mirror>\n    <id>alimaven</id>\n    <name>aliyun maven</name>\n    <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n    <mirrorOf>central</mirrorOf>\n</mirror>\n```\n\n![image-20220308154746010](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220308154746.png)\n\n### 配置环境变量\n\n因为下载的是 ⼆ 进制版安装包，所以解压完，配置好环境变量即可使用了。\n\n编辑修改 `/etc/profile` ⽂ 件，在 ⽂ 件尾部添加如下内容，配置 `maven` 的安装路径\n\n```\nexport MAVEN_HOME=/usr/local/maven/apache-maven-3.6.3\nexport PATH=$MAVEN_HOME/bin:$PATH\n```\n\n接下来执行 `source /etc/profile` 来刷新环境变量，让 `maven` 环境的路径配置生效\n\n### 检验安装结果\n\n执 ⾏ `mvn –v` ，能打印出 `maven` 版本信息说明安装、配置成功：\n\n![image-20220308155428868](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220308155428.png)\n\n## Jenkins 安装与配置\n\n### 安装 Jenkins Master\n\n> [Jenkins 官方安装文档](https://www.jenkins.io/zh/doc/book/installing/)\n\n**Docker 安装 Jenkins（推荐）**\n\n- 使用 Docker 安装 Jenkins\n\n  ```\n  # 使用命令直接安装（包含构建工具）\n  docker run -d --name jenkins --restart always \\\n  --user root -p 8080:8080 -p 50000:50000 \\\n  -v /var/jenkins_home:/var/jenkins_home \\\n  -v /usr/local/maven/apache-maven-3.6.3:/usr/local/maven/apache-maven-3.6.3 \\\n  -v /usr/local/java/jdk1.8.0_251:/usr/local/java/jdk1.8.0_251 \\\n  -v /usr/local/sonar-scanner/sonar-scanner-4.6.0.2311-linux:/usr/local/sonar-scanner/sonar-scanner-4.6.0.2311-linux \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkinsci/blueocean\n  \n  # 简易安装\n  docker run -d --name jenkins --restart always \\\n  --user root -p 8080:8080 -p 50000:50000 \\\n  -v /u01/jenkins_home:/var/jenkins_home \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  jenkinsci/blueocean\n  ```\n\n**War 安装 Jenkins**\n\n- 获取 Jenkins 安装包\n\n下载页面：https://jenkins.io/zh/download/\n\n安装文件：jenkins.war\n\n```\n1、将最新的稳定Jenkins WAR包 下载到您计算机上的相应目录。\n\n2、在下载的目录内打开一个终端/命令提示符窗口到。\n\n3、运行命令java -jar jenkins.war\n\n4、浏览http://localhost:8080并等到*Unlock Jenkins*页面出现。\n\n5、继续使用Post-installation setup wizard后面步骤设置向导。\n```\n\n**解锁 Jenkins**\n\n![image-20220309174609417](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309174609.png)\n\n获取并输入 admin 账户密码（我这里是 docker 安装的，目录是映射到指定位置的，密码实际存放路径以提示为主）\n\n`cat /var/jenkins_home/secrets/initialAdminPassword`\n\n**跳过插件安装**\n\n因为 Jenkins 插件需要连接默认官网下载，速度非常慢，而且容易安装失败，所以我们暂时先跳过插件安装。\n\n![image-20220309174531892](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309174531.png)\n\n![image-20220309174831016](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309174831.png)\n\n**添加一个管理员账户，并进入 Jenkins 后台**\n\n![image-20220309174953956](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309174954.png)\n\n**保存并完成**\n\n![image-20220309175748708](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309175748.png)\n\n**开始使用 Jenkins**\n\n![image-20220309175816074](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309175816.png)\n\n![image-20220309175908276](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309175908.png)\n\n### 安装 Jenkins Slave\n\n`系统设置 > 节点管理 > 新建节点`\n\n![image-20220315112454277](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220315112501.png)\n\n**<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220315112942.png\" alt=\"image-20220315112942218\" style=\"zoom:67%;\" />**\n\n下载 `agent.jar`\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220315112649.png\" alt=\"image-20220315112649284\" style=\"zoom:67%;\" />\n\n```\n## 创建agent目录\n\nmkdir -p /dev/jenkinsagent\ncd /dev/jenkinsagent\nwget http://192.168.88.230:8080/jnlpJars/agent.jar\n\n\n## 编写启动脚本\n#!/bin/bash\n\necho 0bdf5bac23b7d4e66880934b25bda0f353509529b7f843ebb688614ba389680e > secret-file\n\nnohup java -jar agent.jar -jnlpUrl http://192.168.88.230:8080/computer/build/jenkins-agent.jnlp -secret @secret-file -workDir \"/u01/jenkins-agent\" 2>&1 &\n\n## 启动agent\nsh -x start.sh\nps aux | grep agent\n```\n\n### Jenkins 插件管理\n\nJenkins 本身不提供很多功能，我们可以通过使用插件来满足我们的使用。例如从 Gitlab 拉取代码，使用 Maven 构建项目等功能需要依靠插件完成。接下来演示如何下载插件。\n\n**修改 Jenkins 插件下载地址**\n\nJenkins 国外官方插件地址下载速度非常慢，所以可以修改为国内插件地址：\n\n`Jenkins -> Manage Jenkins -> Manage Plugins，点击Available`\n\n![image-20220309180153473](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309180153.png)\n\n这样做是为了把 Jenkins 官方的插件列表下载到本地，接着修改地址文件，替换为国内插件地址：\n\n```\n# 进入配置目录 （目录视情况而定，安装的jenkins_home下）\ncd /var/jenkins_home/updates\n\n# 执行命令\nsed -i 's/http:\\/\\/updates.jenkins\u0002ci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g' default.json && sed -i 's/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g' default.json\n```\n\n最后，Manage Plugins 点击 Advanced，把 Update Site 改为国内插件下载地址\n\n![image-20220309180807037](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309180807.png)\n\nSumbit 后，在浏览器输入： http://120.78.204.65:8180/restart ，重启 Jenkins。\n\n**下载中文汉化插件**\n\n`Jenkins -> Manage Jenkins -> Manage Plugins，点击Available，搜索\"Chinese\"`\n\n![image-20220309181055822](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181055.png)\n\n完成后如下图所示：\n\n![image-20220309181122066](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181122.png)\n\n重启 Jenkins 之后，就看到 Jenkins 汉化了！（PS：某些菜单可能会汉化失败）\n\n![image-20220309181408200](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181408.png)\n\n### Jenkins 用户权限管理\n\n我们可以利用 `Role-based Authorization Strategy` 插件来管理 Jenkins 用户权限\n\n**安装 Role-based Authorization Strategy 插件**\n\n![image-20220309181600238](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181600.png)\n\n**开启权限全局安全配置**\n\n![image-20220309181914873](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181914.png)\n\n授权策略切换为 \"Role-Based Strategy\"，保存\n\n![image-20220309181940124](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309181940.png)\n\n**创建角色**\n\n在系统管理页面进入 Manage and Assign Roles\n\n![image-20220309182209559](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182209.png)\n\n点击 \"Manage Roles\"\n\n![image-20220309182301430](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182301.png)\n\n![image-20220309182435102](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182435.png)\n\n`Global roles（全局角色）`：管理员等高级用户可以创建基于全局的角色\n\n`Item roles（项目角色）`： 针对某个或者某些项目的角色\n\n`Node roles（节点角色）`：节点相关的权限\n\n我们添加以下三个角色：\n\n- baseRole：该角色为全局角色。这个角色需要绑定 Overall 下面的 Read 权限，是为了给所有用户绑定最基本的 Jenkins 访问权限。注意：如果不给后续用户绑定这个角色，会报错误：`用户名 is missing the Overall/Read permission`\n- role1：该角色为项目角色。使用正则表达式绑定 `.vx-chx.\\*`，意思是只能操作 vx-chx 开头的项目。\n- role2：该角色为项目角色。使用正则表达式绑定 `.vx-phm.\\*`，意思是只能操作 vx-phm 开头的项目。\n\n![image-20220309182812353](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182812.png)\n\n保存\n\n**创建用户**\n\n在系统管理页面进入 Manage Users\n\n![image-20220309182917026](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309182917.png)\n\n![image-20220309183107565](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309183107.png)\n\n分别创建两个用户：vxchx 和 vxphm\n\n![image-20220309183223041](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309183223.png)\n\n**给用户分配角色**\n\n系统管理页面进入 Manage and Assign Roles，点击 Assign Roles\n\n绑定规则如下：\n\n- vxchx 用户分别绑定 baseRole 和 role1 角色\n\n- vxphm 用户分别绑定 baseRole 和 role2 角色\n\n  ![image-20220309183455591](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309183455.png)\n\n保存\n\n**创建项目测试权限**\n\n以 admin 管理员账户创建两个项目，分别为 vx-chx-test 和 vx-phm-test\n\n结果为： vxchx 用户登录，只能看到 vx-chx-test 项目 vxphm 用户登录，只能看到 vx-phm-test 项目\n\n### Jenkins 凭证管理\n\n凭据可以用来存储需要密文保护的数据库密码、Gitlab 密码信息、Docker 私有仓库密码等，以便 Jenkins 可以和这些第三方的应用进行交互。\n\n**安装 Credentials Binding 插件**\n\n要在 Jenkins 使用凭证管理功能，需要安装 `Credentials Binding` 插件\n\n> 注：新版本已经默认安装了此插件，这里无需另外再安装了\n\n系统管理中选择 `Manage Credentials`\n\n![image-20220309184117479](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309184117.png)\n\n可以添加的凭证有 5 种：\n\n![image-20220309184218399](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220309184218.png)\n\n- Username with password：用户名和密码\n- SSH Username with private key： 使用 SSH 用户和密钥\n- Secret file：需要保密的文本文件，使用时 Jenkins 会将文件复制到一个临时目录中，再将文件路径 设置到一个变量中，等构建结束后，所复制的 Secret file 就会被删除。\n- GitHub App：GitHub 的 API 令牌\n- Secret text：需要保存的一个加密的文本串，如钉钉机器人或 Github 的 api token\n- Certificate：通过上传证书文件的方式\n\n常用的凭证类型有：**Username with password（用户密码）** 和 **SSH Username with private key（SSH 密钥）**\n\n接下来以使用 Git 工具到 Gitlab 拉取项目源码为例，演示 Jenkins 的如何管理 Gitlab 的凭证。\n\n**安装 Git 插件和 Git 工具**\n\n为了让 Jenkins 支持从 Gitlab 拉取源码，需要安装 Git 插件以及在服务器上安装 Git 工具。\n\nGit 插件安装：\n\n![image-20220310094712046](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310094719.png)\n\n服务器上安装 Git 工具（以 CentOS7 为例）：\n\n```bash\n# 安装\nyum install git -y\n# 安装后查看版本\ngit --version\n```\n\n**用户密码类型**\n\n1）创建凭据\n\n`Jenkins -> 凭证 -> 系统 -> 全局凭据 -> 添加凭据`\n\n![image-20220310095750604](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310095750.png)\n\n选择 \"Username with password\"，输入 Gitlab 的用户名和密码，点击 \"确定\"。\n\n![image-20220310100359012](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310100359.png)\n\n**SSH 密钥类型**\n\nSSH 免密登录示意图\n\n![image-20220310100539140](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310100539.png)\n\n1）使用 root 用户生成公钥和私钥\n\n`ssh-keygen -t rsa`\n\n在/root/.ssh/目录保存了公钥和使用\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310101013.png\" alt=\"image-20220310101013313\" style=\"zoom:67%;\" />\n\nid_rsa：私钥文件\n\nid_rsa.pub：公钥文件\n\n2）把生成的公钥放在 Gitlab 中\n\n`登录gitlab -> 点击头像 -> Settings -> SSH Keys`\n\n复制刚才 id_rsa.pub 文件的内容到这里，点击 \"Add Key\"\n\n![image-20220310101538008](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310101538.png)\n\n3）在 Jenkins 中添加凭证，配置私钥\n\n在 Jenkins 添加一个新的凭证，类型为 \"SSH Username with private key\"，把刚才生成私有文件内容复制过来\n\n![image-20220310102203814](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310102203.png)\n\n![image-20220310102427213](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310102427.png)\n\n### Jenkins 关联 JDK 和 Maven\n\n**关联 JDK**\n\n`Jenkins -> 系统管理 -> 全局工具配置 -> JDK -> 新增JDK，配置如下：`\n\n![image-20220310102744563](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310102744.png)\n\n**关联 Maven**\n\n`Jenkins -> 系统管理 -> 全局工具配置 -> Maven -> 新增Maven，配置如下：`\n\n![image-20220310102835922](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310102836.png)\n\n### Jenkins 关闭跨站请求伪造保护\n\n- Docker 容器运行\n\n```\n# 1、进入运行的容器\ndocker exec -u root -it 你的Jenkins容器名称或者容器id bash\n\n# 2、输入命令，编辑jenkins启动配置文件\nvi /usr/local/bin/jenkins.sh\n\n# 3、在图中标记处，加入以下配置\n-Dhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION=true\n\n# 4、重启容器\ndocker restart jenkins\n```\n\n![image-20220312001020531](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220312001027.png)\n\n### **添加 Jenkins 全局变量**\n\n`Jenkins -> 系统管理 -> 全局属性 -> 添加三个环境变量，配置如下：`\n\n![image-20220310103241974](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310103242.png)\n\n### Jenkins 数据迁移和备份\n\n将安装 Jenkins 的机器上的 `jenkins_home` 目录下的 config.xml 文件，jobs 文件夹，users 文件夹和 plugins 文件夹打包\n\n- config.xml 是存放配置信息的\n- jobs 是存放创建的工程项目的\n- users 是存放用户账信息的\n- plugins 是存放插件的\n\n### Jenkins 删除构建历史\n\n```groovy\n//项目名称\ndef jobName = \"xxx\"\n//删除小于等于maxNumber的构建历史\ndef maxNumber = xxx\n\nJenkins.instance.getItemByFullName(jobName).builds.findAll {\n  it.number <= maxNumber\n}.each {\n  it.delete()\n}\n```\n\n## Jenkins 构建 Maven 项目\n\n> 构建方式均采用 Jar 包方式，War 方式参考 [WAR 部署方案 · JeecgBoot 开发文档](http://doc.jeecg.com/2043887)\n\n### Jenkins 项目构建类型\n\nJenkins 中自动构建项目的类型有很多，常用的有以下三种：\n\n- 自由风格软件项目（FreeStyle Project）\n- Maven 项目（Maven Project）\n- 流水线项目（Pipeline Project）\n\n每种类型的构建其实都可以完成一样的构建过程与结果，只是在操作方式、灵活度等方面有所区别，在实际开发中可以根据自己的需求和习惯来选择。（PS：个人推荐使用流水线类型，因为灵活度非常高）\n\n### 自由风格项目构建\n\n下面演示创建一个自由风格项目来完成项目的集成过程：\n\n`拉取代码 -> 编译 -> 打包 -> 部署`\n\n**拉取代码**\n\n1）创建项目\n\n![image-20220310112707895](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310112707.png)\n\n2）源码管理，从 Gitlab 拉取代码\n\n![image-20220310112815147](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310112815.png)\n\n**编译打包**\n\n`构建 -> 添加构建步骤 -> 执行shell`\n\n```bash\necho \"开始编译和打包\"\nmvn clean package\necho \"编译和打包结束\"\n```\n\n![image-20220310112952936](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310112952.png)\n\n**部署**\n\n把项目部署到远程的服务器上，并启动\n\n1）安装 `Publish Over SSH` 插件\n\nJenkins 本身无法实现远程部署到服务器上的功能，需要安装 `Publish Over SSH` 插件实现\n\n![image-20220310113332137](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310113332.png)\n\n2）配置 `Publish over SSH`，添加 SSH 服务器\n\n`打开系统管理 -> 系统配置 -> 拉到底部，选择Publish over SSH区域选择新增`\n\n![image-20220310114012322](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310114012.png)\n\n`点击高级 -> 填写服务器密码`（也可选择 ssh 验证，在 Jenkins 中配置本机私钥，将公钥发送到目标机器，即可完成无密码登录）\n\n`发送命令：ssh-copy-id -i /root/.ssh/id_rsa.pub root@192.168.xxx.xxx`\n\n![image-20220310114702171](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310114702.png)\n\n- Passphrase： 密码（目标机器的密码）\n- Path to key：key 文件（私钥）的路径\n- SSH Server Name： 标识的名字（随便你取什么）\n- Hostname： 需要连接 ssh 的主机名或 ip 地址，此处填写应用服务器 IP（建议 ip）\n- Username： 用户名\n- Remote Directory： 远程目录(要发布的目录, 比如/usr/local/tomcat/webapps/)\n\n3）添加构建步骤\n\n![image-20220310115055853](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310115055.png)\n\n![image-20220310115245384](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310115245.png)\n\n```\n# 脚本参考\nsource /etc/profile\n\ncd /apps\nps -ef|grep jeecg-boot-module-system-3.1.0.jar|grep -v grep|awk '{print $2}'|xargs kill -s 9\nBUILD_ID=dontKillMe\nnohup java -jar jeecg-boot-module-system-3.1.0.jar > jeecg-boot-module-system-3.1.0.log 2>&1 &\n```\n\n4）点击 \"立即构建\"，开始构建过程\n\n![image-20220310115628609](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310115628.png)\n\n5）构建成功，并自动化部署，访问测试！\n\n### Maven 项目构建\n\n1）安装 Maven Integration Plugin（高版本的 Jenkins 已预装了此插件）\n\n![image-20220310135008339](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310135008.png)\n\n2）创建 Maven 项目\n\n![image-20220310135103444](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310135103.png)\n\n3）配置项目\n\n拉取代码和远程部署的过程和自由风格项目一样，只是 \"构建\" 部分不同\n\n![image-20220310135300799](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310135300.png)\n\n### Pipeline 流水线项目构建(\\*)\n\n#### Pipeline 简介\n\n**1）概念**\n\nPipeline，简单来说，就是一套运行在 Jenkins 上的工作流框架，将原来独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂流程编排和可视化的工作。\n\n**2）使用 Pipeline 有以下好处（来自翻译自官方文档）：**\n\n代码：Pipeline 以代码的形式实现，通常被检入源代码控制，使团队能够编辑，审查和迭代其传送流 程。持久：无论是计划内的还是计划外的服务器重启。Pipeline 都是可恢复的。可停止：Pipeline 可接 收交互式输入，以确定是否继续执行 Pipeline。多功能：Pipeline 支持现实世界中复杂的持续交付要求。它支持 fork/join、循环执行，并行执行任务的功能。可扩展：Pipeline 插件支持其 DSL 的自定义扩展，以及与其他插件集成的多个选项。\n\n**3）如何创建 Jenkins Pipeline 呢？**\n\n- Pipeline 脚本是由 **Groovy** 语言实现的，但是我们没必要单独去学习 Groovy\n- Pipeline 支持两种语法：**Declarative**(声明式)和 **Scripted Pipeline**(脚本式)语法\n- Pipeline 也有两种创建方法：可以直接在 Jenkins 的 Web UI 界面中输入脚本；也可以通过创建一个 Jenkinsfile 脚本文件放入项目源码库中（一般我们都推荐在 Jenkins 中直接从源代码控制(SCM)中直接载入 Jenkinsfile Pipeline 这种方法）。\n\n#### Pipeline 语法快速入门\n\n**1）Declarative 声明式-Pipeline**\n\n创建一个流水线项目\n\n![image-20220310154144897](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310154144.png)\n\n`流水线 -> 选择HelloWorld模板`\n\n![image-20220310154618000](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310154618.png)\n\n生成的内容如下：\n\n```groovy\npipeline {\n    agent any\n\n    stages {\n        stage('Hello') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n```\n\n- **stages：** 代表整个流水线的所有执行阶段。通常 stages 只有 1 个，里面包含多个 stage\n\n- **stage：** 代表流水线中的某个阶段，可能出现 n 个。一般分为拉取代码，编译构建，部署等阶段。\n\n- **steps：** 代表一个阶段内需要执行的逻辑。steps 里面是 shell 脚本，git 拉取代码，ssh 远程发布等任意内容。\n\n编写一个简单声明式的 Pipeline：\n\n```groovy\npipeline {\n    agent any\n    stages {\n        stage('拉取代码') {\n            steps {\n            \techo '拉取代码'\n            }\n        }\n        stage('编译构建') {\n            steps {\n            \techo '编译构建'\n            }\n        }\n        stage('项目部署') {\n            steps {\n            \techo '项目部署'\n            }\n        }\n    }\n}\n```\n\n点击构建，进入 `Blue Ocean` 可以看到整个构建过程\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310155756.png\" alt=\"image-20220310155756052\" style=\"zoom: 150%;\" />\n\n**2）Scripted Pipeline 脚本式-Pipeline**\n\n创建项目\n\n![image-20220310155938728](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310155938.png)\n\n选择 `Scripted Pipeline\"`\n\n![image-20220310160044398](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310160044.png)\n\n```groovy\nnode {\n    def mvnHome\n    stage('Preparation') { // for display purposes\n\n    }\n    stage('Build') {\n\n    }\n    stage('Results') {\n\n    }\n}\n```\n\n- Node：节点，一个 Node 就是一个 Jenkins 节点，Master 或者 Agent，是执行 Step 的具体运行环境，后续讲到 Jenkins 的 Master-Slave 架构的时候用到。\n- Stage：阶段，一个 Pipeline 可以划分为若干个 Stage，每个 Stage 代表一组操作，比如： Build、Test、Deploy，Stage 是一个逻辑分组的概念。\n- Step：步骤，Step 是最基本的操作单元，可以是打印一句话，也可以是构建一个 Docker 镜像， 由各类 Jenkins 插件提供，比如命令：sh ‘make’，就相当于我们平时 shell 终端中执行 make 命令 一样。\n\n编写一个简单的脚本式 Pipeline\n\n```\nnode {\n    def mvnHome\n    stage('拉取代码') { // for display purposes\n    \techo '拉取代码'\n    }\n    stage('编译构建') {\n    \techo '编译构建'\n    }\n    stage('项目部署') {\n    \techo '项目部署'\n    }\n}\n```\n\n构建结果和声明式一样！\n\n**Pipeline Script from SCM**\n\n刚才我们都是直接在 Jenkins 的 UI 界面编写 Pipeline 代码，这样不方便脚本维护，建议把 Pipeline 脚本放在项目中（一起进行版本控制）\n\n**1）在项目根目录建立 Jenkinsfile 文件，把内容复制到该文件中**\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310163924.png\" alt=\"image-20220310163924603\" style=\"zoom:67%;\" />\n\n把 Jenkinsfile 上传到 Gitlab\n\n**2）在项目中引用该文件**\n\n![image-20220310164207097](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310164207.png)\n\n![image-20220310164225747](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310164225.png)\n\n### Jenkinsfile\n\n#### Jenkinsfile 环境变量\n\n| 环境变量                       | 说明                                                                              |\n| ------------------------------ | --------------------------------------------------------------------------------- |\n| BRANCH_NAME                    | 在 multibranch 项目中，BRANCH_NAME 用于标明构建分支的名称。                       |\n| CHANGE_ID                      | 在 multibranch 的项目中，相较于特定的变更请求，用于标明变更 ID，比如 Pull Request |\n| CHANGE_URL                     | 在 multibranch 的项目中，相较于特定的变更请求，用于标明变更的 URL                 |\n| CHANGE_TITLE                   | 在 multibranch 的项目中，相较于特定的变更请求，用于标明变更的标题                 |\n| CHANGE_AUTHOR                  | 在 multibranch 的项目中，相较于特定的变更请求，用于标明提交变更的人员的名称       |\n| CHANGE_AUTHOR_DISPLAY_NAME     | 在 multibranch 的项目中，相较于特定的变更请求，用于标明提交变更的人员的显示名称   |\n| CHANGE_AUTHOR_EMAIL            | 在 multibranch 的项目中，相较于特定的变更请求，用于标明提交变更的人员的邮件地址   |\n| CHANGE_TARGET                  | 在 multibranch 的项目中，相较于特定的变更请求，用于合并后的分支信息等             |\n| BUILD_NUMBER                   | 当前的构建编号                                                                    |\n| BUILD_ID                       | 在 1.597 版本后引进，表示当前构建 ID                                              |\n| BUILD_DISPLAY_NAME             | 当前构建的显示信息                                                                |\n| JOB_NAME                       | 构建 Job 的全称，包含项目信息                                                     |\n| JOB_BASE_NAME                  | 除去项目信息的 Job 名称                                                           |\n| BUILD_TAG                      | 构建标签                                                                          |\n| EXECUTOR_NUMBER                | 执行器编号，用于标识构建器的不同编号                                              |\n| NODE_NAME                      | 构建节点的名称                                                                    |\n| NODE_LABELS                    | 节点标签                                                                          |\n| WORKSPACE                      | 构建时使用的工作空间的绝对路径                                                    |\n| JENKINS_HOME                   | JENKINS 根目录的绝对路径                                                          |\n| JENKINS_URL                    | Jenkins 的 URL 信息                                                               |\n| BUILD_URL                      | 构建的 URL 信息                                                                   |\n| JOB_URL                        | 构建 Job 的 URL 信息                                                              |\n| GIT_COMMIT                     | git 提交的 hash 码                                                                |\n| GIT_PREVIOUS_COMMIT            | 当前分支上次提交的 hash 码                                                        |\n| GIT_PREVIOUS_SUCCESSFUL_COMMIT | 当前分支上次成功构建时提交的 hash 码                                              |\n| GIT_BRANCH                     | 远程分支名称                                                                      |\n| GIT_LOCAL_BRANCH               | 本地分支名称                                                                      |\n| GIT_URL                        | 远程 URL 地址                                                                     |\n| GIT_COMMITTER_NAME             | Git 提交者的名称                                                                  |\n| GIT_AUTHOR_NAME                | Git Author 的名称                                                                 |\n| GIT_COMMITTER_EMAIL            | Git 提交者的 email 地址                                                           |\n| GIT_AUTHOR_EMAIL               | Git Author 的 email 地址                                                          |\n| MERCURIAL_REVISION             | Mercurial 的版本 ID 信息                                                          |\n| MERCURIAL_REVISION_SHORT       | Mercurial 的版本 ID 缩写                                                          |\n| MERCURIAL_REVISION_NUMBER      | Mercurial 的版本号信息                                                            |\n| MERCURIAL_REVISION_BRANCH      | 分支版本信息                                                                      |\n| MERCURIAL_REPOSITORY_URL       | 仓库 URL 信息                                                                     |\n| SVN_REVISION                   | Subversion 的当前版本信息                                                         |\n| SVN_URL                        | 当前工作空间中被 checkout 的 Subversion 工程的 URL 地址信息                       |\n\n### 常用的构建触发器\n\nJenkins 内置 4 种构建触发器：\n\n- 触发远程构建\n- 其他工程构建后触发（Build after other projects are build）\n- 定时构建（Build periodically）\n- 轮询 SCM（Poll SCM）\n- GitHub 钩子触发的 GIT SCM 轮询（GitHub hook trigger for GITScm polling）\n\n**触发远程构建**\n\n![image-20220310164928630](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310164928.png)\n\n触发构建 url：http://192.168.88.86:8180/job/vx-phm/build?token = abcabc\n\n**其他工程构建后触发**\n\n1）创建 pre_job 流水线工程\n\n![image-20220310170454942](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310170455.png)\n\n2）配置需要触发的工程\n\n![image-20220310170935519](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310170935.png)\n\n**定时构建**\n\n![image-20220310171234011](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310171234.png)\n\n定时字符串从左往右分别为： 分 时 日 月 周\n\n一些定时表达式的例子：\n\n```\n每30分钟构建一次：H代表形参 H/30 * * * * 10:02 10:32\n\n每2个小时构建一次: H H/2 * * *\n\n每天的8点，12点，22点，一天构建3次： (多个时间点中间用逗号隔开) 0 8,12,22 * * *\n\n每天中午12点定时构建一次 H 12 * * *\n\n每天下午18点定时构建一次 H 18 * * *\n\n在每个小时的前半个小时内的每10分钟 H(0-29)/10 * * * *\n\n每两小时一次，每个工作日上午9点到下午5点(也许是上午10:38，下午12:38，下午2:38，下午\n4:38) H H(9-16)/2 * * 1-5\n```\n\n**轮询 SCM**\n\n轮询 SCM，是指定时扫描本地代码仓库的代码是否有变更，如果代码有变更就触发项目构建。\n\n![image-20220310171348558](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310171348.png)\n\n注意：此构建触发器，Jenkins 会定时扫描本地整个项目的代码，增大系统的开销，不建议使用。\n\n### Git Hook 自动触发构建(\\*)\n\n刚才我们看到在 Jenkins 的内置构建触发器中，轮询 SCM 可以实现 Gitlab 代码更新，项目自动构建，但是该方案的性能不佳。那有没有更好的方案呢？有的。就是利用 Gitlab 的 webhook 实现代码 push 到仓库，立即触发项目自动构建。\n\n**安装 Gitlab Hook 插件**\n\n需要安装两个插件：\n\nGitlab Hook 和 Gitlab\n\n![image-20220310172047813](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310172047.png)\n\n**Jenkins 设置自动构建**\n\n![image-20220310172445870](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310172445.png)\n\n等会需要把生成的 webhook URL 配置到 Gitlab 中。\n\n**Gitlab 配置 webhook**\n\n1）开启 webhook 功能\n\n`使用root账户登录到后台，点击Admin Area -> Settings -> Network`\n\n`勾选\"Allow requests to the local network from web hooks and services\"`\n\n![image-20220310172805087](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310172805.png)\n\n2）在项目中添加 webhook\n\n`点击项目 -> Settings -> Webhooks`\n\n![image-20220310173325550](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310173325.png)\n\n注意：以下设置必须完成，否则会报错！\n\n`系统管理 -> 系统配置`\n\n![image-20220310173704682](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220310173704.png)\n\n## SonarQube 平台安装与配置\n\n### 认识 SonarQube\n\nSonarQube 是一款用于代码质量管理的开源工具，是静态代码检查工具，采用 B/S 架构它主要用于管理源代码的质量，可以支持众多计算机语言，比如 php，java, C#, go，C/C++, Cobol, JavaScrip, Groovy 等。sonar 可以通过 PMD，CheckStyle，Findbugs 等等代码规则检测工具来检测你的代码，帮助你发现代码的漏洞，Bug，异味等信息。\n\n#### 架构\n\n- 一台 SonarQube Server 启动 3 个主要过程：\n  - Web 服务器，供开发人员，管理人员浏览高质量的快照并配置 SonarQube 实例\n  - 基于 Elasticsearch 的 Search Server 从 UI 进行后退搜索\n  - Compute Engine 服务器，负责处理代码分析报告并将其保存在 SonarQube 数据库中\n- 一个 SonarQube 数据库要存储：\n  - SonarQube 实例的配置（安全性，插件设置等）\n  - 项目，视图等的质量快照。\n- 服务器上安装了多个 SonarQube 插件，可能包括语言，SCM，集成，身份验证和管理插件\n- 在构建/持续集成服务器上运行一个或多个 SonarScanner，以分析项目\n\n![image-20220314135314928](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314135315.png)\n\n#### 工作原理\n\n开发人员在 IDE 开发代码，可以安装 SonarLint 插件进行提交前代码扫描 当开发人员提交代码到版本控制系统中，自动触发 jenkins 进行代码扫描\n\n![image-20220314135418834](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314135418.png)\n\n#### 版本\n\n开源社区版、开发版、企业版、数据中心版\n\n![image-20220314135630641](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314135630.png)\n\n### Docker 安装 SonarQube\n\n这里采用 docker 容器进行安装，简单快捷\n\n```bash\n## 创建数据目录\nmkdir -p /u01/sonarqube/{data,extensions,logs}\nchmod 777 -R /u01/cicd/sonarqube/\n\n## 调整\nsysctl -w vm.max_map_count=262144\n\n## 运行\ndocker run -d -p 9000:9000 -p 9092:9092 --name sonarqube \\\n\t-v /u01/sonarqube/data:/opt/sonarqube/data \\\n\t-v /u01/sonarqube/extensions:/opt/sonarqube/extensions \\\n\t-v /u01/sonarqube/logs:/opt/sonarqube/logs \\\n\t-e SONAR_JDBC_USERNAME=sonar \\\n\t-e SONAR_JDBC_PASSWORD=sonar \\\n\t-e SONAR_JDBC_URL=\"jdbc:postgresql://192.168.88.236:5432/sonar \" \\\n\t--restart = always \\\n\t--privileged = true \\\n    sonarqube: 8.9.9-community\n\n## 验证\ndocker logs -f sonarqube\n```\n\n访问：http://192.168.88.235:9000/\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314134759.png\" alt=\"image-20220314134752470\" style=\"zoom:67%;\" />\n\n默认账号：admin/admin\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314134841.png\" alt=\"image-20220314134841587\" style=\"zoom:67%;\" />\n\n### 配置 Scanner\n\n**安装**\n\n```\n# 获取安装包\nwget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.6.0.2311-linux.zip\n\n# 解压到指定目录\nunzip -o -d  /usr/local/sonar-scanner /opt/sonar-scanner-cli-4.6.0.2311-linux.zip\n\n# 编辑环境变量\nvim /etc/profile\nexport SCANNER_HOME =/usr/local/sonar-scanner/sonar-scanner-4.6.0.2311-linux\nexport PATH = $PATH:$ SCANNER_HOME/bin\n\n# 使环境变量生效\nsource /etc/profile\n\n# 查看版本\nsonar-scanner -v\nINFO: Scanner configuration file: /usr/local/sonar-scanner-4.6.0.2311-linux/conf/sonar-scanner.properties\nINFO: Project root configuration file: NONE\nINFO: SonarScanner 4.6.0.2311\nINFO: Java 11.0.3 AdoptOpenJDK (64-bit)\nINFO: Linux 4.18.0-80.el8.x86_64 amd64\n\n# 修改使用的 jdk\nvim /usr/local/sonar-scanner/sonar-scanner-4.6.0.2311-linux/bin/sonar-scanner\n```\n\n### SonarQube 平台配置管理\n\n#### 安装中文插件\n\n**在线安装：操作如下图**\n\n![image-20220314140021697](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314140021.png)\n\n#### 配置强制登录\n\n默认所有的项目都可以公开的查看，在企业内肯定要配置成私有的。只有登录后才能查看\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314140634.png\" alt=\"image-20220314140634628\" style=\"zoom:67%;\" />\n\n### Jenkins 配置 SonarScanner\n\n创建 SonarQube 账户 token\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314143339.png\" alt=\"image-20220314143339207\" style=\"zoom:67%;\" />\n\n将 token 保存到 Jenkins 凭据中\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314143433.png\" alt=\"image-20220314143433728\" style=\"zoom:67%;\" />\n\n在 Jenkins 中安装`SonarQube Scanner`插件\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314143552.png\" alt=\"image-20220314143552551\" style=\"zoom:67%;\" />\n\n`系统管理 -> 系统配置 -> 往下翻找到SonarQube servers -> Add SonarQube -> 添加服务器，选择凭据`\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314143936.png\" alt=\"image-20220314143936259\" style=\"zoom:67%;\" />\n\n### IDEA 配置 SonarLint 插件\n\nToken：a3268ff16b2d08b4582ff6a97342cc9d11b4e456\n\n## Nexus 制品库安装与配置\n\n### Docker 安装部署 Nexus 制品库\n\n``` bash\n## 拉取镜像\ndocker pull sonatype/nexus3:3.30.0\n\n## 创建数据目录\nmkdir -p /u01/cicd/nexus3/data\nchmod 777 -R /u01/cicd/nexus3/\n\n## 启动容器\ndocker run -itd \\\n--privileged = true --name = nexus3 \\\n-p 8081:8081 \\\n-v /u01/cicd/nexus3/data:/nexus-data \\\nsonatype/nexus3:3.30.0\n\n## 验证\ndocker logs nexus3 -f\n\n## 日志中出现 “Started Sonatype Nexus OSS 3.30.0-01” 为启动成功\n## http://your-ip-addr: 8081 访问测试\n```\n\n安装完成后，默认的 admin 密码存储在了数据目录，获取初始化密码\n\n`docker exec -i nexus3 cat /nexus-data/admin.password`\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314144935.png\" alt=\"image-20220314144935748\" style=\"zoom:67%;\" />\n\n登录后更新密码\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314145010.png\" alt=\"image-20220314145010632\" style=\"zoom:67%;\" />\n\n### Nexus 制品库搭建\n\n#### 搭建 Maven 私服（代理仓库）\n\n默认安装 nexus 后会自动创建的\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314145707.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n私服：将外网仓库代理到企业内部本地仓库中。图中的地址可以自定义修改\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314145907.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n#### 搭建制品库（本地仓库）\n\n新建 raw 类型的仓库\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314145956.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n设置仓库的信息\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314150017.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n### 上传制品\n\n在 nexus 中新建一个`maven-hostd`仓库，同时在 maven 的配置文件`settings.xml`中配置 maven-hostd 认证。具体配置如下：\n\n``` xml\n<server>\n    <id> maven-hosted </id>\n    <username> admin </username>\n    <password> wx123!@#</password>\n</server>\n```\n\n注意使用`mvn deploy`发布时，server.id=repository.id\n\n``` bash\nmvn deploy: deploy-file\n-DgroupId = xxxxxx pom 中的 groupId\n-DartifactId = xxxxxx pom 中的 artifactId\n-Dversion = xxxxxx pom 中的版本号 version\n-Dpackaging = xxxxxx pom 中打包方式\n-Dfile = xxxxxx 本地文件\n-Durl = xxxxxx 仓库 url\n-DrepositoryId = xxxxxx 对应的是 setting.xml（认证）\n```\n\n直接读取 pom 文件（方便）\n\n``` bash\nmvn deploy: deploy-file \\\n-DgeneratePom = false \\\n-DrepositoryId = maven-hosted \\\n-Durl = http://192.168.1.200:8081/repository/maven-hosted/ \\\n-DpomFile = pom.xml \\\n-Dfile = target/demo-0.0.1-SNAPSHOT.jar\n```\n\n自定义 pom 信息（灵活）\n\n``` bash\nmvn deploy: deploy-file -Dmaven.test.skip = true  \\\n-Dfile = target/demo-0.0.1-SNAPSHOT.jar \\\n-DgroupId = com.example \\\n-DartifactId = demo \\\n-Dversion = 1.1.1  \\\n-Dpackaging = jar \\\n-DrepositoryId = maven-hosted \\\n-Durl = http://192.168.1.200:8081/repository/maven-hosted/\n```\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314152655.png)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314152725.png)\n\n### Jenkins 安装 Nexus 插件\n\n安装`Nexus Artifact Upload`插件，使用片段生成器生成 DSL\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314155314.png)\n\n**发布制品**\n\n安装`Maven Artifact ChoiceListProvider (Nexus)`插件\n\n![images](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314155850.png)\n\n用户选择制品，在应用服务器通过 salt、ansible 下载制品并部署\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220314155911.png)\n\n## Ansible 安装与配置\n\n### 安装\n\n```\n# CentOS7.6 使用 YUM 安装\nyum install ansible -y\nansible --version\n\n# Anolis OS 8.9 使用 PIP3 安装\n# 升级 Python 到 3.9.x\n# 下载安装包并解压\nwget https://www.python.org/ftp/python/3.9.5/Python-3.9.5.tgz\ntar zxvf Python-3.9.5.tgz\ncd Python-3.9.5/\n# 安装所需的依赖\ndnf -y install gcc zlib* libffi-devel\n# 编译并安装\n./configure --prefix=/usr/local/python3 --enable-optimizations\nmake && make install\n# 删除老的 python3 ，并链接新版本\nrm -rf /usr/bin/python3\nln -s /usr/local/python3/bin/python3 /usr/bin/python3\nrm -rf /usr/bin/pip3\nln -s /usr/local/python3/bin/pip3 /usr/bin/pip3\n# 查看是否正确安装 python3\npython3 --version\npip3 --version\n# pip3 安装 ansible\npython3 -m pip install --user ansible\n# 同样进行链接\nln -sf /root/.local/bin/ansible  /usr/bin/ansible\nln -sf /root/.local/bin/ansible-config /usr/bin/ansible-config\n# 查看已安装的软件包\npython3 -m pip show ansible\n# 检查 ansible 是否被正确安装\nansible --version \n```\n\n### 添加 Ansible 主机列表\n\n#### 基于密钥连接\n\n``` Bash\n# 生成私钥和公钥（已有则忽略）\ncd ~/.ssh && ssh-keygen -t rsa\n# 批量发送到管理机器\nfor i in {1,2,3,6}; do ssh-copy-id -i 192.168.1.3$i ; done\n```\n\n#### 配置 /etc/ansible/hosts 文件\n\n```\n[root@ansible ~]# vim /etc/ansible/hosts\n# 方法一 主机+端口+密钥\n[webserver]\n192.168.1.31:22\n192.168.1.32\n192.168.1.33\n192.168.1.36\n\n# 方法二 别名主机+端口+密钥\n[webserver]\nnode1 ansible_ssh_host=192.168.1.31 ansible_ssh_port=22\nnode2 ansible_ssh_host=192.168.1.32 ansible_ssh_port=22\nnode3 ansible_ssh_host=192.168.1.33 ansible_ssh_port=22\nnode6 ansible_ssh_host=192.168.1.36 ansible_ssh_port=22\n```\n\n#### 测试连通性\n\n``` Bash\nansible webserver -m ping -o\n```\n\n## 安装 NPM 包管理器\n\n```\n# 下载 node 安装包\nwget https://nodejs.org/dist/v14.16.1/node-v14.16.1-linux-x64.tar.xz\nmkdir -p /usr/local/node\ntar xf node-v14.16.1-linux-x64.tar.xz -C /usr/local/node/\n\n# 编辑环境变量\nvim /etc/profile\nexport NODE_HOME =/usr/local/node/node-v14.16.1-linux-x64\nexport PATH = $NODE_HOME/bin:$ PATH\n# 生效\nsource /etc/profile\n# 查看是否安装成功\nnode -v\nnpm -v\n\n# 设置镜像\nnpm config set registry https://registry.npm.taobao.org --global\nnpm config set disturl https://npm.taobao.org/dist --global\n\n# 设置软链接\nunlink /usr/bin/node\nwhereis node\nln -s /usr/local/node/node-v14.16.1-linux-x64/bin/node /usr/bin/node\n```\n\n## Centos6 配置 YUM\n\n```\n# centos6 配置 yum\nsed -i “s|enabled = 1|enabled = 0|g” /etc/yum/pluginconf.d/fastestmirror.conf\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://www.xmpan.com/Centos-6-Vault-Aliyun.repo\nyum clean all\nyum makecache\n```\n\n## Minio 文件服务安装与配置\n\n```\n# 二进制安装\nwget https://dl.min.io/server/minio/release/linux-amd64/minio\nchmod +x minio\nMINIO_ROOT_USER = admin MINIO_ROOT_PASSWORD = password ./minio server /mnt/data --console-address \": 9001\"\n\n# 后台启动\nMINIO_ROOT_USER = admin MINIO_ROOT_PASSWORD ='wx123!@#' nohup /u01/minio-server/minio server /u01/minio-server/data --console-address \": 9001\" > /u01/minio-server/minio.log 2 >&1 &\n\n# docker 安装\nmkdir -p /u01/minio/data\n\ndocker run -d \\\n  -p 9000:9000 \\\n  -p 9001:9001 \\\n  --name minio \\\n  -v /u01/minio/data:/data \\\n  -v /u01/minio/config:/root/.minio \\\n  -e \"MINIO_ROOT_USER = q5H0EO1pbv\" \\\n  -e \"MINIO_ROOT_PASSWORD = Wyk1dkn4Xp\" \\\n  -e MINIO_SERVER_URL = http://192.168.88.200:9000 \\\n  -e MINIO_BROWSER_REDIRECT_URL = http://192.168.88.200:9001 \\\n  quay.io/minio/minio server /data \\\n  --address \": 9000\" --console-address \": 9001\"\n```\n\n## GitStats 代码统计工具安装与配置\n\n### 安装 Ruby 环境\n\nGitStats 需要 ruby-2.5 以上环境\n\n```\n# 下载：\nwget https://cache.ruby-lang.org/pub/ruby/2.5/ruby-2.5.0.tar.gz\n# 解压：\ntar -zxvf ruby-2.5.0.tar.gz\n# 进入目录：\ncd ruby-2.5.0\n# 创建安装目录：\nmkdir -p /usr/local/ruby\n# 安装必备依赖\nyum -y install gcc openssl-devel make\n# 配置并制定安装位置：\n./configure --prefix =/usr/local/ruby\n# 编译安装\nmake  && make install\n\n安装完成输入  ruby -v 提示/usr/bin/ruby: No such file or directory\n\n解决问题之前，先确认一个情况，输入命令 /usr/local/ruby/bin/ruby --version\n\n如果有版本信息，那说明 ruby 被装到了该目录下，而非系统认为的 /usr/bin/ruby\n\n解决方法是在系统默认运行 ruby 的位置 [/usr/bin/ruby] 创建一个 symlink（相当于 win 下的快捷方式），指向 ruby 的实际位置 [/usr/local/ruby/bin/ruby]\n\n建立软链接\n命令是  ln -s /usr/local/ruby/bin/ruby /usr/bin/ruby\n再输入   ruby -v           OK 完成\n\n\n附赠：要是安装 gem 也出现这种情况 [-bash: /usr/bin/gem: No such file or directory] 也是同理\n\nln -s /usr/local/ruby/bin/gem /usr/bin/gem\n\n#查看当前仓库地址\ngem sources -l\n#配置阿里云仓库源\ngem sources -a http://mirrors.aliyun.com/rubygems/ --remove https://rubygems.org/\n```\n\n### 安装 GitStats\n\n```\n# 安装 git_stats\ngem install git_stats\n# 安装 locate\nyum install mlocate -y\nupdatedb\n# find 命令查找 git_stats 目录\nfind / -name 'git_stats'\n# 进入到配置目录\ncd /usr/local/ruby/lib/ruby/gems/2.5.0/gems/git_stats-1.0.17/config/locales/\ncp zh_tw_default.yml zh_default.yml\n#修改以下 2 个 yml, 将最上边的 zh_tw 调整为 zh_cn，其余不变\nvim zh_default.yml\nvim zh.yml\n\n\n# 若报以下错误\nERROR:  Error installing git_stats:\n\tThe last version of nokogiri (~> 1.6) to support your Ruby & RubyGems was 1.12.5. Try installing it with `gem install nokogiri -v 1.12.5` and then running the current command again\n\n# 运行\ngem install nokogiri -v 1.12.5\n\n# 配置环境变量，放到末尾\nvim /etc/profile\nPATH =/usr/local/ruby/bin:$PATH\nexport PATH\n\n# 使之生效\nsource /etc/profile\n```\n\n### 使用 GitStats 生成报告\n\n```\n# 创建一个项目文件夹\nmkdir -p /u01/git-project\n# 创建一个报告生成文件夹\nmkdir -p /var/www/git-report\n\n# 使用 git 将项目 clone 到项目文件夹中\ngit clone xxx.git\n# 切换到项目根目录，使用 git_stats 生成报告\ngit_stats generate -o /var/www/git-report/xxx --language zh_cn\n```\n\n### 配置 nginx 访问\n\n``` nginx\nserver {\n        listen       8098;\n        server_name  192.168.88.235;\n\n\t    location /vansysboot {\n            alias   /var/www/git-report/vansysboot;\n            index  index.html index.htm;\n        }\n}\n```\n\n## 安装 Prometheus + Grafana 监控平台\n\n> 官网：https://prometheus.io/\n>\n> 下载地址：https://prometheus.io/download/\n\n### 安装 Prometheus Server\n\n`Prometheus` 基于 `Golang` 编写，编译后的软件包，不依赖于任何的第三方依赖。只需要下载对应平台的二进制包，解压并且添加基本的配置即可正常启动 `Prometheus Server`。\n\n#### 上传安装包\n\n上传 `prometheus-2.29.1.linux-amd64.tar.gz` 到虚拟机的 `/opt` 目录\n\n#### 解压安装包\n\n1. 解压到 `/u01/module` 目录下\n\n``` bash\ntar -zxvf prometheus-2.37.0.linux-amd64.tar.gz -C /u01/module\n```\n\n2. 修改目录名\n\n``` bash\ncd /u01/module\nmv prometheus-2.37.0.linux-amd64.tar.gz prometheus-2.37.0\n```\n\n#### 修改配置文件 prometheus.yml\n\n``` bash\ncd prometheus-2.37.0\nvim prometheus.yml\n```\n\n在 scrape_configs 配置项下添加配置：\n\n``` yaml\n  # 添加 PushGateway 监控配置\n  - job_name: 'pushgateway'\n    static_configs:\n    - targets: ['192.168.88.231:9091']\n      labels:\n        instance: pushgateway\n\n  # 添加 Node Exporter 监控配置\n  - job_name: 'node exporter'\n    static_configs:\n    - targets: ['192.168.88.230:9100', '192.168.88.231:9100', '192.168.88.232:9100']\n```\n\n**配置说明：**\n\n1. **global 配置块**：控制 Prometheus 服务器的全局配置\n\n   - scrape_interval：配置拉取数据的时间间隔，默认为 1 分钟。\n   - evaluation_interval：规则验证（生成 alert）的时间间隔，默认为 1 分钟。\n\n2. **rule_files 配置块**：规则配置文件\n\n3. **scrape_configs 配置块**：配置采集目标相关， prometheus 监视的目标。Prometheus自身的运行信息可以通过  HTTP 访问，所以 Prometheus 可以监控自己的运行数据。\n\n   - job_name：监控作业的名称\n\n   - static_configs：表示静态目标配置，就是固定从某个 target 拉取数据\n   - targets ： 指 定 监 控 的 目 标 ， 其 实 就 是 从 哪 儿 拉 取 数 据 。 Prometheus 会从 http://ip:9090/metrics 上拉取数据。\n\n> *Prometheus 是可以在运行时自动加载配置的。启动时需要添加：--web.enable-lifecycle*\n>\n> *重载配置命令：`curl -X POST http://127.0.0.1:9090/-/reload`*\n\n### 安装 Node Exporter\n\n在 `Prometheus` 的架构设计中，`Prometheus Server` 主要负责数据的收集，存储并且对外提供数据查询支持，而实际的监控样本数据的收集则是由 `Exporter` 完成。因此为了能够监控到某些东西，如主机的 `CPU` 使用率，我们需要使用到 `Exporter`。`Prometheus` 周期性的从 `Exporter` 暴露的 HTTP 服务地址（通常是 `/metrics` ）拉取监控样本数据。\n\n`Exporter` 可以是一个相对开放的概念，其可以是一个独立运行的程序独立于监控目标以外，也可以是直接内置在监控目标中。只要能够向 `Prometheus` 提供标准格式的监控样本数据即可。\n\n为了能够采集到主机的运行指标如 CPU, 内存，磁盘等信息。我们可以使用 `Node Exporter`。`Node Exporter` 同样采用 `Golang` 编写，并且不存在任何的第三方依赖，只需要下载，解压即可运行。\n\n#### 上传安装包\n\n上传 `node_exporter-1.4.0-rc.0.linux-amd64.tar.gz` 到虚拟机的 `/opt` 目录\n\n#### 解压安装包\n\n1. 解压到 `/u01/module` 目录下\n\n``` bash\ntar -zxvf node_exporter-1.4.0-rc.0.linux-amd64.tar.gz -C /u01/module\n```\n\n2. 修改目录名\n\n``` bash\ncd /u01/module\nmv node_exporter-1.4.0-rc.0.linux-amd64.tar.gz node_exporter-1.4.0-rc\n```\n\n3. 启动并访问端点查看是否成功\n\n``` bash\n# 执行启动命令\n./node_exporter\n```\n\n浏览器输入：http://ip:9100/metrics，可以看到当前 node exporter 获取到的当前主机的所有监控数据。\n\n#### 节点分发\n\n将解压的目录分发到要监控的节点\n\n``` bash\nxsync node_exporter-1.4.0-rc\n```\n\n**添加文件分发脚本**\n\n创建脚本文件：\n\n``` bash\nvim /usr/bin/xsync\n```\n\n脚本内容：\n\n``` bash\n#!/bin/bash\n# 判断参数是否足够\nif [ $# -lt 1 ]\nthen\n echo Not Enounh Arguement!\n exit;\nfi\n\n# 遍历所有的机器\nfor host in 192.168.88.230 192.168.88.231 192.168.88.232 \ndo\n echo ==== ==== ====  $host ============\n for file in $@\n do\n  # 判断文件是否存在\n  if [ -e $file ]\n  then\n   # 获取父目录\n   pdir = $(cd -P $(dirname $file); pwd)\n\n   # 获取当前目录的名称\n   fname = $(basename $ file)\n   ssh $host \"mkdir -p $ pdir \"\n   rsync -av $pdir/$ fname $host:$ pdir\n  else\n   echo $file does not exists!\n  fi\n done\ndone\n```\n\n若报错 `bash: rsync: command not found`，请在目标机器上安装\n\n``` bash\n# Centos\nyum install rsync -y \n```\n\n\n\n赋予执行权限\n\n``` bash\nchmod +x /usr/bin/xsync\n```\n\n**运行条件**\n\n使用 ssh 密钥验证登录，这样在传输文件时就不需要进行二次验证\n\n``` bash\n# 生成 ssh 私钥（若有这忽略）\nssh-keygen -f ~/.ssh/id_rsa -N '' \n# 循环把公钥传递到服务器上，免密登录\nfor i in 192.168.88.230 192.168.88.231 192.168.88.232  \ndo \n  ssh-copy-id $i\ndone\n\n# 根据提示输入密码\n```\n\n#### 设置开机自启\n\n##### centos6\n\n1. 创建自启动脚本\n\n``` bash\nvim /etc/init.d/node_exporter\n#!/bin/bash\n#\t/etc/rc.d/init.d/node_exporter\n# chkconfig: 2345 80 80\n#\n# config: /etc/prometheus/node_exporter.conf\n# pidfile: /var/run/prometheus/node_exporter.pid\n \n# Source function library.\n. /etc/init.d/functions\n \n \nRETVAL = 0\nPROG = \"node_exporter\"\nDAEMON_SYSCONFIG =/etc/sysconfig/${PROG}\nDAEMON =/usr/bin/${PROG} #要把安装目录下/u01/module/node_exporter/node_exporter 可执行文件拷贝到/usr/bin 目录下\nPID_FILE =/var/run/prometheus/${PROG}.pid\nLOCK_FILE =/var/lock/subsys/${PROG}\nLOG_FILE =/var/log/prometheus/node_exporter.log\nDAEMON_USER = \"prometheus\"\nFQDN =$(hostname)\nGOMAXPROCS =$(grep -c ^processor /proc/cpuinfo)\n \n. ${DAEMON_SYSCONFIG}\n \nstart() {\n  if check_status > /dev/null; then\n    echo \"node_exporter is already running\"\n    exit 0\n  fi\n \n  echo -n $\" Starting node_exporter: \"\n  daemonize -u ${DAEMON_USER} -p ${PID_FILE} -l ${LOCK_FILE} -a -e ${LOG_FILE} -o ${LOG_FILE} ${DAEMON} ${ARGS}\n  RETVAL =$?\n  echo \"\"\n  return $RETVAL\n}\n \nstop() {\n    echo -n $\" Stopping node_exporter: \"\n    killproc -p ${PID_FILE} -d 10 ${DAEMON}\n    RETVAL =$?\n    echo\n    [ $RETVAL = 0 ] && rm -f ${LOCK_FILE} ${PID_FILE}\n    return $RETVAL\n}\n \ncheck_status() {\n    status -p ${PID_FILE} ${DAEMON}\n    RETVAL =$?\n    return $RETVAL\n}\n \ncase \"$1 \" in\n    start)\n        start\n        ;;\n    stop)\n        stop\n        ;;\n    status)\n\tcheck_status\n        ;;\n    reload|force-reload)\n        reload\n        ;;\n    restart)\n        stop\n        start\n        ;;\n    *)\n        N =/etc/init.d/${NAME}\n        echo \" Usage: $N {start|stop|status|restart|force-reload}\" >&2\n        RETVAL = 2\n        ;;\nesac\n \nexit ${RETVAL}\n```\n\n2. 编辑etc/sysconfig/node_exporter\n\n```\nvim /etc/sysconfig/node_exporter  \n##添加如下内容\nARGS = \"\"\n```\n\n3. 创建启动脚本中对应文件和目录\n\n``` bash\n##开机脚本赋权\nchmod 777 /etc/init.d/node_exporter\n\n##拷贝可执行文件到/usr/bin/\ncp /u01/node_exporter-1.4.0-rc/node_exporter /usr/bin/node_exporter\n\n## 添加用户组 \ngroupadd -r prometheus\n\n## 创建目录\nmkdir -p /usr/hostonnet/prometheus/\nuseradd -r -g prometheus -s /sbin/nologin -d /usr/hostonnet/prometheus/ -c \"prometheus Daemons\" prometheus\n\n## 家目录修改属主\nchown -R prometheus: prometheus /usr/hostonnet/prometheus/\n\n## 创建运行目录\nmkdir -p /var/run/prometheus/\nchmod 777 /var/run/prometheus/\n\n## 创建 pid 文件，并赋权\ntouch /var/run/prometheus/node_exporter.pid\nchmod 777 /var/run/prometheus/node_exporter.pid \n\n## 创建日志目录，并创建日志文件，赋权，修改属主\nmkdir -p /var/log/prometheus/\ntouch /var/log/prometheus/node_exporter.log\nchmod 777 /var/log/prometheus\nchmod 777 /var/log/prometheus/node_exporter.log\nchown prometheus: prometheus /var/log/prometheus/node_exporter.log\n\n# 批量执行语句\nchmod 777 /etc/init.d/node_exporter && cp /u01/node_exporter-1.4.0-rc/node_exporter /usr/bin/node_exporter && groupadd -r prometheus && mkdir -p /usr/hostonnet/prometheus/ && useradd -r -g prometheus -s /sbin/nologin -d /usr/hostonnet/prometheus/ -c \"prometheus Daemons\" prometheus && chown -R prometheus: prometheus /usr/hostonnet/prometheus/ && mkdir -p /var/run/prometheus/ && chmod 777 /var/run/prometheus/ && touch /var/run/prometheus/node_exporter.pid && chmod 777 /var/run/prometheus/node_exporter.pid && mkdir -p /var/log/prometheus/ && touch /var/log/prometheus/node_exporter.log && chmod 777 /var/log/prometheus && chmod 777 /var/log/prometheus/node_exporter.log && chown prometheus: prometheus /var/log/prometheus/node_exporter.log\n```\n\n4. 安装daemonize\n\n``` bash\nrpm -ivh daemonize-1.6.0-1.el6.rf.x86_64.rpm\n```\n\n5. 运行node_exporter\n\n```\n#启动 node_exporter 并设置开机自启动\ncd /etc/init.d/ && ./node_exporter start && chkconfig node_exporter on  \n```\n\n##### centos7\n\n1. 创建 service 文件\n\n``` bash\nsudo vim /usr/lib/systemd/system/node_exporter.service\n```\n\n文件内容：\n\n``` ini\n[Unit]\nDescription = node_export\nDocumentation = https://github.com/prometheus/node_exporter\nAfter = network.target\n\n[Service]\nType = simple\nUser = root\nExecStart = /u01/node_exporter-1.4.0-rc/node_exporter\nRestart = on-failure\n\n[Install]\nWantedBy = multi-user.target\n```\n\n2. 分发文件\n\n``` bash\nxsync /usr/lib/systemd/system/node_exporter.service\n```\n\n2. 设置开机自启并启动（所有机器都执行）\n\n``` bash\n# 开机自启\nsudo systemctl enable node_exporter.service\n\n# 启动服务\nsudo systemctl start node_exporter.service\n```\n\n### 安装 Alertmanager\n\n#### 上传安装包\n\n上传 `alertmanager-0.24.0.linux-amd64.tar.gz` 到虚拟机的 `/opt` 目录\n\n#### 解压安装包\n\n1. 解压到 `/u01/module` 目录下\n\n``` bash\ntar -zxvf alertmanager-0.24.0.linux-amd64.tar.gz -C /u01/module\n```\n\n2. 修改目录名\n\n``` bash\ncd /u01/module\nmv alertmanager-0.24.0.linux-amd64.tar.gz alertmanager-0.24.0\n```\n\n### 启动 Prometheus Server 和 Alertmanager\n\n#### 在 Prometheus Server 目录下执行启动命令\n\n``` bash\nnohup ./prometheus --config.file = prometheus.yml --web.enable-lifecycle > ./prometheus.log 2 >&1 &\n```\n\n#### 在 Alertmanager 目录下启动\n\n``` bash\nnohup ./alertmanager --config.file = alertmanager.yml > ./alertmanager.log 2 >&1 &\n```\n\n### 安装 Grafana 数据展示\n\ngrafana 是一款采用 Go 语言编写的开源应用，主要用于大规模指标数据的可视化展现，是网络架构和应用分析中最流行的时序数据展示工具，目前已经支持绝大部分常用的时序数据库。\n\n> 下载地址：https://grafana.com/grafana/download\n\n#### 上传安装包\n\n将 `grafana-enterprise-9.0.6.linux-amd64.tar.gz` 上传至 `/opt` 目录下\n\n#### 解压安装包\n\n1. 解压到 `/u01/module` 目录下\n\n``` bash\ntar -zxvf grafana-enterprise-9.0.6.linux-amd64.tar.gz -C /u01/module\n```\n\n2. 修改目录名\n\n``` bash\ncd /u01/module\nmv grafana-enterprise-9.0.6.linux-amd64.tar.gz grafana-enterprise-9.0.6\n```\n\n3. 启动 grafana 服务\n\n``` bash\nnohup ./bin/grafana-server web > ./grafana.log 2 >&1 &\n```\n\n3. 打开浏览器，访问：`http://ip:3000`，默认用户名/密码：`admin`\n\n### Grafana 与 Prometheus 数据对接\n\n#### 添加 Prometheus 数据源\n\n1. `配置 -> 数据源 -> 添加数据源`\n\n![image-20220804165739264](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804165746.png)\n\n2. 选择 `Prometheus` 数据源\n\n![image-20220804165940226](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804165940.png)\n\n3. 配置 Prometheus Server 地址\n\n![image-20220804170315289](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804170315.png)\n\n4. 点击下方的 Save&Test\n\n![image-20220804170439669](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804170439.png)\n\n5. 点击 Back 返回即可，可以看到 Data Sources 页面，出现了添加的 Prometheus：\n\n![image-20220804171224982](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804171225.png)\n\n#### 添加仪表盘 Dashboard\n\n手动一个个添加 Dashboard 比较繁琐，Grafana 社区鼓励用户分享 Dashboard，通过 https://grafana.com/grafana/dashboards 网站，可以找到大量可直接使用的 Dashboard 模板。\n\nGrafana 中所有的 Dashboard 通过 JSON 进行共享，下载并且导入这些 JSON 文件，就可以直接使用这些已经定义好的 Dashboard。\n\n1. 选择一款中文版本的 `Node Exporter` 仪表板\n\n![image-20220804173336648](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804173336.png)\n\n2. 下载模板 json 文件\n\n![image-20220804173609120](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804173609.png)\n\n3. 在 Grafana 中导入模板\n\n![image-20220804173822051](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804173822.png)\n\n4. 导入之后选择 `Prometheus` 数据源即可\n\n![image-20220804174153940](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804174154.png)\n\n5. 导入成功之后就能看到炫酷的仪表板\n\n![image-20220804174503814](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220804174504.png)\n\n### 安装 OracleDB Exporter 监控 Oracle 数据库\n\n> GitHub 仓库：[iamseth/oracledb_exporter: Prometheus Oracle database exporter. (github.com)](https://github.com/iamseth/oracledb_exporter)\n>\n> Grafana 面板：[Oracledb监控-性能与表空间 | Grafana Labs](https://grafana.com/grafana/dashboards/11121-oracledb/)\n>\n> 以下步骤是采用 Docker 进行安装\n\n``` bash\n# 1、拉取最新版本镜像\ndocker pull ghcr.io/iamseth/oracledb_exporter: 0.5.0\n# 2、使用 docker run 命令启动\n# 注意：1、--link 连接 oracle 数据库容器，这样在 oracledb_exporter 容器中可以直接使用容器名字代替 IP 地址进行通信\n# \t   2、若密码中含有 !@#$ 等特殊字符，可以使用 URLEncode 进行转义\ndocker run -d --name oracledb_exporter --link = oracle11g -p 9161:9161 -e 'DATA_SOURCE_NAME = oracle://sys: 123456@oracle11g: 1521/orcl' ghcr.io/iamseth/oracledb_exporter: 0.5.0\n# 3、使用 culr 访问指标情况\ncurl -l http://127.0.0.1:9161/metric\n# 4、接入 Prometheus\n在 prometheus.yml 中添加一段配置：\n  - job_name: oracledb_exporter\n    metrics_path: /metrics\n    static_configs:\n      - targets: ['chxdb21.vansys.com: 15090']\n```\n\n## 使用 Docker 安装服务\n\n### Docker 安装 ClickHouse 数据库\n\n> 前提：请先安装好 Docker 容器服务（[安装 Docker 容器服务](https://blog.kyire.site/2022/04/02/2f74bb89.html#%E5%AE%89%E8%A3%85-Docker-%E5%AE%B9%E5%99%A8%E6%9C%8D%E5%8A%A1)）\n\n1. 创建目录并更改权限\n\n``` Bash\nmkdir -p /u01/clickhouse/{data, config, log}\n\nchmod -R 777 /u01/clickhouse/{data, config, log}\n```\n\n2. 拉取镜像\n\n``` Bash\ndocker pull yandex/clickhouse-server\n```\n\n3. 创建临时容器\n\n``` Bash\ndocker run --rm -d --name = clickhouse-server \\\n--ulimit nofile = 262144:262144 \\\n-p 8123:8123 -p 9009:9009 -p 9000:9000 \\\nyandex/clickhouse-server: latest\n```\n\n4. 复制临时容器内配置文件到宿主机\n\n``` Bash\ndocker cp clickhouse-server:/etc/clickhouse-server/config.xml /u01/clickhouse/config/config.xml\n\ndocker cp clickhouse-server:/etc/clickhouse-server/users.xml /u01/clickhouse/config/users.xml\n```\n\n5. 停掉临时容器\n\n``` Bash\ndocker rm -f clickhouse-server\n```\n\n6. default用户配置\n\n``` Bash\n# 生成 sha256sum 密码\n\n# 随机生成密码\nPASSWORD = $(base64 < /dev/urandom | head -c8); echo \"$ PASSWORD \"; echo -n \"$PASSWORD \" | sha256sum | tr -d '-'\n\n会输出明码和 SHA256 密码（每个人生成的不一样）\njQ+72k17\na70b3173bfef01aff0d2472fd1f86a4be647aed4e0624f1b6c867a69072e1273\n\n# 生成指定密码 wx123456\necho \"wx123456\"; echo -n \"wx123456\" | sha256sum | tr -d '-'\nwx123456\n37acf78e288b1323fae2115749edcf696b6190d8c8ca1cbc66e39b10e22f2a86\n\n# 打开 users.xml 文件 default 用户设置密码为 123456\nvim /u01/clickhouse/config/users.xml\n\n# 将文件中 <password> </password> 改为以下内容\n<password_sha256_hex> 37acf78e288b1323fae2115749edcf696b6190d8c8ca1cbc66e39b10e22f2a86 </password_sha256_hex>\n\n# 将 default 用户改为只读\n# 将 <profile> default </profile> 改为以下内容\n<profile> readonly </profile>\n```\n\n7. 新增root用户\n\n``` Bash\n# 生成 root 用户密码 wx123456\necho \"wx123456\"; echo -n \"wx123456\" | sha256sum | tr -d '-'\nwx123456\n37acf78e288b1323fae2115749edcf696b6190d8c8ca1cbc66e39b10e22f2a86\n\n# 打开 users.xml 文件 \nvim /u01/clickhouse/config/users.xml\n# 在 </default> 下一行添加以下内容\n<root>\n<password_sha256_hex> 37acf78e288b1323fae2115749edcf696b6190d8c8ca1cbc66e39b10e22f2a86 </password_sha256_hex>\n    <networks incl=\"networks\" replace=\"replace\">\n            <ip>::/0 </ip>\n    </networks>\n    <profile> default </profile>\n    <quota> default </quota>\n</root>\n```\n\n8. 部署clickhouse-server\n\n``` Bash\ndocker run -d \\\n--name clickhouse-server \\\n--privileged = true --restart = always \\\n--ulimit nofile = 262144:262144 \\\n-p 8123:8123 \\\n-p 9000:9000 \\\n-p 9009:9009 \\\n-v /u01/clickhouse/data:/var/lib/clickhouse: rw \\\n-v /u01/clickhouse/log:/var/log/clickhouse-server: rw \\\n-v /u01/clickhouse/config/config.xml:/etc/clickhouse-server/config.xml \\\n-v /u01/clickhouse/config/users.xml:/etc/clickhouse-server/users.xml \\\nyandex/clickhouse-server: latest\n```\n\n### Docker 安装 ElasticSearch 搜索引擎\n\n> 前提：请先安装好 Docker 容器服务（[安装 Docker 容器服务](https://blog.kyire.site/2022/04/02/2f74bb89.html#%E5%AE%89%E8%A3%85-Docker-%E5%AE%B9%E5%99%A8%E6%9C%8D%E5%8A%A1)）\n\n1. 创建目录、配置文件并修改权限\n\n``` bash\n# 创建 es 相关挂载目录\nmkdir -p /hd/docker/es/{config, data, plugins}\n# 创建文件\nvi /hd/docker/es/config/elasticsearch.yml\nhttp.host: 0.0.0.0\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nhttp.cors.allow-headers: Authorization\nxpack.security.enabled: true\nxpack.security.transport.ssl.enabled: true\n\n# 设置目录权限，否则会报错\nchmod +x ./config/elasticsearch.yml\n# 设置为目录 777 权限\nchmod -R 777 /hd/docker/es\n```\n\n2. 拉取镜像\n\n``` bash\ndocker pull elasticsearch: 7.17.4\n```\n\n3. 启动容器\n\n``` bash\ndocker run --name es --restart = always -p 9200:9200 -p 9300:9300 \\\n-e \"ES_JAVA_OPTS =-Xms512m -Xmx1024m\" \\\n-v /hd/docker/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\\n-v /hd/docker/es/data:/usr/share/elasticsearch/data \\\n-v /hd/docker/es/plugins:/usr/share/elasticsearch/plugins \\\n-d elasticsearch: 7.17.4\n```\n\n4. 配置 es 访问密码\n\n``` bash\n# 进入容器内部\ndocker exec -it es /bin/bash\n\n# 配置密码命令\n./bin/elasticsearch-setup-passwords interactive\n```\n\n5. 访问网页 `http://localhost:9200`（账号密码：`elastic`/`123456`）\n\n### Docker 安装 Nginx Proxy Manager 代理管理平台\n\n> 前提：请先安装好 Docker 容器服务（[安装 Docker 容器服务](https://blog.kyire.site/2022/04/02/2f74bb89.html#%E5%AE%89%E8%A3%85-Docker-%E5%AE%B9%E5%99%A8%E6%9C%8D%E5%8A%A1)）\n\n1. 创建 `docker-compose.yml`\n\n**使用 network_mode: host 与宿主机共享网络**\n\n``` yml\nversion: '3'\nservices:\n  app:\n    image: '2691432189/nginx-proxy-manager-monitor-zh: latest'\n    restart: always\n    network_mode: host\n    volumes:\n      - ./data:/data\n      - ./letsencrypt:/etc/letsencrypt\n```\n\n2. 部署运行\n\n``` bash\ndocker compose up -d\n```\n\n3. 登录管理平台\n\n容器运行成功后，使用浏览器访问 `81` 端口。\n\nhttp://127.0.0.1:81\n\n默认管理员信息：\n\n```\nEmail:    admin@example.com\nPassword: changeme\n```\n\n登录之后系统会要求修改详细信息和密码\n\n4. 快速升级\n\n``` bash\ndocker-compose down\ndocker-compose pull\ndocker-compose up -d\n```\n\n### Docker 安装 Redis 服务\n\n1. 拉取 `Redis` 镜像\n\n``` bash\n# 拉取最新版本\ndocker pull redis\n# 指定版本号\ndocker pull redis: 5.0.8\n```\n\n2. 启动 `Redis` 容器\n\n> 建议使用配置文件启动，先从 Redis 官网下载标准配置文件（也可以自己准备一个）\n\n``` bash\n# 创建配置文件存放目录\nmkdir -p /u01/software/redis/conf\ncd /u01/software/redis/conf\n\n# 下载 redis.conf 配置文件\nwget http://download.redis.io/redis-stable/redis.conf\n\n# 给配置文件授权\nchmod 777 redis.conf\n\n# 修改配置文件\n1、注释 bind 127.0.0.1，开启远程访问\n2、关闭保护模式 protected-mode no\n3、设置密码 requirepass 123456\n\n# 启动 Redis 容器\ndocker run -p 6379:6379 --name redis --restart = always \\\n-v /u01/software/redis/conf/redis.conf:/etc/redis/redis.conf \\\n-v /u01/software/redis/data:/data \\\n-itd redis redis-server /etc/redis/redis.conf \\\n--appendonly yes\n\n```\n\n## Linux 下静默安装 Oracle 19c\n\n### 安装准备\n\n#### 下载安装包\n\n官网下载：[下载地址 | 点击跳转](https://www.oracle.com/database/technologies/oracle19c-linux-downloads.html)\n\n#### 服务器环境\n\n| 事项       | 详情                                        |\n| ---------- | ------------------------------------------- |\n| 操作系统   | Centos 7.9                                  |\n| 数据库版本 | 19.3.0                                      |\n| CPU        | Intel(R) Xeon(R) Silver 4210R CPU @ 2.40GHz |\n| 内存       | 32GB                                        |\n| Swap       | 15GB                                        |\n\n### 准备安装环境\n\n#### 服务器环境检查\n\n1. 检查缺少了那些依赖包\n\n``` bash\nrpm --query --queryformat \"%{NAME}-%{VERSION}.%{RELEASE} (%{ARCH})\\n\" bc binutils compat-libcap1 compat-libstdc++-33 gcc gcc-c++ glibc glibc-devel ksh libaio libaio-devel libgcc libstdc++ libstdc++-devel make sysstat elfutils-libelf elfutils-libelf-devel fontconfig-devel libxcb smartmontools libX11 libXau libXtst libXrender libXrender-devel\n```\n\n2. 使用 yum 安装缺少的依赖\n\n``` bash\nyum install -y $NOT_INSTALLED\n```\n\n#### 创建 Oracle 用户组\n\n``` bash\ngroupadd oinstall && groupadd dba && groupadd asmdba && groupadd backupdba && groupadd dgdba && groupadd kmdba && groupadd racdba && groupadd oper && useradd -g oinstall -G dba, asmdba, backupdba, dgdba, kmdba, racdba, oper -m oracle\n```\n\n#### 配置 hosts 文件\n\n``` bash\nvi /etc/hosts\n```\n\n#### 配置系统内核参数\n\n``` bash\n# 编辑 /etc/sysctl.conf 文件\nvi /etc/sysctl.conf\nfs.aio-max-nr = 1048576\nfs.file-max = 6815744\nkernel.shmall = 16451328\nkernel.shmmax = 33692319744\nkernel.shmmni = 4096\nkernel.sem = 250 32000 100 128\nnet.ipv4.ip_local_port_range = 9000 65500\nnet.core.rmem_default = 262144\nnet.core.rmem_max = 4194304\nnet.core.wmem_default = 262144\nnet.core.wmem_max = 1048576\n\n# 执行 sysctl -p 使配置生效\n/sbin/sysctl -p\n```\n\n#### 关闭 SELINUX 跟防火墙\n\n``` bash\n# 查看 /etc/selinux/config 中 SELINUX 配置是否是 disabled\ncat /etc/selinux/config\n# This file controls the state of SELinux on the system.\n# SELINUX = can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\nSELINUX = disabled\n# SELINUXTYPE = can take one of three two values:\n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy. Only selected processes are protected. \n#     mls - Multi Level Security protection.\nSELINUXTYPE = targeted \n\n# 查看防火墙状态\nsystemctl status firewalld\n\n# 关闭防火墙服务\nsystemctl stop firewalld\n# 停止防火墙服务开机自启\nsystemctl disable firewalld\n```\n\n#### 配置用户环境\n\n1. 配置 oracle 用户环境变量\n\n``` bash\n# 切换 oracle 用户\nsu - oracle\n# 编辑 .bash_profile 文件，在文件末尾添加\nvi .bash_profile\nexport ORACLE_BASE =/u01/app/oracle\nexport ORACLE_HOME =/u01/app/oracle/product/19.3.0\nexport PATH = $PATH:$ ORACLE_HOME/bin:/usr/local/bin\n# 修改为具体的机器名称 /etc/hosts 配置\nexport ORACLE_HOSTNAME = xxx\nexport ORACLE_SID = orcl\nexport LD_LIBRARY_PATH = $ORACLE_HOME/lib:$ ORACLE_HOME/rdbms/lib:$ORACLE_HOME/network/lib:/lib:/usr/lib\nexport CLASSPATH = $ORACLE_HOME/jlib:$ ORACLE_HOME/rdbms/jlib:$ORACLE_HOME/network/jlib\n```\n\n2. 修改用户的 shell 限制\n\n``` bash\n# 在 /etc/security/limits.conf  文件末尾添加\nvi /etc/security/limits.conf \n@oinstall soft nofile 2048\n@oinstall hard nofile 65536\n@oinstall soft nproc 16384\n@oinstall soft stack 10240\n```\n\n### 开始安装\n\n响应文件模板存放位置：\n\n- 软件：/u01/app/oracle/product/19.5.0/install/response/db_install.rsp\n- 监听：/u01/app/oracle/product/19.5.0/assistants/netca/netca.rsp\n- 建库：/u01/app/oracle/product/19.5.0/assistants/dbca/dbca.rsp\n\n#### 解压安装包\n\n``` bash\n# 创建 oracle 安装目录（root 用户）\nmkdir -p /u01/app/oracle/product/19.3.0\nchown -R oracle: oinstall /u01/app\n# 切换到 oracle 用户解压\nsu - oracle\nunzip LINUX.X64_193000_db_home.zip -d $ORACLE_HOME\n```\n\n#### 命令行静默安装\n\n#### 配置响应文件\n\n``` bash\n# 备份 db_install.rsp 文件\ncd $ORACLE_HOME/install/response\ncp db_install.rsp db_install.rsp.bak\n\n# 编辑 db_install.rsp 文件，修改以下参数\noracle.install.option = INSTALL_DB_SWONLY\nUNIX_GROUP_NAME = oinstall\nINVENTORY_LOCATION =/u01/app/oraInventory\nORACLE_HOME =/u01/app/oracle/product/19.3.0\nORACLE_BASE =/u01/app/oracle\noracle.install.db.InstallEdition = EE\noracle.install.db.OSDBA_GROUP = dba\noracle.install.db.OSOPER_GROUP = oper\noracle.install.db.OSBACKUPDBA_GROUP = backupdba\noracle.install.db.OSDGDBA_GROUP = dgdba\noracle.install.db.OSKMDBA_GROUP = kmdba\noracle.install.db.OSRACDBA_GROUP = racdba\noracle.install.db.rootconfig.executeRootScript = false\n```\n\n#### 执行安装\n\n``` bash\n./runInstaller -silent -responseFile $ORACLE_HOME/install/response/db_install.rsp\n```\n\n**若出现安装错误，请根据提示查看日志，分析错误原因**\n\n#### 安装成功根据提示使用 root 用户执行脚本\n\n```\nsh /u01/app/oraInventory/orainstRoot.sh\nsh /u01/app/oracle/product/19.3.0/root.sh\n```\n\n**查看相关执行日志，若没有错误，表示已经安装完成**\n\n### 创建数据库实例\n\n#### 配置监听\n\n``` bash\n# 创建监听\nnetca /silent /responseFile $ORACLE_HOME/assistants/netca/netca.rsp\n# 查看监听状态\nlsnrctl status\n```\n\n#### 创建数据库\n\n``` bash\n# 备份 dbca.rsp 响应文件\ncd $ORACLE_HOME/assistants/dbca\ncp dbca.rsp dbca.rsp.bak\n# 配置 dbca.rsp 响应文件\nvi dbca.rsp\n# 主要修改以下参数\ngdbName = orcl\nsid = orcl\ndatabaseConfigType = SI\ntemplateName = General_Purpose.dbc\nsysPassword = Qwer1234\nsystemPassword = Qwer1234\nemConfiguration = DBEXPRESS\ndbsnmpPassword = Qwer1234\ndatafileDestination =/u01/app/oracle/oradata\ncharacterSet = ZHS16GBK\ntotalMemory = 8192\n```\n\n#### 执行安装\n\n``` bash\ndbca -silent -createDatabase -responseFile $ORACLE_HOME/assistants/dbca/dbca.rsp\n```\n\n#### 检查\n\n``` bash\n# 连接 sqlplus\nsqlplus / as sysdba\n# 查看实例的运行状态\nselect instance_name, status from v$instance;\n```\n\n### 完全卸载 Oracle 数据库\n\n##### 停止数据库服务\n\n``` bash\n# 连接 sqlplus\nsqlplus / as sysdba\n# 停止数据库服务\nshutdown immediate;\n```\n\n##### 停止数据库监听\n\n``` bash\n# 停止数据库监听\nlsnrctl stop\n```\n\n##### 使用 deinstall 工具进行卸载\n\n``` bash\n# 执行 deinstall 工具，按提示进行操作\n/u01/app/oracle/product/19.3.0/deinstall/deinstall\n# 执行结束后按提示使用 root 用户执行脚本\nrm -rf /etc/oraInst.loc\nrm -rf /opt/ORCLfmap\nrm -r /etc/oratab\n```\n\n","tags":["技巧","笔记"],"categories":["Linux"]},{"title":"分库分表理论知识","slug":"分库分表理论知识","url":"/2022/02/18/a3a0c28e.html","content":"\n## 一、前言\n\n当一张表的数据达到几千万时，查询一次所花的时间会变得很长，系统效率会下降。`Oracle` 官方推荐单表容量为 **500w** 以下为最佳状态。\n\n但单表或单库达到性能瓶颈时，就需要对数据库进行拆分，数据库拆分又分为：\n\n- **垂直拆分**\n- **水平拆分**\n\n## 二、垂直拆分\n\n垂直拆分可以分为：`垂直分表` 和 `垂直分库`。\n\n### 垂直分表\n\n**概念：**把一个表的多个字段分别拆成多个表，一般按字段的访问频次拆分，经常访问的字段一个表，不经常访问的字段一个表。减少布不必要的字段查询，提高数据库性能。\n\n**如图：**\n\n![image-20220217164518085](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220217164518.png)\t\n\n### 垂直分库\n\n**概念：**就是根据业务耦合性，将关联度低的不同表存储在不同的数据库中。做法与大系统拆分成多个小系统类似，按业务类型进行独立划分。与 `微服务划分` 的做法类似。每个微服务使用单独的一个数据库。\n\n**如图：**\n\n![image-20220217155607149](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220217155607.png)\t\n\n**说明：**\n\n业务数据量小的情况下，只有一个数据库，所有的表都在这个库里。\n\n业务扩展，数据量增加，单体服务转变为微服务治理。要将之前的库按业务类型拆分成多个库。每个微服务对应一个库。\n\n### 垂直拆分优缺点\n\n**优点：**\n\n- 解决业务系统层面的耦合，业务清晰\n- 与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等\n- 高并发场景下，垂直切分能一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈\n\n**缺点：**\n\n- 分库后无法Join查询，只能通过接口聚合方式解决，提高了开发的复杂度\n- 分库后分布式事务问题处理复杂\n- 依然会存在单表数据量过大的问题（需要进行水平拆分）\n\n## 三、水平拆分\n\n当一个应用难以再通过细粒度的垂直拆分或拆分之后数据量行数过大，存在单库、单表读写及存储性能瓶颈，这时就需要进行水平拆分。\n\n水平拆分也可以分为：`水平分库` 和 `水平分表`。\n\n### 水平分库\n\n**原因：**上面虽然已经把商品库分成3个库，但是随着业务的增加，系统的QPS过高，数据库响应速度来不及。但系统QPS达到瓶颈时就要考虑分库。\n\n**如图：**\n\n![image-20220217163006880](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220217163006.png)\t\n\n### 水平分表\n\n**原因：**一般我们一张表的数据不要超过 **500w**，如果表数据超过 **500w**，并且还在不断增加数据，那就可以考虑分表。\n\n**如图：**\n\n![image-20220217164412132](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220217164412.png)\n\n### 水平拆分优缺点\n\n**优点：**\n\n- 避免单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力\n- 应用端改造较小，不需要拆分业务模块\n\n**缺点：**\n\n- 跨分片的事务一致性难以保证\n- 跨库的Join关联查询性能较差\n- 数据多次扩展难度和维护量极大\n\n## 四、数据分片规则\n\n当我们考虑去水平拆分表时，需要将一张表水平拆分成多张表，这就涉及到数据分片的规则，比较常见的有：`Hash取模分表`、`数值Range分表`、`一致性Hash算法分表`。\n\n### Hash取模分表\n\n**概念：**一般采用Hash取模的拆分方式，例如：假设按 `goods_id` 分4张表。（`goods_id%4` 取整数确定表）\n\n![image-20220217225906590](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220217225906.png)\t\n\n**优点：**\n\n- 数据分片相对均匀，不容易出现热点和并发访问的瓶颈\n\n**缺点：**\n\n-  后期分片集群扩容时，需要迁移旧的数据很难。 \n- 容易面临跨分片查询的复杂问题。比如上例中，如果频繁用到的查询条件中不带goods_id时，将会导致无法定位数据库，从而需要同时向4个库发起查询， 再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。\n\n### 数值Range分表\n\n**概念：**按照时间区间或ID区间来拆分。比如：将goods_id为1-1000的记录分到第一个表，1001-2000的分到第二个表，以此类推。\n\n**如图：**\n\n![image-20220218104054253](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220218104101.png)\t\n\n**优点：**\n\n- 单表大小可控\n- 天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片数据进行迁移\n- 使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题\n\n**缺点：**\n\n- 热点数据成为性能瓶颈（例如按时间进行分片，有些分片存储醉经时间段内的数据，可能会被频繁的读写，而有些分片存储的历史数据，则很少被查询）\n\n### 一致性Hash算法\n\n一致性Hash算法可以很好的 **解决因为Hash取模而产生的分片集群扩容时，需要迁移旧的数据的难题。**\n\n> 参考：[一致性Hash算法详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/98030096)\n\n## 五、分库分表带来的问题\n\n==**在非必要的情况下，能不分就不分**==\n\n因为分库分表会引入新的问题，任何单体系统拆分成多个都会提高系统维护的复杂度，破坏整体性。\n\n### 分布式事务问题\n\n使用分布式事务中间件解决，具体是通过最终一致性还是强一致性分布式事务，看业务需求决定。\n\n>参考：[分库分表导致的分布式事务及其解决方案](https://blog.csdn.net/u014590757/article/details/80100085)\n\n### 跨节点关联查询 Join 问题\n\n切分之前，我们可以通过Join来完成。而切分之后，数据可能分布在不同的节点上，此时 Join 带来的问题就比较麻烦了，考虑到性能，尽量避免使用 Join 查询。\n\n**解决方案：**\n\n- `全局表`\n\n全局表，也可以看做是 `数据字典表`，就是系统中所有模块都可以依赖的一些表，为了避免跨库 Join 查询，可以将这类表\n\n- `字段冗余`\n\n**利用空间换时间，为了性能而避免 Join 查询。**例如：订单表保存 userId 时，也将 userName 冗余保存一份，这样查询订单详情时就不需要再去查询 `买家user表`了。\n\n- `数据组装`\n\n**在系统层面，分两次查询。**第一次查询的结果集中找出关联数据id，然后根据id发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装。\n\n### 跨节点分页、排序、函数问题\n\n跨节点多库进行查询时，会出现Limit分页、Order by 排序等问题。分页需要按照指定字段进行排序，当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片；当排序字段非分片字段时，就变得比较复杂了。需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。\n\n### 全局主键避重问题\n\n如果都用 `主键自增` 是肯定不行的，如果用 `UUID` 又无法做到根据主键排序，所以我们可以考虑通过 `雪花ID` 来作为数据库的主键。\n\n> [什么是雪花ID？ - 分布式ID生成算法](https://zhuanlan.zhihu.com/p/374667160)\n\n### 数据迁移问题\n\n采用 `双写的方式`，修改代码，所有涉及到分库分表的表的增、删、改的代码，都要对新库进行增删改。同时，再有一个数据抽取服务，不断地从老库抽数据，往新库写，边写边按时间比较数据是不是最新的。\n","tags":["笔记","分布式"],"categories":["后端开发"]},{"title":"GitLab 的安装与使用","slug":"Gitlab安装与使用","url":"/2022/01/11/3653ea16.html","content":"\n## Docker 安装 GitLab\n\nDockerHub 上有许多制作完善的镜像，直接搜索 `gitlab` 查看镜像：\n\n**搜索镜像**\n\n```shell\ndocker search gitlab\n```\n\n![image-20220111153600801](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220111153600.png)\n\n> 这里可以选择汉化的 GitLab 社区版的镜像进行下载\n\n**下载镜像**\n\n```shell\ndocker pull twang2218/gitlab-ce-zh\n```\n\n**启动镜像**\n\n```shell\ndocker run -d -p 8443:443 -p 8090:80 -p 8022:22 --restart always --name gitlab -v /usr/local/gitlab/etc:/etc/gitlab -v /usr/local/gitlab/log:/var/log/gitlab -v /usr/local/gitlab/data:/var/opt/gitlab --privileged=true twang2218/gitlab-ce-zh\n\n命令解释：\n-d 后台启动\n-p 映射端口\n--restart 重启配置\n-v 卷挂载\n--privileged=true 设置root权限\n```\n\n## 配置 GitLab\n\n**编辑 `gitlab.rb` 文件**\n\n```shell\n# 直接修改 -v 挂载后的目录，docker会自动同步到容器内部\nvim /usr/local/gitlab/etc/gitlab.rb\n\n# 修改ip和端口 可以使用 / 来定位配置项\n# http地址 -- 无需配置端口\nexternal_url 'http://xx.xx.xx.xx'\n# ssh地址 -- 无需配置端口\ngitlab_rails['gitlab_ssh_host'] = 'xx.xx.xx.xx'(不用添加端口)\n# ssh端口 默认22 启动容器时我们映射为8022\ngitlab_rails['gitlab_shell_ssh_port'] = 8022\n\n# ========== 邮箱配置 ==============\n# 是否启用\ngitlab_rails['smtp_enable'] = true\n# SMTP服务的地址\ngitlab_rails['smtp_address'] = \"smtp.qq.com\"\n# 端口\ngitlab_rails['smtp_port'] = 465\n# 你的QQ邮箱（发送账号）\ngitlab_rails['smtp_user_name'] = \"958317640@qq.com\"\n# 授权码\ngitlab_rails['smtp_password'] = \"********\"\n# 域名\ngitlab_rails['smtp_domain'] = \"smtp.qq.com\"\n# 登录验证\ngitlab_rails['smtp_authentication'] = \"login\"\n\n# 使用了465端口，就需要配置下面三项\ngitlab_rails['smtp_enable_starttls_auto'] = true\ngitlab_rails['smtp_tls'] = true\ngitlab_rails['smtp_openssl_verify_mode'] = 'none'\n\n# 你的QQ邮箱（发送账号）\ngitlab_rails['gitlab_email_from'] = '958317640@qq.com'\n```\n\n**应用配置**\n\n```shell\n# 注意观察日志输出\ngitlab-ctl reconfigure\n```\n\n![image-20220111154833139](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220111154833.png)\n\n**编辑 `gitlab.yml`**\n\n```shell\n# 进入容器\ndocker exec -it gitlab bash\n# 编辑yml配置\nvim /opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml\n# 修改port为启动时映射的端口\nport: 8090\n\n# 重启服务并测试\ngitlab-ctl restart\n```\n\n![image-20220111155220504](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220111155220.png)\n","tags":["Docker","容器","Git"],"categories":["Linux"]},{"title":"Dom4j 如何新增 standalone？","slug":"Dom4j如何新增standalone","url":"/2021/12/16/2e39132d.html","content":"\n## 前言\n\n工作中调用一个第三方接口，需要上传 xml 文件。Java 操作 xml 文件的 api 很多，有 Dom、SAX 、JDom、Dom4j。我一般常用的是 Dom4j，但是对接此接口上传的 xml 文件需要添加 `standalone=\"no\"` 属性。查阅相关资料，发现 `Dom4j -1.6.1` 版本并没有提供相应的方法设置。\n\n## 解决方案\n\n重写 `XMLWriter` 类中的 `writeDeclaration` 方法，具体代码如下：\n\n```java\nimport java.io.FileOutputStream;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.io.UnsupportedEncodingException;\n\nimport org.dom4j.io.OutputFormat;\nimport org.dom4j.io.XMLWriter;\n\npublic class StandaloneWriter extends XMLWriter {\n\n    public StandaloneWriter(FileOutputStream fileOutputStream, OutputFormat format)\n    throws UnsupportedEncodingException {\n        super(fileOutputStream, format);\n    }\n\n    public StandaloneWriter(FileWriter fileWriter, OutputFormat format)\n    throws UnsupportedEncodingException {\n        super(fileWriter, format);\n    }\n\n    @Override\n    protected void writeDeclaration() throws IOException {\n        OutputFormat format = getOutputFormat();\n\n        String encoding = format.getEncoding();\n\n        if (!format.isSuppressDeclaration()) {\n            if (encoding.equals(\"UTF8\")) {\n                writer.write(\"<?xml version=\\\"1.0\\\"\");\n\n                if (!format.isOmitEncoding()) {\n                    writer.write(\" encoding=\\\"UTF-8\\\"\");\n                }\n\n                writer.write(\" standalone=\\\"yes\\\"\");\n                writer.write(\"?>\");\n            } else {\n                writer.write(\"<?xml version=\\\"1.0\\\"\");\n\n                if (!format.isOmitEncoding()) {\n                    writer.write(\" encoding=\\\"\" + encoding + \"\\\"\");\n                }\n\n                writer.write(\" standalone=\\\"no\\\"\");\n                writer.write(\"?>\");\n            }\n\n            if (format.isNewLineAfterDeclaration()) {\n                println();\n            }\n        }\n    }\n}\n```\n\n在使用过程中，用 `StandaloneWriter` 替换掉 `XMLWriter` 即可。\n","tags":["技巧","笔记"],"categories":["后端开发"]},{"title":"Docker 容器-基础篇","slug":"Docker容器-基础篇","url":"/2021/12/12/e33c148b.html","content":"\n## Docker 概述\n\n### Docker 为什么会出现？\n\n> 环境切换/配置麻烦\n\n一般一个产品的生命周期中，可能会存在多个环境：\n\n- 开发环境\n- 测试环境\n- 生产环境\n\n其实我们在编程的过程中，很大一部分时间都花在 `环境` 上：\n\n- 比如重装系统之后，想要运行 `Jar/War` 包，就必须在系统里装上 `JDK` . `Tomcat`. `MySQL` 等环境 ，并配置好相应的环境变量\n- 以前生产环境和测试环境完全是两套不同的环境，可能会出现：==代码在测试环境跑没问题，到生产环境就出各种错！==\n- 在学习 `分布式/集群` 项目时，需要搭建多个环境，以前使用 `Vmware` 搭建费时费力，且对电脑的配置要求较高\n\n> 应用之间需要隔离\n\n- 假设，我只有一台服务器，我写了两个应用（网站），都部署在一台服务器里，倘若其中一个应用出现了问题，导致 CPU 跑满到 100%，那么另一个应用也会受影响！\n- 同一个服务器下端口冲突. JRE 版本冲突...\n\nDocker 的出现就为以上问题带来了解决方案：\n\nDocerk 的思想就来自于集装箱！\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211212012101.png)\n\n### Docker 是什么？\n\n#### Docker 基本介绍\n\n`Docker` 是一个开源的应用容器引擎，基于 `Go 语言` 并遵从 `Apache2.0` 协议开源。\n\n`Docker` 可以让开发者打包他们的应用以及依赖包到一个轻量级. 可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。\n\n容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app），更重要的是容器性能开销极低。\n\n`Docker` 从 `17.03` 版本之后分为 `CE（Community Edition: 社区版）` 和 `EE（Enterprise Edition: 企业版）`，我们用社区版就可以了。\n\n官方文档：https://docs.docker.com/\n\n#### 应用场景\n\n- Web 应用的自动化打包和发布。\n- 自动化测试和持续集成. 发布。\n- 在服务型环境中部署和调整数据库或其他的后台应用。\n- 从头编译或者扩展现有的 `OpenShift` 或 `Cloud Foundry` 平台来搭建自己的 `PaaS` 环境。\n\n#### Docker 的优势\n\n- 更快速地进行应用的交付和部署\n- 更便携的升级和扩容\n- 更简单的系统运维\n- 更高效的计算机资源利用\n\n> 总结：解决了==运行环境和配置问题==的==软件容器==，方便做持续集成并有助于整体发布的容器虚拟化技术。\n\n### 虚拟化技术和容器化技术的区别\n\n- 虚拟化技术：\n  1. 资源占用多\n  1. 冗余步骤多\n  1. 启动很慢\n\n* 容器化技术：容器化技术不是模拟的一个完整的操作系统\n\n比较 Docker 和虚拟机的不同：\n\n1. 传统虚拟机，虚拟出硬件，运行一个完整的操作系统，然后在这个系统上安装和运行软件。\n2. Docker 容器内的应用直接运行在宿主机的内容，容器是没有自己的内核的，也没有虚拟硬件。\n3. 每个容器都是相互隔离的，每个容器都有属于自己的文件系统，互不影响。\n\n### Docker 的基本组成\n\nDocker 的基本组成图如下：\n\n![image-20211212134734666](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211212134734.png)\n\n- **镜像（image）**\n\n  ```\n  Docker 镜像（Image）就是一个只读的模板。镜像可以用来创建 Docker 容器，一个镜像可以创建很多容器。就好似 Java 中的类和对象，类就是镜像，容器就是对象！\n  ```\n\n- **容器（container）**\n\n  ```\n  Docker 利用容器（Container）独立运行的一个或一组应用。容器就用镜像创建的运行实例。\n  \n  它可以被启动. 开始. 停止. 删除。每个容器都是相互隔离的，保证安全的平台。\n  \n  可以把容器看作是一个简易版的 Linux 环境（包括root用户权限. 进程空间. 用户空间和网络空间）和运行在其中的应用程序。\n  \n  容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那层是可读可写的。\n  ```\n\n* **仓库（repository）**\n\n  ```\n  仓库（Repository）是集中存放镜像文件的场所。\n  \n  仓库（Repository）和仓库注册服务器（Registry）是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。\n  \n  仓库分为公开仓库（Public）和私有仓库（Private）两种形式。\n  \n  最大的公开仓库是 Docker Hub（https://hub.docker.com/），存放了数量庞大的镜像供用户下载。\n  国内最大的公开仓库包括阿里云. 网易云等。\n  ```\n\n## Docker 安装\n\n### Docker 的安装与卸载\n\n> 环境准备\n\n1. 需要会一点点的 Linux 的基础\n2. CentOS 7\n3. 使用 Xshell 连接远程服务器进行操作！\n\n> 环境查看\n\n```shell\n# 系统内核是 3.10 以上的\n[root@ouwen666 ~]# uname -r\n3.10.0-1062.18.1.el7.x86_64\n# 系统版本 centOS7\n[root@ouwen666 ~]# cat /etc/os-release\nNAME=\"CentOS Linux\"\nVERSION=\"7 (Core)\"\nID=\"centos\"\nID_LIKE=\"rhel fedora\"\nVERSION_ID=\"7\"\nPRETTY_NAME=\"CentOS Linux 7 (Core)\"\nANSI_COLOR=\"0;31\"\nCPE_NAME=\"cpe:/o:centos:centos:7\"\nHOME_URL=\"https://www.centos.org/\"\nBUG_REPORT_URL=\"https://bugs.centos.org/\"\n\nCENTOS_MANTISBT_PROJECT=\"CentOS-7\"\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\nREDHAT_SUPPORT_PRODUCT=\"centos\"\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\n```\n\n> 安装\n\n帮助文档：[Docker 官方帮助文档](https://docs.docker.com/engine/install/centos/)\n\n```shell\n# 1. 卸载旧的版本\nyum list installed | grep docker\nsudo yum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-engine\n\n# 2. 安装yum-utils包（提供 yum-config-manager 程序）\nsudo yum install -y yum-utils\n\n# 3. 设置镜像的仓库\nsudo yum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo # 默认是国外的，十分慢！\n# 建议使用阿里云的镜像地址\nsudo yum-config-manager \\\n    --add-repo \\\n    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n# 更新yum软件包索引\nsudo yum makecache fast\n\n# 4. 安装docker相关的 docker-ce docker-compose （默认为最新版）\nsudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n# 安装指定版本\nsudo yum install docker-ce-<VERSION_STRING> docker-ce-cli-<VERSION_STRING> containerd.io docker-compose-plugin\nsudo yum install docker-ce-20.10.13 docker-ce-cli-20.10.13 containerd.io docker-compose-plugin\n# 5. 启动docker\nsystemctl start docker\n\n# 6. 使用docker version查看是否安装成功\n```\n\n![image-20211212144007872](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211212144008.png)\n\n```shell\n# 7. 启动docker-hello-world\ndocker run hello-world\n```\n\n![image-20211212144259750](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211212144259.png)\n\n```shell\n# 8. 查看下载的这个hello-world镜像\n[root@ouwen666 /]# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED        SIZE\nhello-world   latest    feb5d9fea6a5   2 months ago   13.3kB\n```\n\n> 卸载 Docker\n\n```shell\n# 1. 卸载依赖\nyum remove docker-ce docker-ce-cli containerd.io\n# 2. 删除资源 docker的默认工作路径\nrm -rf /var/lib/docker\nrm -rf /var/lib/containerd\n```\n\n### 阿里云镜像加速\n\n- 登录阿里云，找到容器镜像服务\n\n  ![image-20211218143146762](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218143348.png)\n\n- 找到镜像加速地址\n\n  ![image-20211218143621304](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218143621.png)\n\n- 配置使用\n\n  ```shell\n  sudo mkdir -p /etc/docker\n  \n  sudo tee /etc/docker/daemon.json <<-'EOF'\n  {\n    \"registry-mirrors\": [\"https://alq7pwwu.mirror.aliyuncs.com\"]\n  }\n  EOF\n  \n  sudo systemctl daemon-reload\n  \n  sudo systemctl restart docker\n  ```\n\n### 回顾 HelloWorld 流程\n\n![image-20211218144212215](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218144212.png)\n\n### 底层原理\n\n#### Docker 是怎么工作的？\n\nDocker 是一个 Client - Server 结构的系统，Docker 的守护进程运行在主机上。通过 Socket 从客户端访问！\n\nDockerServer 接收到 Docker - Client 的指令，就会执行这个命令！\n\n![image-20211218144701740](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218144701.png)\n\n#### Docker 为什么比 VM 快？\n\n1. Docker 有着比虚拟机更少的抽象层\n\n2. Docker 利用的是宿主机的内核，VM 需要的是 Guest OS（操作系统）\n\n   ![image-20211218144918851](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218144918.png)\n\n   新建一个容器的时候，Docker 不需要像虚拟机一样重新加载一个操作系统内核，避免不必要的消耗。\n\n## Docker 的常用命令\n\n### 帮助命令\n\n```shell\n# 显示docker的版本信息\ndocker version\n# 显示docker的系统信息，包括镜像和容器\ndocker info\n# 帮助命令\ndocker 命令 --help\n```\n\n帮助文档地址：[Docker 官方帮助文档](https://docs.docker.com/engine/reference/commandline/cli/)\n\n### 镜像命令\n\n#### 列出本机所有镜像\n\n```shell\n[root@ouwen666 ~]# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED        SIZE\nhello-world   latest    feb5d9fea6a5   2 months ago   13.3kB\n\n# 解释\nREPOSITORY  镜像的仓库源\nTAG         镜像的标签\nIMAGE ID    镜像的ID\nCREATED     镜像的创建时间\nSIZE        镜像的大小\n\n# 可选项\n  -a， --all             # 列出所有镜像\n  -q， --quiet           # 只显示镜像的ID\n```\n\n#### 搜索镜像\n\n```shell\n[root@ouwen666 ~]# docker search mysql\nNAME                              DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nmysql                             MySQL is a widely used， open-source relation…   11833     [OK]\nmariadb                           MariaDB Server is a high performing open sou…   4505      [OK]\n\n# 可选项，通过收藏来过滤\n--filter=STARS=3000\n[root@ouwen666 ~]# docker search mysql --filter=STARS=3000\nNAME      DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nmysql     MySQL is a widely used， open-source relation…   11833     [OK]\nmariadb   MariaDB Server is a high performing open sou…   4505      [OK]\n```\n\n#### 下载镜像\n\n```shell\n# 下载镜像 docker pull 镜像名[:tag]\n[root@ouwen666 ~]# docker pull mysql\nUsing default tag: latest   # 如果写 tag，默认就是 latest\nlatest: Pulling from library/mysql\nffbb094f4f9e: Pull complete # 分层下载，docker image 的核心 联合文件系统\ndf186527fc46: Pull complete\nfa362a6aa7bd: Pull complete\n5af7cb1a200e: Pull complete\n949da226cc6d: Pull complete\nbce007079ee9: Pull complete\neab9f076e5a3: Pull complete\n8a57a7529e8d: Pull complete\nb1ccc6ed6fc7: Pull complete\nb4af75e64169: Pull complete\n3aed6a9cd681: Pull complete\n23390142f76f: Pull complete\nDigest: sha256:ff9a288d1ecf4397967989b5d1ec269f7d9042a46fc8bc2c3ae35458c1a26727  # 签名\nStatus: Downloaded newer image for mysql:latest\ndocker.io/library/mysql:latest  # 真实地址\n\n# 等价与它\ndocker pull mysql\ndocker pull docker.io/library/mysql:latest\n\n# 指定版本下载\n[root@ouwen666 ~]# docker pull mysql:5.7\n5.7: Pulling from library/mysql\nffbb094f4f9e: Already exists\ndf186527fc46: Already exists\nfa362a6aa7bd: Already exists\n5af7cb1a200e: Already exists\n949da226cc6d: Already exists\nbce007079ee9: Already exists\neab9f076e5a3: Already exists\nc7b24c3f27af: Pull complete\n6fc26ff6705a: Pull complete\nbec5cdb5e7f7: Pull complete\n6c1cb25f7525: Pull complete\nDigest: sha256:d1cc87a3bd5dc07defc837bc9084f748a130606ff41923f46dec1986e0dc828d\nStatus: Downloaded newer image for mysql:5.7\ndocker.io/library/mysql:5.7\n```\n\n![image-20211218170934412](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218170934.png)\n\n#### 删除镜像\n\n```shell\n[root@ouwen666 ~]# docker rmi -f 镜像ID  # 删除指定的镜像\n[root@ouwen666 ~]# docker rmi -f 镜像ID 镜像ID 镜像ID 镜像ID  # 删除多个镜像\n[root@ouwen666 ~]# docker rmi -f $(docker images -aq)   # 删除全部的镜像\n```\n\n### 容器命令\n\n有了镜像才可以创建容器：linux，下载一个 centos 镜像来学习\n\n```shell\ndocker pull centos\n```\n\n#### 新建容器并启动\n\n```shell\ndocker run [可选参数] image\n\n# 参数说明\n--name=\"Name\"  # 容器名字 为容器指定一个名称\n-d             # 后台方式运行\n-it            # 使用交互方式运行，并分配一个伪终端，等待交互\n-p             # 指定容器的端口  -p 8080:8080\n  -p ip:主机端口:容器端口 (常用)\n  -p 主机端口:容器端口 (常用)\n  -p 容器端口\n-P             # 随机指定端口\n\n# 测试一下 启动并进入容器\n[root@ouwen666 ~]# docker run -it centos /bin/bash\n# 查看容器内的centos，官方镜像是一个基础版本，很多命令都是不完善的！\n[root@0226b99be9ff /]# ls\nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n# 从容器中退出主机\n[root@0226b99be9ff /]# exit\nexit\n```\n\n#### 列出所有运行的容器\n\n```shell\n# docker ps 命令\n-a    # 列出当前正在运行的容器+带出历史运行过的容器\n-l    # 显示最近创建的容器\n-n=?  # 显示最近创建n个容器\n-q    # 只显示容器的编号\n[root@ouwen666 ~]# docker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n[root@ouwen666 ~]# docker ps -a\nCONTAINER ID   IMAGE          COMMAND       CREATED         STATUS                             NAMES\n0226b99be9ff   centos         \"/bin/bash\"   3 minutes ago   Exited (0) About a minute ago\n55a3ece5f682   feb5d9fea6a5   \"/hello\"      6 days ago      Exited (0) 6 days ago\n```\n\n#### 退出容器\n\n```shell\nexit    # 直接停止容器并退出\nCtrl + P + Q  # 容器不停止并退出\n```\n\n#### 删除容器\n\n```shell\ndocker rm 容器ID  # 删除指定的容器，不能删除正在运行的容器，如果要强制删除 rm -f\ndocker rm -f $(docker ps -aq)  # 删除所有的容器\ndocker ps -a -q|xargs docker rm  #删除所有的容器\n```\n\n#### 启动和停止容器\n\n```shell\ndocker start 容器ID       # 启动容器\ndocker restart 容器ID     # 重启容器\ndocker stop 容器ID        # 停止容器\ndocker kill 容器ID        # 强制停止当前容器\n```\n\n### 常用其他命令【重要】\n\n#### 后台启动容器\n\n```shell\n# 命令 docker run -d 镜像名！\n[root@ouwen666 /]# docker run -d centos\n\n# 问题 docker ps，发现 centos 停止了\n\n# 常见的坑：docker容器使用后台运行，就必须要有要给前台进程，docker发现没有应用，就会自动停止\n```\n\n#### 查看日志\n\n```shell\ndocker logs -f -t --tail 10 容器ID\n\n# 写一段shell脚本，不停的打印输出\n[root@ouwen666 /]# docker run -d centos /bin/sh -c \"while true;do echo helloworld;sleep 1;done\"\n5fff272a8948f573264a09ac17d437b6d7424a5b03604b4191666f252993a6f3\n\n[root@ouwen666 /]# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS\n5fff272a8948   centos    \"/bin/sh -c 'while t…\"   5 seconds ago   Up 5 seconds\n\n# 显示日志\n-tf             # 显示所有的日志\n--tail number   # 显示指定行数的日志\n[root@ouwen666 /]# docker logs -tf --tail 10 5fff272a8948\n\n```\n\n#### 查看容器中的进程信息\n\n```shell\n# 命令 docker top 容器ID\n[root@ouwen666 /]# docker top 5fff272a8948\nUID                 PID                 PPID                C                   STIME\nroot                326                 32457               0                   17:46\nroot                32457               32438               0                   17:42\n```\n\n#### 查看镜像/容器的详细信息\n\n```shell\n# 命令 docker inspect 镜像/容器ID\n[root@ouwen666 /]# docker inspect 5fff272a8948\n```\n\n#### 进入当前正在运行的容器\n\n```shell\n# 通常容器都是使用后台方式运行的，需要进入容器，修改一些配置\n\n# 命令\ndocker exec -it 容器ID bashShell\n# 测试\n[root@ouwen666 /]# docker exec -it 5fff272a8948 /bin/bash\n[root@5fff272a8948 /]#\n\n# 方式二\ndocker attach 容器ID\n# 测试\n[root@ouwen666 /]# docker attach 5fff272a8948\n正在执行的代码...\n\n# docker exec     # 进入容器后，开启一个新的终端，exit后不会停止容器（常用）\n# docker attach   # 进入容器正在执行的终端，不会启动新的进程，exit后会停止容器！\n```\n\n#### 从容器内拷贝文件到主机上\n\n```shell\ndocker cp 容器ID:容器内路径 目的主机路径\n# 测试\n[root@ouwen666 home]# docker ps\nCONTAINER ID   IMAGE     COMMAND       CREATED              STATUS\n7938b1a7dece   centos    \"/bin/bash\"   About a minute ago   Up About a minute\n# 进入容器内部\n[root@ouwen666 home]# docker attach 7938b1a7dece\n[root@7938b1a7dece /]# cd /home/\n# 创建一个文件\n[root@7938b1a7dece home]# touch helloworld.java\n[root@7938b1a7dece home]# ls\nhelloworld.java\n# 退出容器\n[root@7938b1a7dece home]# exit\nexit\n# 将容器中的文件拷贝到主机中\n[root@ouwen666 home]# docker cp 7938b1a7dece:/home/helloworld.java /home/\n[root@ouwen666 home]# ls\ngit  helloworld.java\n```\n\n#### 导入/导出容器\n\n- export 导出容器的内容留作为一个 tar 归档文件[对应 import 命令]\n\n- import 从 tar 包中的内容创建一个新的文件系统再导入为镜像[对应 export]\n\n```\n# 导出\n[root@88233 ~]# docker export 71720f3a8f51 > myubuntu.tar\n\n# 导入\n[root@88233 ~]# cat myubuntu.tar | docker import - vansys/ubuntu:1.0\n```\n\n### 小结\n\n![image-20211218192225807](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218192225.png)\n\n```\nattach       # 当前 shell 下 attach 连接指定运行镜像\nbuild        # 通过 Dockerfile 定制镜像\ncommit       # 提交当前容器为新的镜像\ncp           #从容器中拷贝指定文件或者目录到宿主机中\ncreate       # 创建一个新的容器，同 run，但不启动容器\ndiff         # 查看 docker 容器变化\nevents       # 从 docker 服务获取容器实时事件\nexec         # 在已存在的容器上运行命令\nexport       # 导出容器的内容流作为一个 tar 归档文件[对应 import ]\nhistory      # 展示一个镜像形成历史\nimages       # 列出系统当前镜像\nimport       # 从tar包中的内容创建一个新的文件系统映像[对应export]\ninfo         # 显示系统相关信息\ninspect      # 查看容器详细信息\nkill         # kill 指定 docker 容器\nload         # 从一个 tar 包中加载一个镜像[对应 save]\nlogin        # 注册或者登陆一个 docker 源服务器\nlogout       # 从当前 Docker registry 退出\nlogs         # 输出当前容器日志信息\nport         # 查看映射端口对应的容器内部源端口\npause        # 暂停容器\nps           # 列出容器列表\npull         # 从docker镜像源服务器拉取指定镜像或者库镜像\npush         # 推送指定镜像或者库镜像至docker源服务器\nrestart      # 重启运行的容器\nrm           # 移除一个或者多个容器\nrmi          # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除]\nrun          # 创建一个新的容器并运行一个命令\nsave         # 保存一个镜像为一个 tar 包[对应 load]\nsearch       # 在 docker hub 中搜索镜像\nstart        # 启动容器\nstop         # 停止容器\ntag          # 给源中镜像打标签\ntop          # 查看容器中运行的进程信息\nunpause      # 取消暂停容器\nversion      # 查看 docker 版本号\nwait         # 截取容器停止时的退出状态值\n```\n\n### 练习\n\n#### Docker 安装 Nginx\n\n```shell\n# 1. 搜索镜像 或者去 dockerHub 上搜索 https://hub.docker.com/search?q=nginx&type=image\n[root@ouwen666 home]# docker search nginx\n# 2. 下载镜像\n[root@ouwen666 home]# docker pull nginx\n# 3. 运行测试\n[root@ouwen666 home]# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\nnginx        latest    f652ca386ed1   2 weeks ago    141MB\ncentos       latest    5d0da3dc9764   3 months ago   231MB\n# -d 后台运行\n# --name 给容器命名\n# -p 宿主机端口:容器内部端口 映射端口\n[root@ouwen666 home]# docker run -d --name nginx01 -p 3344:80 nginx\n639cb4f9a9e60d96d698f0c1200f216176a3735b40b3276b25af5e8fb502e337\n[root@ouwen666 home]# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS         PORTS                  NAMES\n639cb4f9a9e6   nginx     \"/docker-entrypoint.…\"   10 seconds ago   Up 9 seconds   0.0.0.0:3344->80/tcp   nginx01\n[root@ouwen666 home]# curl localhost:3344\n\n# 进入容器\n[root@ouwen666 home]# docker exec -it nginx01 /bin/bash\nroot@639cb4f9a9e6:/# whereis nginx\nnginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginx\nroot@639cb4f9a9e6:/# cd /etc/nginx/\nroot@639cb4f9a9e6:/etc/nginx# ls\nconf.d\tfastcgi_params\tmime.types  modules  nginx.conf  scgi_params  uwsgi_params\nroot@639cb4f9a9e6:/etc/nginx#\n```\n\n> 端口暴露：\n\n![image-20211218194409553](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218194409.png)\n\n#### Docker 安装 Tomcat\n\n```shell\n# 官方的使用\ndocker run -it --rm tomcat:9.0\n# 这种方式停止了容器之后，会直接删除容器\n\n# 下载再启动\ndocker pull tomcat:9.0\n\n# 启动运行\ndocker run -d -p 3355:8080 --name tomcat01 tomcat:9.0\n\n# 测试访问没有问题\n\n# 进入容器内部\n[root@ouwen666 home]# docker exec -it tomcat01 /bin/bash\nroot@b59126dcef8d:/usr/local/tomcat# ls\nBUILDING.txt\t LICENSE  README.md\t RUNNING.txt  conf  logs\t    temp     webapps.dist\nCONTRIBUTING.md  NOTICE   RELEASE-NOTES  bin\t      lib   native-jni-lib  webapps  work\n```\n\n#### Docker 安装 ElasticSearch + Kibana\n\n```shell\n# 官方的使用\ndocker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.6.2\n\n# es 是十分耗内存的 1.xG 服务器 2核2G\n\n# 查看 docker stats\n[root@ouwen666 home]# docker stats\nCONTAINER ID   NAME            CPU %     MEM USAGE / LIMIT     MEM %     NET I/O   BLOCK I/O\nb496914b7726   elasticsearch   0.00%     1.237GiB / 1.694GiB   73.00%    0B / 0B   197MB / 729kB\n\n# 测试一下es是否安装成功\n[root@ouwen666 home]# curl localhost:9200\n{\n  \"name\" : \"b496914b7726\"，\n  \"cluster_name\" : \"docker-cluster\"，\n  \"cluster_uuid\" : \"v5CISdg4Sw-d8-Jui-XXTw\"，\n  \"version\" : {\n    \"number\" : \"7.6.2\"，\n    \"build_flavor\" : \"default\"，\n    \"build_type\" : \"docker\"，\n    \"build_hash\" : \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\"，\n    \"build_date\" : \"2020-03-26T06:34:37.794943Z\"，\n    \"build_snapshot\" : false，\n    \"lucene_version\" : \"8.4.0\"，\n    \"minimum_wire_compatibility_version\" : \"6.8.0\"，\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  }，\n  \"tagline\" : \"You Know， for Search\"\n}\n\n# 增加对内存的限制 修改配置文件 -e 环境配置的修改\ndocker run -d --name elasticsearch01 -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms64m -Xmx512m\" elasticsearch:7.6.2\n\n# 查看 docker stats 内存明显变小\n[root@ouwen666 home]# docker stats\nCONTAINER ID   NAME              CPU %     MEM USAGE / LIMIT     MEM %    NET I/O      BLOCK I/O\nc0d59f8ca889   elasticsearch01   0.00%     375.2MiB / 1.694GiB   21.63%   524B / 942B  107MB/733kB\n# 测试是否启动成功\n[root@ouwen666 home]# curl localhost:9200\n{\n  \"name\" : \"c0d59f8ca889\"，\n  \"cluster_name\" : \"docker-cluster\"，\n  \"cluster_uuid\" : \"ECE4OHoqQ5Sk-fhT-ALuPg\"，\n  \"version\" : {\n    \"number\" : \"7.6.2\"，\n    \"build_flavor\" : \"default\"，\n    \"build_type\" : \"docker\"，\n    \"build_hash\" : \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\"，\n    \"build_date\" : \"2020-03-26T06:34:37.794943Z\"，\n    \"build_snapshot\" : false，\n    \"lucene_version\" : \"8.4.0\"，\n    \"minimum_wire_compatibility_version\" : \"6.8.0\"，\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  }，\n  \"tagline\" : \"You Know， for Search\"\n}\n```\n\n如何使用 Kibana 连接 ES？\n\n![image-20211218201949070](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218201949.png)\n\n## Docker 镜像详解\n\n### 镜像是什么\n\n镜像是一种轻量级、可执行的独立软件包，它包含运行某个软件所需的所有内容，我们把应用程序和配置依赖打包好形成一个可交付的运行环境(包括代码、运行时需要的库、环境变量和配置文件等)，这个打包好的运行环境就是 image 镜像文件。\n\n只有通过这个镜像文件才能生成 Docker 容器实例(类似 Java 中 new 出来一个对象)。\n\n如何得到镜像：\n\n- 从远程仓库下载\n- 自己制作一个镜像 DockerFile\n\n### Docker 镜像加载原理\n\n> UnionFS(联合文件系统)\n\nUnion 文件系统(UnionFS) 是一种分层. 轻量级并且高性能的文件系统，他支持对文件系统的修改作为一次提交来层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下（unite several directories into a single virtual filesystem）。Union 文件系统是 Docker 镜像的基础。==镜像可以通过分层来进行继承==，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。\n\n特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层文件和目录。\n\n> Docker 镜像加载原理\n\ndocker 的镜像实际上由一层一层的文件系统组成，这种层级的文件系统 UnionFS。\n\nbootfs(boot file system) 主要包含 bootloader 和 kernel，bootloader 主要是引导加载 kernel，Linux 刚启动时会加载 bootfs 文件系统，==在 Docker 镜像的最底层是 bootfs==。这一层与我们典型的 Linux/Unix 系统是一样的，包含 boot 加载器和内核。当 boot 加载完成之后整个内核就存在内存中了，此时内存的使用权已由 bootfs 转交给内核，此时系统也会卸载 bootfs。\n\nroorfs （root file system），在 bootfs 之上。包含的就是典型 Linux 系统中的 /dev ，/proc，/bin ，/etx 等标准的目录和文件。rootfs 就是各种不同的操作系统发行版。比如 Ubuntu，Centos 等等。\n\n![image-20211218204700594](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218204700.png)\n\n平时安装进虚拟机的 CentOS 镜像都是好几个 G，为什么 Docker 这里才 200M？\n\n![image-20211218204834885](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218204834.png)\n\n对于一个精简的 OS，rootfs 可以很小，只需要包括最基本的命令. 工具和程序库就可以了，因为底层直接用 Host（宿主机）的 kernel，自己只需要提供 rootfs 就行了，由此可见对于不同的 Linux 发行版，bootfs 基本是一致的，rootfs 会有差别，因此不同的发行版可以公用 bootfs。\n\n### 分层的镜像\n\n下载一个镜像，观察下载的日志，可以发现是一层一层往下下载的！\n\n```shell\n[root@ouwen666 home]# docker pull redis\nUsing default tag: latest\nlatest: Pulling from library/redis\ne5ae68f74026: Already exists\n37c4354629da: Pull complete\nb065b1b1fa0f: Pull complete\n6954d19bb2e5: Pull complete\n6333f8baaf7c: Pull complete\nf9772c8a44e7: Pull complete\nDigest: sha256:2f502d27c3e9b54295f1c591b3970340d02f8a5824402c8179dcd20d4076b796\nStatus: Downloaded newer image for redis:latest\ndocker.io/library/redis:latest\n```\n\n> 为什么 Docker 镜像要采用这种分层的结构？\n\n==最大的好处，就是是资源共享了！==\n\n如有多个镜像都从相同的基本镜像构建而来，那么宿主机只需在磁盘上保留一份基本镜像，同时内存中也只需要加载一份基本镜像 ，这样就可以为所有的容器服务了，且镜像的每一层都可以被共享。\n\n查看镜像分层的方式可以通过`docker image inspect` 命令！\n\n```shell\n[root@ouwen666 home]# docker image inspect redis\n[\n...\n        \"RootFS\": {\n            \"Type\": \"layers\"，\n            \"Layers\": [\n                \"sha256:9321ff862abbe8e1532076e5fdc932371eff562334ac86984a836d77dfb717f5\"，\n                \"sha256:aa2858ea5edc9c0981901a1b63b49a8f4a6e7099b4304b49e680ffdcc6b71b3e\"，\n                \"sha256:93079bf13a6d5fe7c4bd9f00cb96183f9d1db9968c4bd15b395df2f3867bf8e5\"，\n                \"sha256:9ca504b88e256aa6f6c04ec65aeeed6b926661ea30a0b97f829fbe230155241a\"，\n                \"sha256:9468a3f0498bd5cc298ce25ea6ce9c6adf14aa2ce152856b5f389510a9bb9e01\"，\n                \"sha256:b7851a62867d82784052d7662862adc0b47b2bddcddc89ae78307f75ba1b29ae\"\n            ]\n        }\n...\n]\n```\n\n> 理解\n\n所有的 Docker 镜像都起始于一个基础镜像层 ，当进行修改或增加新的内容时，就会在当前镜像层之上，创建新的镜像层。\n\n举一个简单的例子，假如基于 Ubuntu Linux 16.04 创建一个新的镜像 ，这就是新镜像的第一层。如果在该镜像中添加 Python 包，就会在基础镜像层之上创建第二个镜像层;如果继续添加一个安全补丁，就会创建第三个镜像层。\n\n该镜像当前已经包含 3 个镜像层，如下图所示(这只是一个用于演示的很简单的例子 )。\n\n![image-20211218210258974](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218210259.png)\n\n在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。\n\n下图中举 了一个简单的例子，每个镜像层包含 3 个文件，而镜像包含了来自两个镜像层的 6 个文件。\n\n![image-20211218210445762](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218210445.png)\n\n上图中的镜像层跟之前图中的略有区别，主要目的是便于展示文件。\n\n下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有 6 个文件，这是因为最上层中的文件 7 是文件 5 的一一个更新版本。\n\n![image-20211218210534319](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218210534.png)\n\n这种情况下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中。\n\nDocker 通过存储引擎(新版本采用快照机制)的方式来实现镜像层堆栈，并保证多镜像层对外展示为统一的文件系统。\n\nLinux 上可用的存储引擎有 AUFS. Overlay2. Device Mapper. Btrfs 以及 ZFS。顾名思义，每种存储引擎都基于 Linux 中对应的文件系统或者块设备技术，并且每种存储引擎都有其独有的性能特点。\n\nDocker 在 Windows 上仅支持 windowsfilter -种存储引擎，该引擎基于 NTFS 文件系统之上实现了分层和 CoW[1]。\n\n下图展示了与系统显示相同的三层镜像。所有镜像层堆叠并合并，对外提供统一的视图。\n\n![image-20211218210605289](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211218210605.png)\n\n> 特点\n\nDocker 镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部！这一层就是我们通常说的容器层，容器之下都叫镜像层！\n\n### 提交镜像\n\n```shell\ndocker commit 提交容器成为一个新的镜像副本\n\n# 命令和git原理类似\ndocker commit -m=\"提交的描述信息\" -a=\"作者\" 容器ID 目标镜像名:[标签名]\n```\n\n**实战测试**\n\n```shell\n# 启动一个默认的tomcat\n\n# 发现默认的tomcat的webapps目录下是没用部署应用的。原因是官方的镜像都是默认webapps下是没有应用的\n\n# 将webapps.dist目录下的应用拷贝到webapps下\n\n# 将更改过的镜像提交到仓库，以后就能使用修改过的镜像进行启动！\n[root@ouwen666 ~]# docker commit -a=\"Irving\" -m=\"add webapps app\" 9bffc8b128c7 mytomcat:1.0\nsha256:ef1ba8ee4bba1a39202b89a9bfecc4cb4dfbf20263b6e1b913a4cecf80ff8381\n[root@ouwen666 ~]# docker images\nREPOSITORY            TAG       IMAGE ID       CREATED          SIZE\nmytomcat              1.0       ef1ba8ee4bba   10 seconds ago   685MB\ntomcat                9.0       3f3cadde9a68   10 days ago      680MB\nredis                 latest    aea9b698d7d1   2 weeks ago      113MB\nnginx                 latest    f652ca386ed1   2 weeks ago      141MB\ncentos                latest    5d0da3dc9764   3 months ago     231MB\nportainer/portainer   latest    580c0e4e98b0   9 months ago     79.1MB\nelasticsearch         7.6.2     f29a1ee41030   21 months ago    791MB\n```\n\n### 提交镜像到阿里云\n\n本地镜像发布到阿里云流程\n\n![image-20220604164136425](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220612132649.png)\n\n1. 登录阿里云控制台，选择容器镜像服务\n\n![image-20220604211107790](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220604211156.png)\n\n2. 选择个人实例\n\n![image-20220604211320410](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220604211320.png)\n\n3. 创建命名空间\n\n![image-20220604211650899](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220604211651.png)\n\n4. 创建镜像仓库\n\n![image-20220604212038508](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220604212038.png)\n\n5. 继续\n\n![image-20220604212532015](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220604212554.png)\n\n6. 继续\n\n![image-20220604212648063](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220604212648.png)\n\n7. 进入管理界面获取脚本\n\n![image-20220604212843596](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220604212843.png)\n\n8. 将镜像推送到阿里云\n\n![image-20220604213052191](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220604213052.png)\n\n### 提交镜像到私有库\n\nDocker Registry 是官方提供的工具，可以用于构建私有镜像仓库。\n\n1. **下载镜像 Docker Registry**\n\n```bash\n[root@88231 ~]# docker pull registry\nUsing default tag: latest\nlatest: Pulling from library/registry\n79e9f2f55bf5: Pull complete\n0d96da54f60b: Pull complete\n5b27040df4a2: Pull complete\ne2ead8259a04: Pull complete\n3790aef225b9: Pull complete\nDigest: sha256:169211e20e2f2d5d115674681eb79d21a217b296b43374b8e39f97fcf866b375\nStatus: Downloaded newer image for registry:latest\n```\n\n2. **运行私有库 Registry，相当于自己搭建一个 Docker Hub**\n\n默认情况，仓库被创建在容器内的 /var/lib/registry 目录下，建议自行用容器卷映射，方便于宿主机联调\n\n```bash\n[root@88231 hd]# docker run -d -p 5000:5000  -v /hd/docker-registry/:/var/lib/registry --privileged=true registry\n96579e94a32238269d25239394f62a7d38492d27834ebb4863fe8d3baea55b77\n```\n\n3. **curl 验证私服库上有什么镜像**\n\n`curl -XGET http://192.168.88.231:5000/v2/_catalog`\n\n可以看到，目前私服库没有任何镜像上传过\n\n```bash\n[root@88231 docker-registry]# curl -XGET http://192.168.88.231:5000/v2/_catalog\n{\"repositories\":[]}\n```\n\n4. **提交一个新镜像到私有的 Registry 库**\n\n- 修改符合私服规范的 Tag\n\n`docker tag 镜像ID Host:Port/Repository:Tag`\n\n```\n[root@88231 docker-registry]# docker tag ba6acccedd29 192.168.88.231:5000/myubuntu:1.0\n```\n\n- 修改配置文件，使之支持 http 上传\n\n这里的地址是 registry 私服所在主机的地址\n\n```bash\n[root@88231 docker-registry]# vim /etc/docker/daemon.json\n{\n  \"registry-mirrors\": [\"https://alq7pwwu.mirror.aliyuncs.com\"],\n  \"insecure-registries\": [\"192.168.88.231:5000\"]\n}\n# 重启 docker 生效\n[root@88231 docker-registry]# service docker restart\nStopping docker:                                       [  OK  ]\nStarting docker:\t                                   [  OK  ]\n```\n\n- push 推送到私服库\n\n```\n# 使用 docker push 命令推送私服库\n[root@88231 docker-registry]# docker push 192.168.88.231:5000/myubuntu:1.0\nThe push refers to a repository [192.168.88.231:5000/myubuntu]\n9f54eef41275: Pushed\n1.0: digest: sha256:870c68e5f7e5cac7cb9a747e18865524dbc0952575dcc498621c79b94a78a846 size: 529\n\n# 使用 curl 查看私服库上的镜像\n[root@88231 docker-registry]# curl -XGET http://192.168.88.231:5000/v2/_catalog\n{\"repositories\":[\"myubuntu\"]}\n```\n\n5. **将私服库上的镜像 pull 到本地运行**\n\n```\n# 使用 docker pull 命令将私服库上的镜像下载到本地\n[root@88231 /]# docker pull 192.168.88.231:5000/myubuntu:1.0\n1.0: Pulling from myubuntu\nf9945daba3cc: Pull complete\nDigest: sha256:870c68e5f7e5cac7cb9a747e18865524dbc0952575dcc498621c79b94a78a846\nStatus: Downloaded newer image for 192.168.88.231:5000/myubuntu:1.0\n```\n\n## 容器数据卷\n\n### 什么是容器数据卷？\n\n> docker 的理念回顾\n\n将应用和环境打包成一个镜像！\n\n数据都在容器中，如果删除容器，数据就会丢失！==数据如何持久化？数据需要存储在本地！==\n\n容器之间可以有一个数据共享的技术！Docker 容器中产生的数据，可以同步到本地！\n\n这就是卷技术！其本质就是目录的挂载，将容器内的目录，挂载到 Linux 上！\n\n### 使用数据卷\n\n> ==坑！使用容器数据卷时记得加入：--privileged=true==\n>\n> Docker 挂载主机目录访问如果出现 cannot open directory: Permission denied\n> 解决办法：在挂载目录后多加一个--privileged=true 参数即可\n>\n> 如果是 CentOS7 安全模块会比之前系统版本加强，不安全的会先禁止，所以目录挂载的情况被默认为不安全的行为，\n> 在 SELinux 里面挂载目录被禁止掉了额，如果要开启，我们一般使用--privileged=true 命令，扩大容器的权限解决挂载目录没有权限的问题，也即使用该参数，container 内的 root 拥有真正的 root 权限，否则，container 内的 root 只是外部的一个普通用户权限。\n\n> 方式一：直接使用命令来挂载 -v\n\n```shell\ndocker run -it -v 主机目录:容器内目录\n\n# 测试\n[root@ouwen666 ~]# docker run -it -v /home/ceshi:/home --privileged=true centos /bin/bash\n\n# 启动成功后查看详细信息\n[root@ouwen666 ceshi]# docker inspect 015ee9a39cf1\n```\n\n![image-20211219162714621](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219162714.png)\n\n测试文件的同步\n\n![image-20211219163426342](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219163426.png)\n\n继续测试！\n\n1. 停止容器\n2. 宿主机上修改文件\n3. 启动并进入容器\n4. 发现容器内的数据跟宿主机是同步的！\n\n![image-20211219163920495](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219163920.png)\n\n> 好处：修改只需要在本地修改即可，容器内会自动同步！\n\n### 实战：安装 MySQL\n\n思考：MySQL 的数据持久化问题！\n\n```shell\n# 获取镜像\n[root@ouwen666 ~]# docker pull mysql:5.7\n\n# 运行容器，需要做数据挂载！ # 安装启动mysql，需要配置密码的\n# 官方命令: docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag\n\n# 启动mysql\ndocker run -d -p 3306:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7\n# 命令解释\n-d  后台运行\n-p  端口映射\n-v  卷挂载\n-e  环境配置\n--name 容器名字\n\n# 启动成功，通过Navicat连接测试！\n```\n\n![image-20211219171950528](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219171950.png)\n\n用 Navicat 建一个数据库\n\n![image-20211219193046702](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219193046.png)\n\n服务器上映射的路径下，出现了同名文件\n\n![image-20211219193150622](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219193150.png)\n\n将容器删除，发现 `/home/mysql/data` 目录下的文件还是存在的。这就实现了容器数据持久化！\n\n![image-20211219193417029](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219193417.png)\n\n### 具名和匿名挂载\n\n```shell\n# 匿名挂载\n-v 容器内路径\ndocker run -d -P --name nginx01 -v /etc/nginx nginx\n\n# 查看所有 volume 的情况\n[root@ouwen666 data]# docker volume ls\nDRIVER    VOLUME NAME\nlocal     5370f027b4d5a86a9718f66c9bc9c39138aa92ad2b6368a74f930c09f94c52bb\n\n# 这里发现 volume name 是一串乱码，是因为我们挂载时没有指定名字。这就是匿名挂载。我们在 -v 时只写了容器内路径，没有写容器外路径！\n\n# 具名挂载\n[root@ouwen666 data]# docker run -d -P --name nginx02 -v nginxvolumename:/etc/nginx nginx\n11ba9ffded8187484386ff37103c91a6a2bd2e103420b9376c45c61f604dab57\n[root@ouwen666 data]# docker volume ls\nDRIVER    VOLUME NAME\nlocal     nginxvolumename\n\n# 通过 -v 卷名:容器内路径 完成具名挂载\n# 查看这个卷的具体信息 inspect\n[root@ouwen666 data]# docker volume inspect nginxvolumename\n[\n    {\n        \"CreatedAt\": \"2021-12-19T19:44:11+08:00\",\n        \"Driver\": \"local\",\n        \"Labels\": null,\n        \"Mountpoint\": \"/var/lib/docker/volumes/nginxvolumename/_data\",\n        \"Name\": \"nginxvolumename\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n```\n\n> 所有的 docker 容器内的卷，没有指定目录的情况下都是在 `/var/lib/docker/volumes/xxx/_data` 下！\n>\n> 通过具名挂载可以方便地找到卷所在的位置，大多数请况下使用 `具名挂载` ！\n\n![image-20211219194814407](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219194814.png)\n\n**如何确定是具名挂载. 匿名挂载还是指定路径挂载？**\n\n- `-v 容器内路径` 匿名挂载\n- `-v 卷名:容器内路径` 具名挂载\n- `-v /宿主机路径:容器内路径` 指定路径挂载\n\n拓展：\n\n```shell\n# 通过 -v 容器内路径:ro/rw  改变读写权限\nro   readonly  # 只读\nrw   readwrite # 可读可写\n\n# 例如\ndocker run -d -P --name nginx02 -v nginxvolumename:/etc/nginx:ro nginx\ndocker run -d -P --name nginx02 -v nginxvolumename:/etc/nginx:rw nginx\n\n# 一旦设置了ro，就说这个路径只能通过映射后宿主机的来操作，容器内部是无法操作的！\n```\n\n### 初识 DockerFile\n\nDockerFile 就是用来构建 docker 镜像的构建文件！其实就是一段命令脚本！\n\n通过这个脚本可以生成镜像，镜像是一层一层的，脚本是一个个的命令，每个命令都是一层！\n\n```shell\n# 创建一个dockerfile文件，名字可以随意 建议 Dockerfile\n[root@ouwen666 docker-test]# vim Dockerfile\nFROM centos\n\nVOLUME [\"volume01\",\"volume02\"]\n\nCMD echo \"-----end-----\"\n\nCMD /bin/bash\n\n# 通过Dockerfile构建一个属于自己的镜像 注意末尾有一个 . 代表当前路径\n[root@ouwen666 docker-test]# docker build -f /home/docker-test/Dockerfile -t irving/centos:1.0 .\nSending build context to Docker daemon  2.048kB\nStep 1/4 : FROM centos\n ---> 5d0da3dc9764\nStep 2/4 : VOLUME [\"volume01\",\"volume02\"]\n ---> Running in e121337bcbbe\nRemoving intermediate container e121337bcbbe\n ---> 2e6cad23ca38\nStep 3/4 : CMD echo \"-----end-----\"\n ---> Running in 7025e750f7ac\nRemoving intermediate container 7025e750f7ac\n ---> cf376f17795b\nStep 4/4 : CMD /bin/bash\n ---> Running in 60e0bccacc5d\nRemoving intermediate container 60e0bccacc5d\n ---> 2aee0e7445ac\nSuccessfully built 2aee0e7445ac\nSuccessfully tagged irving/centos:1.0\n\n# 查看生成的镜像\n[root@ouwen666 docker-test]# docker images\nREPOSITORY            TAG       IMAGE ID       CREATED         SIZE\nirving/centos         1.0       2aee0e7445ac   2 minutes ago   231MB\nmytomcat              1.0       ef1ba8ee4bba   4 hours ago     685MB\ntomcat                9.0       3f3cadde9a68   10 days ago     680MB\nredis                 latest    aea9b698d7d1   2 weeks ago     113MB\nmysql                 5.7       738e7101490b   2 weeks ago     448MB\nnginx                 latest    f652ca386ed1   2 weeks ago     141MB\ncentos                latest    5d0da3dc9764   3 months ago    231MB\nportainer/portainer   latest    580c0e4e98b0   9 months ago    79.1MB\nelasticsearch         7.6.2     f29a1ee41030   21 months ago   791MB\n\n# 使用刚刚生成的镜像启动一个容器\n[root@ouwen666 docker-test]# docker run -it 2aee0e7445ac /bin/bash\n[root@b2707d29bda4 /]#\n```\n\n![image-20211219203120341](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219203120.png)\n\n这个挂载的卷目录一定和外部有一个同步的目录！\n\n通过 `docker inspect 容器ID` 查看具体信息\n\n![image-20211219203438140](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219203438.png)\n\n发现确实是在 `/var/lib/docker/volumes/` 目录下的一个随机目录下！\n\n### 卷的继承和共享\n\n> 图解\n\n![image-20211219203754331](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211219203754.png)\n\n> 测试！\n\n```shell\n# 启动三个容器！通过刚刚自己制作的镜像启动\n\n# 第一个容器 docker01\n[root@ouwen666 ~]# docker run -it --name docker01 irving/centos:1.0\n[root@9e033da9de3e /]# ls\nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var  volume01\tvolume02\n\n# 第二个容器 docker02 通过 --volumes-from 挂载 docker01 容器\n[root@ouwen666 ~]# docker run -it --name docker02 --volumes-from docker01 irving/centos:1.0\n[root@75fb856af436 /]# ls\nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var  volume01\tvolume02\n\n# docker01 创建的文件同步到 docker02 容器上了\n[root@ouwen666 ~]# docker attach docker01\n[root@9e033da9de3e /]# ls\nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var  volume01\tvolume02\n[root@9e033da9de3e /]# cd volume01\n[root@9e033da9de3e volume01]# ls\n[root@9e033da9de3e volume01]# touch docker01\n[root@9e033da9de3e volume01]# ls\ndocker01\n\n[root@ouwen666 /]# docker attach docker02\n[root@75fb856af436 /]# ls\nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var  volume01\tvolume02\n[root@75fb856af436 /]# cd volume01\n[root@75fb856af436 volume01]# ls\ndocker01\n\n# 第三个容器 docker03 也通过 --volumes-from 挂载 docker01\n[root@ouwen666 ~]# docker run -it --name docker03 --volumes-from docker01 irving/centos:1.0\n[root@eda4d0cad3f0 /]# ls\nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var  volume01\tvolume02\n[root@eda4d0cad3f0 /]# cd volume01\n[root@eda4d0cad3f0 volume01]# ls\ndocker01\n\n# 发现文件还是同步过来，在 docker03 中新建一个文件\n[root@eda4d0cad3f0 volume01]# touch docker03\n[root@eda4d0cad3f0 volume01]# ls\ndocker01  docker03\n\n# 进入 docker01 容器，发现 docker03 中创建的文件也同步过来了！\n[root@ouwen666 /]# docker attach docker01\n[root@9e033da9de3e /]# cd volume01\n[root@9e033da9de3e volume01]# ls\ndocker01  docker03\n```\n\n> 结论\n\n只要通过 `--volumes-from` 就可以做到容器间的数据共享！\n\n思考：删除 docker01，查看 docker02. docker03 是否还能访问这些文件\n\n依旧可以访问！本质上是一种数据拷贝，而不是单纯的数据共享！\n\n容器之间配置信息的传递，数据卷容器的生命周期可以一直持续到没有人使用为止！\n","tags":["Docker","容器"],"categories":["Linux"]},{"title":"Docker 安装 Centos7","slug":"Docker安装Centos7","url":"/2021/12/12/f414591e.html","content":"\n## 前言\n\n本地化启动一个 `Linux` 服务器，使用 `Docker` 容器来构建一个包含 SSH 服务的 Linux 镜像。\n\n## 准备 centos 官方镜像\n\n具体步骤：\n\n```shell\n# 1、拉取centos7官方镜像\ndocker pull centos:7\n# 2、启动镜像\ndocker run -itd --privileged centos:7 init\n# 3、进入容器bash中\ndocker exec -it 镜像ID bash\n# 4、修改root用户密码\n[root@33c7ee24f43e /]# passwd\nChanging password for user root.\nNew password:\nBAD PASSWORD: The password is shorter than 8 characters\nRetype new password:\npasswd: all authentication tokens updated successfully.\n# 5、安装和配置ssh服务\nyum install openssh-server -y\n# 6、修改/etc/ssh/sshd_config配置并保存：PermitRootLogin yes    UsePAM no\n```\n\n![image-20220223145827608](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220223145834.png)\n\n![image-20220223145949729](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20220223145949.png)\n\n```shell\n# 7、启动ssh服务\n[root@33c7ee24f43e /]# systemctl start sshd\n# 8、退出容器\n[root@33c7ee24f43e /]# exit\nexit\n```\n\n## 构建镜像\n\n通过 `docker commit` 来构建包含 ssh 服务的镜像\n\n```shell\n# 1、通过commit构建镜像\ndocker commit -a=\"Irving\" -m=\"本地linux镜像\" 容器ID mycentos:1.0\n# 2、启动镜像 -p 10000:22 映射本地10000端口\ndocker run -d -p 10000:22 --name 容器名 镜像ID /usr/sbin/sshd -D\n```\n\n## 使用 xshell 进行连接\n\n```shell\nssh://root:****@127.0.0.1:10000\n```\n","tags":["Docker","容器"],"categories":["Linux"]},{"title":"Java 操作 Excel 之 POI 与 EasyExcel","slug":"Java操作Excel之POI与EasyExcel","url":"/2021/08/05/13a54546.html","content":"\n## 前言\n\n在工作中，使用 excel 表格处理数据是很常见的操作，作为一个 Java 开发工程师，学会使用 Java 来操作 excel 表格是必备的技能之一。\n\n本文就通过市面上常用的两种方式来实现 Java 对 excel 表格的操作：\n\n- Apache POI\n- Alibaba EasyExcel\n\n## 一、Apache POI\n\n### 简介\n\nApache POI 官网： https://poi.apache.org/\n\nPOI 是目前比较流行的 Java 处理 excel 框架，但是其缺点是 **数据量大容易造成 OOM 异常**\n\n### 基本结构\n\n- HSSF － 提供读写[Microsoft Excel](https://baike.baidu.com/item/Microsoft Excel)格式档案的功能（03 版本 excel）\n- XSSF － 提供读写[Microsoft](https://baike.baidu.com/item/Microsoft) Excel [OOXML](https://baike.baidu.com/item/OOXML)格式档案的功能（07 版本 excel）\n- HWPF － 提供读写[Microsoft Word](https://baike.baidu.com/item/Microsoft Word)格式档案的功能\n- HSLF － 提供读写[Microsoft PowerPoint](https://baike.baidu.com/item/Microsoft PowerPoint)格式档案的功能\n- HDGF － 提供读写[Microsoft Visio](https://baike.baidu.com/item/Microsoft Visio)格式档案的功能\n\n### 快速开始\n\n创建 一个空项目，在空项目中新建一个 module 模块：一个普通的 maven 项目即可\n\n#### 1、导入 pom 依赖\n\n```xml\n<dependencies>\n    <!--xLs(03)-->\n    <dependency>\n        <groupId>org.apache.poi</groupId>\n        <artifactId>poi</artifactId>\n        <version>4.1.2</version>\n    </dependency>\n    <!--xLsx(07)-->\n    <dependency>\n        <groupId>org.apache.poi</groupId>\n        <artifactId>poi-ooxml</artifactId>\n        <version>4.1.2</version>\n    </dependency>\n    <!--日期格式化工具-->\n    <dependency>\n        <groupId>joda-time</groupId>\n        <artifactId>joda-time</artifactId>\n        <version>2.10.1</version>\n    </dependency>\n    <!--test-->\n    <dependency>\n        <groupId>junit</groupId>\n        <artifactId>junit</artifactId>\n        <version>4.12</version>\n    </dependency>\n</dependencies>\n```\n\n#### 2、POI 写入 Excel\n\n```java\npackage com.lxki;\n\nimport org.apache.poi.hssf.usermodel.HSSFWorkbook;\nimport org.apache.poi.ss.usermodel.Cell;\nimport org.apache.poi.ss.usermodel.Row;\nimport org.apache.poi.ss.usermodel.Sheet;\nimport org.apache.poi.ss.usermodel.Workbook;\nimport org.apache.poi.xssf.usermodel.XSSFWorkbook;\nimport org.joda.time.DateTime;\nimport org.junit.Test;\n\nimport java.io.FileOutputStream;\n\n/**\n * POI写入Excel测试\n * @author IRVING QQ:2362766003\n * @create 2021-06-22 14:20\n */\npublic class WriteExcelTest {\n\n    // 生成文件路径\n    private static final String PATH = \"E:\\\\workspace\\\\IdeaProjects\\\\POI-EasyExcel\\\\lxki-poi\\\\\";\n\n    /**\n     * 写入03版本的excel\n     */\n    @Test\n    public void testWrite03() throws Exception {\n        // 创建工作簿\n        Workbook workbook = new HSSFWorkbook();\n\n        // 创建工作表\n        Sheet sheet = workbook.createSheet(\"员工信息表03\");\n\n        // 创建第一行\n        Row row1 = sheet.createRow(0);\n        // 创建单元格\n        Cell cell11 = row1.createCell(0);\n        cell11.setCellValue(\"姓名\");\n        Cell cell12 = row1.createCell(1);\n        cell12.setCellValue(\"张三\");\n\n        // 创建第二行\n        Row row2 = sheet.createRow(1);\n        // 创建单元格\n        Cell cell21 = row2.createCell(0);\n        cell21.setCellValue(\"出生日期\");\n        Cell cell22 = row2.createCell(1);\n        cell22.setCellValue(new DateTime().toString(\"yyyy-MM-dd HH:mm:ss\"));\n\n        // 生成表 io流 -- 03版本使用xls后缀名\n        FileOutputStream fileOutputStream = new FileOutputStream(PATH + \"员工信息表03.xls\");\n        workbook.write(fileOutputStream);\n\n        // 关闭流\n        fileOutputStream.close();\n        System.out.println(\"员工信息表03.xls ==> 输出完毕\");\n    }\n\n    /**\n     * 写入07版本的excel\n     */\n    @Test\n    public void testWrite07() throws Exception {\n        // 创建工作簿\n        Workbook workbook = new XSSFWorkbook();\n\n        // 创建工作表\n        Sheet sheet = workbook.createSheet(\"员工信息表07\");\n\n        // 创建第一行\n        Row row1 = sheet.createRow(0);\n        // 创建单元格\n        Cell cell11 = row1.createCell(0);\n        cell11.setCellValue(\"姓名\");\n        Cell cell12 = row1.createCell(1);\n        cell12.setCellValue(\"张三\");\n\n        // 创建第二行\n        Row row2 = sheet.createRow(1);\n        // 创建单元格\n        Cell cell21 = row2.createCell(0);\n        cell21.setCellValue(\"出生日期\");\n        Cell cell22 = row2.createCell(1);\n        cell22.setCellValue(new DateTime().toString(\"yyyy-MM-dd HH:mm:ss\"));\n\n        // 生成表 io流 -- 07版本使用xlsx后缀名\n        FileOutputStream fileOutputStream = new FileOutputStream(PATH + \"员工信息表07.xlsx\");\n        workbook.write(fileOutputStream);\n\n        // 关闭流\n        fileOutputStream.close();\n        System.out.println(\"员工信息表07.xls ==> 输出完毕\");\n    }\n}\n```\n\n#### 3、POI 读取 Excel\n\n```java\npackage com.lxki;\n\nimport org.apache.poi.hssf.usermodel.HSSFWorkbook;\nimport org.apache.poi.ss.usermodel.Cell;\nimport org.apache.poi.ss.usermodel.Row;\nimport org.apache.poi.ss.usermodel.Sheet;\nimport org.apache.poi.ss.usermodel.Workbook;\nimport org.apache.poi.xssf.usermodel.XSSFWorkbook;\nimport org.junit.Test;\n\nimport java.io.FileInputStream;\n\n/**\n * POI读取Excel测试\n * @author IRVING QQ:2362766003\n * @create 2021-06-22 15:49\n */\npublic class ReadExcelTest {\n\n    // 生成文件路径\n    private static final String PATH = \"E:\\\\workspace\\\\IdeaProjects\\\\POI-EasyExcel\\\\lxki-poi\\\\\";\n\n    /**\n     * 读取03版本的excel\n     */\n    @Test\n    public void testRead03() throws Exception{\n        // 通过文件路径得到文件输入流\n        FileInputStream fileInputStream = new FileInputStream(PATH + \"员工信息表03.xls\");\n\n        // 通过文件输入流拿到工作簿\n        Workbook workbook = new HSSFWorkbook(fileInputStream);\n\n        // 通过工作簿获取工作表\n        Sheet sheet = workbook.getSheetAt(0);\n        // 拿到行数，通过循环读取数据\n        int rowCount = sheet.getPhysicalNumberOfRows();\n        for (int rowNum = 0; rowNum < rowCount; rowNum++) {\n            // 通过工作表读取行，并取到对应的列数\n            Row row = sheet.getRow(rowNum);\n            int cellCount = row.getPhysicalNumberOfCells();\n            // 通过行读取单元格\n            for (int cellNum = 0; cellNum < cellCount; cellNum++) {\n                Cell cell = row.getCell(cellNum);\n                // 读取 excel 表格中的数据时要注意类型\n                System.out.print(cell.getStringCellValue()+\"\\t\");\n            }\n            System.out.println();\n        }\n    }\n\n    /**\n     * 读取07版本的excel\n     */\n    @Test\n    public void testRead07() throws Exception{\n        // 通过文件路径得到文件输入流\n        FileInputStream fileInputStream = new FileInputStream(PATH + \"员工信息表07.xlsx\");\n\n        // 通过文件输入流拿到工作簿\n        Workbook workbook = new XSSFWorkbook(fileInputStream);\n\n        // 通过工作簿获取工作表\n        Sheet sheet = workbook.getSheetAt(0);\n        // 拿到行数，通过循环读取数据\n        int rowCount = sheet.getPhysicalNumberOfRows();\n        for (int rowNum = 0; rowNum < rowCount; rowNum++) {\n            // 通过工作表读取行，并取到对应的列数\n            Row row = sheet.getRow(rowNum);\n            int cellCount = row.getPhysicalNumberOfCells();\n            // 通过行读取单元格\n            for (int cellNum = 0; cellNum < cellCount; cellNum++) {\n                Cell cell = row.getCell(cellNum);\n                // 读取 excel 表格中的数据时要注意类型\n                System.out.print(cell.getStringCellValue()+\"\\t\");\n            }\n            System.out.println();\n        }\n    }\n\n}\n```\n\n#### 注意：\n\n- `03` 和 `07` 版本的 `excel` 表格对应的 POI 操作 API 是不同的（`HSSF` 与 `XSSF`）\n  - `03` 版本最多支持 `65536` 行数据，而 `07` 则没有限制\n  - `HSSF` 操作响应速度快于 `XSSF`， `XSSF`可以使用 `SXSSF` 替换来提升响应数据\n- ==读取 `excel` 表格中的数据时要注意判断不同的数据类型，使用对应的读取方法==\n\n最终的项目目录结构：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210622175140.png\" alt=\"image-20210622175133621\" style=\"zoom:50%;\" />\n\n## 二、EasyExcel\n\n### 简介\n\nEasyExcel 官网地址：https://github.com/alibaba/easyexcel\n\nEasyExcel 是 Alibaba 开源的一个 excel 处理框架，特点是 **使用简单、节约内存**。\n\n### 快速开始\n\n在空项目中新建一个新的 module 模块，类型为普通的 maven 项目\n\n#### 1、导入 pom 依赖\n\n```xml\n<dependencies>\n    <!-- 导入easyexcel依赖 -->\n    <dependency>\n        <groupId>com.alibaba</groupId>\n        <artifactId>easyexcel</artifactId>\n        <version>2.2.10</version>\n    </dependency>\n    <!-- lombok依赖 -->\n    <dependency>\n        <groupId>org.projectlombok</groupId>\n        <artifactId>lombok</artifactId>\n        <version>1.18.16</version>\n    </dependency>\n    <!-- junit单元测试 -->\n    <dependency>\n        <groupId>org.junit.jupiter</groupId>\n        <artifactId>junit-jupiter</artifactId>\n        <version>RELEASE</version>\n        <scope>compile</scope>\n    </dependency>\n    <!-- json工具 -->\n    <dependency>\n        <groupId>com.alibaba</groupId>\n        <artifactId>fastjson</artifactId>\n        <version>1.2.72</version>\n    </dependency>\n</dependencies>\n```\n\n#### 2、数据实体对象\n\n```java\npackage com.lxki;\n\nimport com.alibaba.excel.annotation.ExcelIgnore;\nimport com.alibaba.excel.annotation.ExcelProperty;\nimport lombok.Data;\n\nimport java.util.Date;\n\n@Data\npublic class DemoData {\n    @ExcelProperty(\"字符串标题\")\n    private String string;\n    @ExcelProperty(\"日期标题\")\n    private Date date;\n    @ExcelProperty(\"数字标题\")\n    private Double doubleData;\n    /**\n     * 忽略这个字段\n     */\n    @ExcelIgnore\n    private String ignore;\n}\n```\n\n#### 3、EasyExcel 写入 Excel\n\n```java\npackage com.lxki;\n\nimport com.alibaba.excel.EasyExcel;\nimport org.junit.jupiter.api.Test;\n\nimport java.util.ArrayList;\nimport java.util.Date;\nimport java.util.List;\n\n/**\n * @author IRVING QQ:2362766003\n * @create 2021-06-22 16:41\n */\npublic class EasyExcelWrite {\n\n    // 生成文件路径\n    private static final String PATH = \"E:\\\\workspace\\\\IdeaProjects\\\\POI-EasyExcel\\\\lxki-easyexcel\\\\\";\n\n    /**\n     * 生成示例数据\n     * @return 示例数据\n     */\n    private List<DemoData> data() {\n        List<DemoData> list = new ArrayList<DemoData>();\n        for (int i = 0; i < 10; i++) {\n            DemoData data = new DemoData();\n            data.setString(\"字符串\" + i);\n            data.setDate(new Date());\n            data.setDoubleData(0.56);\n            list.add(data);\n        }\n        return list;\n    }\n\n    /**\n     * 最简单的写\n     * <p>1. 创建excel对应的实体对象 参照{@link DemoData}\n     * <p>2. 直接写即可\n     */\n    @Test\n    public void simpleWrite() {\n\n        String fileName = PATH + \"easyexcel07.xlsx\";\n        // 这里 需要指定写用哪个class去写，然后写到第一个sheet，名字为模板 然后文件流会自动关闭\n        // 如果这里想使用 03版本 则 传入excelType参数即可\n        EasyExcel.write(fileName, DemoData.class).sheet(\"模板\").doWrite(data());\n\n    }\n}\n```\n\n#### 4、EasyExcel 读取 Excel\n\n数据持久层：\n\n```java\npackage com.lxki;\n\nimport java.util.List;\n\n/**\n * 假设这个是你的DAO存储。当然还要这个类让spring管理，当然你不用需要存储，也不需要这个类。\n **/\npublic class DemoDAO {\n    public void save(List<DemoData> list) {\n        // 如果是mybatis,尽量别直接调用多次insert,自己写一个mapper里面新增一个方法batchInsert,所有数据一次性插入\n    }\n}\n```\n\n读取监听器：\n\n```java\npackage com.lxki;\n\nimport com.alibaba.excel.context.AnalysisContext;\nimport com.alibaba.excel.event.AnalysisEventListener;\nimport com.alibaba.fastjson.JSON;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\n// 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去\npublic class DemoDataListener extends AnalysisEventListener<DemoData> {\n    private static final Logger LOGGER = LoggerFactory.getLogger(DemoDataListener.class);\n    /**\n     * 每隔5条存储数据库，实际使用中可以3000条，然后清理list ，方便内存回收\n     */\n    private static final int BATCH_COUNT = 5;\n    List<DemoData> list = new ArrayList<DemoData>();\n    /**\n     * 假设这个是一个DAO，当然有业务逻辑这个也可以是一个service。当然如果不用存储这个对象没用。\n     */\n    private DemoDAO demoDAO;\n    public DemoDataListener() {\n        // 这里是demo，所以随便new一个。实际使用如果到了spring,请使用下面的有参构造函数\n        demoDAO = new DemoDAO();\n    }\n    public DemoDataListener(DemoDAO demoDAO) {\n        this.demoDAO = demoDAO;\n    }\n    /**\n     * 这个每一条数据解析都会来调用\n     *\n     * @param data\n     *            one row value. Is is same as {@link AnalysisContext#readRowHolder()}\n     * @param context\n     */\n    @Override\n    public void invoke(DemoData data, AnalysisContext context) {\n        LOGGER.info(\"解析到一条数据:{}\", JSON.toJSONString(data));\n        System.out.println(JSON.toJSONString(data));\n        list.add(data);\n        // 达到BATCH_COUNT了，需要去存储一次数据库，防止数据几万条数据在内存，容易OOM\n        if (list.size() >= BATCH_COUNT) {\n            saveData();\n            // 存储完成清理 list\n            list.clear();\n        }\n    }\n    /**\n     * 所有数据解析完成了 都会来调用\n     *\n     * @param context\n     */\n    @Override\n    public void doAfterAllAnalysed(AnalysisContext context) {\n        // 这里也要保存数据，确保最后遗留的数据也存储到数据库\n        saveData();\n        LOGGER.info(\"所有数据解析完成！\");\n    }\n    /**\n     * 加上存储数据库\n     */\n    private void saveData() {\n        LOGGER.info(\"{}条数据，开始存储数据库！\", list.size());\n        demoDAO.save(list);\n        LOGGER.info(\"存储数据库成功！\");\n    }\n}\n```\n\n读取测试：\n\n```java\npackage com.lxki;\n\nimport com.alibaba.excel.EasyExcel;\nimport com.alibaba.excel.ExcelReader;\nimport com.alibaba.excel.read.metadata.ReadSheet;\nimport org.junit.jupiter.api.Test;\n\nimport java.io.File;\n\n/**\n * @author IRVING QQ:2362766003\n * @create 2021-06-22 16:57\n */\npublic class EasyExcelRead {\n\n    // 生成文件路径\n    private static final String PATH = \"E:\\\\workspace\\\\IdeaProjects\\\\POI-EasyExcel\\\\lxki-easyexcel\\\\\";\n\n    /**\n     * 最简单的读\n     * <p>1. 创建excel对应的实体对象 参照{@link DemoData}\n     * <p>2. 由于默认一行行的读取excel，所以需要创建excel一行一行的回调监听器，参照{@link DemoDataListener}\n     * <p>3. 直接读即可\n     */\n    @Test\n    public void simpleRead() {\n        // 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去\n        String fileName = PATH + \"easyexcel07.xlsx\";\n        // 这里 需要指定读用哪个class去读，然后读取第一个sheet 文件流会自动关闭\n        EasyExcel.read(fileName, DemoData.class, new DemoDataListener()).sheet().doRead();\n    }\n}\n```\n\n#### 注意：\n\n- 如果需要操作 `03` 版本的 `excel`，需要在读写操作时传入 `excelType` 参数\n\n最终的项目结构：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210622175228.png\" alt=\"image-20210622175227995\" style=\"zoom:50%;\" />\n","tags":["技巧","笔记"],"categories":["后端开发"]},{"title":"Tomcat 配置 HTTPS 协议访问","slug":"Tomcat配置HTTPS协议访问","url":"/2021/07/15/b5db2b95.html","content":"\n## 前言\n\nTomcat 默认支持 HTTP 协议访问，项目需求要修改 Tomcat 支持 HTTPS 协议访问。\n\n## 操作步骤\n\n### 使用 Java 自带的 keytool 生成证书\n\n打开控制台输入：\n\n```bash\nkeytool -genkey -v -alias testKey -keyalg RSA -validity 3650 -keystore D:\\apache-tomcat-7.0.26\\keys\\test.keystore -ext SAN=ip:127.0.0.1\n\nkeytool -export -alias testKey -file wxsccp.cer -keystore test.jks\n```\n\n参数说明：\n\n```\nalias: 别名 这里起名keys\nkeyalg: 证书算法，RSA\nvalidity：证书有效时间，10年\nkeystore：证书生成的目标路径和文件名,替换成你自己的路径即可,我定义的是D:\\apache-tomcat-7.0.26\\keys\\test.keystore，其中keys文件夹必须存在\n```\n\n之后回车，然后需要输入一些信息，其中秘钥库口令和秘钥口令最好一致，并且记下来（之后配置 Tomcat 需要用到）\n\n![image-20210607134909105](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210607134909.png)\n\n### 配置 Tomcat\n\n打开 Tomcat 的 conf 目录下的 `server.xml`文件，定位 `https` 到指定位置，完整配置如下：\n\n```xml\n<Connector port=\"8443\" protocol=\"org.apache.coyote.http11.Http11Protocol\"\n               maxThreads=\"150\" SSLEnabled=\"true\" scheme=\"https\" secure=\"true\"\n               clientAuth=\"false\" sslProtocol=\"TLS\"\n               keystoreFile=\"D:\\software\\EOS\\apache-tomcat-7.0.54\\keys\\test.keystore\"\n               keystorePass=\"vansys\" />\n```\n\n参数说明：\n\n- keystoreFile：上面生成的证书所在目录\n- keystorePass：生成证书时输入的秘钥\n\n![image-20210607135533347](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210607135533.png)\n\n添加 http 跳转 https 协议访问，在 web.xml 文件末尾添加如下配置：\n\n```xml\n<security-constraint>\n    <web-resource-collection >\n        <web-resource-name >SSL</web-resource-name>\n        <url-pattern>/*</url-pattern>\n    </web-resource-collection>\n    <user-data-constraint>\n        <transport-guarantee>CONFIDENTIAL</transport-guarantee>\n    </user-data-constraint>\n</security-constraint>\n```\n\n如图：\n\n![image-20210607135715701](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210607135715.png)\n\n### 重启 Tomcat 服务器\n\n这样就能通过 https 协议访问我们的项目：\n\n![image-20210607140001797](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210607140001.png)\n\n但是发现：\n\n使用自己生成的证书会遇到一些问题：\n\n- **浏览器会对 HTTPS 使用危险标识。**\n- **浏览器默认不会加载非 HTTPS 域名下的 javascript**\n- **移动设备显示页面空白**\n\n## 解决证书无效问题\n\n要解决自己生成的证书无效的问题，需要购买相应的 SSL 证书。[证书服务*SSL 数字证书\\_HTTPS 加密*服务器证书\\_CA 认证-阿里云](https://www.aliyun.com/product/cas)\n\n不过我之前用过一些免费的证书申请网站 [FreeSSL 首页 - FreeSSL.cn 一个提供免费 HTTPS 证书申请的网站](https://freessl.cn/)\n\n### 申请证书\n\n略\n\n### Tomcat 配置 PFX 证书\n\n打开 Tomcat 配置文件 `conf\\server.xml`\n\n定位 `https` 到指定位置，修改三个属性 ：`keystoreFile`，`keystoreType`，`keystorePass`\n\n```xml\n  <Connector\n        protocol=\"org.apache.coyote.http11.Http11NioProtocol\"\n        port=\"443\" maxThreads=\"200\"\n        scheme=\"https\" secure=\"true\" SSLEnabled=\"true\"\n        clientAuth=\"false\" sslProtocol=\"TLS\"\n        keystoreFile=\"/你的磁盘目录/证书文件名.pfx\"  <!--这里是证书文件存放路径-->\n        keystoreType=\"PKCS12\"   <!--这里是证书格式，.pfx和.p12都是PKCS12格式的-->\n        keystorePass=\"123456\"    <!--刚才输入的密码-->\n   />\n```\n\n### 重启 Tomcat 服务器，访问测试\n","tags":["笔记","Tomcat"],"categories":["后端开发"]},{"title":"Java 中的集合概述","slug":"Java中的集合","url":"/2021/07/02/13a54546.html","content":"## 前言\n\n本文记录了Java中的集合框架，文章中的内容摘录自[Java 集合框架 | 菜鸟教程 (runoob.com)](https://www.runoob.com/java/java-collections.html)、CSDN、博客园等开源网站。\n\n## Java 集合体系\n\nJava 集合框架主要包括两种类型的容器，一种是集合（Collection），存储一个元素集合，另一种是图（Map），存储键/值对映射。Collection 接口又有 3 种子类型，List、Set 和 Queue，再下面是一些抽象类，最后是具体实现类，常用的有 [ArrayList](https://www.runoob.com/java/java-arraylist.html)、[LinkedList](https://www.runoob.com/java/java-linkedlist.html)、[HashSet](https://www.runoob.com/java/java-hashset.html)、LinkedHashSet、[HashMap](https://www.runoob.com/java/java-hashmap.html)、LinkedHashMap 等等。\n\n集合框架是一个用来代表和操纵集合的统一架构。所有的集合框架都包含如下内容：\n\n- **接口：**是代表集合的抽象数据类型。例如 Collection、List、Set、Map 等。之所以定义多个接口，是为了以不同的方式操作集合对象\n- **实现（类）：**是集合接口的具体实现。从本质上讲，它们是可重复使用的数据结构，例如：ArrayList、LinkedList、HashSet、HashMap。\n- **算法：**是实现集合接口的对象里的方法执行的一些有用的计算，例如：搜索和排序。这些算法被称为多态，那是因为相同的方法可以在相似的接口上有着不同的实现。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210520211027.png\" alt=\"image-20210520211027579\" style=\"zoom: 50%;\" />\n\n上图堪称集合框架的**上帝视角**，整个框架的组成部分：\n\n1. 集合框架提供了两个遍历接口： `Iterator` 和 `ListIterator` ，其中后者是前者的 `优化版` ，支持在任意一个位置进行**前后双向遍历**。注意图中的 `Collection` 应当继承的是 `Iterable` 而不是 `Iterator` ，后面会解释 `Iterable` 和 `Iterator` 的区别\n2. 整个集合框架分为两个门派（类型）：`Collection` 和 `Map`，前者是一个容器，存储一系列的**对象**；后者是键值对`<key,value>`，存储一系列的**键值对**\n3. 在集合框架体系下，衍生出四种具体的集合类型：`Map`、`Set`、`List`、`Queue`\n4. `Map` 存储 `<key,value>` 键值对，查找元素时通过 `key` 查找 `value`\n5. `Set` 内部存储一系列**不可重复**的对象，且是一个**无序**集合，对象排列顺序不一\n6. `List` 内部存储一系列**可重复**的对象，是一个**有序**集合，对象按插入顺序排列\n7. `Queue` 是一个队列容器，其特性与 `List` 相同，但只能从 `对头` 和 `队尾` 操作元素\n8. JDK为集合的各种操作提供了两个工具类 `Collections` 和 `Arrays` ，之后会讲解工具类的常用方法\n9. 四种抽象集合类型内部也会衍生出许多具有不同特性的集合类，**不同场景下择优使用，没有最佳的集合**\n\n### 集合与数组的区别\n\n- **长度区别：**\n  - 数组固定\n  - 集合可变\n- **内容区别：**\n  - 数组可以是基本类型，也可以是引用类型\n  - 集合只能是引用类型\n- **元素区别：**\n  - 数组只能存储同一种类型\n  - 集合可以存储不同类型（其实集合一般也是存储同一种类型）\n\n### 二、Iterator Iterable ListIterator\n\n`Iterator` 和 `Iterable`，在第一次看这两个接口时，真以为是一摸一样的，没发现里面有啥不同，**存在即合理**，它们两个还是有本质区别的。\n\n首先来看 `Iterator` 接口：\n\n```java\npublic interface Iterator<E> {\n    boolean hasNext();\n    E next();\n    void remove();\n}\n```\n\n提供的API接口含义如下：\n\n- `hasNext()` ：判断集合中是否存在下一个对象\n- `next()` ：返回集合中的下一个对象，并将访问指针移动一位\n- `remove()` ：删除集合中调用 `next()` 方法返回的对象\n\n在早期，遍历集合的方式只有一种，通过 `Iterator` 迭代器操作：\n\n```java\nList<Integer> list = new ArrayList<>();\nlist.add(1);\nlist.add(2);\nlist.add(3);\nIterator<Integer> iterator = list.iterator();\nwhile (iterator.hasNext()){\n    Integer next = iterator.next();\n    System.out.println(next);\n    if(next==2){iterator.remove();}\n}\n```\n\n再来看 `Iterable` 接口：\n\n```java\npublic interface Iterable<T> {\n\tIterator<T> iterator();\n    // JDK1.8\n    default void forEach(Consumer<? super T> action) {\n        Objects.requireNonNull(action);\n        for (T t : this) {\n            action.accept(t);\n        }\n    }\n}\n```\n\n可以看到 `Iterable` 接口里面提供了 `Iterator` 接口，所以实现了 `Iterable` 接口的集合依旧可以使用 `迭代器` 遍历和操作集合中的对象；\n\n而在 `JDK1.8` 中， `Iterable` 提供了一个新的方法 `forEach()` ，它允许使用增强 for 循环遍历对象。\n\n```java\nList<Integer> list = new ArrayList<>();\nfor(Integer num : list){\n    System.out.println(num);\n}\n```\n\n我们通过反编译上面这段代码，发现它只是 Java 中的一个 `语法糖` ，本质上还是调用 `Iterator` 去遍历。\n\n```java\nIterator iter = list.iterator();\nwhile(iter.hasNext()){\n    Integer num = iter.next();\n    System.out.println(num);\n}\n```\n\n> 为什么要设计两个接口 `Iterable` 和 `Iterator` ，而不是保留其中一个就可以了。\n>\n> 简单来说：`Iterator` 的保留可以让子类去实现自己的迭代器，而 `Iterable` 接口更加关注与 `for-each` 的增强语法。\n\n**总结：**\n\n- `Iterator` 是提供集合操作内部对象的一个迭代器，它可以 **遍历** 、**移除** 对象，且只能够 **单向移动**\n-  `Iterable` 是对 `Iterator` 的封装，在`JDK 1.8` 时，实现了 `Iterable` 接口的结合可以使用 **增强 for 循环** 遍历集合对象，我们通过 **反编译** 后发现底层还是使用 `Iterator` 迭代器进行遍历\n\n等等，这一章还没完，还有一个 `ListIterator`。它继承 Iterator 接口，在遍历 `List` 集合时可以从 **任意索引下标** 开始遍历，而且支持 **双向遍历**\n\n ListIterator 存在于 List 集合之中，通过调用方法可以返回 **起始下标** 为 `index` 的迭代器：\n\n```java\nList<Integer> list = new ArrayList<>();\n//返回下标为0的迭代器\nListIterator<Integer> listIter1 = list.listIterator();\n//返回下标为5的迭代器\nListIterator<Integer> listIter2 = list.listIterator(5);\n```\n\nListIterator 中有几个重要方法，大多数方法与 Iterator 中定义的含义相同，但是 Iterator 强大的地方是可以在 **任意一个下标位置** 返回该迭代器，且可以实现 **双向遍历**。\n\n  ```java\n  public interface ListIterator<E> extends Iterator<E> {\n      boolean hasNext();\n      E next();\n      boolean hasPrevious();\n      E previous();\n      int nextIndex();\n      int previousIndex();\n      void remove();\n      // 替换当前下标的元素，即访问过的最后一个元素\n      void set(E e);\n      void add(E e);\n  }\n  ```\n\n## Map 和 Collection 接口\n\n![image-20210530093758757](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530093805.png)\n\n`Map` 接口定义了存储的数据结构是 `<key,value>` 形式，根据 key 映射到 value，一个 key 对应一个 value，所以 `key` 不可重复，而 `value` 可重复。\n\n在 `Map` 接口下会将存储的方式细分为不同的种类：\n\n- `SortedMap` 接口：该接口映射可以对 `<key,value>` 按照自己的规则进行 **排序**，具体实现有 TreeMap \n- `AbstractMap` 类：它为子类提供好一些 **通用的API实现**，所有的具体 Map 如 `HashMap` 都会继承它\n\n而 `Collection` 接口提供了所有集合的 **通用方法**（注意这里不包括 `Map`）：\n\n- 添加方法：`add(E e)` / `addAll(Collection<? extends E> c)`\n- 删除方法：`remove(Object o)` / `removeAll(Collection<?> c)`\n- 查找方法：`contains(Object o)` / `containsAll(Collection<?> c)`\n- 查询集合自身信息；`size()` /  `isEmpty()`\n- ···\n\n在 `Collection` 接口下，同样会将集合细分为不同的种类：\n\n- `Set` 接口：一个**不允许存储重复元素**的**无序**集合，具体实现有 `HashSet` / `TreeSet` ···\n- `List` 接口：一个**可存储重复元素**的**有序**集合，具体实现有 `ArrayList` / `LinkedList` ···\n- `Queue` 接口：一个**可存储重复元素**的**队列**，具体实现有 `PriorityQueue` / `ArrayDeque` ···\n\n## Map 集合体系详解\n\n`Map` 接口时由 `<key,value>` 组成的集合，由 `key` 映射到**唯一**的 `value`，所以 `Map` 不能包含重复的 `key` ，每个键**至多**映射一个值。下图是整个 Map 集合体系的主要组成部分：\n\n![image-20210530122749775](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530122749.png)\n\n### HashMap \n\nHashMap 是一个 **最通用的** 利用哈希表存储元素的集合，将元素放入 HashMap 时，将 `key` 的哈希值转换为数组的 `索引` 下标 **确定存放位置**，查找时，根据 `key` 的哈希地址转换成数组的 `索引` 下标 **确定查找位置**。\n\nHashMap 底层是用数组 + 链表 + 红黑树这三种数据结构实现，它是 **非线程安全** 的集合。\n\n![image-20210530124731984](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530124732.png)\n\n发送哈希冲突时，HashMap 的解决方法是将相同映射地址的元素连成一条 `链表`，如果链表的长度大于 `8` 时，且数组的长度大于 `64` 则会转换成 `红黑树` 数据结构。\n\n 关于 HashMap 的简要总结：\n\n1. 它是集合中最常用的 `Map` 集合类型，底层由 `数组 + 链表 + 红黑树` 组成\n2. HashMap 不是线程安全的\n3. 插入元素时，通过计算元素的 `哈希值`，通过 **哈希映射函数** 转换为 `数组下标`；查找元素时，同样通过哈希映射函数得到数组下标 `定位元素的位置`\n\n### LinkedHashMap\n\nLinkedHashMap 可以看作是 `HashMap` 和 `LinkedList` 的结合：它在 HashMap 的基础上添加了一条双向链表，`默认` 存储各个元素的插入顺序，但由于这条双向链表，使得 LinkedHashMap 可以实现 `LRU` 缓存淘汰策略，因为我们可以设置这条双向链表按照 `元素的访问次序` 进行排序\n\n![image-20210530175812409](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530175812.png)\n\nLinkedHashMap 是 HashMap 的子类，所以它具备 HashMap 的所有特点，其次，它在 HashMap 的基础上维护了一条 `双向链表`，该链表存储了 **所有元素**，`默认` 元素的顺序与插入顺序 **一致**。若 `accessOrder` 属性为 `true` ，则遍历顺序按元素的访问次序进行排序。\n\n```java\n// 头节点\ntransient LinkedHashMap.Entry<K,V> head;\n// 尾节点\ntransient LinkedHashMap.Entry<K,V> tail;\n```\n\n利用 LinkedHashMap 可以实现 `LRU` 缓存淘汰策略，因为它提供了一个方法：\n\n```java\nprotected boolean removeEldestEntry(Map.Entry<K,V> eldest) {\n    return false;\n}\n```\n\n该方法可以移除 `最靠近链表头部` 的一个节点，而在 `get()` 方法中可以看到下面这段代码，起作用是挪动节点的位置：\n\n```java\nif (accessOrder){\n    afterNodeAccess(e);\n}      \n```\n\n只要调用了 `get()` 且 `accessOrder = true`，则会将该节点更新到链表 `尾部`，具体的逻辑在 `afterNodeAccess()` 中，感兴趣可翻看源码，这里不再展开：\n\n如果现在要实现一个 `LRU` 缓存策略，则需要做两件事：\n\n- 指定 `accessOrder = true` 可以设定链表按照访问顺序排列，通过提供的构造器可以设定 `accessOrder`\n\n```java\npublic LinkedHashMap(int initialCapacity,float loadFactor,boolean accessOrder) {\n    super(initialCapacity, loadFactor);\n    this.accessOrder = accessOrder;\n}\n```\n\n- 重写 `removeEldestEntry()` 方法，内部定义逻辑，通常是判断 `容量` 是否达到上限，若是则执行淘汰。\n\n>[LeetCode146——LRU缓存机制](https://blog.csdn.net/qq_41231926/article/details/86173740)\n\n-关于 LinkedHashMap 主要介绍两点：\n\n1. 它底层维护了一条 `双向链表`，因为继承了 HashMap，所以它也不是线程安全的\n2. LinkedHashMap 可实现 `LRU` 缓存淘汰策略，其原理是通过设置 `accessOrder` 为 `true` 并重写 `removeEldestEntry` 方法定义淘汰元素时需满足的条件\n\n### TreeMap\n\nTreeMap 的底层实现是红黑树！\n\n![image-20210530183425914](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530183426.png)\n\nTreeMap 是 `SortedMap` 的子类，所以它具有 排序 功能。它是基于 红黑树 数据结构实现的，每一个键值对 `<key,value>` 都是一个节点，默认情况下按照 `key` 自然排序，另一种是可以通过传入定制的 `Comparator` 进行自定义规则排序\n\n图中红黑树的每一个节点都是一个 `Entry` ，在这里为了图片的简洁性，就不标明 key 和 value 了，注意这些元素都是已经按照 `key` 排好序了，整个数据结构都是保持着 `有序` 的状态！\n\n关于 `自然` 排序与 `定制` 排序：\n\n- 自然排序：要求 `key` 必须实现 `Comparable` 接口。\n\n由于 `Integer` 类实现了 Comparable 接口，按照自然排序规则是按照 `key` 从小到大排序。\n\n```java\nTreeMap<Integer,String> treeMap = new TreeMap<>();\ntreeMap.put(2,\"TWO\");\ntreeMap.put(1,\"ONE\");\nSystem.out.print(treeMap);\n// {1=ONE,2=TWO}\n```\n\n- 定制排序：在初始化 TreeMap 时传入新的 `Comparator`，不要求 `key` 实现 Comparable 接口\n\n```java\nTreeMap<Integer,String> treeMap = new TreeMap<>((o1,o2) -> Integer.compare(o2,o1));\ntreeMap.put(2,\"TWO\");\ntreeMap.put(1,\"ONE\");\ntreeMap.put(3,\"Three\");\ntreeMap.put(4,\"Four\");\nSystem.out.print(treeMap);\n// {4=Four, 3=Three, 2=TWO, 1=ONE}\n```\n\n通过传入新的 `Comparator` 比较器，可以覆盖默认的排序规则，上面的代码按照 `key` 降序排序，在实际应用中还可以按照其它规则自定义排序。\n\n`compare()` 方法的返回值有三种，分别是：`0`，`-1`，`+1`\n\n（1）如果返回 `0` ，代表两个元素相等，不需要调换顺序\n\n（2）如果返回 `+1` ，代表前面的元素需要与后面的元素调换位置\n\n（3）如果返回 `-1` ，代表前面的元素不需要与后面的元素调换位置\n\n而何时返回 `+1` 和 `-1`，则由我们自己去定义，JDK默认是按照 **自然排序**，而我们可以根据 `key` 的不同去定义降序还是升序排序。\n\n关于 TreeMap 主要介绍了两点：\n\n1. 它底层是由 `红黑树` 这种数据结构实现的，所以操作的时间复杂度恒为 `0(logN)`\n2. TreeMap 可以对 `key` 进行自然排序或者自定义排序，自定义排序时需要传入 `Comparator`，而自然排序要求 `key`实现了 `Comparable` 接口\n3. TreeMap 不是线程安全的。\n\n### WeakHashMap\n\nWeakHashMap 日常开发中比较少见，它是基于普通的 `Map` 实现的，而里面 `Entry` 中的键在每一次的 `垃圾回收` 都会被清除掉，所以非常适合用于 **短暂访问**、**仅访问一次** 的元素，缓存在 `WeakHashMap` 中，并尽早地把它回收掉。\n\n当 `Entry` 被 `GC` 时，WeakHashMap 是如何感知到某个元素被回收的呢？\n\n在 WeakHashMap 内部维护了一个引用队列 `queue`\n\n```java\nprivate final ReferenceQueue<Object> queue = new ReferenceQueue<>();\n```\n\n这个 queue 里包含了所有被 `GC` 掉的键，当JVM开启 `GC` 后，如果回收掉 WeakHashMap 中的 key，会将 key 放入 queue 中，在 `expungeStaleEntries()` 中遍历 queue，把 queue 中的所有 `key` 拿出来，并在 WeakHashMap 中删除掉，以达到 **同步**。\n\n```java\nprivate void expungeStaleEntries() {\n    for (Object x; (x = queue.poll()) != null; ) {\n        synchronized (queue) {\n           // 删除 WeakHashMap 中的该键值对\n        }\n    }\n}\n```\n\n需要注意的是 WeakHashMap 底层存储的元素的数据结构是 `数组 + 链表`，**没有红黑树**哦，可以换一个角度想，如果还有红黑树，那干脆直接继承 HashMap ，然后再扩展不就行了，然而它并没有这样做：\n\n```java\npublic class WeakHashMap<K,V> extends AbstractMap<K,V> implements Map<K,V> {\n    \n}\n```\n\n所以，WeakHashMap 的数据结构图如下：\n\n![image-20210530211807636](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530211807.png)\n\n图中被虚线标识的元素将会在下一次访问 WeakHashMap 时删除掉，WeakHashMap 内部会做好一系列的调整工作，所以记住队列的作用就是标志那些已经被 `GC` 回收掉的元素。\n\n关于 WeakHashMap 需要注意两点：\n\n1. 它的键是一种 `弱键`，放入 WeakHashMap 时，随时会被回收掉，所以不能确保某次访问元素一定存在\n2. 它依赖普通的 `Map` 进行实现，是一个非线程安全的集合\n3. WeakHashMap 通常作为 **缓存** 使用，适用存储那些 `只需访问一次`、或 `只需保存短暂时间` 的键值对\n\n### HashTable\n\nHashTable 底层的存储结构是 `数组 + 链表`，而它是一个 **线程安全** 的集合，但是因为这个线程安全，它就被淘汰掉了。\n\n![image-20210530213300809](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530213300.png)\n\n> 这幅图是否有点眼熟呢哈哈哈，其实本质上就是 WeakHashMap 的底层存储结构。那么为什么 WeakHashMap 不继承 HashTable 呢？HashTable 的 `性能` 在并发环境下是非常差的，在非并发环境下可以用 `HashMap` 更优。\n\nHashTable 本质上是 HashMap 的前辈，它被淘汰的原因也主要因为两个字：**性能**\n\nHashTable 是一个 **线程安全** 的Map，它所有的方法都被加上了 **synchronized** 关键字，也是因为这个关键字，它注定成为了时代的弃儿。\n\nHashTable 底层采用 数组+链表 存储键值对，由于被弃用，后人也没有对它进行任何改进\n\nHashTable 默认长度为 `11`，负载因子为 `0.75f`，即元素个数达到数组长度的 75% 时，会进行一次扩容，每次扩容为原来数组长度的 `2` 倍\n\nHashTable 所有的操作都是线程安全的。\n\n## Collection 集合体系详解\n\n![image-20210530222444963](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530222445.png)\n\n### Set 接口\n\n`Set` 接口继承了 `Collection` 接口，是一个不包括重复元素的集合，更确切地说，Set 中任意两个元素不会出现 `o1.equals(o2)`，而且 Set **至多** 只能存储一个 `NULL` 值元素，Set 集合的组成部分可以用下面这张图概括：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210530225016.png\" alt=\"image-20210530225016622\" style=\"zoom: 50%;\" />\n\n在 Set 集合体系中，我们需要关注两点：\n\n- 存入 **可变元素** 时，必须非常小心，因为任意时候元素状态的改变都有可能使得 Set 内部出现两个 **相等** 的元素，即 `o1.equals(o2) = true`，所以一般不要更改存入 Set 中的元素，否则将会破坏了 `equals()`  的作用！\n- Set 的最大作用就是判重，在项目中的最大的作用也是 **判重**！\n\n接下来我们来分析它的实现类和子类：`AbstractSet` 和 `SortedSet`\n\n#### AbstractSet 抽象类\n\n`AbstractSet` 是一个实现 Set 的一个抽象类，定义在这里的方法可以将所有具体 Set 集合的 **相同行为** 在这里实现，**避免子类包含大量的重复代码**\n\n所有的 Set 也应该要有相同的 `hashCode()` 和 `equals()` 方法，所以使用抽象类把该方法重写后，子类就无需关心这两个方法。\n\n```java\npublic abstract class AbstractSet<E> implements Set<E> {\n    // 判断两个 set 是否相等\n    public boolean equals(Object o) {\n        if (o == this) // 集合本身\n            return true;\n\n        if (!(o instanceof Set)) // 集合不是 set\n            return false;\n        Collection<?> c = (Collection<?>) o; // 比较两个集合中的元素是否全部相同\n        if (c.size() != size())\n            return false;\n        try {\n            return containsAll(c);\n        } catch (ClassCastException unused)   {\n            return false;\n        } catch (NullPointerException unused) {\n            return false;\n        }\n    }\n    \n    // 计算所有元素的 hashcode 总和\n    public int hashCode() {\n        int h = 0;\n        Iterator<E> i = iterator();\n        while (i.hasNext()) {\n            E obj = i.next();\n            if (obj != null)\n                h += obj.hashCode();\n        }\n        return h;\n    }\n   \n}\n```\n\n#### SortedSet 接口\n\n`SortedSet` 是一个接口，它在 Set 的基础上扩展了 **排序** 的行为，所以所有实现它的子类都会拥有排序功能。\n\n```java\npublic interface SortedSet<E> extends Set<E> {\n\t// 元素的比较器，决定元素的排列顺序\n    Comparator<? super E> comparator();\n\t// 获取 [from,to] 之间的 set\n    SortedSet<E> subSet(E fromElement, E toElement);\n\t// 获取以 to 开头的 set\n    SortedSet<E> headSet(E toElement);\n    // 获取以 from 结尾的 set\n    SortedSet<E> tailSet(E fromElement);\n    // 获取首个元素\n    E first();\n\t// 获取最后一个元素\n    E last();\n}\n```\n\n#### HashSet\n\nHashSet 底层是借助 `HashMap` 实现，我们可以观察它的多个构造方法，本质上都是 new 一个 HashMap\n\n> 这也是为什么我们先学习 Map 的原因！先学 Map ，再学 Set，有助于理解 Set ！\n\n```java\npublic class HashSet<E> extends AbstractSet<E> implements Set<E>, Cloneable, java.io.Serializable\n{\n    public HashSet() {\n        map = new HashMap<>();\n    }\n    public HashSet(int initialCapacity, float loadFactor) {\n        map = new HashMap<>(initialCapacity, loadFactor);\n    }\n    public HashSet(int initialCapacity) {\n        map = new HashMap<>(initialCapacity);\n    }\n}\n```\n\n我们可以观察 `add()` 和 `remove()` 方法是如何将 HashSet 的操作嫁接到 HashMap 上的\n\n```java\nprivate static final Object PRESENT = new Object();\n\npublic boolean add(E e) {\n    return map.put(e, PRESENT)==null;\n}\npublic boolean remove(Object o) {\n    return map.remove(o)==PRESENT;\n}\n```\n\n我们看到 `PRESENT` 就是一个 **静态常量** ：使用 PRESENT 作为 HashMap 的 value 值，使用 HashSet 的开发者只需要 **关注**  插入的 `key`，**屏蔽** 了 HashMap 的 `value`\n\n![image-20210602103912091](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210602103919.png)\n\n上图可以观察到每个 `Entry` 的 `value` 都是 PRESENT 空对象，我们就不用理会它了。\n\nHashSet  在 HashMap 基础上实现，所以很多地方可以联系到 HashMap：\n\n- 底层数据结构：HashSet 也是采用 `数组 + 链表 + 红黑树` 实现\n- 线程安全性：由于采用 HashMap 实现，而 HashMap 本身线程不安全，在 HashSet 中又没有额外添加同步策略，所以 HashSet 也 **线程不安全**\n- 存入 HashSet 的对象的状态 **最好不要发生变化**，因为有可能改变状态后，在集合内部出现两个元素 `o1.equals(o2) == true`，破坏了 `equals` 的含义。\n\n#### LinkedHashSet \n\nLinkedHashSet 的代码很少，不信我给你粘出来：\n\n```java\npublic class LinkedHashSet<E>\n    extends HashSet<E>\n    implements Set<E>, Cloneable, java.io.Serializable {\n\n    private static final long serialVersionUID = -2851667679971038690L;\n\n    public LinkedHashSet(int initialCapacity, float loadFactor) {\n        super(initialCapacity, loadFactor, true);\n    }\n\n    public Link\tedHashSet(int initialCapacity) {\n        super(initialCapacity, .75f, true);\n    }\n\n    public LinkedHashSet() {\n        super(16, .75f, true);\n    }\n\n    public LinkedHashSet(Collection<? extends E> c) {\n        super(Math.max(2*c.size(), 11), .75f, true);\n        addAll(c);\n    }\n\n    @Override\n    public Spliterator<E> spliterator() {\n        return Spliterators.spliterator(this, Spliterator.DISTINCT | Spliterator.ORDERED);\n    }\n}\n```\n\n代码少归少，还是得分析一下，`LinkedHashSet` 继承了 `HashSet`，我们跟随到父类 HashSet 的构造方法看看：\n\n```java\nHashSet(int initialCapacity, float loadFactor, boolean dummy) {\n    map = new LinkedHashMap<>(initialCapacity, loadFactor);\n}\n```\n\n发现父类中 map 的实现采用 `LinkedHashMap` ，这里注意不是 `HashMap` ，而 LinkedHashMap 底层又采用 HashMap + 双向链表 实现的，所以本质上 LinkedHashSet 还是使用 HashMap 实现的。\n\n> LinkedHashSet -> LinkedHashMap -> HashMap + 双向链表\n\n![image-20210602125701765](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210602125701.png)\n\n而 LinkedHashMap 是采用 `HashMap` + `双向链表` 实现的，这条双向链表中保存了元素的插入顺序。所以 LinkedHashSet 可以按照元素的插入顺序遍历元素，如果你熟悉 `LinkedHashMap` ，那么 LinkedHashSet 也就不在话下了。\n\n关于 LinkedHashSet 需要注意的几个地方：\n\n- 它继承于 `HashSet`，而 HashSet 默认是采用 HashMap 存储数据的，但是 LinkedHashSet 调用父类的构造方法初始化 map 时是 LinkedHashMap 而不是 HashMap \n- 由于 LinkedHashMap 不是线程安全的，且在 LinkedHashSet 中没有添加额外的同步策略，所以 LinkedHashSet 集合**也不是线程安全** 的\n\n#### TreeSet\n\nTreeSet 是基于 TreeMap 的实现，所以存储的元素是有序的，底层的数据结构是 `数组 + 红黑树`。\n\n![image-20210602131111383](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210602131111.png)\n\n而元素的排列顺序有 `2` 种，和 TreeMap 相同：自然排序和定制排序，常用的构造方法在下面已经展现出来了，TreeSet 默认使用自然排序，如果需要使用定制排序，需要传入 `Comparator`。\n\n```java\npublic TreeSet() {\n    this(new TreeMap<E,Object>());\n}\n\npublic TreeSet(Comparator<? super E> comparator) {\n    this(new TreeMap<>(comparator));\n}\n```\n\n关于 TreeSet ，有几个值得注意的点：\n\n- TreeSet 的所有操作都会转换为对 TreeMap 的操作，TreeMap 采用 **红黑树** 实现，任意操作的 **时间复杂度** 为 `0(logN)`\n- TreeSet 是一个 **线程不安全** 的集合\n\n- TreeSet 常用于对 **不重复** 的元素 **定制排序**，如玩家战斗力排行榜\n\n> 注意：TreeSet 判断元素是否重复的方法是判断 **compareTo()** 方法是否返回0，而不是调用 **hashCode()** 和 **equals()** 方法，如果返回 0 则认为集合内已存在相同的元素，不会再加入到集合当中。\n\n### List 接口\t\n\nList 接口和 Set 接口齐头并进，是我们日常开发过程中接触很多的一种集合类型了。整个 List 集合的组成部分如下图：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210602133220.png\" alt=\"image-20210602133220362\" style=\"zoom:50%;\" />\n\n`List` 接口直接继承于 Collection 接口，它定义为可以存储 **重复** 元素的集合，并且元素按照插入顺序 **有序排列**，且可以通过 **索引**访问指定位置的元素。常见的实现有：ArrayList、linkedList、Vector 和 Stack\n\n#### AbstractList 和 AbstractSequentialList\n\nAbstractList 抽象类实现了 List 接口，其内部实现了所有的 List 都需具备的功能，子类可以专注于实现自己具体的操作逻辑。\n\n```java\n// 查找元素 o 第一次出现的位置\npublic int indexOf(Object o) {\n    ListIterator<E> it = listIterator();\n    if (o==null) {\n        while (it.hasNext())\n            if (it.next()==null)\n                return it.previousIndex();\n    } else {\n        while (it.hasNext())\n            if (o.equals(it.next()))\n                return it.previousIndex();\n    }\n    return -1;\n}\n\n// 查找元素 o 最后一次出现的位置\n public int lastIndexOf(Object o) {\n     ListIterator<E> it = listIterator(size());\n     if (o==null) {\n         while (it.hasPrevious())\n             if (it.previous()==null)\n                 return it.nextIndex();\n     } else {\n         while (it.hasPrevious())\n             if (o.equals(it.previous()))\n                 return it.nextIndex();\n     }\n     return -1;\n }\n```\n\nAbstractSequentialList 抽象类继承了 AbstractList ，在原基础上限制了访问元素的顺序 **只能够按照顺序访问**，而 **不支持随机访问**，如果需要满足随机访问的特性，则继承 AbstractList。子类 LinkedList 使用链表实现，所以仅能支持 **顺序访问**，故继承了 `AbstractSequentialList` 而不是 AbstractList。\n\n#### Vector\n\n![image-20210602140414443](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210602140414.png)\n\n`Vector` 在现在已经是一种过时的集合了，包括继承它的 `Stack` 集合也是如此，它们被淘汰的原因都是因为 **性能** 低下。\n\n> JDK 1.0 时代，ArrayList 还没诞生，大家都是使用 Vector 集合，但由于 Vector 的 **每个操作** 都被 **synchronized** 关键字修饰，即使在线程安全的情况下， 仍然 **进行着无意义的加锁/释放锁**，造成额外的性能开销，做了无用功。\n\n```java\npublic synchronized boolean add(E e);\npublic synchronized E get(int index);\n```\n\n在 JDK 1.2 时，Collection 家族出现了，它提供了大量 **高性能、适用于不同场合** 的集合，而 Vector 也是其中一员，但由于 Vector 在每个方法上都加了锁，并且需要兼容许多的老项目，很难在这基础上优化 `Vector` 了，所以渐渐地也就被历史淘汰了。\n\n现在，在 **线程安全** 的情况下，不要选用 Vector 集合，取而代之的是 **ArrayList** 集合；在并发环境下，出现了 `CopyOnWriteArrayList`，Vector 被完全弃用了。\n\n#### Stack\n\n![image-20210602142433141](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210602142433.png)\n\n`Stack` 是一种 `后入先出（LIFO）` 型的集合容器，如图所示，`大雄` 是最后一个进入容器的，top 指针指向大雄，那么弹出元素时，大雄也是第一个被弹出去的。\n\nStack 继承了 Vector 类，提供了栈顶的压入元素操作（push）和弹出元素（pop），以及查看栈顶元素（peek）等等，但由于继承于 Vector，Stack 也渐渐被淘汰了。\n\n取而代之的是后起之秀 `Deque` 接口，其实现有 `ArrayDeque`，该数据结构更加完善，可靠性更好，依靠队列也可以实现 `LIFO` 的栈操作，所以优先选择 ArrayDeque 实现栈。\n\n```java\nDeque<Integer> stact = new ArrayDeque<Integer>();\n```\n\nArrayDeque 的数据结构是：`数组` ，并提供 **头尾指针下标** 对数组元素进行操作。本文也会在接下来的内容中讲到，请接着往下看！\n\n#### ArrayList\n\nArrayList 以 **数组** 作为存储结构，它是 **线程不安全** 的集合；具有 **查询快、在数组中或头部增删慢** 的特点，所以它除了线程不安全这一点，其余可以替代 `Vector` ，而且线程安全的 ArrayList 可以使用 `CopyOnWriteArrayList` 代替 Vector。\n\n![image-20210603085732114](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210603085739.png)\n\n关于 ArrayList 有几个重要的点需要注意：\n\n- 具有 **随机访问** 特点，**访问元素的效率** 较高，ArrayList 在 **频繁插入、删除** 集合元素的场景下效率较 `低`\n- 底层数据结构：ArrayList 底层是使用数组作为存储结构，具有 **查找快、增删慢** 的特点\n- 线程安全性：ArrayList 是 **线程不安全** 的集合\n- ArrayList **首次扩容** 后的长度为 `10`，调用 `add()` 时需要将计算容器 的最小容量。可以看到如果数组 `elementData` 为空数组，会将最小容量设置为 `10`，之后会将数组长度完成首次扩容到 10。\n\n```java\n// new ArrayList 时的默认空数组\nprivate static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};\n// 默认容量\nprivate static final int DEFAULT_CAPACITY = 10;\n// 计算该容器满足的最小容量\nprivate void ensureCapacityInternal(int minCapacity) {\n    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {\n        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);\n    }\n    ensureExplicitCapacity(minCapacity);\n}\n\nprivate void ensureExplicitCapacity(int minCapacity) {\n    modCount++;\n\n    // overflow-conscious code\n    if (minCapacity - elementData.length > 0)\n        grow(minCapacity);\n}\n```\n\n- 集合从 **第二次扩容** 开始，数组长度将扩容为原来的 `1.5` 倍，即：`newLength = oldLength * 1.5`\n\n```java\nprivate void grow(int minCapacity) {\n    // overflow-conscious code\n    int oldCapacity = elementData.length;\n    int newCapacity = oldCapacity + (oldCapacity >> 1);\n    if (newCapacity - minCapacity < 0)\n        newCapacity = minCapacity;\n    if (newCapacity - MAX_ARRAY_SIZE > 0)\n        newCapacity = hugeCapacity(minCapacity);\n    // minCapacity is usually close to size, so this is a win:\n    elementData = Arrays.copyOf(elementData, newCapacity);\n}\n```\n\n#### LinkedList\n\nLinkedList 底层采用 `双向链表` 数据接口存储元素，由于链表的内存地址 `非连续`，所以它不具备随机访问的特点，但由于它利用指针连接各个元素，所以插入、删除元素只需要 `操作指针`，不需要 `移动元素`，故具有 **增删快、查询慢** 的特点。它也是一个非线程安全的集合。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210626130625.png\" alt=\"image-20210626130618786\"  />\n\n由于以双向链表作为数据结构，它是 **线程不安全** 的集合；存储的每个节点称为一个 `Node` ，下图可以看到 Node 中保存了 `next` 和 `prev` 指针，`item` 是该节点的值。在插入和删除时，时间复杂度都保持为 `0(1)`\n\n![image-20210626131638144](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210626131638.png)\n\n关于 LinkedList，除了它是以链表实现的集合外，还有一些特殊的地方需要注意：\n\n- 优势：LinkedList 底层没有 `扩容机制`，使用 `双向链表` 存储元素，所以插入和删除元素效率较高，适用于频繁操作元素的场景\n\n- 劣势：LinkedList 不具备 `随机访问` 的特点，查找某个元素只能从 `head` 或 `tail` 指针一个一个比较，所以 **查找中间元素是效率很低**\n\n- 查找优化：LinkedList 查找某个下标 `index` 的元素时做了优化，若 `index < (size / 2)`，则从 `head` 往后查找，否则从 `tail` 开始往前查找，代码如下所示：\n\n  ```java\n  Node<E> node(int index) {\n      if (index < (size >> 1)) { // 查找的下标处于链表的前半部分则从头开始找\n          Node<E> x = first;\n          for (int i = 0; i < index; i++)\n              x = x.next;\n          return x;\n      } else {  // 查找的下标处于链表的后半部分则从尾开始找\n          Node<E> x = last;\n          for (int i = size - 1; i > index; i--)\n              x = x.prev;\n          return x;\n      }\n  }\n  ```\n\n- 双端队列：使用双链表实现，并且实现了 `Deque` 接口，使得 LinkedList 可以用作 **双端队列** 。下图可以看到 Node 是集合中的元素，提供了前驱指针和后继指针，还提供了一系列操作 `头结点` 和 `尾结点` 的方法，具有双端队列的特性。\n\n  ![image-20210626133733427](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210626133733.png)\t\n\n### Queue 接口\n\n`Queue` 队列，在 JDK 中两种不同类型的集合实现： **单向队列**（AbstractQueue）和 **双端队列**（Deque）\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210626152155.png\" alt=\"image-20210626152154946\" style=\"zoom:80%;\" />\t\n\nQueue 中提供了两套增加、删除元素的 API，当插入或删除元素失败时，会有两种不同的失败处理策略。\n\n| 方法及失败策略 | 插入方法 | 删除方法 | 查找方法 |\n| -------------- | -------- | -------- | -------- |\n| 抛出异常       | add()    | remove() | get()    |\n| 返回失败默认值 | offer()  | poll()   | peek()   |\n\n选区哪种方法的决定因素：插入和删除元素失败时，希望 `抛出异常` 还是返回 `布尔值` \n\n`add()` 和 `offer()` 对比：\n\n在队列长度大小确定的场景下，队列放满元素后，添加下一个元素时，add() 会抛出 `IllegalStateException` 异常，而 `offer()` 会返回 `false`。\n\n但是他们两个方法在插入 **某些不合法的元素** 时会抛出三个相同的异常：\n\n![image-20210626153333747](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210626153333.png)\t\n\n`remove()` 和 `poll()` 对比：\n\n在 **队列为空** 的场景下：`remove()` 会抛出 `NoSuchElmentException` 异常，而 `poll()` 则返回 `null`。\n\n`get()` 和 `peek()` 对比：\n\n在队列为空的情况，`get()` 会抛出 `NoSuchElementException` 异常，而 `peek()` 则返回 `null`。\n\n### Deque 接口\n\n`Deque` 接口的实现非常好理解：从 **单向** 队列演变为 **双向** 队列，内部额外提供 **双向队列的操作方法** 即可：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210626161113.png\" alt=\"image-20210626161106057\" style=\"zoom:80%;\" />\t\n\nDeque 接口额外提供了 **针对队列的头结点和尾结点** 操作的方法，而 **插入、删除方法同样也提供了两套不同的失败策略**。\n\n除了 `add()` 和 `offer()` ，`remove()` 和 `poll()` 以外，还有 `get()` 和 `peek()` 出现了不同的策略\n\n#### AbstractQueue 抽象类\n\nAbstractQueue 类中提供了各个 API 的基本实现，主要针对各个不同的处理策略给出基本的方法实现，定义在这里的作用让 `子类` 根据其 `方法规范` （操作失败时抛出异常还是返回默认值）实现具体的业务逻辑。\n\n![image-20210626162155775](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210626162155.png)\t\n\n#### LinkedList \n\nLinkedList 在上面已经详细解释了，它实现了 `Deque` 接口，提供了针对头结点和尾结点的操作，并且每个结点都有 **前驱** 和 **后继** 指针，具备双向队列的所有特性。\n\n#### ArrayDeque\n\n使用 **数组** 实现的双端队列，它是 **无界** 的双端队列，最小的容量是 `8` （JDK1.8）。在 JDK11 之后看到它默认容量已经是 `16` 了。\n\n![image-20210702150909935](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210702150910.png)\n\n`ArrayDeque` 在日常使用得不多，值得注意的是它与 `LinkedList` 的对比：`LinkedList` 采用链表实现双端队列，而 `ArrayDeque` 使用 **数组** 实现双端队列。\n\n> 在文档中作者写到：ArrayDeque 作为栈时比 Stack 性能好，作为队列时比  LinkedList 性能好\n\n由于双端队列 **只能在头部和尾部** 操作元素，所以删除元素和插入元素的时间复杂度大部分都稳定在 `0(1)`，除非在扩容时会涉及到元素的批量复制操作。但是在大多数情况下，使用它应该指定一个大概的数组长度，避免频繁的扩容。\n\n#### PriorityQueue\n\nPriorityQueue 基于 **优先级堆实现** 的优先级队列，而堆是采用 **数组** 实现的：\n\n![image-20210702153102716](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210702153102.png)\n\n文档中的描述告诉我们：该数组中的元素通过传入 `Comparator` 进行定制排序，如果不传入 `Comparator` 时，则按照元素本身 `自然排序`，但要求元素实现了 `Comparable` 接口，所以 PriorityQueue  **不允许存储 NULL 元素**。\n\nPriorityQueue 应用场景：元素本身具有优先级，需要按照 **优先级处理元素** \n\nPriorityQueue 总结：\n\n- PriorityQueue 是基于 **优先级堆** 实现的优先级队列，而堆是用 **数组** 维护的\n- PriorityQueue 适用于 **元素按优先级处理** 的业务场景，例如用户在请求人工客服需要排队时，根据用户的 **VIP等级** 进行 `插队` 处理，等级越高，越先安排客服。\n\n各集合总结：（以 JDK1.8 为例）\n\n![image-20210702155305221](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210702155305.png)\n\n","tags":["技巧","笔记"],"categories":["后端开发"]},{"title":"Linux 系统基础","slug":"Linux系统基础","url":"/2021/06/23/15ddae98.html","content":"\n## 入门概述\n\n> 我们为什么要学习 Linux？\n\nlinux 诞生了这么多年，以前还喊着如何能取代 windows 系统，现在这个口号已经小多了，任何事物发展都有其局限性都有其天花板。就如同在国内再搞一个社交软件取代腾讯一样，想想而已基本不可能，因为用户已经习惯于使用微信交流，不是说技术上实现不了解而是老百姓已经习惯了，想让他们不用，即使他们自己不用亲戚朋友还是要用，没有办法的事情。\n\n用习惯了 windows 操作系统，再让大家切换到别的操作系统基本上是不可能的事情，改变一个人已经养成的习惯太难。没有办法深入到普通老百姓的生活中，并不意味着 linux 就没有用武之地了。在服务器端，在开发领域 linux 倒是越来越受欢迎，很多程序员都觉得不懂点 linux 都觉得不好意思，linux 在开源社区的地位依然岿然不动。\n\n尤其是作为一个后端程序员，是必须要掌握 Linux 的，因为这都成为了你找工作的基础门槛了，所以不得不学习！\n\n> Linux 简介\n\nLinux 内核最初只是由芬兰人林纳斯·托瓦兹（Linus Torvalds）在赫尔辛基大学上学时出于个人爱好而编写的。\n\nLinux 是一套免费使用和自由传播的类 Unix 操作系统，是一个基于 POSIX（可移植操作系统接口） 和 UNIX 的多用户、多任务、支持多线程和多 CPU 的操作系统。\n\nLinux 能运行主要的 UNIX 工具软件、应用程序和网络协议。它支持 32 位和 64 位硬件。Linux 继承了 Unix 以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。\n\n> Linux 发行版\n\nLinux 的发行版说简单点就是将 Linux 内核与应用软件做一个打包。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210421091705.jpeg)\n\n目前市面上较知名的发行版有：Ubuntu、RedHat、CentOS、Debian、Fedora、SuSE、OpenSUSE、Arch Linux、SolusOS 等。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210421091730.jpeg)\n\n> Linux 应用领域\n\n今天各种场合都有使用各种 Linux 发行版，从嵌入式设备到超级计算机，并且在服务器领域确定了地位，通常服务器使用 LAMP（Linux + Apache + MySQL + PHP）或 LNMP（Linux + Nginx+ MySQL + PHP）组合。\n\n目前 Linux 不仅在家庭与企业中使用，并且在政府中也很受欢迎。\n\n- 巴西联邦政府由于支持 Linux 而世界闻名。\n- 有新闻报道俄罗斯军队自己制造的 Linux 发布版的，做为 G.H.ost 项目已经取得成果。\n- 印度的 Kerala 联邦计划在向全联邦的高中推广使用 Linux。\n- 中华人民共和国为取得技术独立，在龙芯处理器中排他性地使用 Linux。\n- 在西班牙的一些地区开发了自己的 Linux 发布版，并且在政府与教育领域广泛使用，如 Extremadura 地区的 gnuLinEx 和 Andalusia 地区的 Guadalinex。\n- 葡萄牙同样使用自己的 Linux 发布版 Caixa Mágica，用于 Magalh?es 笔记本电脑和 e-escola 政府软件。\n- 法国和德国同样开始逐步采用 Linux。\n\n> Linux VS Windows\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210421092008.jpeg)\n\n## 环境搭建\n\n省略...\n\n## 走进 Linux 系统\n\n> 开机登录\n\n开机会启动许多程序。它们在 Windows 叫做\"服务\"（service），在 Linux 就叫做\"守护进程\"（daemon）。\n\n开机成功后，它会显示一个文本登录界面，这个界面就是我们经常看到的登录界面，在这个登录界面中会提示用户输入用户名，而用户输入的用户将作为参数传给 login 程序来验证用户的身份，密码是不显示的，输完回车即可！\n\n一般来说，用户的登录方式有三种：\n\n- 命令行登录\n- ssh 登录\n- 图形界面登录\n\n最高权限账户为 root，可以操作一切！\n\n> 关机\n\n在 linux 领域内大多用在服务器上，很少遇到关机的操作。毕竟服务器上跑一个服务是永无止境的，除非特殊情况下，不得已才会关机。\n\n关机指令为：shutdown：\n\n```bash\nsync # 将数据由内存同步到硬盘中。\n\nshutdown # 关机指令，你可以man shutdown 来看一下帮助文档。例如你可以运行如下命令关机：\n\nshutdown –h 10 # 这个命令告诉大家，计算机将在10分钟后关机\n\nshutdown –h now # 立马关机\n\nshutdown –h 20:25 # 系统会在今天20:25关机\n\nshutdown –h +10 # 十分钟后关机\n\nshutdown –r now # 系统立马重启\n\nshutdown –r +10 # 系统十分钟后重启\n\nreboot # 就是重启，等同于 shutdown –r now\n\nhalt # 关闭系统，等同于shutdown –h now 和 poweroff\n```\n\n最后总结一下，不管是重启系统还是关闭系统，首先要运行 **sync** 命令，把内存中的数据写到磁盘中。\n\n> 系统目录结构\n\n登录系统后，在当前命令窗口下输入命令：\n\n```bash\nls /\n```\n\n你会看到如下图所示：\n\n本地虚拟机：\n\n![image-20210421095447557](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210421095447.png)\n\n云服务器：\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210421095548.png)\n\n树状目录结构：（Linux 的一切资源都挂载在这个 / 根节点下）\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210421095524.jpeg)\n\n**以下是对这些目录的解释：**\n\n- `/bin`：bin 是 Binary 的缩写, 这个目录存放着最经常使用的命令。\n- `/boot`： 这里存放的是启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。\n- `/dev` ： dev 是 Device(设备)的缩写, 存放的是 Linux 的外部设备，在 Linux 中访问设备的方式和访问文件的方式是相同的。\n- ==`/etc`： 这个目录用来存放所有的系统管理所需要的配置文件和子目录。==\n- ==`/home`：用户的主目录，在 Linux 中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。==\n- `/lib`：这个目录里存放着系统最基本的动态连接共享库，其作用类似于 Windows 里的 DLL 文件。\n- `/lost+found`：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。\n- `/media`：linux 系统会自动识别一些设备，例如 U 盘、光驱等等，当识别后，linux 会把识别的设备挂载到这个目录下。\n- `/mnt`：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。\n- ==`/opt`：这是给主机额外安装软件所摆放的目录。比如你安装一个 ORACLE 数据库则就可以放到这个目录下。默认是空的。==\n- `/proc`：这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。\n- ==`/root`：该目录为系统管理员，也称作超级权限者的用户主目录。==\n- `/sbin`：s 就是 Super User 的意思，这里存放的是系统管理员使用的系统管理程序。\n- `/srv`：该目录存放一些服务启动之后需要提取的数据。\n- `/sys`：这是 linux2.6 内核的一个很大的变化。该目录下安装了 2.6 内核中新出现的一个文件系统 sysfs 。\n- ==`/tmp`：这个目录是用来存放一些临时文件的。==\n- ==`/usr`：这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于 windows 下的 program files 目录。==\n- `/usr/bin`： 系统用户使用的应用程序。\n- `/usr/sbin`： 超级用户使用的比较高级的管理程序和系统守护程序。\n- `/usr/src`： 内核源代码默认的放置目录。\n- ==`/var`：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。==\n- `/run`：是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。\n- `/www`：存放服务器网站相关的资源，环境，网站的项目\n\n## 常用的基本命令\n\n### 目录管理\n\n> 绝对路径、相对路径\n\n我们知道 Linux 的目录结构为树状结构，最顶级的目录为根目录 /。\n\n其他目录通过挂载可以将它们添加到树中，通过解除挂载可以移除它们。\n\n在开始本教程前我们需要先知道什么是绝对路径与相对路径。\n\n常用的：\n\n- `cd`：切换目录命令\n- `./`：当前目录\n- `cd ..`：返回上一级目录\n\n**绝对路径：**\n\n路径的写法，由根目录 / 写起，例如：/usr/share/doc 这个目录。\n\n**相对路径：**\n\n路径的写法，不是由 / 写起，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写成：cd ../man 这就是相对路径的写法啦！\n\n> 处理目录的常用命令\n\n接下来我们就来看几个常见的处理目录的命令吧：\n\n- `ls`: 列出目录\n- `cd`：切换目录\n- `pwd`：显示目前的目录\n- `mkdir`：创建一个新的目录\n- `rmdir`：删除一个空的目录\n- `cp`: 复制文件或目录\n- `rm`: 移除文件或目录\n- `mv`: 移动文件与目录，或修改文件与目录的名称\n\n你可以使用 _man [命令]_ 来查看各个命令的使用文档，如 ：man cp。\n\n> ls - 列出目录\n\n在 Linux 系统当中， ls 命令可能是最常被运行的。\n\n语法：\n\n```shell\n[root@www ~]# ls [-aAdfFhilnrRSt] 目录名称\n```\n\n选项与参数：\n\n- **-a** ：全部的文件，连同隐藏文件( 开头为 . 的文件) 一起列出来(常用)\n- **-l** ：长数据串列出，包含文件的属性与权限等等数据；(常用)\n\n将目录下的所有文件列出来(含属性与隐藏档)\n\n```bash\n[root@www ~]# ls -al ~\n```\n\n> cd - 切换目录\n\ncd 是 Change Directory 的缩写，这是用来变换工作目录的命令。\n\n语法：\n\n```bash\ncd [相对路径或绝对路径]\n```\n\n> pwd - 显示当前所在的目录\n\npwd 是 **Print Working Directory** 的缩写，也就是显示目前所在目录的命令。\n\n```bash\n[root@kuangshen kuangstudy]#pwd [-P]\n```\n\n> mkdir - 创建新目录\n\n如果想要创建新的目录的话，那么就使用 mkdir (make directory)吧。\n\n```bash\nmkdir [-mp] 目录名称\n```\n\n选项与参数：\n\n- **-m** ：配置文件的权限喔！直接配置，不需要看默认权限 (umask) 的脸色～\n- **-p** ：帮助你直接将所需要的目录(包含上一级目录)递归创建起来！\n\n> rmdir - 删除空目录\n\n语法：\n\n```bash\n rmdir [-p] 目录名称\n```\n\n选项与参数：**-p ：**连同上一级『空的』目录也一起删除\n\n注意：这个 rmdir 仅能删除空的目录，你可以使用 rm 命令来删除非空目录，后面我们会学到！\n\n> cp - 复制文件或目录\n\n语法：\n\n```bash\n[root@www ~]# cp [-adfilprsu] 来源档(source) 目标档(destination)\n[root@www ~]# cp [options] source1 source2 source3 .... directory\n```\n\n选项与参数：\n\n- **-a**：相当於 -pdr 的意思，至於 pdr 请参考下列说明；(常用)\n- **-p**：连同文件的属性一起复制过去，而非使用默认属性(备份常用)；\n- **-d**：若来源档为连结档的属性(link file)，则复制连结档属性而非文件本身；\n- **-r**：递归持续复制，用於目录的复制行为；(常用)\n- **-f**：为强制(force)的意思，若目标文件已经存在且无法开启，则移除后再尝试一次；\n- **-i**：若目标档(destination)已经存在时，在覆盖时会先询问动作的进行(常用)\n- **-l**：进行硬式连结(hard link)的连结档创建，而非复制文件本身。\n- **-s**：复制成为符号连结档 (symbolic link)，亦即『捷径』文件；\n- **-u**：若 destination 比 source 旧才升级 destination ！\n\n> rm - 移除文件/目录\n\n语法：\n\n```bash\nrm [-fir] 文件或目录\n```\n\n选项与参数：\n\n- **-f** ：就是 force 的意思，忽略不存在的文件，不会出现警告信息；\n- **-i** ：互动模式，在删除前会询问使用者是否动作\n- **-r** ：递归删除啊！最常用在目录的删除了！这是非常危险的选项！！！\n\n> mv - 移动文件或目录/修改名称\n\n语法：\n\n```shell\n[root@www ~]# mv [-fiu] source destination\n[root@www ~]# mv [options] source1 source2 source3 .... directory\n```\n\n选项与参数：\n\n- **-f** ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖；\n- **-i** ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！\n- **-u** ：若目标文件已经存在，且 source 比较新，才会升级 (update)\n\n### 基本属性\n\n> 看懂文件属性\n\nLinux 系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限。为了保护系统的安全性，Linux 系统对不同的用户访问同一文件（包括目录文件）的权限做了不同的规定。\n\n在 Linux 中我们可以使用`ll`或者`ls –l`命令来显示一个文件的属性以及文件所属的用户和组，如：\n\n <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210421201636.png\" alt=\"image-20210421201636835\" style=\"zoom:67%;\" />\n\n实例中，boot 文件的第一个属性用\"d\"表示。\"d\"在 Linux 中代表该文件是一个目录文件。\n\n在 Linux 中第一个字符代表这个文件是目录、文件或链接文件等等：\n\n- **当为[ d ]则是目录**\n- **当为[ - ]则是文件**\n- **若是[ l ]则表示为链接文档 ( link file )**\n- 若是[ **b** ]则表示为装置文件里面的可供储存的接口设备 ( 可随机存取装置 )\n- 若是[ **c** ]则表示为装置文件里面的串行端口设备，例如键盘、鼠标 ( 一次性读取装置 )\n\n接下来的字符中，以三个为一组，且均为『rwx』 的三个参数的组合。\n\n其中，[ r ]代表可读(read)、[ w ]代表可写(write)、[ x ]代表可执行(execute)。\n\n要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已。\n\n每个文件的属性由左边第一部分的 10 个字符来确定（如下图）：\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210421224446.jpeg)\n\n从左至右用 0-9 这些数字来表示。\n\n第 0 位确定文件类型，第 1-3 位确定属主（该文件的所有者）拥有该文件的权限。第 4-6 位确定属组（所有者的同组用户）拥有该文件的权限，第 7-9 位确定其他用户拥有该文件的权限。\n\n其中：\n\n第 1、4、7 位表示读权限，如果用\"r\"字符表示，则有读权限，如果用\"-\"字符表示，则没有读权限；\n\n第 2、5、8 位表示写权限，如果用\"w\"字符表示，则有写权限，如果用\"-\"字符表示没有写权限；\n\n第 3、6、9 位表示可执行权限，如果用\"x\"字符表示，则有执行权限，如果用\"-\"字符表示，则没有执行权限。\n\n对于文件来说，它都有一个特定的所有者，也就是对该文件具有所有权的用户。\n\n同时，在 Linux 系统中，用户是按组分类的，一个用户属于一个或多个组。\n\n文件所有者以外的用户又可以分为文件所有者的同组用户和其他用户。\n\n因此，Linux 系统按文件所有者、文件所有者同组用户和其他用户来规定了不同的文件访问权限。\n\n在以上实例中，boot 文件是一个目录文件，属主和属组都为 root。\n\n> 修改文件属性\n\n**1、chgrp：更改文件属组**\n\n```bash\nchgrp [-R] 属组名 文件名\n```\n\n-R：递归更改文件属组，就是在更改某个目录文件的属组时，如果加上-R 的参数，那么该目录下的所有文件的属组都会更改。\n\n**2、chown：更改文件属主，也可以同时更改文件属组**\n\n```bash\nchown [–R] 属主名 文件名\nchown [-R] 属主名：属组名 文件名\n```\n\n==**3、chmod：更改文件 9 个属性**==\n\n```bash\nchmod [-R] xyz 文件或目录\n```\n\nLinux 文件属性有两种设置方法，一种是数字，一种是符号。\n\nLinux 文件的基本权限就有九个，分别是 owner/group/others 三种身份各有自己的 read/write/execute 权限。\n\n先复习一下刚刚上面提到的数据：文件的权限字符为：『-rwxrwxrwx』， 这九个权限是三个三个一组的！其中，我们可以使用数字来代表各个权限，各权限的分数对照表如下：\n\n```bash\nr:4      w:2         x:1\n```\n\n每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，例如当权限为：[-rwxrwx---] 分数则是：\n\n- owner = rwx = 4+2+1 = 7\n- group = rwx = 4+2+1 = 7\n- others= --- = 0+0+0 = 0\n\n```bash\nchmod 770 filename\n```\n\n### 文件内容查看\n\nLinux 系统中使用以下命令来查看文件的内容：\n\n- ==`cat` 由第一行开始显示文件内容==\n- `tac`从最后一行开始显示，可以看出 tac 是 cat 的倒着写！\n- ==`nl`显示的时候，顺道输出行号！==\n- `more`一页一页的显示文件内容（空格代表翻页，enter 代表向下看一行，:f 行号）\n- ==`less`与`more` 类似，但是比 `more`更好的是，他可以往前翻页！（空格翻页，上下键翻页，退出是 q 命令，查询字符串 / 要查询的字符串向下查询，向上查询使用 ? 要查询的字符串，n 向下寻找，N 向上寻找 ）==\n- `head`只看头几行 通过-n 参数来控制显示几行\n- `tail`只看尾巴几行\n\n你可以使用 *man [命令]*来查看各个命令的使用文档，如 ：`man cp`。\n\n> cat - 由第一行开始显示文件内容\n\n语法：\n\n```shell\ncat [-AbEnTv]\n```\n\n选项与参数：\n\n- -A ：相当於 -vET 的整合选项，可列出一些特殊字符而不是空白而已；\n- -b ：列出行号，仅针对非空白行做行号显示，空白行不标行号！\n- -E ：将结尾的断行字节 \\$ 显示出来；\n- -n ：列印出行号，连同空白行也会有行号，与 -b 的选项不同；\n- -T ：将 [tab] 按键以 ^I 显示出来；\n- -v ：列出一些看不出来的特殊字符\n\n> tac - 由最后一行开始显示文件内容\n\ntac 与 cat 命令刚好相反，文件内容从最后一行开始显示，可以看出 tac 是 cat 的倒着写！如：\n\n```shell\n[root@kuangshen ~]# tac /etc/sysconfig/network-scripts/ifcfg-eth0\nONBOOT=yes\nBOOTPROTO=dhcp\nDEVICE=eth0\n```\n\n> nl - 显示行号\n\n语法：\n\n```shell\nnl [-bnw] 文件\n```\n\n选项与参数：\n\n- -b ：指定行号指定的方式，主要有两种：-b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)；-b t ：如果有空行，空的那一行不要列出行号(默认值)；\n- -n ：列出行号表示的方法，主要有三种：-n ln ：行号在荧幕的最左方显示；-n rn ：行号在自己栏位的最右方显示，且不加 0 ；-n rz ：行号在自己栏位的最右方显示，且加 0 ；\n- -w ：行号栏位的占用的位数。\n\n> more - 一页一页翻动\n\n在 more 这个程序的运行过程中，你有几个按键可以按的：\n\n- 空白键 (space)：代表向下翻一页；\n- Enter ：代表向下翻『一行』；\n- /字串 ：代表在这个显示的内容当中，向下搜寻『字串』这个关键字；\n- :f ：立刻显示出档名以及目前显示的行数；\n- q ：代表立刻离开 more ，不再显示该文件内容。\n- b 或 [ctrl]-b ：代表往回翻页，不过这动作只对文件有用，对管线无用。\n\n> less - 一页一页翻动\n\nless 运行时可以输入的命令有：\n\n- 空白键 ：向下翻动一页；\n- [pagedown]：向下翻动一页；\n- [pageup] ：向上翻动一页；\n- /字串 ：向下搜寻『字串』的功能；\n- ?字串 ：向上搜寻『字串』的功能；\n- n ：重复前一个搜寻 (与 / 或 ? 有关！)\n- N ：反向的重复前一个搜寻 (与 / 或 ? 有关！)\n- q ：离开 less 这个程序；\n\n> head - 取出文件前面几行\n\n语法：\n\n```shell\nhead [-n number] 文件\n```\n\n选项与参数：**-n** 后面接数字，代表显示几行的意思！\n\n> tail - 取出文件后面几行\n\n语法：\n\n```shell\ntail [-n number] 文件\n```\n\n选项与参数：**-n** 后面接数字，代表显示几行的意思！\n\n> 拓展：Linux 链接的概念（了解即可）\n\nLinux 链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。\n\n情况下，ln 命令产生硬链接。\n\n**硬连接**\n\n硬连接指通过索引节点来进行连接。在 Linux 的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在 Linux 中，多个文件名指向同一索引节点是存在的。比如：A 是 B 的硬链接（A 和 B 都是文件名），则 A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号相同，即一个 inode 节点对应两个不同的文件名，两个文件名指向同一个文件，A 和 B 对文件系统来说是完全平等的。删除其中任何一个都不会影响另外一个的访问。\n\n硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。\n\n**软连接**\n\n另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于 Windows 的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。比如：A 是 B 的软链接（A 和 B 都是文件名），A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号不相同，A 和 B 指向的是两个不同的 inode，继而指向两块不同的数据块。但是 A 的数据块中存放的只是 B 的路径名（可以根据这个找到 B 的目录项）。A 和 B 之间是“主从”关系，如果 B 被删除了，A 仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。\n\n### Vim 编辑器\n\n> 什么是 Vim 编辑器\n\nVim 是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。\n\n简单的来说， vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。\n\nvim 则可以说是程序开发者的一项很好用的工具。\n\n所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定会存在。\n\n连 vim 的官方网站 (http://www.vim.org) 自己也说 vim 是一个程序开发工具而不是文字处理软件。\n\nvim 键盘图：\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210422001208.jpeg)\n\n> 三种使用模式\n\n基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。这三种模式的作用分别是：\n\n**命令模式：**\n\n用户刚刚启动 vi/vim，便进入了命令模式。\n\n此状态下敲击键盘动作会被 Vim 识别为命令，而非输入字符。比如我们此时按下 i，并不会输入一个字符，i 被当作了一个命令。\n\n以下是常用的几个命令：\n\n- **i** 切换到输入模式，以输入字符。\n- **x** 删除当前光标所在处的字符。\n- **:** 切换到底线命令模式，以在最底一行输入命令。（如果是编辑模式，需要先退出编辑模式`esc`）\n\n若想要编辑文本：启动 Vim，进入了命令模式，按下 i，切换到输入模式。\n\n命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。\n\n**输入模式：**\n\n在命令模式下按下 i 就进入了输入模式。\n\n在输入模式中，可以使用以下按键：\n\n- 字符按键以及 Shift 组合，输入字符\n- ENTER，回车键，换行\n- BACK SPACE，退格键，删除光标前一个字符\n- DEL，删除键，删除光标后一个字符\n- 方向键，在文本中移动光标\n- HOME/END，移动光标到行首/行尾\n- Page Up/Page Down，上/下翻页\n- Insert，切换光标为输入/替换模式，光标将变成竖线/下划线\n- ESC，退出输入模式，切换到命令模式\n\n**底线命令模式**\n\n在命令模式下按下:（英文冒号）就进入了底线命令模式。\n\n底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。\n\n在底线命令模式中，基本的命令有（已经省略了冒号）：\n\n- **q** 退出程序\n- **w** 保存文件\n\n按 ESC 键可随时退出底线命令模式。\n\n简单的说，我们可以将这三个模式想成底下的图标来表示：\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210422001803.jpeg)\n\n> Vim 按键说明\n\n除了上面简易范例的 i, Esc, :wq 之外，其实 vim 还有非常多的按键可以使用。\n\n### 账号管理\n\n> 简介\n\nLinux 系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。\n\n用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。\n\n每个用户账号都拥有一个唯一的用户名和各自的口令。\n\n用户在登录时键入正确的用户名和口令后，就能够进入系统和自己的主目录。\n\n实现用户账号的管理，要完成的工作主要有如下几个方面：\n\n- 用户账号的添加、删除与修改。\n- 用户口令的管理。\n- 用户组的管理。\n\n> 用户账号的管理\n\n用户账号的管理工作主要涉及到用户账号的添加、修改和删除。\n\n添加用户账号就是在系统中创建一个新账号，然后为新账号分配用户号、用户组、主目录和登录 Shell 等资源。\n\n> 添加账号 - useradd\n\n```bash\nuseradd 选项 用户名\n```\n\n参数说明：\n\n- 选项 :\n  - -c comment 指定一段注释性描述\n  - -d 目录 指定用户主目录，如果此目录不存在，则同时使用-m 选项，可以创建主目录\n  - -g 用户组 指定用户所属的用户组\n  - -G 用户组，用户组 指定用户所属的附加组\n  - -m 　使用者目录如不存在则自动建立\n  - -s Shell 文件 指定用户的登录 Shell\n  - -u 用户号 指定用户的用户号，如果同时有-o 选项，则可以重复使用其他用户的标识号\n- 用户名 :\n  - 指定新账号的登录名\n\n> 切换用户\n\n```bash\nsu username #username:需要切换的用户名\nsudo su #普通用户切换到root用户\n```\n\n1. 切换用户的命令为：su username 【username 是你的用户名哦】\n2. 从普通用户切换到 root 用户，还可以使用命令：sudo su\n3. 在终端输入 exit 或 logout 或使用快捷方式 ctrl+d，可以退回到原来用户，其实 ctrl+d 也是执行的 exit 命令\n4. 在切换用户时，如果想在切换用户之后使用新用户的工作环境，可以在 su 和 username 之间加-，例如：【su - root】\n\n==\\$ 表示普通用户==\n\n==#表示超级用户，也就是 root 用户==\n\n> 删除用户 - userdel\n\n如果一个用户的账号不再使用，可以从系统中删除。\n\n删除用户账号就是要将/etc/passwd 等系统文件中的该用户记录删除，必要时还删除用户的主目录。\n\n删除一个已有的用户账号使用 userdel 命令，其格式如下：\n\n```bash\nuserdel 选项 用户名\n```\n\n常用的选项是 **-r**，它的作用是把用户的主目录一起删除。\n\n```\n[root@kuangshen home]# userdel -r 用户名\n```\n\n此命令删除用户 kuangshen 在系统文件中（主要是/etc/passwd, /etc/shadow, /etc/group 等）的记录，同时删除用户的主目录。\n\n> 修改用户 - usermod\n\n修改用户账号就是根据实际情况更改用户的有关属性，如用户号、主目录、用户组、登录 Shell 等。\n\n修改已有用户的信息使用 usermod 命令，其格式如下：\n\n```bash\nusermod 选项 用户名\n```\n\n常用的选项包括-c, -d, -m, -g, -G, -s, -u 以及-o 等，这些选项的意义与 useradd 命令中的选项一样，可以为用户指定新的资源值。\n\n> 用户密码的管理\n\n用户管理的一项重要内容是用户口令的管理。用户账号刚创建时没有口令，但是被系统锁定，无法使用，必须为其指定口令后才可以使用，即使是指定空口令。\n\n指定和修改用户口令的 Shell 命令是 passwd。超级用户可以为自己和其他用户指定口令，普通用户只能用它修改自己的口令。\n\n命令的格式为：\n\n```bash\npasswd 选项 用户名\n```\n\n可使用的选项：\n\n- -l 锁定口令，即禁用账号。\n- -u 口令解锁。\n- -d 使账号无口令。\n- -f 强迫用户下次登录时修改口令。\n\n如果默认用户名，则修改当前用户的口令。\n\n命令修改该用户自己的口令：\n\n```bash\n$ passwd\nOld password:******\nNew password:*******\nRe-enter new password:*******\n```\n\n如果是超级用户，可以用下列形式指定任何用户的口令：\n\n```bash\n# passwd kuangshen\nNew password:*******\nRe-enter new password:*******\n```\n\n普通用户修改自己的口令时，passwd 命令会先询问原口令，验证后再要求用户输入两遍新口令，如果两次输入的口令一致，则将这个口令指定给用户；而超级用户为用户指定口令时，就不需要知道原口令。\n\n为了系统安全起见，用户应该选择比较复杂的口令，例如最好使用 8 位长的口令，口令中包含有大写、小写字母和数字，并且应该与姓名、生日等不相同。\n\n为用户指定空口令时，执行下列形式的命令：\n\n```bash\n# passwd -d kuangshen\n```\n\n此命令将用户 kuangshen 的口令删除，这样用户 kuangshen 下一次登录时，系统就不再允许该用户登录了。\n\npasswd 命令还可以用 -l(lock) 选项锁定某一用户，使其不能登录，例如：\n\n```bash\n# passwd -l kuangshen\n```\n\n### 用户组管理\n\n每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同 Linux 系统对用户组的规定有所不同，如 Linux 下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。\n\n用户组的管理涉及用户组的添加、删除和修改。==组的增加、删除和修改实际上就是对/etc/group 文件的更新。==\n\n> 添加用户组 - groupadd\n\n```bash\ngroupadd 选项 用户组\ncat /etc/group\n```\n\n可以使用的选项有：\n\n- -g GID 指定新用户组的组标识号（GID）。\n- -o 一般与-g 选项同时使用，表示新用户组的 GID 可以与系统已有用户组的 GID 相同。\n\n> 删除用户组 - groupdel\n\n```bash\ngroupdel 用户组\n```\n\n> 修改用户组 - groupmod\n\n```bash\ngroupmod 选项 用户组\n```\n\n常用的选项有：\n\n- -g GID 为用户组指定新的组标识号。\n- -o 与-g 选项同时使用，用户组的新 GID 可以与系统已有用户组的 GID 相同。\n- -n 新用户组 将用户组的名字改为新名字\n\n```bash\n# 此命令将组group2的组标识号修改为102。\ngroupmod -g 102 group2\n\n# 将组group2的标识号改为10000，组名修改为group3。\ngroupmod –g 10000 -n group3 group2\n```\n\n> 切换组\n\n如果一个用户同时属于多个用户组，那么用户可以在用户组之间切换，以便具有其他用户组的权限。\n\n用户可以在登录后，使用命令 newgrp 切换到其他用户组，这个命令的参数就是目的用户组。例如：\n\n```bash\n$ newgrp root\n```\n\n这条命令将当前用户切换到 root 用户组，前提条件是 root 用户组确实是该用户的主组或附加组。\n\n> /etc/passwd\n\n完成用户管理的工作有许多种方法，但是每一种方法实际上都是对有关的系统文件进行修改。\n\n与用户和用户组相关的信息都存放在一些系统文件中，这些文件包括/etc/passwd, /etc/shadow, /etc/group 等。\n\n下面分别介绍这些文件的内容。\n\n/etc/passwd 文件是用户管理工作涉及的最重要的一个文件。\n\nLinux 系统中的每个用户都在/etc/passwd 文件中有一个对应的记录行，它记录了这个用户的一些基本属性。\n\n这个文件对所有用户都是可读的。它的内容类似下面的例子：\n\n```\n＃ cat /etc/passwd\n\nroot:x:0:0:Superuser:/:\ndaemon:x:1:1:System daemons:/etc:\nbin:x:2:2:Owner of system commands:/bin:\nsys:x:3:3:Owner of system files:/usr/sys:\nadm:x:4:4:System accounting:/usr/adm:\nuucp:x:5:5:UUCP administrator:/usr/lib/uucp:\nauth:x:7:21:Authentication administrator:/tcb/files/auth:\ncron:x:9:16:Cron daemon:/usr/spool/cron:\nlisten:x:37:4:Network daemon:/usr/net/nls:\nlp:x:71:18:Printer administrator:/usr/spool/lp:\n```\n\n从上面的例子我们可以看到，/etc/passwd 中一行记录对应着一个用户，每行记录又被冒号(:)分隔为 7 个字段，其格式和具体含义如下：\n\n```\n用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell\n```\n\n1）\"用户名\"是代表用户账号的字符串。\n\n通常长度不超过 8 个字符，并且由大小写字母和/或数字组成。登录名中不能有冒号(:)，因为冒号在这里是分隔符。\n\n为了兼容起见，登录名中最好不要包含点字符(.)，并且不使用连字符(-)和加号(+)打头。\n\n2）“口令”一些系统中，存放着加密后的用户口令字。\n\n虽然这个字段存放的只是用户口令的加密串，不是明文，但是由于/etc/passwd 文件对所有用户都可读，所以这仍是一个安全隐患。因此，现在许多 Linux 系统（如 SVR4）都使用了 shadow 技术，把真正的加密后的用户口令字存放到/etc/shadow 文件中，而在/etc/passwd 文件的口令字段中只存放一个特殊的字符，例如“x”或者“\\*”。\n\n3）“用户标识号”是一个整数，系统内部用它来标识用户。\n\n一般情况下它与用户名是一一对应的。如果几个用户名对应的用户标识号是一样的，系统内部将把它们视为同一个用户，但是它们可以有不同的口令、不同的主目录以及不同的登录 Shell 等。\n\n通常用户标识号的取值范围是 0 ～ 65 535。0 是超级用户 root 的标识号，1 ～ 99 由系统保留，作为管理账号，普通用户的标识号从 100 开始。在 Linux 系统中，这个界限是 500。\n\n4）“组标识号”字段记录的是用户所属的用户组。\n\n它对应着/etc/group 文件中的一条记录。\n\n5)“注释性描述”字段记录着用户的一些个人情况。\n\n例如用户的真实姓名、电话、地址等，这个字段并没有什么实际的用途。在不同的 Linux 系统中，这个字段的格式并没有统一。在许多 Linux 系统中，这个字段存放的是一段任意的注释性描述文字，用作 finger 命令的输出。\n\n6)“主目录”，也就是用户的起始工作目录。\n\n它是用户在登录到系统之后所处的目录。在大多数系统中，各用户的主目录都被组织在同一个特定的目录下，而用户主目录的名称就是该用户的登录名。各用户对自己的主目录有读、写、执行（搜索）权限，其他用户对此目录的访问权限则根据具体情况设置。\n\n7)用户登录后，要启动一个进程，负责将用户的操作传给内核，这个进程是用户登录到系统后运行的命令解释器或某个特定的程序，即 Shell。\n\nShell 是用户与 Linux 系统之间的接口。Linux 的 Shell 有许多种，每种都有不同的特点。常用的有 sh(Bourne Shell), csh(C Shell), ksh(Korn Shell), tcsh(TENEX/TOPS-20 type C Shell), bash(Bourne Again Shell)等。\n\n系统管理员可以根据系统情况和用户习惯为用户指定某个 Shell。如果不指定 Shell，那么系统使用 sh 为默认的登录 Shell，即这个字段的值为/bin/sh。\n\n用户的登录 Shell 也可以指定为某个特定的程序（此程序不是一个命令解释器）。\n\n利用这一特点，我们可以限制用户只能运行指定的应用程序，在该应用程序运行结束后，用户就自动退出了系统。有些 Linux 系统要求只有那些在系统中登记了的程序才能出现在这个字段中。\n\n8)系统中有一类用户称为伪用户（pseudo users）。\n\n这些用户在/etc/passwd 文件中也占有一条记录，但是不能登录，因为它们的登录 Shell 为空。它们的存在主要是方便系统管理，满足相应的系统进程对文件属主的要求。\n\n常见的伪用户如下所示：\n\n```\n伪 用 户 含 义\nbin 拥有可执行的用户命令文件\nsys 拥有系统文件\nadm 拥有帐户文件\nuucp UUCP使用\nlp lp或lpd子系统使用\nnobody NFS使用\n```\n\n> /etc/shadow\n\n**1、除了上面列出的伪用户外，还有许多标准的伪用户，例如：audit, cron, mail, usenet 等，它们也都各自为相关的进程和文件所需要。**\n\n由于/etc/passwd 文件是所有用户都可读的，如果用户的密码太简单或规律比较明显的话，一台普通的计算机就能够很容易地将它破解，因此对安全性要求较高的 Linux 系统都把加密后的口令字分离出来，单独存放在一个文件中，这个文件是/etc/shadow 文件。有超级用户才拥有该文件读权限，这就保证了用户密码的安全性。\n\n**2、/etc/shadow 中的记录行与/etc/passwd 中的一一对应，它由 pwconv 命令根据/etc/passwd 中的数据自动产生**\n\n它的文件格式与/etc/passwd 类似，由若干个字段组成，字段之间用\":\"隔开。这些字段是：\n\n```\n登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志\n```\n\n1. \"登录名\"是与/etc/passwd 文件中的登录名相一致的用户账号\n2. \"口令\"字段存放的是加密后的用户口令字，长度为 13 个字符。如果为空，则对应用户没有口令，登录时不需要口令；如果含有不属于集合 { ./0-9A-Za-z }中的字符，则对应的用户不能登录。\n3. \"最后一次修改时间\"表示的是从某个时刻起，到用户最后一次修改口令时的天数。时间起点对不同的系统可能不一样。例如在 SCO Linux 中，这个时间起点是 1970 年 1 月 1 日。\n4. \"最小时间间隔\"指的是两次修改口令之间所需的最小天数。\n5. \"最大时间间隔\"指的是口令保持有效的最大天数。\n6. \"警告时间\"字段表示的是从系统开始警告用户到用户密码正式失效之间的天数。\n7. \"不活动时间\"表示的是用户没有登录活动但账号仍能保持有效的最大天数。\n8. \"失效时间\"字段给出的是一个绝对的天数，如果使用了这个字段，那么就给出相应账号的生存期。期满后，该账号就不再是一个合法的账号，也就不能再用来登录了。\n\n> /etc/group\n\n用户组的所有信息都存放在/etc/group 文件中。\n\n将用户分组是 Linux 系统中对用户进行管理及控制访问权限的一种手段。\n\n每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不同的组。\n\n当一个用户同时是多个组中的成员时，在/etc/passwd 文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。\n\n用户要访问属于附加组的文件时，必须首先使用 newgrp 命令使自己成为所要访问的组中的成员。\n\n用户组的所有信息都存放在/etc/group 文件中。此文件的格式也类似于/etc/passwd 文件，由冒号(:)隔开若干个字段，这些字段有：\n\n```\n组名:口令:组标识号:组内用户列表\n```\n\n1. \"组名\"是用户组的名称，由字母或数字构成。与/etc/passwd 中的登录名一样，组名不应重复。\n2. \"口令\"字段存放的是用户组加密后的口令字。一般 Linux 系统的用户组都没有口令，即这个字段一般为空，或者是\\*。\n3. \"组标识号\"与用户标识号类似，也是一个整数，被系统内部用来标识组。\n4. \"组内用户列表\"是属于这个组的所有用户的列表/b]，不同用户之间用逗号(,)分隔。这个用户组可能是用户的主组，也可能是附加组。\n\n### 磁盘管理\n\n> 概述\n\nLinux 磁盘管理好坏直接关系到整个系统的性能问题。\n\nLinux 磁盘管理常用命令为 df、du。\n\n- df ：列出文件系统的整体磁盘使用量\n- du：检查磁盘空间使用量\n\n> df\n\ndf 命令参数功能：检查文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。\n\n语法：\n\n```bash\ndf [-ahikHTm] [目录或文件名]\n```\n\n选项与参数：\n\n- -a ：列出所有的文件系统，包括系统特有的 /proc 等文件系统；\n- -k ：以 KBytes 的容量显示各文件系统；\n- -m ：以 MBytes 的容量显示各文件系统；\n- -h ：以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示；\n- -H ：以 M=1000K 取代 M=1024K 的进位方式；\n- -T ：显示文件系统类型, 连同该 partition 的 filesystem 名称 (例如 ext3) 也列出；\n- -i ：不用硬盘容量，而以 inode 的数量来显示\n\n> du\n\nLinux du 命令也是查看使用空间的，但是与 df 命令不同的是 Linux du 命令是对文件和目录磁盘使用的空间的查看，还是和 df 命令有一些区别的，这里介绍 Linux du 命令。\n\n语法：\n\n```bash\ndu [-ahskm] 文件或目录名称\n```\n\n选项与参数：\n\n- -a ：列出所有的文件与目录容量，因为默认仅统计目录底下的文件量而已。\n- -h ：以人们较易读的容量格式 (G/M) 显示；\n- -s ：列出总量而已，而不列出每个各别的目录占用容量；\n- -S ：不包括子目录下的总计，与 -s 有点差别。\n- -k ：以 KBytes 列出容量显示；\n- -m ：以 MBytes 列出容量显示；\n\n> 磁盘挂载与卸除\n\n根文件系统之外的其他文件要想能够被访问，都必须通过“关联”至根文件系统上的某个目录来实现，此关联操作即为“挂载”，此目录即为“挂载点”,解除此关联关系的过程称之为“卸载”\n\nLinux 的磁盘挂载使用 mount 命令，卸载使用 umount 命令。\n\n磁盘挂载语法：\n\n```bash\nmount [-t 文件系统] [-L Label名] [-o 额外选项] [-n]  装置文件名  挂载点\n```\n\n磁盘卸载命令 umount 语法：\n\n```bash\numount [-fn] 装置文件名或挂载点\n```\n\n选项与参数：\n\n- -f ：强制卸除！可用在类似网络文件系统 (NFS) 无法读取到的情况下；\n- -n ：不升级 /etc/mtab 情况下卸除。\n\n### 进程管理\n\n> 什么是进程\n\n1. 在 Linux 中，每一个程序都是有自己的一个进程，每一个进程都有一个 id 号！\n2. 每一个进程都会有一个父进程！\n3. 进程可以有两种存在方式：前台！后台运行！\n4. 一般的话服务都是后台运行，基本的程序都是前台进行的！\n\n> 命令\n\n`ps` 查看当前系统中正在执行的各种进程信息\n\n参数选项：\n\n- -A 显示当前终端运行的所有的进程信息\n- -u 以用户的信息显示进程\n- -x 显示后台运行的参数\n\n```bash\n# ps -aux 查看所有的进程\nps -aux|\n\n# | 在Linux中叫做管道符 A|B\n# grep 查找文件中符合条件的字符串\n```\n\n**ps -ef** ：可以查到父进程的信息\n\n```bash\nps -ef|grep mysql #看父进程我们一般通过目录树结构来查看！\n\n#进程树\npstree -pu\n     -p 显示父id\n     -u 显示用户组\n```\n\n结束进程：杀掉进程，等价于 window 结束任务\n\n**kill -9** 进程的 id\n\n```bash\nkill -9 pid\n```\n","tags":["技巧","笔记"],"categories":["Linux"]},{"title":"SpringCloud 快速搭建","slug":"SpringCloud快速搭建","url":"/2021/06/22/939440f7.html","content":"\n## SpringCloud 五大组件\n\n- 服务注册与发现——Netflix Eureka\n- 负载均衡：\n  - 客户端负载均衡——Netflix Ribbon\n  - 服务端负载均衡：——Feign(其也是依赖于 Ribbon，只是将调用方式 RestTemplete 更改成 Service 接口)\n- 断路器——Netflix Hystrix\n- 服务网关——Netflix Zuul\n- 分布式配置——Spring Cloud Config\n\n## 常见面试题\n\n- 什么是微服务？\n- 微服务之间是如何独立通讯的？\n- SpringCloud 和 Dubbo 有那些区别？\n- SpringBoot 和 SpringCloud，请谈谈你对他们的理解\n- 什么是服务熔断？什么是服务降级？\n- 微服务的优缺点分别是什么？说下你在项目开发中遇到的坑\n- 你所知道的微服务技术栈有哪些？列举一二\n- Eureka 和 Zookeeper 都可以提供服务注册与发现的功能，请说说两者的区别\n\n## 微服务概述\n\n### 什么是微服务\n\n> 什么是微服务？\n\n微服务(Microservice Architecture) 是近几年流行的一种架构思想，关于它的概念很难一言以蔽之。\n\n究竟什么是微服务呢？我们在此引用 ThoughtWorks 公司的首席科学家 Martin Fowler 于 2014 年提出的一段话：\n\n原文：https://martinfowler.com/articles/microservices.html\n\n汉化：https://www.cnblogs.com/liuning8023/p/4493156.html\n\n- 就目前而言，对于微服务，业界并没有一个统一的，标准的定义。\n- 但通常而言，微服务架构是一种架构模式，或者说是一种架构风格，**它体长将单一的应用程序划分成一组小的服务**，每个服务运行在其独立的自己的进程内，服务之间互相协调，互相配置，为用户提供最终价值，服务之间采用轻量级的通信机制(HTTP)互相沟通，每个服务都围绕着具体的业务进行构建，并且能狗被独立的部署到生产环境中，另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应该根据业务上下文，选择合适的语言，工具(**Maven**)对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。\n\n> 再来从技术维度角度理解下：\n\n- 微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合，每一个微服务提供单个业务功能的服务，一个服务做一件事情，从技术角度看就是一种小而独立的处理过程，类似进程的概念，能够自行单独启动或销毁，拥有自己独立的数据库。\n\n### 微服务与微服务架构\n\n> 微服务\n\n强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题/提供落地对应服务的一个服务应用，狭义的看，可以看作是 IDEA 中的一个个微服务工程，或者 Moudel。IDEA 工具里面使用 Maven 开发的一个个独立的小 Moudel，它具体是使用 SpringBoot 开发的一个小模块，专业的事情交给专业的模块来做，一个模块就做着一件事情。强调的是一个个的个体，每个个体完成一个具体的任务或者功能。\n\n> 微服务架构\n\n一种新的架构形式，Martin Fowler 于 2014 年提出。\n\n微服务架构是一种架构模式，它体长将单一应用程序划分成一组小的服务，服务之间相互协调，互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务之间采用轻量级的通信机制**(如 HTTP)互相协作，每个服务都围绕着具体的业务进行构建，并且能够被独立的部署到生产环境中，另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具(如 Maven)**对其进行构建。\n\n### 微服务优缺点\n\n> 优点\n\n- 单一职责原则；\n- 每个服务足够内聚，足够小，代码容易理解，这样能聚焦一个指定的业务功能或业务需求；\n- 开发简单，开发效率高，一个服务可能就是专一的只干一件事；\n- 微服务能够被小团队单独开发，这个团队只需 2-5 个开发人员组成；\n- 微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的；\n- 微服务能使用不同的语言开发；\n- 易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如 jenkins，Hudson，bamboo；\n- 微服务易于被一个开发人员理解，修改和维护，这样小团队能够更关注自己的工作成果，无需通过合作才能体现价值；\n- 微服务允许利用和融合最新技术；\n- 微服务只是业务逻辑的代码，不会和 HTML，CSS，或其他的界面混合;\n- 每个微服务都有自己的存储能力，可以有自己的数据库，也可以有统一的数据库；\n\n> 缺点\n\n- 开发人员要处理分布式系统的复杂性；\n- 多服务运维难度，随着服务的增加，运维的压力也在增大；\n- 系统部署依赖问题；\n- 服务间通信成本问题；\n- 数据一致性问题；\n- 系统集成测试问题；\n- 性能和监控问题；\n\n### 微服务技术栈\n\n| **微服务技术条目**                     | 落地技术                                                       |\n| -------------------------------------- | -------------------------------------------------------------- |\n| 服务开发                               | SpringBoot、Spring、SpringMVC 等                               |\n| 服务配置与管理                         | Netfix 公司的 Archaius、阿里的 Diamond 等                      |\n| 服务注册与发现                         | Eureka、Consul、Zookeeper 等                                   |\n| 服务调用                               | Rest、PRC、gRPC                                                |\n| 服务熔断器                             | Hystrix、Envoy 等                                              |\n| 负载均衡                               | Ribbon、Nginx 等                                               |\n| 服务接口调用(客户端调用服务的简化工具) | Fegin 等                                                       |\n| 消息队列                               | Kafka、RabbitMQ、ActiveMQ 等                                   |\n| 服务配置中心管理                       | SpringCloudConfig、Chef 等                                     |\n| 服务路由(API 网关)                     | Zuul 等                                                        |\n| 服务监控                               | Zabbix、Nagios、Metrics、Specatator 等                         |\n| 全链路追踪                             | Zipkin、Brave、Dapper 等                                       |\n| 数据流操作开发包                       | SpringCloud Stream(封装与 Redis，Rabbit，Kafka 等发送接收消息) |\n| 时间消息总栈                           | SpringCloud Bus                                                |\n| 服务部署                               | Docker、OpenStack、Kubernetes 等                               |\n\n### 为什么选择 SpringCloud 作为微服务架构\n\n1. **选型依据**\n\n   - 整体解决方案和框架成熟度\n   - 社区热度\n   - 可维护性\n   - 学习曲线\n\n2. **当前各大 IT 公司用的微服务架构有那些？**\n\n   - 阿里：dubbo+HFS\n   - 京东：JFS\n   - 新浪：Motan\n   - 当当网：DubboX\n\n3. 各微服务框架对比\n\n   ![image-20210424223407910](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210424223415.png)\n\n## SpringCloud 入门概述\n\n### SpringCloud 是什么？\n\nSpring 官网：https://spring.io/\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210424223656.png)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210424223702.png)\n\n---\n\n- Spring Cloud 是一个微服务框架，相比 Dubbo 等 RPC 框架, **Spring Cloud 提供的全套的分布式系统解决方案**。\n- Spring Cloud 对微服务基础框架 Netflix 的多个开源组件进行了封装，同时又实现了和云端平台以及和 Spring Boot 开发框架的集成。\n- Spring Cloud 为微服务架构开发涉及的**配置管理，服务治理，熔断机制，智能路由，微代理，控制总线，一次性 token，全局一致性锁，leader 选举，分布式 session，集群状态**管理等操作提供了一种简单的开发方式。\n- Spring Cloud 为开发者提供了快速构建**分布式系统的工具**，开发者可以快速的启动服务或构建应用、同时能够快速和云平台资源进行对接。\n\n### SpringCloud 和 SpringBoot 的关系\n\n- SpringBoot 专注于开苏方便的开发单个个体微服务；\n- SpringCloud 是关注全局的微服务协调整理治理框架，它将 SpringBoot 开发的一个个单体微服务，整合并管理起来，为各个微服务之间提供：配置管理、服务发现、断路器、路由、为代理、事件总栈、全局锁、决策竞选、分布式会话等等集成服务；\n- SpringBoot 可以离开 SpringCloud 独立使用，开发项目，但 SpringCloud 离不开 SpringBoot，属于依赖关系；\n- **SpringBoot 专注于快速、方便的开发单个个体微服务，SpringCloud 关注全局的服务治理框架；**\n\n### Dubbo 和 SpringCloud 技术选型\n\n##### 分布式+服务治理 Dubbo\n\n目前成熟的互联网架构，应用服务化拆分 + 消息中间件\n\n##### Dubbo 和 SpringCloud 对比\n\n最大区别：Spring Cloud 抛弃了 Dubbo 的 RPC 通信，采用的是基于 HTTP 的 REST 方式\n\n严格来说，这两种方式各有优劣。虽然从一定程度上来说，后者牺牲了服务调用的性能，但也避免了上面提到的原生 RPC 带来的问题。而且 REST 相比 RPC 更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这个优点在当下强调快速演化的微服务环境下，显得更加合适。\n\n### SpringCloud 能干嘛？\n\n- Distributed/versioned configuration 分布式/版本控制配置\n- Service registration and discovery 服务注册与发现\n- Routing 路由\n- Service-to-service calls 服务到服务的调用\n- Load balancing 负载均衡配置\n- Circuit Breakers 断路器\n- Distributed messaging 分布式消息管理\n\n**自学参考书：**\n\n- SpringCloud Netflix 中文文档：https://springcloud.cc/spring-cloud-netflix.html\n- SpringCloud 中文 API 文档(官方文档翻译版)：https://springcloud.cc/spring-cloud-dalston.html\n- SpringCloud 中国社区：http://springcloud.cn/\n- SpringCloud 中文网：https://springcloud.cc\n\n## Eureka 服务注册与发现\n\n### 什么是 Eureka？\n\n- Netflix 在涉及 Eureka 时，遵循的就是 API 原则.\n- Eureka 是 Netflix 的有个子模块，也是核心模块之一。Eureka 是基于 REST 的服务，用于定位服务，以实现云端中间件层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务注册与发现，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了，功能类似于 Dubbo 的注册中心，比如 Zookeeper.\n\n### 原理理解\n\n- Eureka 基本的架构\n  - Springcloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务注册与发现 (对比 Zookeeper).\n  - Eureka 采用了 C-S 的架构设计，EurekaServer 作为服务注册功能的服务器，他是服务注册中心.\n  - 而系统中的其他微服务，使用 Eureka 的客户端连接到 EurekaServer 并维持心跳连接。这样系统的维护人员就可以通过 EurekaServer 来监控系统中各个微服务是否正常运行，Springcloud 的一些其他模块 (比如 Zuul) 就可以通过 EurekaServer 来发现系统中的其他微服务，并执行相关的逻辑.\n\n![image-20210516114206565](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210516114346.png)\n\n- 和 Dubbo 架构对比.\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210426230548.png)\n\n- Eureka 包含两个组件：Eureka Server 和 Eureka Client.\n\n* Eureka Server 提供服务注册，各个节点启动后，会在 EurekaServer 中进行注册，这样 Eureka Server 中的服务注册表中将会储存所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到.\n\n- Eureka Client 是一个 Java 客户端，用于简化 EurekaServer 的交互，客户端同时也具备一个内置的，使用轮询负载算法的负载均衡器。在应用启动后，将会向 EurekaServer 发送心跳 (默认周期为 30 秒) 。如果 Eureka Server 在多个心跳周期内没有接收到某个节点的心跳，EurekaServer 将会从服务注册表中把这个服务节点移除掉 (默认周期为 90s).\n\n- **三大角色**\n  - Eureka Server：提供服务的注册与发现\n  - Service Provider：服务生产方，将自身服务注册到 Eureka 中，从而使服务消费方能狗找到\n  - Service Consumer：服务消费方，从 Eureka 中获取注册服务列表，从而找到消费服务\n\n### 构建 Eureka\n\n#### eureka-server\n\n1. 新建 springcloud-eureka-7001 模块\n\n2. pom.xml 配置\n\n   ```xml\n   <!--导包~-->\n   <dependencies>\n       <!--导入Eureka Server依赖-->\n       <dependency>\n           <groupId>org.springframework.cloud</groupId>\n           <artifactId>spring-cloud-starter-eureka-server</artifactId>\n           <version>1.4.6.RELEASE</version>\n       </dependency>\n       <!--热部署工具-->\n       <dependency>\n           <groupId>org.springframework.boot</groupId>\n           <artifactId>spring-boot-devtools</artifactId>\n       </dependency>\n   </dependencies>\n   ```\n\n3. application.yml\n\n   ```yaml\n   server:\n     port: 7001\n   eureka:\n     instance:\n       hostname: localhost #eureka服务端的实例名称\n     client:\n       register-with-eureka: false #是否向eureka注册中心注册自己\n       fetch-registry: false # false代表自己为注册中心\n       service-url: # 监控页面\n         defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/\n   ```\n\n4. 主启动类\n\n   ```java\n   package com.luojunjie.springcloud;\n\n   import org.springframework.boot.SpringApplication;\n   import org.springframework.boot.autoconfigure.SpringBootApplication;\n   import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;\n\n   /**\n    * 启动之后，访问http://127.0.0.1/\n    * @author IRVING\n    * @create 2021-04-26 23:24\n    */\n   @SpringBootApplication\n   @EnableEurekaServer //服务端的启动类，可以接受别人注册进来\n   public class EurekaServer_7001 {\n       public static void main(String[] args) {\n           SpringApplication.run(EurekaServer_7001.class,args);\n       }\n   }\n   ```\n\n5. 启动成功后访问 http://localhost:7001/ 得到以下页面\n\n   ![image-20210427094515719](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427094523.png)\n\n#### eureka-client\n\n**只需要在之前的 springcloud-provider-dept-8001**\n\n1. 导入 Eureka 依赖\n\n   ```xml\n   <!-- Eureka -->\n   <dependency>\n       <groupId>org.springframework.cloud</groupId>\n       <artifactId>spring-cloud-starter-eureka</artifactId>\n       <version>1.4.6.RELEASE</version>\n   </dependency>\n   ```\n\n2. application 中新增 Eureka 配置\n\n   ```yaml\n   # Eureka配置：配置服务注册中心地址\n   eureka:\n     client:\n       service-url:\n         defaultZone: http://localhost:7001/eureka/\n     instance:\n       instance-id: springcloud-provider-dept-8001 #修改eureka上的默认描述\n   ```\n\n3. 为主启动类添加@EnableEurekaClient 注解\n\n   ```java\n   /**\n    * @author IRVING\n    * @create 2021-04-25 0:13\n    */\n   @SpringBootApplication\n   @EnableEurekaClient //在服务启动后自动注册到eureka中\n   public class DeptProvider_8001 {\n       public static void main(String[] args) {\n           SpringApplication.run(DeptProvider_8001.class, args);\n       }\n   }\n   ```\n\n4. 先启动 7001 服务端后启动 8001 客户端进行测试，然后访问监控页http://localhost:7001/ 查看结果如图，成功\n\n   ![image-20210427100904350](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427100932.png)\n\n5. 配置关于服务加载的监控信息\n\n   ![image-20210427101125312](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427101125.png)\n\n6. 在 pom.xml 文件中添加依赖\n\n   ```xml\n   <!--actuator完善监控信息-->\n   <dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-actuator</artifactId>\n   </dependency>\n   ```\n\n7. application.yml 中添加配置\n\n   ```yaml\n   # info配置\n   info:\n     # 项目配置\n     app:\n       #项目名称\n       name: springcloud-dept8001\n       #公司名称\n       company: www.ljjblog.com\n   ```\n\n8. 刷新监控页，进入服务\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427103412.png\" alt=\"image-20210427103412175\" style=\"zoom:50%;\" />\n\n9. 跳转页面如下所示\n\n   ![image-20210427103451458](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427103451.png)\n\n### Eureka 自我保护机制：好死不如赖活着\n\n一句话总结就是：**某时刻某一个微服务不可用，eureka 不会立即清理，依旧会对该微服务的信息进行保存！**\n\n- 默认情况下，当 eureka server 在一定时间内没有收到实例的心跳，便会把该实例从注册表中删除**（默认是 90 秒）**，但是，如果短时间内丢失大量的实例心跳，便会触发 eureka server 的自我保护机制，比如在开发测试时，需要频繁地重启微服务实例，但是我们很少会把 eureka server 一起重启（因为在开发过程中不会修改 eureka 注册中心），**当一分钟内收到的心跳数大量减少时，会触发该保护机制**。可以在 eureka 管理界面看到 Renews threshold 和 Renews(last min)，当后者（最后一分钟收到的心跳数）小于前者（心跳阈值）的时候，触发保护机制，会出现红色的警告：==EMERGENCY!EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEGING EXPIRED JUST TO BE SAFE==.从警告中可以看到，eureka 认为虽然收不到实例的心跳，但它认为实例还是健康的，eureka 会保护这些实例，不会把它们从注册表中删掉。\n- 该保护机制的目的是避免网络连接故障，在发生网络故障时，微服务和注册中心之间无法正常通信，但服务本身是健康的，不应该注销该服务，如果 eureka 因网络故障而把微服务误删了，那即使网络恢复了，该微服务也不会重新注册到 eureka server 了，因为只有在微服务启动的时候才会发起注册请求，后面只会发送心跳和服务列表请求，这样的话，该实例虽然是运行着，但永远不会被其它服务所感知。所以，eureka server 在短时间内丢失过多的客户端心跳时，会进入自我保护模式，该模式下，eureka 会保护注册表中的信息，不在注销任何微服务，当网络故障恢复后，eureka 会自动退出保护模式。自我保护模式可以让集群更加健壮。\n- 但是我们在开发测试阶段，需要频繁地重启发布，如果触发了保护机制，则旧的服务实例没有被删除，这时请求有可能跑到旧的实例中，而该实例已经关闭了，这就导致请求错误，影响开发测试。所以，在开发测试阶段，我们可以把自我保护模式关闭，只需在 eureka server 配置文件中加上如下配置即可：==eureka.server.enable-self-preservation=false==【**不推荐关闭自我保护机制**】\n\n### Eureka 集群搭建\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427143231.png\" alt=\"image-20210427143231543\" style=\"zoom:50%;\" />\n\n#### 1、初始化\n\n新建 springcloud-eureka-7002、springcloud-eureka-7003 模块\n\n1.为 pmx.xml 添加依赖（与 springcloud-eureka-7001 相同）\n\n```xml\n<!-- 导包 -->\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-eureka-server</artifactId>\n        <version>1.4.6.RELEASE</version>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-devtools</artifactId>\n    </dependency>\n</dependencies>\n```\n\n2.为 application.yml 配置（与 springcloud-eureka-7001 相同）\n\n```yaml\nserver:\n  port: 7002\neureka:\n  instance:\n    hostname: localhost #eureka服务端的实例名称\n  client:\n    register-with-eureka: false #是否向eureka注册中心注册自己\n    fetch-registry: false # false代表自己为注册中心\n    service-url: # 监控页面\n      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/\n```\n\n3.主启动类(与 springcloud-eureka-7001 相同)\n\n```java\n/**\n * 启动之后，访问http://127.0.0.1/\n * @author IRVING\n * @create 2021-04-26 23:24\n */\n@SpringBootApplication\n@EnableEurekaServer //服务端的启动类，可以接受别人注册进来\npublic class EurekaServer_7002 {\n    public static void main(String[] args) {\n        SpringApplication.run(EurekaServer_7002.class,args);\n    }\n}\n```\n\n#### 2、集群成员之间互相关联\n\n配置一些自定义本机名字，找到本机 hosts 文件并打开\n\n![image-20210427145825690](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427145825.png)\n\n在 hosts 文件最后加上，要访问的本机名称，默认是 localhost\n\n![image-20210427145918816](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427145918.png)\n\n在集群中使 springcloud-eureka-7001 关联 springcloud-eureka-7002、springcloud-eureka-7003\n\n完整的 springcloud-eureka-7001 下的 application.yml 如下：\n\n```yaml\nserver:\n  port: 7001\neureka:\n  instance:\n    hostname: eureka7001.com #eureka服务端的实例名称\n  client:\n    register-with-eureka: false #是否向eureka注册中心注册自己\n    fetch-registry: false # false代表自己为注册中心\n    service-url: # 监控页面\n      #重写Eureka的默认端口以及访问路径 --->http://localhost:7001/eureka/\n      # 单机： defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/\n      # 集群（关联）：7001关联7002、7003\n      defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/\n```\n\n在集群中使 springcloud-eureka-7002 关联 springcloud-eureka-7001、springcloud-eureka-7003\n\n完整的 springcloud-eureka-7002 下的 application.yml 如下：\n\n```yaml\nserver:\n  port: 7002\neureka:\n  instance:\n    hostname: eureka7002.com #eureka服务端的实例名称\n  client:\n    register-with-eureka: false #是否向eureka注册中心注册自己\n    fetch-registry: false # false代表自己为注册中心\n    service-url: # 监控页面\n      #重写Eureka的默认端口以及访问路径 --->http://localhost:7001/eureka/\n      # 单机： defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/\n      # 集群（关联）：7001关联7002、7003\n      defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7003.com:7003/eureka/\n```\n\n在集群中使 springcloud-eureka-7003 关联 springcloud-eureka-7001、springcloud-eureka-7002\n\n完整的 springcloud-eureka-7003 下的 application.yml 如下：\n\n```yaml\nserver:\n  port: 7003\neureka:\n  instance:\n    hostname: eureka7003.com #eureka服务端的实例名称\n  client:\n    register-with-eureka: false #是否向eureka注册中心注册自己\n    fetch-registry: false # false代表自己为注册中心\n    service-url: # 监控页面\n      #重写Eureka的默认端口以及访问路径 --->http://localhost:7001/eureka/\n      # 单机： defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/\n      # 集群（关联）：7001关联7002、7003\n      defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/\n```\n\n通过 springcloud-provider-dept-8001 下的 yml 配置文件，修改**Eureka 配置：配置服务注册中心地址**\n\n```yaml\n#Eureka配置，服务注册到哪里\neureka:\n  client:\n    service-url:\n      #启用eureka集群配置\n      defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/\n  instance:\n    instance-id: springcloud-provider-dept-8001 #修改eureka上的默认描述\n```\n\n这样模拟集群就搭建好了，就可以把一个项目挂载到三个服务器上了\n\n![image-20210427151353122](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210427151353.png)\n\n### 对比和 Zookeeper 区别\n\n1. **回顾 CAP 原则**\n\n   RDBMS (MySQL\\Oracle\\sqlServer) ===> ACID\n\n   NoSQL (Redis\\MongoDB) ===> CAP\n\n2. **ACID 是什么？**\n\n   - A (Atomicity) 原子性\n   - C (Consistency) 一致性\n   - I (Isolation) 隔离性\n   - D (Durability) 持久性\n\n3. **CAP 是什么？**\n\n   - C (Consistency) 强一致性\n   - A (Availability) 可用性\n   - P (Partition tolerance) 分区容错性\n\n   CAP 的三进二：CA、AP、CP\n\n4. ==CAP 理论的核心==\n\n   一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求\n\n   根据 CAP 原理，将 NoSQL 数据库分成了满足 CA 原则，满足 CP 原则和满足 AP 原则三大类\n\n   - CA：单点集群，满足一致性，可用性的系统，通常可扩展性较差\n   - CP：满足一致性，分区容错的系统，通常性能不是特别高\n   - AP：满足可用性，分区容错的系统，通常可能对一致性要求低一些\n\n5. **作为分布式服务注册中心，Eureka 比 Zookeeper 好在哪里？**\n\n   著名的 CAP 理论指出，一个分布式系统不可能同时满足 C (一致性) 、A (可用性) 、P (容错性)，由于分区容错性 P 在分布式系统中是必须要保证的，因此我们只能再 A 和 C 之间进行权衡。\n\n   - Zookeeper 保证的是 CP —> 满足一致性，分区容错的系统，通常性能不是特别高\n   - Eureka 保证的是 AP —> 满足可用性，分区容错的系统，通常可能对一致性要求低一些\n\n   **Zookeeper 保证的是 CP**\n\n   当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接收服务直接 down 掉不可用。也就是说，**服务注册功能对可用性的要求要高于一致性**。但 zookeeper 会出现这样一种情况，当 master 节点因为网络故障与其他节点失去联系时，剩余节点会重新进行 leader 选举。问题在于，选举 leader 的时间太长，30-120s，且选举期间整个 zookeeper 集群是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因为网络问题使得 zookeeper 集群失去 master 节点是较大概率发生的事件，虽然服务最终能够恢复，但是，漫长的选举时间导致注册长期不可用，是不可容忍的。\n\n   **Eureka 保证的是 AP**\n\n   Eureka 看明白了这一点，因此在设计时就优先保证可用性。**Eureka 各个节点都是平等的**，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而 Eureka 的客户端在向某个 Eureka 注册时，如果发现连接失败，则会自动切换至其他节点，只要有一台 Eureka 还在，就能保住注册服务的可用性，只不过查到的信息可能不是最新的，除此之外，Eureka 还有之中自我保护机制，如果在 15 分钟内超过 85%的节点都没有正常的心跳，那么 Eureka 就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况：\n\n   - Eureka 不在从注册列表中移除因为长时间没收到心跳而应该过期的服务\n   - Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上 (即保证当前节点依然可用)\n   - 当网络稳定时，当前实例新的注册信息会被同步到其他节点中\n\n   ==因此，Eureka 可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像 zookeeper 那样使整个注册服务瘫痪==\n\n## Ribbon：负载均衡(基于客户端)\n\n#### 负载均衡以及 Ribbon\n\n> **ribbon 是什么？**\n\n- Spring Cloud Ribbon 是基于 Netflix Ribbon 实现的一套==客户端负载均衡工具==。\n- 简单的说，Ribbon 是 Netflix 发布的一个开源项目，主要功能是提供客户端的软件负载均衡算法，将 Netflix 的中间层服务连接在一起。Ribbon 的客户端组件提供一系列完整的配置项如：连接超时、重试等等。简单的说，就是在配置文件中列出 LoadBalancer（简称 LB：负载均衡）后面所有的机器，Ribbon 会自动的帮助你基于某种规则（如简单轮询、随机连接等等）去连接这些机器。我们也很容易使用 Ribbon 实现自定义的负载均衡算法！\n\n> **ribbon 能干嘛？**\n\n- LB，即负载均衡 (LoadBalancer) ，在微服务或分布式集群中经常用的一种应用。\n- 负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的 HA (高用)。\n- 常见的负载均衡软件有 Nginx、Lvs 等等。\n- Dubbo、SpringCloud 中均给我们提供了负载均衡，**SpringCloud 的负载均衡算法可以自定义**。\n- 负载均衡简单分类：\n  - 集中式 LB\n    - 即在服务的提供方和消费方之间使用独立的 LB 设施，如 Nginx(反向代理服务器)，由该设施负责把访问请求通过某种策略转发至服务的提供方！\n  - 进程式 LB\n    - 将 LB 逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选出一个合适的服务器。\n    - ==Ribbon 就属于进程内 LB==，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址！\n\n#### SpringCloud 集成 Ribbon\n\n向**springcloud-consumer-dept-80**模块的 pom.xml 中添加 Ribbon 和 Eureka 依赖\n\n```xml\n<!-- Ribbon+Eureka -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>\n    <version>1.4.6.RELEASE</version>\n</dependency>\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-eureka</artifactId>\n    <version>1.4.6.RELEASE</version>\n</dependency>\n```\n\n在 application.yml 文件中配置 Eureka\n\n```yaml\n#Eureka配置\neureka:\n  client:\n    register-with-eureka: false #不向注册中心注册自己\n    service-url:\n      defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/\n```\n\n主启动类加上@EnableEurekaClient 注解，开启 Eureka\n\n```java\n/**\n * Ribbon 和 Eureka 整合以后，客户端可以直接调用，不用关心IP地址和端口号\n * @author IRVING\n * @create 2021-04-25 0:36\n */\n@SpringBootApplication\n@EnableEurekaClient\npublic class DeptConsumer_80 {\n    public static void main(String[] args) {\n        SpringApplication.run(DeptConsumer_80.class);\n    }\n}\n```\n\n自定义 Spring 配置类：ConfigBean.java 配置负载均衡实现 RestTemplate\n\n```java\n/**\n * @author IRVING\n * @create 2021-04-25 0:27\n */\n@Configuration\npublic class ConfigBean {\n\n    //配置负载均衡实现RestTemplate\n    @Bean\n    @LoadBalanced //Ribbon\n    public RestTemplate getRestTemplate() {\n        return new RestTemplate();\n    }\n}\n```\n\n#### 使用 Ribbon 实现负载均衡\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428011632.png)\n\n1. 新建两个服务提供者 Moudle：springcloud-provider-dept-8003、springcloud-provider-dept-8002\n2. 参照 springcloud-provider-dept-8001 依次为另外两个 Moudle 添加 pom.xml 依赖 、resourece 下的 mybatis 和 application.yml 配置，Java 代码\n3. 启动所有服务测试(根据自身电脑配置决定启动服务的个数)，访问http://eureka7001.com:7002/查看结果\n\n![image-20210428011818529](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428011818.png)\n\n测试访问http://localhost/consumer/dept/list 这时候随机访问的是服务提供者 8001\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428012211.png\" alt=\"image-20210428012211706\" style=\"zoom: 50%;\" />\n\n再次访问http://localhost/consumer/dept/list这时候随机的是服务提供者8002\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428012255.png\" alt=\"image-20210428012255782\" style=\"zoom: 50%;\" />\n\n以上这种**每次访问http://localhost/consumer/dept/list随机访问集群中某个服务提供者，这种情况叫做轮询**，轮询算法在 SpringCloud 中可以自定义。\n\n**如何切换或者自定义规则呢？**\n\n在 springcloud-provider-dept-80 模块下的 ConfigBean 中进行配置，切换使用不同的规则\n\n```java\n@Configuration\npublic class ConfigBean {\n\n    //配置负载均衡实现RestTemplate\n    @Bean\n    @LoadBalanced //Ribbon\n    public RestTemplate getRestTemplate() {\n        return new RestTemplate();\n    }\n\n    @Bean\n    public IRule myRule() {\n        return new RandomRule();//使用随机策略\n        //return new RoundRobinRule();//使用轮询策略\n        //return new AvailabilityFilteringRule();//使用轮询策略\n        //return new RetryRule();//使用轮询策略\n    }\n}\n```\n\n也可以自定义规则，在 myRule 包下自定义一个配置类 MyRule.java，注意：**该包不要和主启动类所在的包同级，要跟启动类所在包同级**：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428014625.png\" alt=\"image-20210428014625684\" style=\"zoom:50%;\" />\n\n**MyRule.java**\n\n```java\n@Configuration\npublic class MyRule {\n\n    @Bean\n    public IRule myRule(){\n        return new MyRandomRule();//默认是轮询RandomRule,现在自定义为自己的\n    }\n}\n```\n\n主启动类开启负载均衡并指定自定义的 MyRule 配置类\n\n```java\n@SpringBootApplication\n@EnableEurekaClient\n//在微服务启动的时候就能加载自定义的Ribbon类(自定义的规则会覆盖原有默认的规则)\n@RibbonClient(name = \"springcloud-provider-dept\",configuration = MyRandomRule.class)\npublic class DeptConsumer_80 {\n    public static void main(String[] args) {\n        SpringApplication.run(DeptConsumer_80.class);\n    }\n}\n```\n\n自定义的规则(这里我们参考 Ribbon 中默认的规则代码自己稍微改动)：MyRandomRule.java\n\n```java\npackage com.luojunjie.myrule;\n\nimport com.netflix.client.config.IClientConfig;\nimport com.netflix.loadbalancer.AbstractLoadBalancerRule;\nimport com.netflix.loadbalancer.ILoadBalancer;\nimport com.netflix.loadbalancer.Server;\n\nimport java.util.List;\nimport java.util.concurrent.ThreadLocalRandom;\n\n/**\n * @author IRVING\n * @create 2021-04-28 1:47\n */\npublic class MyRandomRule extends AbstractLoadBalancerRule {\n\n    /**\n     * 每个服务访问5次则换下一个服务(总共3个服务)\n     * <p>\n     * total=0,默认=0,如果=5,指向下一个服务节点\n     * index=0,默认=0,如果total=5,index+1\n     */\n    private int total = 0;//被调用的次数\n    private int currentIndex = 0;//当前是谁在提供服务\n\n    //@edu.umd.cs.findbugs.annotations.SuppressWarnings(value = \"RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE\")\n    public Server choose(ILoadBalancer lb, Object key) {\n        if (lb == null) {\n            return null;\n        }\n        Server server = null;\n\n        while (server == null) {\n            if (Thread.interrupted()) {\n                return null;\n            }\n            List<Server> upList = lb.getReachableServers();//获得当前活着的服务\n            List<Server> allList = lb.getAllServers();//获取所有的服务\n\n            int serverCount = allList.size();\n            if (serverCount == 0) {\n                /*\n                 * No servers. End regardless of pass, because subsequent passes\n                 * only get more restrictive.\n                 */\n                return null;\n            }\n\n            //int index = chooseRandomInt(serverCount);//生成区间随机数\n            //server = upList.get(index);//从或活着的服务中,随机获取一个\n\n            //=====================自定义代码=========================\n\n            if (total < 5) {\n                server = upList.get(currentIndex);\n                total++;\n            } else {\n                total = 0;\n                currentIndex++;\n                if (currentIndex > upList.size()) {\n                    currentIndex = 0;\n                }\n                server = upList.get(currentIndex);//从活着的服务中,获取指定的服务来进行操作\n            }\n\n            //======================================================\n\n            if (server == null) {\n                /*\n                 * The only time this should happen is if the server list were\n                 * somehow trimmed. This is a transient condition. Retry after\n                 * yielding.\n                 */\n                Thread.yield();\n                continue;\n            }\n            if (server.isAlive()) {\n                return (server);\n            }\n            // Shouldn't actually happen.. but must be transient or a bug.\n            server = null;\n            Thread.yield();\n        }\n        return server;\n    }\n\n    protected int chooseRandomInt(int serverCount) {\n        return ThreadLocalRandom.current().nextInt(serverCount);\n    }\n\n    @Override\n    public Server choose(Object key) {\n        return choose(getLoadBalancer(), key);\n    }\n\n    @Override\n    public void initWithNiwsConfig(IClientConfig clientConfig) {\n        // TODO Auto-generated method stub\n    }\n}\n```\n\n## Feign：负载均衡(基于服务端)\n\n### Feign 简介\n\nFeign 是声明式 Web Service 客户端，它让微服务之间的调用变得更简单，==类似 controller 调用 service==。SpringCloud 集成了 Ribbon 和 Eureka，可以使用 Feigin 提供负载均衡的 http 客户端\n\n**只需要创建一个接口，然后添加注解即可~**\n\nFeign，主要是社区版，大家都习惯面向接口编程。这个是很多开发人员的规范。调用微服务访问两种方法\n\n- 微服务名字 【ribbon】\n- 接口和注解 【feign】\n\n**Feign 能干什么？**\n\n- Feign 旨在使编写 Java Http 客户端变得更容易\n- 前面在使用 Ribbon + RestTemplate 时，利用 RestTemplate 对 Http 请求的封装处理，形成了一套模板化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一个客户端类来包装这些依赖服务的调用。所以，Feign 在此基础上做了进一步的封装，由他来帮助我们定义和实现依赖服务接口的定义，==在 Feign 的实现下，我们只需要创建一个接口并使用注解的方式来配置它 (类似以前 Dao 接口上标注 Mapper 注解，现在是一个微服务接口上面标注一个 Feign 注解)==，即可完成对服务提供方的接口绑定，简化了使用 Spring Cloud Ribbon 时，自动封装服务调用客户端的开发量。\n\n**Feign 默认集成了 Ribbon**\n\n- 利用 Ribbon 维护了 MicroServiceCloud-Dept 的服务列表信息，并且通过轮询实现了客户端的负载均衡，而与 Ribbon 不同的是，通过 Feign 只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用。\n\n### Feign 的使用步骤\n\n1. 创建 springcloud-consumer-fdept-feign 模块\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428120942.png\" alt=\"image-20210428120935729\" style=\"zoom:50%;\" />\n\n   拷贝 springcloud-consumer-dept-80 模块下的 pom.xml，resource，以及 java 代码到 springcloud-consumer-feign 模块，并添加 feign 依赖。\n\n   ```xml\n   <!--Feign的依赖-->\n   <dependency>\n       <groupId>org.springframework.cloud</groupId>\n       <artifactId>spring-cloud-starter-feign</artifactId>\n       <version>1.4.6.RELEASE</version>\n   </dependency>\n   ```\n\n   通过**Ribbon**实现：—原来的 controller：**DeptConsumerController.java**\n\n   ```java\n   package com.luojunjie.springcloud.controller;\n\n   import com.luojunjie.springcloud.pojo.Dept;\n   import org.springframework.beans.factory.annotation.Autowired;\n   import org.springframework.web.bind.annotation.PathVariable;\n   import org.springframework.web.bind.annotation.RequestBody;\n   import org.springframework.web.bind.annotation.RequestMapping;\n   import org.springframework.web.bind.annotation.RestController;\n   import org.springframework.web.client.RestTemplate;\n\n   import java.util.List;\n\n   /**\n    * @author IRVING\n    * @create 2021-04-25 0:24\n    */\n   @RestController\n   public class DeptConsumerController {\n       //消费者不应该有service层\n       // RestTemplate 供我们直接调用! 注册到spring中\n       // 提供多种便捷远程访问http服务的方法，简单的restful服务模板\n\n       @Autowired\n       private RestTemplate restTemplate;\n\n       //通过Ribbon负载均衡，我们这里的地址应该是一个变量，通过服务名来访问\n       //private static final String REST_URL_PREFIX = \"http://localhost:8001\";\n       private static final String REST_URL_PREFIX = \"http://springcloud-provider-dept\";\n\n       //http://localhost:8001/dept/get/1\n       @RequestMapping(\"/consumer/dept/get/{id}\")\n       public Dept get(@PathVariable(\"id\") Long id) {\n           return restTemplate.getForObject(REST_URL_PREFIX + \"/dept/get/\" + id, Dept.class);\n       }\n\n       @RequestMapping(\"/consumer/dept/add\")\n       public boolean add(@RequestBody Dept dept) {\n           return restTemplate.postForObject(REST_URL_PREFIX + \"/dept/add/\", dept, boolean.class);\n       }\n\n       @RequestMapping(\"/consumer/dept/list\")\n       public List<Dept> list() {\n           return restTemplate.getForObject(REST_URL_PREFIX + \"/dept/list\", List.class);\n       }\n   }\n   ```\n\n   通过**Feign**实现：—改造后 controller：**DeptConsumerController.java**\n\n   ```java\n   package com.luojunjie.springcloud.controller;\n\n   import com.luojunjie.springcloud.pojo.Dept;\n   import com.luojunjie.springcloud.service.DeptClientService;\n   import org.springframework.beans.factory.annotation.Autowired;\n   import org.springframework.beans.factory.annotation.Qualifier;\n   import org.springframework.web.bind.annotation.PathVariable;\n   import org.springframework.web.bind.annotation.RequestBody;\n   import org.springframework.web.bind.annotation.RequestMapping;\n   import org.springframework.web.bind.annotation.RestController;\n\n   import java.util.List;\n\n   /**\n    * @author IRVING\n    * @create 2021-04-25 0:24\n    */\n   @RestController\n   public class DeptConsumerController {\n\n       @Autowired\n       private DeptClientService service = null;\n\n       @RequestMapping(\"/consumer/dept/get/{id}\")\n       public Dept get(@PathVariable(\"id\") Long id) {\n           return service.queryById(id);\n       }\n\n       @RequestMapping(\"/consumer/dept/add\")\n       public boolean add(@RequestBody Dept dept) {\n           return service.addDept(dept);\n       }\n\n       @RequestMapping(\"/consumer/dept/list\")\n       public List<Dept> list() {\n           return service.queryAll();\n       }\n   }\n   ```\n\n   Feign 和 Ribbon 二者对比，前者显现出面向接口编程特点，代码看起来更清爽，而且==Feign 调用方式更符合我们之前在做 SSM 或者 SprngBoot 项目时，Controller 层调用 Service 层的编程习惯==！\n\n   主配置类：\n\n   ```java\n   package com.luojunjie.springcloud;\n\n   import org.springframework.boot.SpringApplication;\n   import org.springframework.boot.autoconfigure.SpringBootApplication;\n   import org.springframework.cloud.netflix.eureka.EnableEurekaClient;\n   import org.springframework.cloud.openfeign.EnableFeignClients;\n\n   /**\n    * Ribbon 和 Eureka 整合以后，客户端可以直接调用，不用关心IP地址和端口号\n    * @author IRVING\n    * @create 2021-04-25 0:36\n    */\n   @SpringBootApplication\n   @EnableEurekaClient\n   @EnableFeignClients(basePackages = {\"com.luojunjie.springcloud\"})\n   public class FeignDeptConsumer_80 {\n       public static void main(String[] args) {\n           SpringApplication.run(FeignDeptConsumer_80.class);\n       }\n   }\n   ```\n\n2. 改造 springcloud-api 模块\n\n   pom.xml 添加 feign 依赖\n\n   ```xml\n   <!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-feign -->\n   <dependency>\n       <groupId>org.springframework.cloud</groupId>\n       <artifactId>spring-cloud-starter-feign</artifactId>\n       <version>1.4.6.RELEASE</version>\n   </dependency>\n   ```\n\n   新建 service 包，并新建 DeptClientService.java 接口\n\n   ```java\n   /**\n    * @author IRVING\n    * @create 2021-04-28 11:37\n    */\n   @Component\n   @FeignClient(value = \"springcloud-provider-dept\")\n   public interface DeptClientService {\n   \n       @GetMapping(\"/dept/get/{id}\")\n       Dept queryById(@PathVariable(\"id\") Long id);\n   \n       @GetMapping(\"/dept/list\")\n       List<Dept> queryAll();\n   \n       @PostMapping(\"/dept/add\")\n       boolean addDept(Dept dept);\n   }\n   \n   ```\n\n## Hystrix：服务熔断\n\n> 分布式系统面临的问题\n\n==复杂的分布式体系结构中的应用程序中有数十个依赖关系，每个依赖关系在某些时候将不可避免失败！==\n\n### 服务雪崩\n\n多个微服务之间调用的时候，假设微服务 A 调用微服务 B 和微服务 C，微服务 B 和微服务 C 又调用其他的微服务，这就是所谓的“扇出”，如果扇出的链路上**某个微服务的调用响应时间过长，或者不可用**，对微服务 A 的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428151122.png)\n\n对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几十秒内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障，**这些都表示需要对故障和延迟进行隔离和管理，以达到单个依赖关系的失败而不影响整个应用程序或系统运行**。\n\n**我们需要，弃车保帅！**\n\n### 什么是 Hystrix？\n\n**Hystrix**是一个应用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时，异常等，**Hystrix**==能够保证在一个依赖出问题的情况下，不会导致整个体系服务失败，避免级联故障，以提高分布式系统的弹性==。\n\n“**断路器**”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控 (类似熔断保险丝) ，**向调用方返回一个服务预期的，可处理的备选响应 (FallBack) ，而不是长时间的等待或者抛出调用方法无法处理的异常，这样就可以保证了服务调用方的线程不会被长时间，不必要的占用**，从而避免了故障在分布式系统中的蔓延，乃至雪崩。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428151551.png)\n\n### Hystrix 能干嘛？\n\n- 服务降级\n- 服务熔断\n- 服务限流\n- 接近实时的监控\n\n当一切正常时，请求流可以如下所示：\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428151740.png)\n\n当许多后端系统中有一个潜在阻塞服务时，它可以阻止整个用户请求：\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428151740.png)\n\n随着大容量通信量的增加，单个后端依赖项的潜在性会导致所有服务器上的所有资源在几秒钟内饱和。\n\n应用程序中通过网络或客户端库可能导致网络请求的每个点都是潜在故障的来源。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，从而备份队列、线程和其他系统资源，从而导致更多跨系统的级联故障。\n\n![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRodWIuY29tL05ldGZsaXgvSHlzdHJpeC93aWtpL2ltYWdlcy9zb2EtMy02NDAucG5n?x-oss-process=image/format,png)\n\n当使用**Hystrix**包装每个基础依赖项时，上面的图表中所示的体系结构会发生类似于以下关系图的变化。**每个依赖项是相互隔离的**，限制在延迟发生时它可以填充的资源中，并包含在回退逻辑中，该逻辑决定在依赖项中发生任何类型的故障时要做出什么样的响应：\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428152041.png)\n\n### 服务熔断\n\n**什么是服务熔断?**\n\n**熔断机制是赌赢雪崩效应的一种微服务链路保护机制。**\n\n当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，**进而熔断该节点微服务的调用，快速返回错误的响应信息**。检测到该节点微服务调用响应正常后恢复调用链路。在 SpringCloud 框架里熔断机制通过 Hystrix 实现。Hystrix 会监控微服务间调用的状况，当失败的调用到一定阀值缺省是**5 秒内 20 次调用失败，就会启动熔断机制**。熔断机制的注解是：@HystrixCommand。\n\n服务熔断解决如下问题：\n\n- 当所依赖的对象不稳定时，能够起到快速失败的目的；\n- 快速失败后，能够根据一定的算法动态试探所依赖对象是否恢复。\n\n**入门案例**\n\n新建 springcloud-provider-dept-hystrix-8001 模块并拷贝 springcloud-provider-dept–8001 内的 pom.xml、resource 和 Java 代码进行初始化并调整。\n\n**导入 hystrix 依赖**\n\n```xml\n<!--导入Hystrix依赖-->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-hystrix</artifactId>\n    <version>1.4.6.RELEASE</version>\n</dependency>\n```\n\n**调整 yml 配置文件**\n\n```yaml\nserver:\n  port: 8001\n#mybatis配置\nmybatis:\n  type-aliases-package: com.luojunjie.springcloud.pojo\n  mapper-locations: classpath:mybatis/mapper/*.xml\n  config-location: classpath:mybatis/mybatis-config.xml\n#spring配置\nspring:\n  application:\n    name: springcloud-provider-dept\n  datasource:\n    type: com.alibaba.druid.pool.DruidDataSource\n    driver-class-name: com.mysql.cj.jdbc.Driver\n    url: jdbc:mysql://localhost:3306/db01?useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true\n    username: root\n    password: root\n#Eureka配置，服务注册到哪里\neureka:\n  client:\n    service-url:\n      #启用eureka集群配置\n      defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/\n  instance:\n    instance-id: springcloud-provider-dept-hystrix-8001 #修改eureka上的默认描述\n    prefer-ip-address: true #改为true后默认显示的是ip地址而不再是localhost\n# info配置\ninfo:\n  # 项目配置\n  app:\n    #项目名称\n    name: springcloud-dept8001\n    #公司名称\n    company: www.ljjblog.com\n```\n\n**修改 controller**\n\n```java\npackage com.luojunjie.springcloud.controller;\n\nimport com.luojunjie.springcloud.pojo.Dept;\nimport com.luojunjie.springcloud.service.DeptService;\nimport com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.*;\n\nimport java.util.List;\n\n/**\n * @author IRVING\n * @create 2021-04-25 0:09\n */\n@RestController\npublic class DeptController {\n\n    @Autowired\n    private DeptService deptService;\n\n    /**\n     * 根据id查询部门信息\n     * 如果根据id查询出现异常,则走hystrixGet这段备选代码\n     *\n     * @param id\n     * @return\n     */\n    @GetMapping(\"/dept/get/{id}\")\n    @HystrixCommand(fallbackMethod = \"hystrixGet\")\n    public Dept get(@PathVariable(\"id\") Long id) {\n        Dept dept = deptService.queryById(id);\n        if (dept==null){\n            throw new RuntimeException(\"这个id=>\"+id+\",不存在该用户，或信息无法找到~\");\n        }\n        return dept;\n    }\n\n\n    /**\n     * 根据id查询备选方案(熔断)\n     *\n     * @param id\n     * @return\n     */\n    public Dept hystrixGet(@PathVariable(\"id\") Long id) {\n        return new Dept().setDeptno(id)\n                .setDname(\"这个id=>\" + id + \",没有对应的信息,null---@Hystrix~\")\n                .setDb_source(\"在MySQL中没有这个数据库\");\n    }\n\n}\n```\n\n**为主启动类添加对熔断的支持注解@EnableCircuitBreaker**\n\n```java\npackage com.luojunjie.springcloud;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n/**\n * 在服务启动后自动注册到eureka中\n *\n * @author IRVING\n * @create 2021-04-25 0:13\n */\n@SpringBootApplication\n@EnableDiscoveryClient\n@EnableCircuitBreaker //添加对熔断的支持注解\npublic class HystrixDeptProvider_8001 {\n    public static void main(String[] args) {\n        SpringApplication.run(HystrixDeptProvider_8001.class, args);\n    }\n}\n```\n\n**测试**：\n\n使用熔断后，当访问一个不存在的 id 时，前台页展示数据如下:\n\n![image-20210428224831260](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428224838.png)\n\n**为了避免因某个微服务后台出现异常或错误而导致整个应用或网页报错，使用熔断是必要的**\n\n### 服务降级\n\n什么是服务降级?\n\n服务降级是指 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理，或换种简单的方式处理，从而释放服务器资源以保证核心业务正常运作或高效运作。说白了，**就是尽可能的把系统资源让给优先级高的服务**。\n\n资源有限，而请求是无限的。如果在并发高峰期，不做服务降级处理，一方面肯定会影响整体服务的性能，严重的话可能会导致宕机某些重要的服务不可用。所以，一般在高峰期，为了保证核心功能服务的可用性，都要对某些服务降级处理。比如当双 11 活动时，把交易无关的服务统统降级，如查看蚂蚁深林，查看历史订单等等。\n\n服务降级主要用于什么场景呢？当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，可以将一些 不重要 或 不紧急 的服务或任务进行服务的 延迟使用 或 暂停使用。\n\n降级的方式可以根据业务来，可以延迟服务，比如延迟给用户增加积分，只是放到一个缓存中，等服务平稳之后再执行 ；或者在粒度范围内关闭服务，比如关闭相关文章的推荐。\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210428230041.png)\n\n由上图可得，**当某一时间内服务 A 的访问量暴增，而 B 和 C 的访问量较少，为了缓解 A 服务的压力，这时候需要 B 和 C 暂时关闭一些服务功能，去承担 A 的部分服务，从而为 A 分担压力，叫做服务降级**。\n\n**服务降级需要考虑的问题**\n\n1）那些服务是核心服务，哪些服务是非核心服务\n2）那些服务可以支持降级，那些服务不能支持降级，降级策略是什么\n3）除服务降级之外是否存在更复杂的业务放通场景，策略是什么？\n\n**自动降级分类**\n\n1）超时降级：主要配置好超时时间和超时重试次数和机制，并使用异步机制探测回复情况\n\n2）失败次数降级：主要是一些不稳定的 api，当失败调用次数达到一定阀值自动降级，同样要使用异步机制探测回复情况\n\n3）故障降级：比如要调用的远程服务挂掉了（网络故障、DNS 故障、http 服务返回错误的状态码、rpc 服务抛出异常），则可以直接降级。降级后的处理方案有：默认值（比如库存服务挂了，返回默认现货）、兜底数据（比如广告挂了，返回提前准备好的一些静态页面）、缓存（之前暂存的一些缓存数据）\n\n4）限流降级：秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）。\n\n##### 入门案例\n\n在 springcloud-api 模块下的 service 包中新建降级配置类 DeptClientServiceFallBackFactory.java\n\n```java\npackage com.luojunjie.springcloud.service;\n\nimport com.luojunjie.springcloud.pojo.Dept;\nimport feign.hystrix.FallbackFactory;\n\nimport java.util.List;\n\n/**\n * @author IRVING\n * @create 2021-04-28 23:03\n */\npublic class DeptClientServiceFallBackFactory implements FallbackFactory {\n    @Override\n    public Object create(Throwable throwable) {\n        return new DeptClientService() {\n            @Override\n            public Dept queryById(Long id) {\n                return new Dept()\n                        .setDeptno(id)\n                        .setDname(\"id=>\" + id + \"没有对应的信息，客户端提供了降级的信息，这个服务现在已经被关闭\")\n                        .setDb_source(\"没有数据~\");\n            }\n\n            @Override\n            public List<Dept> queryAll() {\n                return null;\n            }\n\n            @Override\n            public boolean addDept(Dept dept) {\n                return false;\n            }\n        };\n    }\n}\n```\n\n在 DeptClientService 中指定降级配置类 DeptClientServiceFallBackFactory\n\n```java\npackage com.luojunjie.springcloud.service;\n\nimport com.luojunjie.springcloud.pojo.Dept;\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.PostMapping;\n\nimport java.util.List;\n\n/**\n * @author IRVING\n * @create 2021-04-28 11:37\n */\n@Component\n@FeignClient(value = \"springcloud-provider-dept\",fallbackFactory = DeptClientServiceFallBackFactory.class)\npublic interface DeptClientService {\n\n    @GetMapping(\"/dept/get/{id}\")\n    Dept queryById(@PathVariable(\"id\") Long id);\n\n    @GetMapping(\"/dept/list\")\n    List<Dept> queryAll();\n\n    @PostMapping(\"/dept/add\")\n    boolean addDept(Dept dept);\n}\n```\n\n在**springcloud-consumer-dept-feign**模块中开启降级：\n\n```yaml\nserver:\n  port: 80\n#Eureka配置\neureka:\n  client:\n    register-with-eureka: false #不向注册中心注册自己\n    service-url:\n      defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/\n#开启降级feign.hystrix\nfeign:\n  hystrix:\n    enabled: true\n```\n\n#### 服务熔断和服务降级的区别\n\n- 服务熔断—>服务端：某个服务超时或异常，引起熔断~，类似于保险丝(自我熔断)\n- 服务降级—>客户端：从整体网站请求负载考虑，当某个服务熔断或者关闭之后，服务将不再被调用，此时在客户端，我们可以准备一个 FallBackFactory ，返回一个默认的值(缺省值)。会导致整体的服务下降，但是好歹能用，比直接挂掉强。\n- 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）\n- 实现方式不太一样，服务降级具有代码侵入性(由控制器完成/或自动降级)，熔断一般称为自我熔断。\n\n**熔断，降级，限流：**\n\n限流：限制并发的请求访问量，超过阈值则拒绝；\n\n降级：服务分优先级，牺牲非核心服务（不可用），保证核心服务稳定；从整体负荷考虑；\n\n熔断：依赖的下游服务故障触发熔断，避免引发本系统崩溃；系统自动执行和恢复\n\n### Dashboard 流监控\n\n新建 springcloud-consumer-hystrix-dashboard 模块\n\n**添加依赖**\n\n```xml\n<dependencies>\n    <!--导入Hystrix依赖-->\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-hystrix</artifactId>\n        <version>1.4.6.RELEASE</version>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-hystrix-dashboard</artifactId>\n        <version>1.4.6.RELEASE</version>\n    </dependency>\n</dependencies>\n```\n\n**主启动类**\n\n```java\n@SpringBootApplication\n@EnableHystrixDashboard\npublic class DeptConsumerDashboard_9001 {\n    public static void main(String[] args) {\n        SpringApplication.run(DeptConsumerDashboard_9001.class,args);\n    }\n}\n```\n\n给 springcloud-provider-dept-hystrix-8001 模块下的主启动类添加如下代码，开放监控流端口\n\n```java\npackage com.luojunjie.springcloud;\n\nimport com.netflix.hystrix.contrib.metrics.eventstream.HystrixMetricsStreamServlet;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.web.servlet.ServletRegistrationBean;\nimport org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.context.annotation.Bean;\n\n/**\n * 在服务启动后自动注册到eureka中\n *\n * @author IRVING\n * @create 2021-04-25 0:13\n */\n@SpringBootApplication\n@EnableDiscoveryClient\n@EnableCircuitBreaker //添加对熔断的支持注解\npublic class HystrixDeptProvider_8001 {\n    public static void main(String[] args) {\n        SpringApplication.run(HystrixDeptProvider_8001.class, args);\n    }\n\n    @Bean\n    public ServletRegistrationBean hystrixMetricsStreamServlet(){\n        ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet());\n        //访问该页面就是监控页面\n        registrationBean.addUrlMappings(\"/actuator/hystrix.stream\");\n        return registrationBean;\n    }\n}\n\n\n```\n\n访问：http://localhost:9001/hystrix\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210429160335.png\" alt=\"image-20210429160328204\" style=\"zoom:50%;\" />\n\n进入监控页面，效果如下：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210429160510.png\" alt=\"image-20210429160510275\" style=\"zoom:50%;\" />\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210429160522.png)\n\n## Zuul 路由网关\n\n#### 概述\n\n> 什么是 Zuul？\n\nZuul 包含了对请求的路由和过滤的两个最主要的功能：\n\n其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础，而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验，服务聚合等功能的基础。Zuul 和 Eureka 进行整合，将 Zuul 自身注册为 Eureka 中获得其他微服务的消息，也即以后的访问微服务都是通过 Zuul 跳转后获得。\n\n- 注意：Zuul 服务器最终还是会注册 Eureka\n- 提供：==代理 + 路由 + 过滤== 三大功能！\n\n> Zuul 能干嘛？\n\n- 路由\n- 过滤\n\n**入门案例**\n\n**新建 springcloud-zuul 模块，并导入依赖**\n\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-zuul</artifactId>\n        <version>1.4.6.RELEASE</version>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-eureka</artifactId>\n        <version>1.4.6.RELEASE</version>\n    </dependency>\n    <!--导入Hystrix依赖-->\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-hystrix</artifactId>\n        <version>1.4.6.RELEASE</version>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-hystrix-dashboard</artifactId>\n        <version>1.4.6.RELEASE</version>\n    </dependency>\n</dependencies>\n```\n\n**application.yml**\n\n```yaml\nserver:\n  port: 9527\nspring:\n  application:\n    name: springcloud-zuul\neureka:\n  client:\n    service-url:\n      defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/\n  instance:\n    instance-id: zuul9527.com\n    prefer-ip-address: true\n\ninfo:\n  app.name: luojunjie-springcloud\n  company.name: luojunjie\n\nzuul:\n  routes:\n    mydept.serviceId: springcloud-provider-dept\n    mydept.path: /mydept/**\n  ignored-services: \"*\" #不能使用这个路径访问了，* 忽略全部的\n  prefix: /ouwen #公共的前缀\n```\n\n**主启动类**\n\n```java\npackage com.luojunjie.spingcloud;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.zuul.EnableZuulProxy;\n\n/**\n * @author IRVING\n * @create 2021-04-29 21:55\n */\n@SpringBootApplication\n@EnableZuulProxy\npublic class ZuulApplication_9527 {\n    public static void main(String[] args) {\n        SpringApplication.run(ZuulApplication_9527.class,args);\n    }\n}\n```\n\n**测试：**\n\n![image-20210429221139509](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210429221146.png)\n\n可以看出 Zull 路由网关被注册到 Eureka 注册中心中了！\n\n![image-20210429221300961](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210429221301.png)\n\n## Spring Cloud Config\n\n**Dalston.RELEASE**\n\n**Spring Cloud Config 为分布式系统中的外部配置提供服务器和客户端支持。**使用 Config Server，您可以在所有环境中管理应用程序的外部属性。客户端和服务器上的概念映射与 Spring `Environment`和`PropertySource`抽象相同，因此它们与 Spring 应用程序非常契合，但可以与任何以任何语言运行的应用程序一起使用。随着应用程序通过从开发人员到测试和生产的部署流程，您可以管理这些环境之间的配置，并确定应用程序具有迁移时需要运行的一切。服务器存储后端的默认实现使用 git，因此它轻松支持标签版本的配置环境，以及可以访问用于管理内容的各种工具。很容易添加替代实现，并使用 Spring 配置将其插入。\n\n#### 概述\n\n**分布式系统面临的–配置文件问题**\n\n微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务，由于每个服务都需要必要的配置信息才能运行，所以一套集中式的，动态的配置管理设施是必不可少的。spring cloud 提供了 configServer 来解决这个问题，我们每一个微服务自己带着一个 application.yml，那上百个的配置文件修改起来，令人头疼！\n\n**什么是 SpringCloud config 分布式配置中心？**\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210429225000.png)\n\nspring cloud config 为微服务架构中的微服务提供集中化的外部支持，配置服务器为各个不同微服务应用的所有环节提供了一个**中心化的外部配置**。\n\nspring cloud config 分为**服务端**和**客户端**两部分。\n\n服务端也称为 **分布式配置中心**，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密，解密信息等访问接口。\n\n客户端则是**通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息**。配置服务器默认采用 git 来存储配置信息，这样就有助于对环境配置进行版本管理。并且可用通过 git 客户端工具来方便的管理和访问配置内容。\n\n**spring cloud config 分布式配置中心能干嘛？**\n\n- 集中式管理配置文件\n- 不同环境，不同配置，动态化的配置更新，分环境部署，比如 /dev /test /prod /beta /release\n- 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息\n- 当配置发生变动时，服务不需要重启，即可感知到配置的变化，并应用新的配置\n- 将配置信息以 REST 接口的形式暴露\n\n**spring cloud config 分布式配置中心与 GitHub 整合**\n\n由于 spring cloud config 默认使用 git 来存储配置文件 (也有其他方式，比如自持 SVN 和本地文件)，但是最推荐的还是 git ，而且使用的是 http / https 访问的形式。\n\n#### **入门案例**\n\n**服务端**\n\n新建 springcloud-config-server-3344 模块导入 pom.xml 依赖\n\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-config-server</artifactId>\n        <version>2.1.1.RELEASE</version>\n    </dependency>\n</dependencies>\n```\n\nresource 下创建 application.yml 配置文件，Spring Cloud Config 服务器从 git 存储库（必须提供）为远程客户端提供配置：\n\n```yaml\nserver:\n  port: 3344\nspring:\n  application:\n    name: springcloud-config-server\n     # 连接码云远程仓库\n  cloud:\n    config:\n      server:\n        git:\n          uri: https://gitee.com/ouwen666/springcloud-config.git\n```\n\n主启动类\n\n```java\npackage com.luojunjie.springcloud;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.config.server.EnableConfigServer;\n\n/**\n * @author IRVING\n * @create 2021-04-29 23:12\n */\n@SpringBootApplication\n@EnableConfigServer\npublic class SpringCloudConfigServer_3344 {\n    public static void main(String[] args) {\n        SpringApplication.run(SpringCloudConfigServer_3344.class, args);\n    }\n}\n```\n\n将本地 git 仓库 springcloud-config 文件夹下新建的 application.yml 提交到码云仓库：\n\n![image-20210430000230137](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210430000230.png)\n\n定位资源的默认策略是克隆一个 git 仓库（在`spring.cloud.config.server.git.uri`），并使用它来初始化一个迷你`SpringApplication`。小应用程序的`Environment`用于枚举属性源并通过 JSON 端点发布。\n\nHTTP 服务具有以下格式的资源：\n\n```\n/{application}/{profile}[/{label}]\n/{application}-{profile}.yml\n/{label}/{application}-{profile}.yml\n/{application}-{profile}.properties\n/{label}/{application}-{profile}.properties\n```\n\n其中“应用程序”作为 SpringApplication 中的 spring.config.name 注入（即常规的 Spring Boot 应用程序中通常是“应用程序”），“配置文件”是活动配置文件（或逗号分隔列表的属性），“label”是可选的 git 标签（默认为“master”）。\n\n测试访问http://localhost:3344/application-dev.yml\n\n![image-20210430000331332](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210430000331.png)\n\n测试访问 http://localhost:3344/application/test/master\n\n![image-20210430000351363](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210430000351.png)\n\n测试访问 http://localhost:3344/master/application-dev.yml\n\n![image-20210430000417885](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210430000417.png)\n\n如果测试访问不存在的配置则不显示 如：http://localhost:3344/master/application-aaa.yml\n\n![image-20210430000445929](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210430000446.png)\n\n**客户端**\n\n将本地 git 仓库 springcloud-config 文件夹下新建的 config-client.yml 提交到码云仓库：\n\n![image-20210430000230137](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210430000526.png)\n\n新建一个 springcloud-config-client-3355 模块，并导入依赖\n\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-config</artifactId>\n        <version>2.1.1.RELEASE</version>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n</dependencies>\n```\n\nresources 下创建 application.yml 和 bootstrap.yml 配置文件\n\n**bootstrap.yml** 是系统级别的配置\n\n```yaml\n#系统级别的配置\nspring:\n  cloud:\n    config:\n      name: config-client #需要从git上读取的资源名称，不需要后缀\n      uri: http://localhost:3344\n      profile: dev\n      label: master\n```\n\n**application.yml** 是用户级别的配置\n\n```yaml\n#用户级别的配置\nspring:\n  application:\n    name: springcloud-config-client\n```\n\n创建 controller 包下的**ConfigClientController.java** 用于测试\n\n```java\npackage com.luojunjie.springcloud.controller;\n\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n/**\n * @author IRVING\n * @create 2021-04-29 23:44\n */\n@RestController\npublic class ConfigClientController {\n\n    @Value(\"${spring.application.name}\")\n    private String applicationName; //获取微服务名称\n\n    @Value(\"${eureka.client.service-url.defaultZone}\")\n    private String eurekaServer; //获取Eureka服务\n\n    @Value(\"${server.port}\")\n    private String port; //获取服务端的端口号\n\n\n    @RequestMapping(\"/config\")\n    public String getConfig(){\n        return \"applicationName:\"+applicationName +\n                \"eurekaServer:\"+eurekaServer +\n                \"port:\"+port;\n    }\n}\n```\n\n主启动类\n\n```java\npackage com.luojunjie.springcloud;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n/**\n * @author IRVING\n * @create 2021-04-29 23:44\n */\n@SpringBootApplication\npublic class SpringCloudConfigClient_3355 {\n    public static void main(String[] args) {\n        SpringApplication.run(SpringCloudConfigClient_3355.class,args);\n    }\n}\n```\n\n测试：\n\n启动服务端 Config_server_3344 再启动客户端 ConfigClient\n\n访问：http://localhost:8201/config/\n\n![image-20210430000723324](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210430000723.png)\n","tags":["技巧","笔记","分布式"],"categories":["后端开发"]},{"title":"Java8 新特性","slug":"Java8新特性","url":"/2021/06/17/397c083a.html","content":"\n## 前言\n\nJava8 有一个非常显著的特点，就是提供了函数式编程，本文也将介绍 Java8 的几个新特性来实现函数式编程。学会这些 API 能够编写出简单、干净、易读的代码（尤其是对集合的操作）。Java8 新特性包括：\n\n- Lambda 表达式\n- Stream API\n- 接口新特性\n  - 函数式接口（`@FunctionalInterface`）\n  - 默认方法（`default`）\n- Optional API\n- 方法引用\n\nJDK8 新特性\n\n正在努力更新中...\n\n## 函数式接口\n\n- 只包含了一个抽象方法的接口，称为函数式接口（可以有多个非抽象方法）。可以使用`@FunctionalInterface`注解自定义声明\n\n```Java\n//JDK 1.8 之前已有的函数式接口:\n- java.lang.Runnable\n- java.util.concurrent.Callable\n- java.security.PrivilegedAction\n- java.util.Comparator\n- java.io.FileFilter\n- java.nio.file.PathMatcher\n- java.lang.reflect.InvocationHandler\n- java.beans.PropertyChangeListener\n- java.awt.event.ActionListener\n- javax.swing.event.ChangeListener\n//JDK 1.8 新增加的函数接口：\n- java.util.function\n```\n\n## Lambda 表达式\n\n- `Lambda`表达式的使用依赖于函数式接口\n- 使用`Lambda`表达式来表示函数式接口的实现（JAVA 8 之前一般是用匿名类实现的）\n\n### 语法格式\n\n- `-> :Lambda操作符`\n- `-> 左边(parameters):Lambda形参列表`(相当于接口中的抽象方法的形参列表)\n\n1. 参数类型可以省略，可由编译器推断得出(类型推断)\n2. 如果只有一个参数,`()`也可以省略\n\n- `-> 右边:Lambda体`(重写的抽象方法的方法体)\n\n1. 如果只有一条执行语句，`{}`及`return`可以省略\n\n```Java\n(parameters) -> expression\n或\n(parameters) ->{ statements; }\n// 1. 接收2个int型整数,返回他们的和\n(int x, int y) -> x + y\n// 2. 接受一个 string 对象,并在控制台打印,不返回任何值(看起来像是返回void)\n(String s) -> System.out.print(s)\n\n@Test\npublic void test(){\n    Runnable runnable=new Runnable(){\n        @Override\n        public void run(){\n            System.out.println(\"*********\");\n        }\n    }\n    runnable.run();\n    //Lambda表达式写法\n    Runnable runnable= () -> System.out.println(\"*********\");\n    runnable.run();\n}\n```\n\n#### 使用案例\n\n| 使用案例              | Lambda 的例子                                                        | 对应的函数式接口                                                                                      |\n| --------------------- | -------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- |\n| 布尔表达式            | `(List<String> list) -> list.isEmpty()`                              | `Predicate<List<String>>`                                                                             |\n| 创建对象              | `() -> new Project()`                                                | `Supplier<Project>`                                                                                   |\n| 消费一个对象          | `(Project p) -> System.out.println(p.getStars())`                    | `Consumer<Project>`                                                                                   |\n| 从一个对象中选择/提取 | `(int a, int b) -> a * b`                                            | `IntBinaryOperator`                                                                                   |\n| 比较两个对象          | `(Project p1, Project p2) -> p1.getStars().compareTo(p2.getStars())` | `Comparator<Project> 或 BiFunction<Project,` `Project, Integer> 或 ToIntBiFunction<Project, Project>` |\n\n### 方法引用\n\n#### 语法格式\n\n- 使用操作符`::`类或对象与方法名分割\n- 主要有三种使用情况\n\n 对象`::`实例方法名\n\n类`::`实例方法名\n\n类`::`静态方法名\n\n#### 使用案例\n\n```Java\nLambdaQueryWrapper<SysDictItem> queryWrapper = new LambdaQueryWrapper<SysDictItem>();\n//相当于SysDictItem.getStatus();\nqueryWrapper.eq(SysDictItem::getStatus, 1);\nqueryWrapper.orderByAsc(SysDictItem::getSortOrder);\n```\n\n## Stream API\n\n- 使用`Stream API`对集合数据进行操作\n- `stream` 和 `collection` 集合的区别\n  - `collection`是一种静态的内存数据结构，而`stream`是有关计算的，前者主要面向内存，存储在内存中，后者主要面向`cpu`，通过`cpu`计算实现\n- `Stream`的创建方式\n\n```Java\n//1.通过集合创建\n//default Stream<E> stream();//返回一个顺序流\n//default Stream<E> parallelStream();//返回一个并行流\nList<Person> list = new ArrayList<Person>();\nStream<Person> stream = list.stream();\n\n//2.通过Arrays静态方法\nString[] names = {\"chaimm\",\"peter\",\"john\"};\nStream<String> stream = Arrays.stream(names);\n\n//3.通过Stream of\nStream<String> stream = Stream.of(\"chaimm\",\"peter\",\"john\");\n\n//4.创建无限流\n//迭代 遍历0到9\nStream.iterate(0,t->t+1).limit(10).forEach(System.out::println);\n//生成 10个随机数\nStream.generate(Math::random).limit(10).forEach(System.out::println);\n```\n\n- 中间操作\n\n```Java\n//中间操作\n//filer(Predicate p)过滤数据\nList<Person> result = list.stream()\n    .filter(Person::isStudent)\n    .collect(toList());\n\n//limit(n)截断流\nList<Person> result = list.stream()\n    .limit(3)\n    .collect(toList());\n\n//skip(n)跳过元素\nList<Person> result = list.stream()\n    .skip(3)\n    .collect(toList());\n\n//distinct 筛选去重\nList<Person> result = list.stream()\n    .distinct()\n    .collect(toList());\n\n//映射map(Function f)  flatMap(Function f)合并多个流\nList<String> result = list.stream()\n    .map(Person::getName)\n    .collect(toList());\n\n//排序 sorted() 自然排序 sorted(Comparator c)定制顺序\n```\n\n- 终止操作\n\n```Java\n //终止操作\n//匹配与查找\n//allMatch(Predicate e)检查是否匹配所有元素 返回boolean\nboolean result = list.stream()\n    .allMatch(Person::isStudent);\n//anyMatch(Predicate e)检查是否至少匹配一个元素\nboolean result = list.stream()\n    .anyMatch(Person::isStudent);\n//noneMatch(Predicate e)检查是否没有匹配的元素\nboolean result = list.stream()\n    .noneMatch(Person::isStudent);\n//findFierst()返回第一个元素\nOptional<Person> person = list.stream().findFirst();\n//findAny()返回当前流中的任意元素\nOptional<Person> person = list.stream().findAny();\n//count 返回流中元素的总个数\n//max(Comparator c)返回流中最大值\n//min(Comparator c)返回流中最小值\n//forEach(Consumer c)内部迭代\n//归约 reduce(T identity,BinaryOperator)可以将流中元素结合起来得到一个值（求和）\n//例：计算所有人的年龄总和\nint age = list.stream().reduce(0, (person1,person2)->person1.getAge()+person2.getAge());\n//收集collect(Collector c) 将流中元素收集返回相应类型\n```\n\n#### 中间操作和收集操作\n\n| 操作        | 类型 | 返回类型      | 使用的类型/函数式接口   | 函数描述符       |\n| ----------- | ---- | ------------- | ----------------------- | ---------------- |\n| `filter`    | 中间 | `Stream<T>`   | `Predicate<T>`          | `T -> boolean`   |\n| `distinct`  | 中间 | `Stream<T>`   |                         |                  |\n| `skip`      | 中间 | `Stream<T>`   | `long`                  |                  |\n| `map`       | 中间 | `Stream<R>`   | `Function<T, R>`        | `T -> R`         |\n| `flatMap`   | 中间 | `Stream<R>`   | `Function<T,Stream<R>>` | `T -> Stream<R>` |\n| `limit`     | 中间 | `Stream<T>`   | `long`                  |                  |\n| `sorted`    | 中间 | `Stream<T>`   | `Comparator<T>`         | `(T, T) -> int`  |\n| `anyMatch`  | 终端 | `boolean`     | `Predicate<T>`          | `T -> boolean`   |\n| `noneMatch` | 终端 | `boolean`     | `Predicate<T>`          | `T -> boolean`   |\n| `allMatch`  | 终端 | `boolean`     | `Predicate<T>`          | `T -> boolean`   |\n| `findAny`   | 终端 | `Optional<T>` |                         |                  |\n| `findFirst` | 终端 | `Optional<T>` |                         |                  |\n| `forEach`   | 终端 | `void`        | `Consumer<T>`           | `T -> void`      |\n| `collect`   | 终端 | `R`           | `Collector<T, A, R>`    |                  |\n| `reduce`    | 终端 | `Optional<T>` | `BinaryOperator<T>`     | `(T, T) -> T`    |\n| `count`     | 终端 | `long`        |                         |                  |\n\n### 新的日期和 API\n\n> 参考：[hellokaton/learn-java8](https://github.com/hellokaton/learn-java8/blob/master/java8-datetime-api/README.md)\n","tags":["技巧","笔记","Java"],"categories":["后端开发"]},{"title":"Redis 缓存穿透、缓存击穿、缓存雪崩问题","slug":"Redis缓存穿透、缓存击穿、缓存雪崩问题","url":"/2021/06/17/3db3af36.html","content":"\n## 前言\n\n在项目中引入一个缓存系统，不得不考虑的问题就是：缓存穿透、缓存击穿和缓存雪崩问题。\n\n## 缓存穿透\n\n缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。\n\n在流量大时，可能 DB 就挂掉了，要是有人利用不存在的 key 频繁攻击我们的应用，这就是漏洞。\n\n如发起为 id 为`-1`的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。\n\n**解决方案：**\n\n- 接口层增加校验，如用户鉴权校验、id 基础校验（id<=0 直接拦截）\n- 在数据库和缓存中都取不到的数据，可以将在缓存中存入一个空对象（**key-null**），设置一个短的有效时间。这样可以防止一个用户反复暴力攻击一个 id 请求\n\n## 缓存击穿\n\n**缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期）**，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。\n\n**解决方案：**\n\n1. **设置热点数据永不过期**\n2. **接口限流与熔断，降级**。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要做好降级准备，当接口中某些服务不可用时，进行熔断，失败快速返回机制\n3. **布隆过滤器**。bloomfilter 就类似于一个 hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个 key 是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于 hash 算法和容器大小，\n4. **加互斥锁**\n\n## 缓存雪崩\n\n缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至 down 机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。\n\n**解决方案：**\n\n1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。\n2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。\n3. 设置热点数据永远不过期。\n","tags":["笔记","Redis"],"categories":["中间件"]},{"title":"深入理解 RESTful 风格","slug":"深入理解RESTful风格","url":"/2021/06/12/6b25d652.html","content":"\n## 前言\n\n大家对 RESTful 肯定不陌生，就算不知道它到底是什么，但肯定听过这个玩意。相信大家也很想知道 RESTful 能解决什么样的问题，有什么应用场景？看完本篇文章你就能明白：\n\n在互联网并没有盛行的时代， 移动端也还没有发展起来，页面请求和并发量也不高，那时候人们对接口的要求并不高，一些常规的动态页面（JSP）就能满足大部分人们的需求。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210610104619.png\" alt=\"image-20210610104612710\" style=\"zoom: 67%;\" />\n\n但是随着移动设备和互联网的发展，人们对 Web 应用的需求也逐渐增加，传统的动态页面（JSP）也因效率低下而渐渐被 HTML + JavaScript（Ajax）的前后端分离所替代，而安卓、IOS、小程序等不同的客户端层出不穷，客户端的种类出现多元化，**而客户端需要接口跟服务端进行通信**，但接口的 **规范性** 就成了一个问题：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210610105253.png\" alt=\"image-20210610105253175\" style=\"zoom: 67%;\" />\n\n所以一套 **结构清晰、符合标准、易于理解、扩展方便** 并且让大部分人都能理解并接收的接口风格就显得尤为重要，而 RESTful 风格的接口（RESTful API）刚好符合以上标准，就逐渐被应用从而流行起来。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210610105729.png\" alt=\"image-20210610105729739\" style=\"zoom: 67%;\" />\n\n现在，RESTful 是目前最流行的接口设计规范，在很多公司有着广泛的使用。在开发实践中我们很多人可能还是使用传统 API 进行请求交互，很多人其实并不特别了解 RESTful API，对 RESTful API 的认知可能会停留在：\n\n- 面向资源类型的\n- 是一种风格\n- （误区）接口传递参数使用斜杆（/）分割而用问号（?）传参\n\n而其实一个很大的误区不要认为没有查询字符串就是 RESTful API，也不要认为用了查询字符串就不是 RESTful API，更不要认为用了 JSON 传输的 API 就是 RESTful API。\n\n## 一、REST 介绍\n\nREST 涉及一些概念性的东西可能比较多，在实战 RESTful API 之前，要对 REST 相关的知识有个系统的认知。\n\n### REST 的诞生\n\nREST（英文：Representational State Transfer，简称 REST，直译过来表现层状态转换）是一种软件架构风格、设计风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。\n\n它首次出现在 2000 年 Roy Thomas Fielding 的博士论文中，这篇论文定义并详细介绍了表述性状态转移（Representational State Transfer，REST）的架构风格，并且描述了 如何使用 REST 来指导现代 Web 架构的设计和开发。用他自己的原话说：\n\n> 写这篇文章的目的是：在符合架构原理前提下，理解和评估基于网络的应用软件的架构设计，得到一个功能强、性能好、适宜通信的架构。\n\n需要注意的是 **REST 并没有一个明确的标准，而更像是一种设计的风格** ，满足这种设计风格的程序或接口我们称之为 RESTful(从单词字面来看就是一个形容词)。所以 RESTful API 就是满足 REST 架构风格的接口。\n\n### REST 架构特征\n\n既然知道 REST 和 RESTful 的联系和区别，现在就要开始好好了解 RESTful 的一些约束条件和规则，RESTful 是一种风格而不是标准，而这个风格大致有以下几个主要 **特征**：\n\n**以资源为基础** ：资源可以是一个图片、音乐、一个 XML 格式、HTML 格式或者 JSON 格式等网络上的一个实体，除了一些二进制的资源外普通的文本资源更多以 JSON 为载体、面向用户的一组数据(通常从数据库中查询而得到)。\n\n**统一接口**: 对资源的操作包括获取、创建、修改和删除，这些操作正好对应 HTTP 协议提供的 GET、POST、PUT 和 DELETE 方法。换言而知，使用 RESTful 风格的接口但从接口上你可能只能定位其资源，但是无法知晓它具体进行了什么操作，需要具体了解其发生了什么操作动作要从其 HTTP 请求方法类型上进行判断。具体的 HTTP 方法和方法含义如下：\n\n- GET（SELECT）：从服务器取出资源（一项或多项）。\n- POST（CREATE）：在服务器新建一个资源。\n- PUT（UPDATE）：在服务器更新资源（客户端提供完整资源数据）。\n- PATCH（UPDATE）：在服务器更新资源（客户端提供需要修改的资源数据）。\n- DELETE（DELETE）：从服务器删除资源。\n\n当然也有很多在具体使用的时候使用 PUT 表示更新。从请求的流程来看，RESTful API 和传统 API 大致架构如下：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210610133407.png\" alt=\"image-20210610133407454\" style=\"zoom:67%;\" />\n\n**URI 指向资源**：URI = Universal Resource Identifier 统一资源标志符，用来标识抽象或物理资源的一个紧凑字符串。URI 包括 URL 和 URN，在这里更多时候可能代指 URL(统一资源定位符)。RESTful 是面向资源的，每种资源可能由一个或多个 URI 对应，但一个 URI 只指向一种资源。\n\n**无状态**：服务器不能保存客户端的信息， 每一次从客户端发送的请求中，要包含所有必须的状态信息，会话信息由客户端保存， 服务器端根据这些状态信息来处理请求。当客户端可以切换到一个新状态的时候发送请求信息， 当一个或者多个请求被发送之后, 客户端就处于一个状态变迁过程中。每一个应用的状态描述可以被客户端用来初始化下一次的状态变迁。\n\n### REST 架构限制条件\n\nFielding 在论文中提出 REST 架构的 6 个**限制条件**，也可称为 RESTful 6 大原则， 标准的 REST 约束应满足以下 6 个原则：\n\n**客户端-服务端（Client-Server）**: 这个更专注客户端和服务端的分离，服务端独立可更好服务于前端、安卓、IOS 等客户端设备。\n\n**无状态（Stateless）**：服务端不保存客户端状态，客户端保存状态信息每次请求携带状态信息。\n\n**可缓存性（Cacheability）** ：服务端需回复是否可以缓存以让客户端甄别是否缓存提高效率。\n\n**统一接口（Uniform Interface）**：通过一定原则设计接口降低耦合，简化系统架构，这是 RESTful 设计的基本出发点。\n\n**分层系统（Layered System）**：客户端无法直接知道连接的到终端还是中间设备，分层允许你灵活的部署服务端项目。\n\n**按需代码（Code-On-Demand，可选）**：按需代码允许我们灵活的发送一些看似特殊的代码给客户端例如 JavaScript 代码。\n\n## 二、RESTful API 设计规范\n\n既然了解了 RESTful 的一些规则和特性，那么具体该怎么去设计一个 RESTful API 呢？要从 URL 路径、HTTP 请求动词、状态码和返回结果等方面详细考虑。\n\n### URL 设计规范\n\nURL 为统一资源定位器 ,接口属于服务端资源，首先要通过 URL 定位到资源才能去访问，而通常一个完整的 URL 组成由以下几个部分构成：\n\n```\nURI = scheme \"://\" host  \":\"  port \"/\" path [ \"?\" query ][ \"#\" fragment ]\n```\n\n- scheme: 指底层用的协议，如 http、https、ftp\n- host: 服务器的 IP 地址或者域名\n- port: 端口，http 默认为 80 端口\n- path: 访问资源的路径，就是各种 web 框架中定义的 route 路由\n- query: 查询字符串，为发送给服务器的参数，在这里更多发送数据分页、排序等参数。\n- fragment: 锚点，定位到页面的资源\n\n我们在设计 API 时 URL 的 path 是需要认真考虑的，而 RESTful 对 path 的设计做了一些规范，通常一个 RESTful API 的 path 组成如下：\n\n```\n/{version}/{resources}/{resource_id}\n```\n\n- version：API 版本号，有些版本号放置在头信息中也可以，通过控制版本号有利于应用迭代。\n- resources：资源，RESTful API 推荐用小写英文单词的复数形式。\n- resource_id：资源的 id，访问或操作该资源。\n\n当然，有时候可能资源级别较大，其下还可细分很多子资源也可以灵活设计 URL 的 path，例如：\n\n```\n/{version}/{resources}/{resource_id}/{subresources}/{subresource_id}\n```\n\n此外，有时可能增删改查无法满足业务要求，可以在 URL 末尾加上 action，例如：\n\n```\n/{version}/{resources}/{resource_id}/action\n```\n\n其中 action 就是对资源的操作。\n\n从大体样式了解 URL 路径组成之后，对于 RESTful API 的 URL 具体设计的规范如下：\n\n1. 不用大写字母，所有单词使用英文且小写。\n2. 连字符用中杠`\"-\"`而不用下杠`\"_\"`\n3. 正确使用 `\"/\"`表示层级关系,URL 的层级不要过深，并且越靠前的层级应该相对越稳定\n4. 结尾不要包含正斜杠分隔符`\"/\"`\n5. URL 中不出现动词，用请求方式表示动作\n6. 资源表示用复数不要用单数\n7. 不要使用文件扩展名\n\n### HTTP 动词\n\n在 `RESTful API` 中，不同的 HTTP 请求方法有各自的含义，这里就展示 `GET,POST,PUT,DELETE` 几种请求 API 的设计与含义分析。针对不同操作，具体的含义如下：\n\n```\nGET /collection：从服务器查询资源的列表（数组）\nGET /collection/resource：从服务器查询单个资源\nPOST /collection：在服务器创建新的资源\nPUT /collection/resource：更新服务器资源\nDELETE /collection/resource：从服务器删除资源\n```\n\n在非 RESTful 风格的 API 中，我们通常使用 GET 请求和 POST 请求完成增删改查以及其他操作，查询和删除一般使用 GET 方式请求，更新和插入一般使用 POST 请求。从请求方式上无法知道 API 具体是干嘛的，所有在 URL 上都会有操作的动词来表示 API 进行的动作，例如：`query，add，update，delete` 等等。\n\n而 RESTful 风格的 API 则要求在 URL 上的都以名词的方式出现，从几种请求方式上就可以看出想要进行的操作，这与非 RSETful 风格的 API 形成鲜明的对比。\n\n在谈及 `GET,POST,PUT,DELETE` 的时候，就必须提一下接口的 **安全性和幂等性**，其中安全性是指方法不会修改资源状态，即读的为安全的，写的操作为非安全的。而幂等性的意思是操作一次和操作多次的最终效果相同，客户端重复调用也只返回同一个结果。\n\n上述四个 HTTP 请求方法的安全性和幂等性如下：\n\n![image-20210610143431940](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210610143432.png)\n\n### 状态码和返回数据\n\n服务端处理完成后客户端也可能不知道具体成功了还是失败了，服务器响应时，包含**状态码**和**返回数据**两个部分。\n\n#### 状态码\n\n我们首先要正确使用各类状态码来表示该请求的处理执行结果。状态码主要分为五大类：\n\n> 1xx：相关信息\n> 2xx：操作成功\n> 3xx：重定向\n> 4xx：客户端错误\n> 5xx：服务器错误\n\n每一大类有若干小类，状态码的种类比较多，而主要常用状态码罗列在下面：\n\n- 200 `OK - [GET]`：服务器成功返回用户请求的数据，该操作是幂等的（Idempotent）\n- 201 `CREATED - [POST/PUT/PATCH]`：用户新建或修改数据成功\n- 202 `Accepted - [*]`：表示一个请求已经进入后台排队（异步任务）\n- 204 `NO CONTENT - [DELETE]`：用户删除数据成功。\n- 400 `INVALID REQUEST - [POST/PUT/PATCH]`：用户发出的请求有错误，服务器没有进行新建或修改数据的操作，该操作是幂等的\n- 401 `Unauthorized - [*]`：表示用户没有权限（令牌、用户名、密码错误）\n- 403 `Forbidden - [*]` 表示用户得到授权（与 401 错误相对），但是访问是被禁止的\n- 404 `NOT FOUND - [*]`：用户发出的请求针对的是不存在的记录，服务器没有进行操作，该操作是幂等的\n- 406 `Not Acceptable - [GET]`：用户请求的格式不可得（比如用户请求 JSON 格式，但是只有 XML 格式）\n- 410 `Gone -[GET]`：用户请求的资源被永久删除，且不会再得到的\n- 422 `Unprocesable entity - [POST/PUT/PATCH]` 当创建一个对象时，发生一个验证错误\n- 500 `INTERNAL SERVER ERROR - [*]`：服务器发生错误，用户将无法判断发出的请求是否成功\n\n#### 返回结果\n\n针对不同操作，服务器向用户返回数据，而各个团队或公司封装的返回实体类也不同，但都返回 JSON 格式数据给客户端。\n\n## 总结\n\nRESTful 风格的 API 固然很好很规范，但大多数互联网公司并没有按照或者完全按照其规则来设计，因为 REST 是一种风格，而不是一种约束或规则，过于理想的 RESTful API 会付出太多的成本。\n\n比如 RESTful API 也有一些缺点：\n\n- 比如操作方式繁琐，`RESTful API` 通常根据 `GET、POST、PUT、DELETE` 来区分操作资源的动作，而 HTTP Method 本身不可直接见，是隐藏的，而如果将动作放到 URL 的 `path` 上反而清晰可见，更利于团队的理解和交流。\n- 并且有些浏览器对 `GET,POST` 之外的请求支持不太友好，还需要特殊额外的处理。\n- 过分强调资源，而实际业务 API 可能有各种需求比较复杂，单单使用资源的增删改查可能并不能有效满足使用需求，强行使用`RESTful` 风格 API 只会增加开发难度和成本。\n\n所以，当你或你们的技术团队在设计 API 的时候，如果使用场景和 REST 风格很匹配，那么你们可以采用 RESTful 风格 API。但是如果业务需求和 RESTful 风格 API 不太匹配或者很麻烦，那也可以不用 RESTful 风格 API 或者可以借鉴一下，毕竟无论那种风格的 API 都是为了方便团队开发、协商以及管理，不能墨守成规。\n","tags":["技巧","笔记"],"categories":["随笔小记"]},{"title":"缓存数据库双写一致性问题","slug":"缓存数据双写一致性问题","url":"/2021/05/23/30168694.html","content":"\n## 前言\n\n在项目中引入缓存系统，我们需要考虑在对旧数据进行更新操作时，我们是先淘汰缓存，再更新数据库；还是先更新数据库，再淘汰缓存。或者是更新数据库，再更新缓存呢？下面是对这三种方案的优缺点的一些总结：\n\n## 缓存更新策略\n\n1. 先更新数据库，再更新缓存\n2. 先更新数据库，再删除缓存\n3. 先删除缓存，再更新数据库\n\n## 先更新数据库，再更新缓存\n\n> 这套方案适用场景比较少，主要从下面几个原因分析：\n\n### 资源浪费\n\n在一些大型的信息网站中（博客、贴吧），我们引入缓存主要是对热数据（请求频繁的）进行缓存，而这时候，如果很多用户对于冷数据（长时间没人访问，或者访问量很少）进行更新，然后再去更新缓存，这就造成了缓存资源的大量浪费（因为访问量少，导致这些缓存命中低，浪费缓存资源）。\n\n### 脏数据\n\n这是由于出现了并发操作的原因导致的，如：同时有两个请求 A 和 B 对数据进行了更新操作，由于网络原因，可能存在以下情况：\n\n1. 请求 A 更新了数据库\n2. 请求 B 更新了数据库\n3. 请求 B 更新了缓存\n4. 请求 A 更新了缓存\n\n这就出现了 A 数据覆盖了 B 数据的情况，此时就产生了脏数据，如果没有缓存定时过期机制，此时的脏数据需要等待下一次的更新，才会对缓存进行更新，虽然用户看到数据出现问题，会再重新更新一次，但这已经有多了一次不必要的请求了，写请求量大的时候，容易造成众多不必要的更新请求。\n\n### 请求时间\n\n如果缓存不是一种简单的数据缓存，而是需要经过较为复杂的运算，才能得出缓存值，这时候，请求将会在计算缓存值上，耗费一部分时间，而这就导致了请求的响应时间变长，增加系统的负担，降低了系统的处理能力。\n\n### 频繁写入\n\n在写请求很多，而读请求很少的场景下，缓存没起到多大的作用，就给频繁更新了，造成了资源浪费，如：\n\n1. 对数据 A 进行了一次修改，生成了缓存 A\n2. 此时没有读取数据 A 的请求\n3. 对数据 A 进行了一次修改，更新了缓存 A\n4. 此时没有读取数据 A 的请求\n5. 对数据 A 进行了一次修改\n6. 此时有了读取数据 A 的请求\n\n这时就会造成缓存的不必要更新操作（没有人读取缓存），用户量大的时候，会造成大量的不必要操作，造成系统资源的浪费\n\n### 适用场景\n\n一般适用于下列几种场景：\n\n1. 读请求占据网站的总流量的 99%\n2. 网站数据量不大（几十万的文章数据）\n3. 很少会去更新数据（一般文章写好后，不会去更新）\n\n### 案例\n\n1. 个人博客\n2. 手册网站（w3cschool、菜鸟教程等）\n\n## 先更新数据库，再删除缓存\n\n这套方案比较多的平台适用，如 FaceBook。但也存在一些问题：\n\n### 脏数据\n\n造成脏数据的原因主要由并发引起，如：\n\n1. 用户 A 请求数据 A\n2. 数据 A 缓存失效\n3. 用户 A 从数据库中得到旧数据数据 A\n4. 用户 B 更新了数据 A（新数据）\n5. 用户 B 删除了缓存\n6. 用户 A 将查到旧数据写入了缓存\n\n**此时就产生了脏数据，虽然这种概率非常小，但对于更新不频繁的网站来说，此时的脏数据就是个很严重的错误。**\n\n### 缓存删除失效\n\n1. 用户 A 更新了数据 A\n2. 用户 A 删除数据 A 的缓存失败\n3. 用户 B 读到数据 A 缓存的旧数据\n\n此时就产生了数据不一致的问题。\n\n### 解决方案：\n\n#### 设置缓存的有效时间（最简单的解决方案）\n\n**优点：**\n\n- 简单\n- 易操作\n\n**缺点：**\n\n- 会存在短时间内的旧数据\n- 如果数据量太多，缓存有效时间短，容易发生一段时间内缓存大量失效，此时的数据库压力突然剧增，引发缓存雪崩现象（缓存有效时间为随机值减少发生缓存雪崩的可能性）\n\n#### 消息队列（增加复杂性，需要引入消息队列系统）\n\n**步骤：**\n\n1. 更新数据库\n2. 删除缓存失败\n3. 将需要删除的 Key 发送到消息队列\n4. 隔断时间从消息队列中拉取要删除的 key\n5. 继续删除，直至成功为止\n\n**优点：**\n\n- 不会引发缓存雪崩\n- 保证了缓存的删除\n- 不会增加更新的处理时间\n\n**缺点：**\n\n- 引入了消息队列系统，增加了系统的复杂性\n\n## 先删除缓存，在更新数据库\n\n这种方案是比较多人使用的，但也会出现脏数据问题\n\n### **原因：**\n\n1. 用户 A 删除缓存失败\n2. 用户 A 成功更新了数据\n\n或者\n\n1. 用户 A 删除了缓存\n2. 用户 B 读取缓存，缓存不存在\n3. 用户 B 从数据库拿到旧数据\n4. 用户 B 更新了缓存\n5. 用户 A 更新了数据\n\n以上两种情况都能造成脏数据的产生\n\n### **解决方案：**\n\n#### 设置缓存的有效时间（最简单的解决方案）\n\n**优点：**\n\n- 简单\n- 易操作\n\n**缺点：**\n\n- 会存在短时间内的旧数据\n- 如果数据量太多，缓存有效时间短，容易发生一段时间内缓存大量失效，此时的数据库压力突然剧增，引发缓存雪崩现象（缓存有效时间为随机值减少发生缓存雪崩的可能性）\n\n#### 消息队列（增加复杂性，需要引入消息队列系统）\n\n**步骤：**\n\n1. 更新数据库\n2. 删除缓存失败\n3. 将需要删除的 Key 发送到消息队列\n4. 隔断时间从消息队列中拉取要删除的 key\n5. 继续删除，直至成功为止\n\n**优点：**\n\n- 不会引发缓存雪崩\n- 保证了缓存的删除\n- 不会增加更新的处理时间\n\n**缺点：**\n\n- 引入了消息队列系统，增加了系统的复杂性\n\n## 总结：\n\n1. 以上的几种方案需根据自己的业务来选择\n2. 存在即合理，各有优缺点\n3. 使用设置缓存失效时间时，需注意缓存雪崩问题\n4. 可以使用消息队列来避免脏数据的出现\n","tags":["笔记","Redis","分布式"],"categories":["随笔小记"]},{"title":"接口幂等性问题","slug":"接口幂等性问题","url":"/2021/05/20/63f0196d.html","content":"\n## 接口调用出现的问题\n\n在分布式架构的系统中，通常是多个微服务之间互相调用，而服务调用服务无非就是 RPC 或 Restful 进行通信，既然是通信，那么就存在服务器处理完毕返回结果的途中挂掉，这也是分布式系统因网络不可达出现的问题。这个时候用户端很久没有得到服务端的响应，那么就会多次点击按钮，这样请求多次，那么处理数据的结果是否要保持一致呢？答案是肯定的！尤其是在一些订单与支付的场景。\n\n## 什么是接口幂等性？\n\n接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条，这就没有保证接口的幂等性。\n\n## 什么情况下需要保持接口的幂等性？\n\n我们对处理数据无非就是增删改查四个操作？那么那些操作需要保持接口的幂等性？==> **insert 与 update**\n\n- 查询操作 ==> 查询一次或者多次对于结果的影响是不会有改变的，所以 select 是天然的幂等性操作\n- 删除操作 ==> 删除一次与删除多次都是将数据删除（但是注意返回的结果是不一样的，成功 1 失败 0，在不考虑结果的情况下，删除操作也是幂等性操作）\n- 更新操作 ==> 修改操作在大多情况下结果都是一样的，除非是增量修改，那么就是要保持幂等性的。例如：\n  - 将表中的某条记录的某个字段设置为 1 ==> 这个操作不管执行多少次都是幂等的\n  - 将表中的某条记录的某个字段增加 1 ==> 这个操作是不保证幂等性的\n- 新增操作 ==> 新增操作肯定是会出现幂等性问题的，例如上面的支付问题。、\n\n## 那么如何才能保持接口的幂等性？\n\n### 增加数据之前先查询\n\n通常情况下，在保存数据的接口中，我们为了防止产生重复数据，一般会在`insert`前，先根据`name`或`code`字段`select`一下数据。如果该数据已存在，则执行`update`操作，如果不存在，才执行`insert`操作。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210519235210.png\" alt=\"image-20210519235203446\" style=\"zoom: 50%;\" />\n\n==该方案并不适用于并发场景，在并发场景中，要配合其他的方案一起使用，否则还是会造成重复的数据。==\n\n### 加悲观锁\n\n在支付场景中，用户 A 的账号余额有 150 元，想转出 100 元，正常情况下用户 A 的余额只剩 50 元。一般情况下，sql 是这样的：\n\n```sql\nupdate user amount = amount-100 where id=123;\n```\n\n如果出现多次相同的请求，可能会导致用户 A 的余额变成负数。这种情况，用户 A 来可能要哭了。与此同时，系统开发人员可能也要哭了，因为这是很严重的系统 bug。\n\n为了解决这个问题，可以加悲观锁，将用户 A 的那行数据锁住，在同一时刻只允许一个请求获得锁，更新数据，其他的请求则等待。\n\n通常情况下通过如下 sql 锁住单行数据：\n\n```sql\nselect * from user id=123 for update;\n```\n\n具体的流程如下：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210519235501.png\" alt=\"image-20210519235500888\" style=\"zoom:50%;\" />\n\n具体步骤：\n\n1. 多个请求同时根据 id 查询用户信息\n2. 判断余额是否不足 100，如果余额不足，则直接返回余额不足\n3. 如果余额充足，则通过 for update 再次查询用户信息，并且尝试获取锁\n4. 只有第一个请求能获取到行锁，其余没有获取锁的请求，则等待下一次获取锁的机会\n5. 第一个请求获取到锁之后，判断余额是否不足 100，如果余额足够，则进行 update 操作\n6. 如果余额不足，说明是重复请求，则直接返回成功\n\n> **需要特别注意的是：如果使用的是 mysql 数据库，存储引擎必须用 innodb，因为它才支持事务。此外，这里 id 字段一定要是主键或者唯一索引，不然会锁住整张表。**\n\n悲观锁需要在同一个事务操作过程中锁住一行数据，如果事务耗时比较长，会造成大量的请求等待，影响接口性能。\n\n此外，每次请求接口很难保证都有相同的返回值，所以不适合幂等性设计场景，但是在防重场景中是可以的使用的。\n\n在这里顺便说一下，`防重设计`和`幂等设计`，其实是有区别的。 防重设计主要为了避免产生重复数据，对接口返回没有太多要求。 而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。\n\n### 加乐观锁\n\n既然悲观锁有性能问题，为了提升接口性能，我们可以使用乐观锁。需要在表中增加一个`timestamp`或者`version`字段，这里以`version`字段为例。\n\n在更新数据之前先查询一下数据：\n\n```sql\nselect id,amount,version from user id=123;\n```\n\n如果数据存在，假设查到的`version`等于`1`，再使用`id`和`version`字段作为查询条件更新数据：\n\n```sql\nupdate user set amount=amount+100,version=version+1where id=123 and version=1;\n```\n\n更新数据的同时`version+1`，然后判断本次`update`操作的影响行数，如果大于 0，则说明本次更新成功，如果等于 0，则说明本次更新没有让数据变更。\n\n由于第一次请求`version`等于`1`是可以成功的，操作成功后`version`变成`2`了。这时如果并发的请求过来，再执行相同的 sql：\n\n```sql\nupdate user set amount=amount+100,version=version+1where id=123 and version=1;\n```\n\n该`update`操作不会真正更新数据，最终 sql 的执行结果影响行数是`0`，因为`version`已经变成`2`了，`where`中的`version=1`肯定无法满足条件。但为了保证接口幂等性，接口可以直接返回成功，因为`version`值已经修改了，那么前面必定已经成功过一次，后面都是重复的请求。\n\n具体的流程如下：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210520000025.png\" alt=\"image-20210520000025733\" style=\"zoom:50%;\" />\n\n具体步骤：\n\n1. 先根据 id 查询用户信息，包含 version 字段\n2. 根据 id 和 version 字段值作为 where 条件的参数，更新用户信息，同时 version+1\n3. 判断操作影响行数，如果影响 1 行，则说明是一次请求，可以做其他数据操作\n4. 如果影响 0 行，说明是重复请求，则直接返回成功\n\n### 加唯一索引\n\n绝大数情况下，为了防止重复数据的产生，我们都会在表中加唯一索引，这是一个非常简单，并且有效的方案。\n\n```sql\nalter table `order` add UNIQUE KEY `un_code` (`code`);\n```\n\n加了唯一索引之后，第一次请求数据可以插入成功。但后面的相同请求，插入数据时会报`Duplicate entry '002' for key 'order.un_code`异常，表示唯一索引有冲突。\n\n虽说抛异常对数据来说没有影响，不会造成错误数据。但是为了保证接口幂等性，我们需要对该异常进行捕获，然后返回成功。\n\n如果是`java`程序需要捕获：`DuplicateKeyException`异常，如果使用了`spring`框架还需要捕获：`MySQLIntegrityConstraintViolationException`异常。\n\n具体流程如下：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210520000719.png\" alt=\"image-20210520000719765\" style=\"zoom:50%;\" />\n\n具体步骤：\n\n1. 用户通过浏览器发起请求，服务端收集数据\n2. 将该数据插入 mysql\n3. 判断是否执行成功，如果成功，则操作其他数据（可能还有其他的业务逻辑）\n4. 如果执行失败，捕获唯一索引冲突异常，直接返回成功\n\n### 根据状态判断\n\n很多时候业务表是有状态的，比如订单表中有：1-下单、2-已支付、3-完成、4-撤销等状态。如果这些状态的值是有规律的，按照业务节点正好是从小到大，我们就能通过它来保证接口的幂等性。\n\n假如 id=123 的订单状态是`已支付`，现在要变成`完成`状态：\n\n```sql\nupdate `order` set status=3 where id=123 and status=2;\n```\n\n第一次请求时，该订单的状态是`已支付`，值是`2`，所以该`update`语句可以正常更新数据，sql 执行结果的影响行数是`1`，订单状态变成了`3`。\n\n后面有相同的请求过来，再执行相同的 sql 时，由于订单状态变成了`3`，再用`status=2`作为条件，无法查询出需要更新的数据，所以最终 sql 执行结果的影响行数是`0`，即不会真正的更新数据。但为了保证接口幂等性，影响行数是`0`时，接口也可以直接返回成功。\n\n具体的流程如下：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210520001401.png\" alt=\"image-20210520001401770\" style=\"zoom:50%;\" />\n\n具体步骤：\n\n1. 用户通过浏览器发起请求，服务端收集数据\n2. 根据 id 和当前状态作为条件，更新成下一个状态\n3. 判断操作影响行数，如果影响了 1 行，说明当前操作成功，可以进行其他数据操作\n4. 如果影响了 0 行，说明是重复请求，直接返回成功\n\n> **主要特别注意的是，该方案仅限于要更新的表有状态字段，并且刚好要更新状态字段的这种特殊情况，并非所有场景都适用。**\n\n### 加分布式锁\n\n其实前面介绍过的`加唯一索引`或者`加防重表`，本质是使用了`数据库`的`分布式锁`，也属于分布式锁的一种。但由于`数据库分布式锁`的性能不太好，我们可以改用：`redis`或`zookeeper`。本文主要介绍`redis`的分布式锁：\n\n目前主要有三种方式实现 redis 的分布式锁：\n\n1. setNx 命令\n2. set 命令\n3. Redission 框架\n\n具体流程如下：\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210520002920.png\" alt=\"image-20210520002920546\" style=\"zoom:50%;\" />\n\n具体步骤：\n\n1. 用户通过浏览器发起请求，服务端会收集数据，并且生成订单号 code 作为唯一业务字段\n2. 使用 redis 的 set 命令，将该订单 code 设置到 redis 中，同时设置超时时间\n3. 判断是否设置成功，如果设置成功，说明是第一次请求，则进行数据操作\n4. 如果设置失败，说明是重复请求，则直接返回成功\n\n> **需要特别注意的是：分布式锁一定要设置一个合理的过期时间，如果设置过短，无法有效的防止重复请求。如果设置过长，可能会浪费 redis 的存储空间，需要根据实际业务情况而定。**\n\n### 根据 token 判断\n\n除了上述方案之外，还有最后一种使用`token`的方案。该方案跟之前的所有方案都有点不一样，需要两次请求才能完成一次业务操作。\n\n1. 第一次请求获取`token`\n2. 第二次请求带着这个`token`，完成业务操作\n\n具体的流程如下：\n\n1. 获取`token`\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210520003135.png\" alt=\"image-20210520003135146\" style=\"zoom:50%;\" />\n\n2. 做具体业务\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210520003206.png\" alt=\"image-20210520003206028\" style=\"zoom:50%;\" />\n\n具体步骤：\n\n1. 用户访问页面时，浏览器自动发起获取 token 请求\n2. 服务端生成 token，保存到 redis 中，然后返回给浏览器\n3. 用户通过浏览器发起请求时，携带该 token\n4. 在 redis 中查询该 token 是否存在，如果不存在，说明是第一次请求，做则后续的数据操作\n5. 如果存在，说明是重复请求，则直接返回成功\n6. 在 redis 中 token 会在过期时间之后，被自动删除\n\n> **需要特别注意的是：token 必须是全局唯一的。**\n","tags":["笔记","分布式"],"categories":["随笔小记"]},{"title":"Redis 缓存数据库","slug":"Redis数据库","url":"/2021/05/17/3db3af36.html","content":"\n## 为什么要用 Nosql\n\n> 1、单机 MySQL 的年代！\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210420135521.png)\n\n90 年代，一个基本的网站访问量一般不会太大，单个数据库完全足够！\n\n那个时候，更多的去使用静态网页 HTML ==> 服务器根本没有太大的压力！\n\n思考一下，这种情况下：整个网站的瓶颈是什么？\n\n1. 数据量如果太大，一个机器放不下了！\n2. 数据的索引（ B + Tree），一个机器内存也放不下\n3. 访问量（读写混合），一个服务器承受不了\n\n只要你开始出现以上的三种情况之一，那么你就必须晋级！\n\n> 2、Memcached（缓存）+ MySQL + 垂直拆分（读写分离）\n\n网站 80%的情况都是在读，每次都要去查询数据库的话就十分的麻烦！所以说我们希望减轻数据库的压力，我们可以使用缓存来保证效率！\n\n发展过程：优化数据结构和索引 --> 文件缓存（IO）--> Memcached（当时最热门的技术！）\n\n> 3、分库分表 + 水平拆分 + MySQL 集群\n\n技术和业务在发展的同时，对人的要求也越来越高！\n\n==本质：数据库（读、写）==\n\n早些年 MyISAM：表锁，十分影响效率！高并发下就会出现严重的锁问题\n\n转战 Innodb：行锁\n\n慢慢的就开始使用分库分表来解决写的压力！MySQL 在那个年代就推出了 表分区！这个并没有多少公司使用！\n\nMySQL 的集群，很好的满足那个年代的需求！\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210420134715.png)\n\n> 4、最近的年代\n\n如今信息量井喷式增长，各种各样的数据出现（用户定位数据，图片数据等），大数据的背景下关系型数据库（RDBMS）无法满足大量数据要求。Nosql 数据库就能轻松解决这些问题。目前一个基本的互联网项目：\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210420134812.png)\n\n> 为什么要用 NoSQL！\n\n用户的个人信息，社交网络，地理位置。用户自己产生的数据，用户日志等等爆发式增长！这时候我们就需要使用 NoSQL 数据库的，Nosql 可以很好的处理以上的情况！\n\n## 什么是 NoSQL\n\n> NoSQL\n\nNoSQL = Not Only SQL（不仅仅是 SQL）\n\nNot Only Structured Query Language\n\n关系型数据库：列+行，同一个表下数据的结构是一样的。\n\n非关系型数据库：数据存储没有固定的格式，并且可以进行横向扩展。\n\nNoSQL 泛指非关系型数据库，随着 web2.0 互联网的诞生，传统的关系型数据库很难对付 web2.0 时代！尤其是超大规模的高并发的社区，暴露出来很多难以克服的问题，NoSQL 在当今大数据环境下发展的十分迅速，Redis 是发展最快的。\n\n> NoSQL 特点\n\n1. 方便扩展（数据之间没有关系，很好扩展！）\n2. 大数据量高性能（Redis 一秒可以写 8 万次，读 11 万次，NoSQL 的缓存记录级，是一种细粒度的缓存，性能会比较高！）\n3. 数据类型是多样型的！（不需要事先设计数据库，随取随用）\n4. 传统的 RDBMS 和 NoSQL\n\n```\n传统的 RDBMS\n- 结构化组织\n- SQL\n- 数据和关系都存在单独的表中 row col\n- 操作，数据定义语言\n- 严格的一致性\n- 严格的事务\n- ...\n```\n\n```\nNoSQL\n- 不仅仅是数据\n- 没有固定的查询语言\n- 键值对存储，列存储，文档存储，图形数据库（社交关系）\n- 最终一致性\n- CAP定理和BASE\n- 高性能，高可用，高可扩\n- ...\n```\n\n> 了解：3V+3 高\n\n- 大数据时代的 3V ：主要是描述问题的\n\n  - 海量 Velume\n  - 多样 Variety\n  - 实时 Velocity\n\n- 大数据时代的 3 高 ： 主要是对程序的要求\n  - 高并发\n  - 高可扩\n  - 高性能\n\n真正在公司中的实践：NoSQL + RDBMS 一起使用才是最强的。\n\n## NoSQL 的四大分类\n\n**KV 键值对**\n\n- 新浪：Redis\n- 美团：Redis + Tair\n- 阿里、百度：Redis + memecache\n\n**文档型数据库（bson 格式 和 json 一样）**\n\n- mongoDB\n  - MongoDB 是一个基于分布式文件存储的数据库，C++编写，主要用来处理大量的文档！\n  - MongoDB 是一个介于关系型数据库和非关系型数据库中间的产品！MongoDB 是非关系型数据库汇总功能最丰富的，最像关系型数据库的！\n- CouchDB\n\n**列存储数据库**\n\n- HBase\n- 分布式文件系统\n\n**图关系数据库**\n\n![image-20210420211847626](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210420211847.png)\n\n- 他不是存图形，放的是关系，比如：朋友圈社交网络，广告推荐！\n- **Neo4j**，infoGrid\n\n# Redis 入门\n\n## 概述\n\n> Redis 是什么？\n\nRedis（Remote Dictionary Server )，即远程字典服务。\n\n是一个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API。\n\n与 memcached 一样，为了保证效率，数据都是缓存在内存中。区别的是 redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了 master-slave(主从)同步。\n\n> Redis 能干嘛？\n\n1. 内存存储、持久化，内存中是断电即失、所以说持久化很重要（RDB、AOF）\n2. 效率高，可以用于高速缓存\n3. 发布订阅系统\n4. 地图信息分析\n5. 计时器、计数器（浏览量！）\n6. ......\n\n> 特性\n\n1. 多样的数据类型\n2. 持久化\n3. 集群\n4. 事务\n5. ...\n\n## 环境搭建（省略）\n\n[Redis 安装 | 菜鸟教程 (runoob.com)](https://www.runoob.com/redis/redis-install.html)\n\n## 测试性能\n\n**redis-benchmark** 是一个压力测试工具！\n\n官方自带的性能测试工具！\n\n```bash\nredis-benchmark [option] [option value]\n```\n\n![image-20210502131730085](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210502131730.png)\n\n我们来简单测试一下：\n\n```bash\n# 测试100个并发连接 100000个请求\nredis-benchmark localhost -p 6379 -c 100 -n 100000\n```\n\n![image-20210502132313424](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210502132313.png)\n\n如何查看这些分析呢？\n\n![image-20210502132426480](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210502132426.png)\n\n## 基础的知识\n\n**redis 默认有 16 个数据库**\n\n![image-20210502132621114](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210502132621.png)\n\n默认使用的是第 0 个\n\n可以使用`select`进行切换数据库！\n\n```bash\n127.0.0.1:6379> select 3 #切换数据库\nOK\n127.0.0.1:6379[3]> DBSIZE #查看db大小\n(integer) 0\n127.0.0.1:6379[3]> set name ouwen #设置key-value\nOK\n127.0.0.1:6379[3]> DBSIZE #查看db大小\n(integer) 1\n127.0.0.1:6379[3]> get name #获取value\n\"ouwen\"\n127.0.0.1:6379[3]> keys * #获取所有key\n1) \"name\"\n127.0.0.1:6379[3]> FLUSHDB #清除当前数据库\nOK\n127.0.0.1:6379[3]> keys *\n(empty list or set)\n127.0.0.1:6379[3]> FLUSHALL #清除全部数据库\nOK\n```\n\n> Redis 是单线程的！\n\n**Redis 到底有多快？**\n\nRedis 采用的是基于内存的采用的是**单进程单线程**模型的 **KV 数据库**，**由 C 语言编写**，官方提供的数据是可以达到 100000+的 QPS（每秒内查询次数）。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差！\n\n**Redis 为什么这么快？**\n\n1. 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)；\n2. 数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；\n3. 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；\n4. 使用多路 I/O 复用模型，非阻塞 IO；\n5. 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；\n\n以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨：\n\n**多路 I/O 复用模型**\n\n多路 I/O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。\n\n**这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。**采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响 Redis 性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。\n\n**那么为什么 Redis 是单线程的？**\n\n我们首先要明白，上边的种种分析，都是为了营造一个 Redis 很快的氛围！官方 FAQ 表示，因为 Redis 是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。\n\n# 五大数据类型\n\n> 官方文档\n\nRedis 是一个开源（BSD 许可）的，内存中的数据结构存储系统，它可以用作==数据库、缓存和消息中间 件 MQ==。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合 （sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间 （geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA 脚本（Lua scripting）， LRU 驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis 哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。\n\n## Redis-Key\n\n| 序号 | 命令及描述                                                                                                                                                                                                      |\n| :--- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | [DEL key](https://www.runoob.com/redis/keys-del.html) <br />该命令用于在 key 存在时删除 key。                                                                                                                   |\n| 2    | [DUMP key](https://www.runoob.com/redis/keys-dump.html) <br />序列化给定 key ，并返回被序列化的值。                                                                                                             |\n| 3    | [EXISTS key](https://www.runoob.com/redis/keys-exists.html) <br />检查给定 key 是否存在。                                                                                                                       |\n| 4    | [EXPIRE key seconds](https://www.runoob.com/redis/keys-expire.html) <br />为给定 key 设置过期时间，以秒计。                                                                                                     |\n| 5    | [EXPIREAT key timestamp](https://www.runoob.com/redis/keys-expireat.html) <br />EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。 |\n| 6    | [PEXPIRE key milliseconds](https://www.runoob.com/redis/keys-pexpire.html) <br />设置 key 的过期时间以毫秒计。                                                                                                  |\n| 7    | [PEXPIREAT key milliseconds-timestamp](https://www.runoob.com/redis/keys-pexpireat.html) <br />设置 key 过期时间的时间戳(unix timestamp) 以毫秒计                                                               |\n| 8    | [KEYS pattern](https://www.runoob.com/redis/keys-keys.html) <br />查找所有符合给定模式( pattern)的 key 。                                                                                                       |\n| 9    | [MOVE key db](https://www.runoob.com/redis/keys-move.html) <br />将当前数据库的 key 移动到给定的数据库 db 当中。                                                                                                |\n| 10   | [PERSIST key](https://www.runoob.com/redis/keys-persist.html) <br />移除 key 的过期时间，key 将持久保持。                                                                                                       |\n| 11   | [PTTL key](https://www.runoob.com/redis/keys-pttl.html) <br />以毫秒为单位返回 key 的剩余的过期时间。                                                                                                           |\n| 12   | [TTL key](https://www.runoob.com/redis/keys-ttl.html) <br />以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。                                                                                        |\n| 13   | [RANDOMKEY<br />](https://www.runoob.com/redis/keys-randomkey.html) 从当前数据库中随机返回一个 key 。                                                                                                           |\n| 14   | [RENAME key newkey](https://www.runoob.com/redis/keys-rename.html) <br />修改 key 的名称                                                                                                                        |\n| 15   | [RENAMENX key newkey](https://www.runoob.com/redis/keys-renamenx.html) <br />仅当 newkey 不存在时，将 key 改名为 newkey 。                                                                                      |\n| 16   | [SCAN cursor [MATCH pattern\\] [COUNT count]](https://www.runoob.com/redis/keys-scan.html) <br />迭代数据库中的数据库键。                                                                                        |\n| 17   | [TYPE key](https://www.runoob.com/redis/keys-type.html) <br />返回 key 所储存的值的类型。                                                                                                                       |\n\n## String（字符串）\n\n| 序号 | 命令及描述                                                                                                                                                                                    |\n| :--- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | [SET key value](https://www.runoob.com/redis/strings-set.html) <br />设置指定 key 的值                                                                                                        |\n| 2    | [GET key](https://www.runoob.com/redis/strings-get.html) <br />获取指定 key 的值。                                                                                                            |\n| 3    | [GETRANGE key start end](https://www.runoob.com/redis/strings-getrange.html) <br />返回 key 中字符串值的子字符                                                                                |\n| 4    | [GETSET key value](https://www.runoob.com/redis/strings-getset.html) <br />将给定 key 的值设为 value ，并返回 key 的旧值(old value)。                                                         |\n| 5    | [GETBIT key offset](https://www.runoob.com/redis/strings-getbit.html) <br />对 key 所储存的字符串值，获取指定偏移量上的位(bit)。                                                              |\n| 6    | [MGET key1 [key2..]](https://www.runoob.com/redis/strings-mget.html) <br />获取所有(一个或多个)给定 key 的值。                                                                                |\n| 7    | [SETBIT key offset value](https://www.runoob.com/redis/strings-setbit.html) <br />对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。                                                  |\n| 8    | [SETEX key seconds value](https://www.runoob.com/redis/strings-setex.html) <br />将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。                                       |\n| 9    | [SETNX key value](https://www.runoob.com/redis/strings-setnx.html) <br />只有在 key 不存在时设置 key 的值。                                                                                   |\n| 10   | [SETRANGE key offset value](https://www.runoob.com/redis/strings-setrange.html) <br />用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。                                      |\n| 11   | [STRLEN key](https://www.runoob.com/redis/strings-strlen.html) <br />返回 key 所储存的字符串值的长度。                                                                                        |\n| 12   | [MSET key value [key value ...]](https://www.runoob.com/redis/strings-mset.html) <br />同时设置一个或多个 key-value 对。                                                                      |\n| 13   | [MSETNX key value[key value ...]](https://www.runoob.com/redis/strings-msetnx.html) <br />同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。                                    |\n| 14   | [PSETEX key milliseconds value](https://www.runoob.com/redis/strings-psetex.html) <br />这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。 |\n| 15   | [INCR key](https://www.runoob.com/redis/strings-incr.html) <br />将 key 中储存的数字值增一。                                                                                                  |\n| 16   | [INCRBY key increment](https://www.runoob.com/redis/strings-incrby.html) <br />将 key 所储存的值加上给定的增量值（increment） 。                                                              |\n| 17   | [INCRBYFLOAT key increment](https://www.runoob.com/redis/strings-incrbyfloat.html) <br />将 key 所储存的值加上给定的浮点增量值（increment） 。                                                |\n| 18   | [DECR key](https://www.runoob.com/redis/strings-decr.html) <br />将 key 中储存的数字值减一。                                                                                                  |\n| 19   | [DECRBY key decrement](https://www.runoob.com/redis/strings-decrby.html) <br />key 所储存的值减去给定的减量值（decrement） 。                                                                 |\n| 20   | [APPEND key value](https://www.runoob.com/redis/strings-append.html) <br />如果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾。                 |\n\n```bash\n##########################################################################\n127.0.0.1:6379> set key1 v1 # 设置值\nOK\n127.0.0.1:6379> get key1 # 获得值\n\"v1\"\n127.0.0.1:6379> keys * # 获得所有的key\n1) \"key1\"\n127.0.0.1:6379> EXISTS key1 # 判断某一个key是否存在\n(integer) 1\n127.0.0.1:6379> APPEND key1 \"hello\" # 追加字符串，如果当前key不存在，就相当于setkey\n(integer) 7\n127.0.0.1:6379> get key1\n\"v1hello\"\n127.0.0.1:6379> STRLEN key1 # 获取字符串的长度！\n(integer) 7\n127.0.0.1:6379> APPEND key1 \",kaungshen\"\n(integer) 17\n127.0.0.1:6379> STRLEN key1\n(integer) 17\n127.0.0.1:6379> get key1\n\"v1hello,kaungshen\"\n\n##########################################################################\n# i++\n# 步长 i+=\n127.0.0.1:6379> set views 0 # 初始浏览量为0\nOK\n127.0.0.1:6379> get views\n\"0\"\n127.0.0.1:6379> incr views # 自增1 浏览量变为1\n(integer) 1\n127.0.0.1:6379> incr views\n(integer) 2\n127.0.0.1:6379> get views\n\"2\"\n127.0.0.1:6379> decr views # 自减1 浏览量-1\n(integer) 1\n127.0.0.1:6379> decr views\n(integer) 0\n127.0.0.1:6379> decr views\n(integer) -1\n127.0.0.1:6379> get views\n\"-1\"\n127.0.0.1:6379> INCRBY views 10 # 可以设置步长，指定增量！\n(integer) 9\n127.0.0.1:6379> INCRBY views 10\n(integer) 19\n127.0.0.1:6379> DECRBY views 5\nbilibili：狂神说Java(integer) 14\n\n##########################################################################\n# 字符串范围 range\n127.0.0.1:6379> set key1 \"hello,kuangshen\" # 设置 key1 的值\nOK\n127.0.0.1:6379> get key1\n\"hello,kuangshen\"\n127.0.0.1:6379> GETRANGE key1 0 3 # 截取字符串 [0,3]\n\"hell\"\n127.0.0.1:6379> GETRANGE key1 0 -1 # 获取全部的字符串 和 get key是一样的\n\"hello,kuangshen\"\n# 替换！\n127.0.0.1:6379> set key2 abcdefg\nOK\n127.0.0.1:6379> get key2\n\"abcdefg\"\n127.0.0.1:6379> SETRANGE key2 1 xx # 替换指定位置开始的字符串！\n(integer) 7\n127.0.0.1:6379> get key2\n\"axxdefg\"\n\n##########################################################################\n# setex (set with expire) # 设置过期时间\n# setnx (set if not exist) # 不存在在设置 （在分布式锁中会常常使用！）\n127.0.0.1:6379> setex key3 30 \"hello\" # 设置key3 的值为 hello,30秒后过期\nOK\n127.0.0.1:6379> ttl key3\n(integer) 26\n127.0.0.1:6379> get key3\n\"hello\"\n127.0.0.1:6379> setnx mykey \"redis\" # 如果mykey 不存在，创建mykey\n(integer) 1\n127.0.0.1:6379> keys *\n1) \"key2\"\n2) \"mykey\"\n3) \"key1\"\n127.0.0.1:6379> ttl key3\n(integer) -2\n127.0.0.1:6379> setnx mykey \"MongoDB\" # 如果mykey存在，创建失败！\n(integer) 0\n127.0.0.1:6379> get mykey\n\"redis\"\n\n##########################################################################\nmset\nmget\n127.0.0.1:6379> mset k1 v1 k2 v2 k3 v3 # 同时设置多个值\nOK\n127.0.0.1:6379> keys *\n1) \"k1\"\n2) \"k2\"\n3) \"k3\"\n127.0.0.1:6379> mget k1 k2 k3 # 同时获取多个值\n1) \"v1\"\n2) \"v2\"\n3) \"v3\"\nbilibili：狂神说Java数据结构是相同的！\nString类似的使用场景：value除了是我们的字符串还可以是我们的数字！\n计数器\n统计多单位的数量\n粉丝数\n对象缓存存储！\nList（列表）\n基本的数据类型，列表\n127.0.0.1:6379> msetnx k1 v1 k4 v4 # msetnx 是一个原子性的操作，要么一起成功，要么一起\n失败！\n(integer) 0\n127.0.0.1:6379> get k4\n(nil)\n# 对象\nset user:1 {name:zhangsan,age:3} # 设置一个user:1 对象 值为 json字符来保存一个对象！\n# 这里的key是一个巧妙的设计： user:{id}:{filed} , 如此设计在Redis中是完全OK了！\n127.0.0.1:6379> mset user:1:name zhangsan user:1:age 2\nOK\n127.0.0.1:6379> mget user:1:name user:1:age\n1) \"zhangsan\"\n2) \"2\"\n\n##########################################################################\ngetset # 先get然后在set\n127.0.0.1:6379> getset db redis # 如果不存在值，则返回 nil\n(nil)\n127.0.0.1:6379> get db\n\"redis\n127.0.0.1:6379> getset db mongodb # 如果存在值，获取原来的值，并设置新的值\n\"redis\"\n127.0.0.1:6379> get db\n\"mongodb\"\n```\n\n数据结构是相同的！\n\nString 类似的使用场景：value 除了是我们的字符串还可以是我们的数字！\n\n- 计数器\n- 统计多单位的数量\n- 粉丝数\n- 对象缓存存储！\n\n## List（列表）\n\nRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）\n\n一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过 40 亿个元素)。\n\n基本的数据类型，列表\n\n![image-20210502143650744](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210502143650.png)\n\n在 redis 里面，我们可以把 list 玩成 ，栈、队列、阻塞队列！\n\n所有的 list 命令都是用 l 开头的，Redis 不区分大小命令\n\n| 序号 | 命令及描述                                                                                                                                                                                                                    |\n| :--- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | [BLPOP key1 [key2] timeout](https://www.runoob.com/redis/lists-blpop.html) <br />移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。                                                    |\n| 2    | [BRPOP key1 [key2] timeout](https://www.runoob.com/redis/lists-brpop.html) 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。                                                        |\n| 3    | [BRPOPLPUSH source destination timeout](https://www.runoob.com/redis/lists-brpoplpush.html) <br />从列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 |\n| 4    | [LINDEX key index](https://www.runoob.com/redis/lists-lindex.html) <br />通过索引获取列表中的元素                                                                                                                             |\n| 5    | [LINSERT key BEFORE\\|AFTER pivot value](https://www.runoob.com/redis/lists-linsert.html) <br />在列表的元素前或者后插入元素                                                                                                   |\n| 6    | [LLEN key](https://www.runoob.com/redis/lists-llen.html) <br />获取列表长度                                                                                                                                                   |\n| 7    | [LPOP key](https://www.runoob.com/redis/lists-lpop.html) <br />移出并获取列表的第一个元素                                                                                                                                     |\n| 8    | [LPUSH key value1 [value2]](https://www.runoob.com/redis/lists-lpush.html) <br />将一个或多个值插入到列表头部                                                                                                                 |\n| 9    | [LPUSHX key value](https://www.runoob.com/redis/lists-lpushx.html) <br />将一个值插入到已存在的列表头部                                                                                                                       |\n| 10   | [LRANGE key start stop](https://www.runoob.com/redis/lists-lrange.html) <br />获取列表指定范围内的元素                                                                                                                        |\n| 11   | [LREM key count value](https://www.runoob.com/redis/lists-lrem.html) <br />移除列表元素                                                                                                                                       |\n| 12   | [LSET key index value](https://www.runoob.com/redis/lists-lset.html) <br />通过索引设置列表元素的值                                                                                                                           |\n| 13   | [LTRIM key start stop](https://www.runoob.com/redis/lists-ltrim.html) <br />对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。                                                |\n| 14   | [RPOP key](https://www.runoob.com/redis/lists-rpop.html) <br />移除列表的最后一个元素，返回值为移除的元素。                                                                                                                   |\n| 15   | [RPOPLPUSH source destination](https://www.runoob.com/redis/lists-rpoplpush.html) <br />移除列表的最后一个元素，并将该元素添加到另一个列表并返回                                                                              |\n| 16   | [RPUSH key value1 [value2]](https://www.runoob.com/redis/lists-rpush.html) <br />在列表中添加一个或多个值                                                                                                                     |\n| 17   | [RPUSHX key value](https://www.runoob.com/redis/lists-rpushx.html) <br />为已存在的列表添加值                                                                                                                                 |\n\n```bash\n##########################################################################\n127.0.0.1:6379> LPUSH list one # 将一个值或者多个值，插入到列表头部 （左）\n(integer) 1\n127.0.0.1:6379> LPUSH list two\n(integer) 2\n127.0.0.1:6379> LPUSH list three\n(integer) 3\n127.0.0.1:6379> LRANGE list 0 -1 # 获取list中值！\n1) \"three\"\n2) \"two\"\n3) \"one\"\n127.0.0.1:6379> LRANGE list 0 1 # 通过区间获取具体的值！\n1) \"three\"\n2) \"two\"\n127.0.0.1:6379> Rpush list righr # 将一个值或者多个值，插入到列表位部 （右）\n(integer) 4\n127.0.0.1:6379> LRANGE list 0 -1\n1) \"three\"\n2) \"two\"\n3) \"one\"\n4) \"righr\"\n##########################################################################\nLPOP\nRPOP\n127.0.0.1:6379> LRANGE list 0 -1\n1) \"three\"\n2) \"two\"\n3) \"one\"\n4) \"righr\"\n127.0.0.1:6379> Lpop list # 移除list的第一个元素\n\"three\"\n127.0.0.1:6379> Rpop list # 移除list的最后一个元素\n\"righr\"\n127.0.0.1:6379> LRANGE list 0 -1\n1) \"two\"\n2) \"one\"\n##########################################################################\nLindex\n127.0.0.1:6379> LRANGE list 0 -1\n1) \"two\"\n2) \"one\"\n127.0.0.1:6379> lindex list 1 # 通过下标获得 list 中的某一个值！\n\"one\"\n127.0.0.1:6379> lindex list 0\n\"two\"\n##########################################################################\nLlen\n127.0.0.1:6379> Lpush list one\n(integer) 1\n127.0.0.1:6379> Lpush list two\nbilibili：狂神说Java(integer) 2\n127.0.0.1:6379> Lpush list three\n(integer) 3\n127.0.0.1:6379> Llen list # 返回列表的长度\n(integer) 3\n##########################################################################\n移除指定的值！\n取关 uid\nLrem\n127.0.0.1:6379> LRANGE list 0 -1\n1) \"three\"\n2) \"three\"\n3) \"two\"\n4) \"one\"\n127.0.0.1:6379> lrem list 1 one # 移除list集合中指定个数的value，精确匹配\n(integer) 1\n127.0.0.1:6379> LRANGE list 0 -1\n1) \"three\"\n2) \"three\"\n3) \"two\"\n127.0.0.1:6379> lrem list 1 three\n(integer) 1\n127.0.0.1:6379> LRANGE list 0 -1\n1) \"three\"\n2) \"two\"\n127.0.0.1:6379> Lpush list three\n(integer) 3\n127.0.0.1:6379> lrem list 2 three\n(integer) 2\n127.0.0.1:6379> LRANGE list 0 -1\n1) \"two\"\n##########################################################################\ntrim 修剪。； list 截断!\n127.0.0.1:6379> keys *\n(empty list or set)\n127.0.0.1:6379> Rpush mylist \"hello\"\n(integer) 1\n127.0.0.1:6379> Rpush mylist \"hello1\"\n(integer) 2\n127.0.0.1:6379> Rpush mylist \"hello2\"\n(integer) 3\n127.0.0.1:6379> Rpush mylist \"hello3\"\n(integer) 4\n127.0.0.1:6379> ltrim mylist 1 2 # 通过下标截取指定的长度，这个list已经被改变了，截断了\n只剩下截取的元素！\nOK\n127.0.0.1:6379> LRANGE mylist 0 -1\n1) \"hello1\"\n2) \"hello2\"\n##########################################################################\nrpoplpush # 移除列表的最后一个元素，将他移动到新的列表中！\n127.0.0.1:6379> rpush mylist \"hello\"\nbilibili：狂神说Java小结\n他实际上是一个链表，before Node after ， left，right 都可以插入值\n如果key 不存在，创建新的链表\n如果key存在，新增内容\n(integer) 1\n127.0.0.1:6379> rpush mylist \"hello1\"\n(integer) 2\n127.0.0.1:6379> rpush mylist \"hello2\"\n(integer) 3\n127.0.0.1:6379> rpoplpush mylist myotherlist # 移除列表的最后一个元素，将他移动到新的\n列表中！\n\"hello2\"\n127.0.0.1:6379> lrange mylist 0 -1 # 查看原来的列表\n1) \"hello\"\n2) \"hello1\"\n127.0.0.1:6379> lrange myotherlist 0 -1 # 查看目标列表中，确实存在改值！\n1) \"hello2\"\n##########################################################################\nlset 将列表中指定下标的值替换为另外一个值，更新操作\n127.0.0.1:6379> EXISTS list # 判断这个列表是否存在\n(integer) 0\n127.0.0.1:6379> lset list 0 item # 如果不存在列表我们去更新就会报错\n(error) ERR no such key\n127.0.0.1:6379> lpush list value1\n(integer) 1\n127.0.0.1:6379> LRANGE list 0 0\n1) \"value1\"\n127.0.0.1:6379> lset list 0 item # 如果存在，更新当前下标的值\nOK\n127.0.0.1:6379> LRANGE list 0 0\n1) \"item\"\n127.0.0.1:6379> lset list 1 other # 如果不存在，则会报错！\n(error) ERR index out of range\n##########################################################################\nlinsert # 将某个具体的value插入到列把你中某个元素的前面或者后面！\n127.0.0.1:6379> Rpush mylist \"hello\"\n(integer) 1\n127.0.0.1:6379> Rpush mylist \"world\"\n(integer) 2\n127.0.0.1:6379> LINSERT mylist before \"world\" \"other\"\n(integer) 3\n127.0.0.1:6379> LRANGE mylist 0 -1\n1) \"hello\"\n2) \"other\"\n3) \"world\"\n127.0.0.1:6379> LINSERT mylist after world new\n(integer) 4\n127.0.0.1:6379> LRANGE mylist 0 -1\n1) \"hello\"\n2) \"other\"\n3) \"world\"\n4) \"new\"\n```\n\n> 小结\n\n- 它实际上是一个链表，before Node after ，left right 都可以插入值\n- 如果 key 不存在，创建新的链表\n- 如果 key 存在，新增内容\n- 如果移除了所有值，空链表，也代表不存在！\n- 在两边插入或者改动值，效率最高！中间元素，相对来说效率会低一点~\n- 消息排队！消息队列（LPUSH RPOP），栈（LPUSH LPOP）\n\n## Set（集合）\n\nset 中的值是不能重复的！\n\nRedis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。\n\nRedis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。\n\n集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储 40 多亿个成员)。\n\n| 序号 | 命令及描述                                                                                                                                    |\n| :--- | :-------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | [SADD key member1 [member2]](https://www.runoob.com/redis/sets-sadd.html) <br />向集合添加一个或多个成员                                      |\n| 2    | [SCARD key](https://www.runoob.com/redis/sets-scard.html) <br />获取集合的成员数                                                              |\n| 3    | [SDIFF key1 [key2]](https://www.runoob.com/redis/sets-sdiff.html) <br />返回第一个集合与其他集合之间的差异。                                  |\n| 4    | [SDIFFSTORE destination key1 [key2]](https://www.runoob.com/redis/sets-sdiffstore.html) <br />返回给定所有集合的差集并存储在 destination 中   |\n| 5    | [SINTER key1 [key2]](https://www.runoob.com/redis/sets-sinter.html) <br />返回给定所有集合的交集                                              |\n| 6    | [SINTERSTORE destination key1 [key2]](https://www.runoob.com/redis/sets-sinterstore.html) <br />返回给定所有集合的交集并存储在 destination 中 |\n| 7    | [SISMEMBER key member](https://www.runoob.com/redis/sets-sismember.html) <br />判断 member 元素是否是集合 key 的成员                          |\n| 8    | [SMEMBERS key](https://www.runoob.com/redis/sets-smembers.html) <br />返回集合中的所有成员                                                    |\n| 9    | [SMOVE source destination member](https://www.runoob.com/redis/sets-smove.html) <br />将 member 元素从 source 集合移动到 destination 集合     |\n| 10   | [SPOP key](https://www.runoob.com/redis/sets-spop.html) <br />移除并返回集合中的一个随机元素                                                  |\n| 11   | [SRANDMEMBER key [count]](https://www.runoob.com/redis/sets-srandmember.html) <br />返回集合中一个或多个随机数                                |\n| 12   | [SREM key member1 [member2]](https://www.runoob.com/redis/sets-srem.html) <br />移除集合中一个或多个成员                                      |\n| 13   | [SUNION key1 [key2]](https://www.runoob.com/redis/sets-sunion.html)<br />返回所有给定集合的并集                                               |\n| 14   | [SUNIONSTORE destination key1 [key2]](https://www.runoob.com/redis/sets-sunionstore.html) <br />所有给定集合的并集存储在 destination 集合中   |\n| 15   | [SSCAN key cursor [MATCH pattern] [COUNT count]](https://www.runoob.com/redis/sets-sscan.html) <br />迭代集合中的元素                         |\n\n```bash\n##########################################################################\n127.0.0.1:6379> sadd myset \"hello\" # set集合中添加匀速\n(integer) 1\n127.0.0.1:6379> sadd myset \"kuangshen\"\n(integer) 1\n127.0.0.1:6379> sadd myset \"lovekuangshen\"\n(integer) 1\n127.0.0.1:6379> SMEMBERS myset # 查看指定set的所有值\n1) \"hello\"\n2) \"lovekuangshen\"\n3) \"kuangshen\"\n127.0.0.1:6379> SISMEMBER myset hello # 判断某一个值是不是在set集合中！\n(integer) 1\n127.0.0.1:6379> SISMEMBER myset world\n(integer) 0\n##########################################################################\n127.0.0.1:6379> scard myset # 获取set集合中的内容元素个数！\n(integer) 4\n##########################################################################\nrem\n127.0.0.1:6379> srem myset hello # 移除set集合中的指定元素\n(integer) 1\n127.0.0.1:6379> scard myset\n(integer) 3\n127.0.0.1:6379> SMEMBERS myset\n1) \"lovekuangshen2\"\n2) \"lovekuangshen\"\n3) \"kuangshen\"\n##########################################################################\nset 无序不重复集合。抽随机！\n127.0.0.1:6379> SMEMBERS myset\n1) \"lovekuangshen2\"\n2) \"lovekuangshen\"\n3) \"kuangshen\"\n127.0.0.1:6379> SRANDMEMBER myset # 随机抽选出一个元素\n\"kuangshen\"\n127.0.0.1:6379> SRANDMEMBER myset\n\"kuangshen\"\n127.0.0.1:6379> SRANDMEMBER myset\n\"kuangshen\"\n127.0.0.1:6379> SRANDMEMBER myset\n\"kuangshen\"\n127.0.0.1:6379> SRANDMEMBER myset 2 # 随机抽选出指定个数的元素\nbilibili：狂神说Java1) \"lovekuangshen\"\n2) \"lovekuangshen2\"\n127.0.0.1:6379> SRANDMEMBER myset 2\n1) \"lovekuangshen\"\n2) \"lovekuangshen2\"\n127.0.0.1:6379> SRANDMEMBER myset # 随机抽选出一个元素\n\"lovekuangshen2\"\n##########################################################################\n删除定的key，随机删除key！\n127.0.0.1:6379> SMEMBERS myset\n1) \"lovekuangshen2\"\n2) \"lovekuangshen\"\n3) \"kuangshen\"\n127.0.0.1:6379> spop myset # 随机删除一些set集合中的元素！\n\"lovekuangshen2\"\n127.0.0.1:6379> spop myset\n\"lovekuangshen\"\n127.0.0.1:6379> SMEMBERS myset\n1) \"kuangshen\"\n##########################################################################\n将一个指定的值，移动到另外一个set集合！\n127.0.0.1:6379> sadd myset \"hello\"\n(integer) 1\n127.0.0.1:6379> sadd myset \"world\"\n(integer) 1\n127.0.0.1:6379> sadd myset \"kuangshen\"\n(integer) 1\n127.0.0.1:6379> sadd myset2 \"set2\"\n(integer) 1\n127.0.0.1:6379> smove myset myset2 \"kuangshen\" # 将一个指定的值，移动到另外一个set集\n合！\n(integer) 1\n127.0.0.1:6379> SMEMBERS myset\n1) \"world\"\n2) \"hello\"\n127.0.0.1:6379> SMEMBERS myset2\n1) \"kuangshen\"\n2) \"set2\"\n##########################################################################\n微博，B站，共同关注！(并集)\n数字集合类：\n- 差集 SDIFF\n- 交集\n- 并集\n127.0.0.1:6379> SDIFF key1 key2 # 差集\n1) \"b\"\n2) \"a\"\n127.0.0.1:6379> SINTER key1 key2 # 交集 共同好友就可以这样实现\n1) \"c\"\n127.0.0.1:6379> SUNION key1 key2 # 并集\n1) \"b\"\n2) \"c\"\n3) \"e\"\n4) \"a\"\n5) \"d\"\n```\n\nbilibili：狂神说 Java 微博，A 用户将所有关注的人放在一个 set 集合中！将它的粉丝也放在一个集合中！\n共同关注，共同爱好，二度好友，推荐好友！（六度分割理论）\n\n## Hash（哈希）\n\nRedis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。\n\nRedis 中每个 hash 可以存储 232 - 1 键值对（40 多亿）。\n\nMap 集合，key-map! 时候这个值是一个 map 集合！ 本质和 String 类型没有太大区别，还是一个简单的 key-vlaue！\n\n| 序号 | 命令及描述                                                                                                                                               |\n| :--- | :------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | [HDEL key field1 [field2]](https://www.runoob.com/redis/hashes-hdel.html) <br />删除一个或多个哈希表字段                                                 |\n| 2    | [HEXISTS key field](https://www.runoob.com/redis/hashes-hexists.html) <br />查看哈希表 key 中，指定的字段是否存在。                                      |\n| 3    | [HGET key field](https://www.runoob.com/redis/hashes-hget.html) <br />获取存储在哈希表中指定字段的值。                                                   |\n| 4    | [HGETALL key](https://www.runoob.com/redis/hashes-hgetall.html) <br />获取在哈希表中指定 key 的所有字段和值                                              |\n| 5    | [HINCRBY key field increment](https://www.runoob.com/redis/hashes-hincrby.html) <br />为哈希表 key 中的指定字段的整数值加上增量 increment 。             |\n| 6    | [HINCRBYFLOAT key field increment](https://www.runoob.com/redis/hashes-hincrbyfloat.html) <br />为哈希表 key 中的指定字段的浮点数值加上增量 increment 。 |\n| 7    | [HKEYS key](https://www.runoob.com/redis/hashes-hkeys.html) <br />获取所有哈希表中的字段                                                                 |\n| 8    | [HLEN key](https://www.runoob.com/redis/hashes-hlen.html) <br />获取哈希表中字段的数量                                                                   |\n| 9    | [HMGET key field1 [field2]](https://www.runoob.com/redis/hashes-hmget.html) <br />获取所有给定字段的值                                                   |\n| 10   | [HMSET key field1 value1 [field2 value2 ]](https://www.runoob.com/redis/hashes-hmset.html) <br />同时将多个 field-value (域-值)对设置到哈希表 key 中。   |\n| 11   | [HSET key field value](https://www.runoob.com/redis/hashes-hset.html) <br />将哈希表 key 中的字段 field 的值设为 value 。                                |\n| 12   | [HSETNX key field value](https://www.runoob.com/redis/hashes-hsetnx.html) <br />只有在字段 field 不存在时，设置哈希表字段的值。                          |\n| 13   | [HVALS key](https://www.runoob.com/redis/hashes-hvals.html) <br />获取哈希表中所有值。                                                                   |\n| 14   | [HSCAN key cursor [MATCH pattern] [COUNT count]](https://www.runoob.com/redis/hashes-hscan.html) <br />迭代哈希表中的键值对。                            |\n\n```bash\n##########################################################################\n127.0.0.1:6379> hset myhash field1 kuangshen # set一个具体 key-vlaue\n(integer) 1\n127.0.0.1:6379> hget myhash field1 # 获取一个字段值\n\"kuangshen\"\n127.0.0.1:6379> hmset myhash field1 hello field2 world # set多个 key-vlaue\nOK\n127.0.0.1:6379> hmget myhash field1 field2 # 获取多个字段值\n1) \"hello\"\n2) \"world\"\n127.0.0.1:6379> hgetall myhash # 获取全部的数据，\n1) \"field1\"\n2) \"hello\"\n3) \"field2\"\n4) \"world\"\n127.0.0.1:6379> hdel myhash field1 # 删除hash指定key字段！对应的value值也就消失了！\n(integer) 1\n127.0.0.1:6379> hgetall myhash\n1) \"field2\"\n2) \"world\"\n##########################################################################\nhlen\n127.0.0.1:6379> hmset myhash field1 hello field2 world\nOK\n127.0.0.1:6379> HGETALL myhash\n1) \"field2\"\n2) \"world\"\n3) \"field1\"\n4) \"hello\"\n127.0.0.1:6379> hlen myhash # 获取hash表的字段数量！\n(integer) 2\n##########################################################################\n127.0.0.1:6379> HEXISTS myhash field1 # 判断hash中指定字段是否存在！\n(integer) 1\n127.0.0.1:6379> HEXISTS myhash field3\n(integer) 0\n##########################################################################\n# 只获得所有field\n# 只获得所有value\n127.0.0.1:6379> hkeys myhash # 只获得所有field\n1) \"field2\"\n2) \"field1\"\nbilibili：狂神说Javahash变更的数据 user name age,尤其是是用户信息之类的，经常变动的信息！ hash 更适合于对象的\n存储，String更加适合字符串存储！\nZset（有序集合）\n在set的基础上，增加了一个值，set k1 v1 zset k1 score1 v1\n127.0.0.1:6379> hvals myhash # 只获得所有value\n1) \"world\"\n2) \"hello\"\n##########################################################################\nincr decr\n127.0.0.1:6379> hset myhash field3 5 #指定增量！\n(integer) 1\n127.0.0.1:6379> HINCRBY myhash field3 1\n(integer) 6\n127.0.0.1:6379> HINCRBY myhash field3 -1\n(integer) 5\n127.0.0.1:6379> hsetnx myhash field4 hello # 如果不存在则可以设置\n(integer) 1\n127.0.0.1:6379> hsetnx myhash field4 world # 如果存在则不能设置\n(integer) 0\n```\n\nhash 变更的数据 user name age，尤其是是用户信息之类的，经常变动的信息！ hash 更适合于对象的 存储，String 更加适合字符串存储！\n\n## Zset（有序集合）\n\nRedis 有序集合和集合一样也是 string 类型元素的集合,且不允许重复的成员。\n\n不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。\n\n有序集合的成员是唯一的,但分数(score)却可以重复。\n\n集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储 40 多亿个成员)。\n\n| 序号 | 命令及描述                                                                                                                                                                                   |\n| :--- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | [ZADD key score1 member1 [score2 member2]](https://www.runoob.com/redis/sorted-sets-zadd.html) <br />向有序集合添加一个或多个成员，或者更新已存在成员的分数                                  |\n| 2    | [ZCARD key](https://www.runoob.com/redis/sorted-sets-zcard.html) <br />获取有序集合的成员数                                                                                                  |\n| 3    | [ZCOUNT key min max](https://www.runoob.com/redis/sorted-sets-zcount.html) <br />计算在有序集合中指定区间分数的成员数                                                                        |\n| 4    | [ZINCRBY key increment member](https://www.runoob.com/redis/sorted-sets-zincrby.html) <br />有序集合中对指定成员的分数加上增量 increment                                                     |\n| 5    | [ZINTERSTORE destination numkeys key [key ...]](https://www.runoob.com/redis/sorted-sets-zinterstore.html) <br />计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 destination 中 |\n| 6    | [ZLEXCOUNT key min max](https://www.runoob.com/redis/sorted-sets-zlexcount.html) <br />在有序集合中计算指定字典区间内成员数量                                                                |\n| 7    | [ZRANGE key start stop [WITHSCORES]](https://www.runoob.com/redis/sorted-sets-zrange.html) <br />通过索引区间返回有序集合指定区间内的成员                                                    |\n| 8    | [ZRANGEBYLEX key min max [LIMIT offset count]](https://www.runoob.com/redis/sorted-sets-zrangebylex.html) <br />通过字典区间返回有序集合的成员                                               |\n| 9    | [ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT]](https://www.runoob.com/redis/sorted-sets-zrangebyscore.html) <br />通过分数返回有序集合指定区间内的成员                                     |\n| 10   | [ZRANK key member](https://www.runoob.com/redis/sorted-sets-zrank.html) <br />返回有序集合中指定成员的索引                                                                                   |\n| 11   | [ZREM key member [member ...]](https://www.runoob.com/redis/sorted-sets-zrem.html) <br />移除有序集合中的一个或多个成员                                                                      |\n| 12   | [ZREMRANGEBYLEX key min max](https://www.runoob.com/redis/sorted-sets-zremrangebylex.html) <br />移除有序集合中给定的字典区间的所有成员                                                      |\n| 13   | [ZREMRANGEBYRANK key start stop](https://www.runoob.com/redis/sorted-sets-zremrangebyrank.html) <br />移除有序集合中给定的排名区间的所有成员                                                 |\n| 14   | [ZREMRANGEBYSCORE key min max](https://www.runoob.com/redis/sorted-sets-zremrangebyscore.html) <br />移除有序集合中给定的分数区间的所有成员                                                  |\n| 15   | [ZREVRANGE key start stop [WITHSCORES]](https://www.runoob.com/redis/sorted-sets-zrevrange.html) <br />返回有序集中指定区间内的成员，通过索引，分数从高到低                                  |\n| 16   | [ZREVRANGEBYSCORE key max min [WITHSCORES]](https://www.runoob.com/redis/sorted-sets-zrevrangebyscore.html) <br />返回有序集中指定分数区间内的成员，分数从高到低排序                         |\n| 17   | [ZREVRANK key member](https://www.runoob.com/redis/sorted-sets-zrevrank.html) <br />返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序                                       |\n| 18   | [ZSCORE key member](https://www.runoob.com/redis/sorted-sets-zscore.html) <br />返回有序集中，成员的分数值                                                                                   |\n| 19   | [ZUNIONSTORE destination numkeys key [key ...]](https://www.runoob.com/redis/sorted-sets-zunionstore.html) <br />计算给定的一个或多个有序集的并集，并存储在新的 key 中                       |\n| 20   | [ZSCAN key cursor [MATCH pattern] [COUNT count]](https://www.runoob.com/redis/sorted-sets-zscan.html) <br />迭代有序集合中的元素（包括元素成员和元素分值）                                   |\n\n```bash\n127.0.0.1:6379> zadd myset 1 one # 添加一个值\n(integer) 1\n127.0.0.1:6379> zadd myset 2 two 3 three # 添加多个值\n(integer) 2\n127.0.0.1:6379> ZRANGE myset 0 -1\n1) \"one\"\n2) \"two\"\n3) \"three\"\n##########################################################################\n排序如何实现\n127.0.0.1:6379> zadd salary 2500 xiaohong # 添加三个用户\n(integer) 1\n127.0.0.1:6379> zadd salary 5000 zhangsan\n(integer) 1\n127.0.0.1:6379> zadd salary 500 kaungshen\n(integer) 1\n# ZRANGEBYSCORE key min max\n127.0.0.1:6379> ZRANGEBYSCORE salary -inf +inf # 显示全部的用户 从小到大！\n1) \"kaungshen\"\n2) \"xiaohong\"\n3) \"zhangsan\"\n127.0.0.1:6379> ZREVRANGE salary 0 -1 # 从大到进行排序！\n1) \"zhangsan\"\n2) \"kaungshen\"\n127.0.0.1:6379> ZRANGEBYSCORE salary -inf +inf withscores # 显示全部的用户并且附带成\n绩\n1) \"kaungshen\"\n2) \"500\"\n3) \"xiaohong\"\n4) \"2500\"\n5) \"zhangsan\"\n6) \"5000\"\n127.0.0.1:6379> ZRANGEBYSCORE salary -inf 2500 withscores # 显示工资小于2500员工的升\n序排序！\n1) \"kaungshen\"\n2) \"500\"\n3) \"xiaohong\"\n4) \"2500\"\n##########################################################################\n# 移除rem中的元素\n127.0.0.1:6379> zrange salary 0 -1\n1) \"kaungshen\"\n2) \"xiaohong\"\n3) \"zhangsan\"\n127.0.0.1:6379> zrem salary xiaohong # 移除有序集合中的指定元素\n(integer) 1\n127.0.0.1:6379> zrange salary 0 -1\n1) \"kaungshen\"\n2) \"zhangsan\"\n127.0.0.1:6379> zcard salary # 获取有序集合中的个数\n(integer) 2\n##########################################################################\n127.0.0.1:6379> zadd myset 1 hello\n(integer) 1\n127.0.0.1:6379> zadd myset 2 world 3 kuangshen\n(integer) 2\n127.0.0.1:6379> zcount myset 1 3 # 获取指定区间的成员数量！\n(integer) 3\n127.0.0.1:6379> zcount myset 1 2\n(integer) 2\n```\n\n其与的一些 API，通过我们的学习吗，你们剩下的如果工作中有需要，这个时候你可以去查查看官方文 档！\n\n案例思路：set 排序 存储班级成绩表，工资表排序！\n\n普通消息，1， 重要消息 2，带权重进行判断！\n\n排行榜应用实现，取 Top N 测试！\n\n# 三种特殊数据类型\n\n## Geospatial 地理位置\n\n朋友的定位，附近的人，打车距离计算？\n\nRedis 的 Geo 在 Redis3.2 版本就推出了！ 这个功能可以推算地理位置的信息，两地之间的距离，方圆 几里的人！\n\n可以查询一些测试数据：[城市经纬度查询-国内城市经度纬度在线查询工具 (jsons.cn)](http://www.jsons.cn/lngcode/)\n\nRedis GEO 操作方法有：\n\n- geoadd：添加地理位置的坐标。\n- geopos：获取地理位置的坐标。\n- geodist：计算两个位置之间的距离。\n- georadius：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。\n- georadiusbymember：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。\n- geohash：返回一个或多个位置对象的 geohash 值。\n\n> geoadd\n\n```bash\n# getadd 添加地理位置\n# 规则：两级无法直接添加，我们一般会下载城市数据，直接通过java程序一次性导入！\n# 有效的经度从-180度到180度。\n# 有效的纬度从-85.05112878度到85.05112878度。\n# 当坐标位置超出上述指定范围时，该命令将会返回一个错误。\n# 127.0.0.1:6379> geoadd china:city 39.90 116.40 beijin\n(error) ERR invalid longitude,latitude pair 39.900000,116.400000\n# 参数 key 值（）\n127.0.0.1:6379> geoadd china:city 116.40 39.90 beijing\n(integer) 1\n127.0.0.1:6379> geoadd china:city 121.47 31.23 shanghai\n(integer) 1\n127.0.0.1:6379> geoadd china:city 106.50 29.53 chongqi 114.05 22.52 shengzhen\n(integer) 2\n127.0.0.1:6379> geoadd china:city 120.16 30.24 hangzhou 108.96 34.26 xian\n(integer) 2\n```\n\n> geopos\n\n获得当前定位：一定是一个坐标值！\n\n```bash\n127.0.0.1:6379> GEOPOS china:city beijing # 获取指定的城市的经度和纬度！\n1) 1) \"116.39999896287918091\"\n2) \"39.90000009167092543\"\n127.0.0.1:6379> GEOPOS china:city beijing chongqi\n1) 1) \"116.39999896287918091\"\n2) \"39.90000009167092543\"\n2) 1) \"106.49999767541885376\"\n2) \"29.52999957900659211\"\n```\n\n> GEODIST\n\n两人之间的距离！\n\n单位：\n\n- m 表示单位为米\n- km 表示单位为千米\n- mi 表示单位为英里\n- ft 表示单位为英尺\n\n```bash\n127.0.0.1:6379> GEODIST china:city beijing shanghai km # 查看上海到北京的直线距离\n\"1067.3788\"\n127.0.0.1:6379> GEODIST china:city beijing chongqi km # 查看重庆到北京的直线距离\n\"1464.0708\"\n```\n\n> georadius 以给定的经纬度为中心， 找出某一半径内的元素\n\n我附近的人？ （获得所有附近的人的地址，定位！）通过半径来查询！\n\n获得指定数量的人，200\n\n所有数据应该都录入：china:city ，才会让结果更加清晰！\n\n```bash\n127.0.0.1:6379> GEORADIUS china:city 110 30 1000 km # 以110，30 这个经纬度为中心，寻\n找方圆1000km内的城市\n1) \"chongqi\"\n2) \"xian\"\n3) \"shengzhen\"\n4) \"hangzhou\"\n127.0.0.1:6379> GEORADIUS china:city 110 30 500 km\n1) \"chongqi\"\n2) \"xian\"\n127.0.0.1:6379> GEORADIUS china:city 110 30 500 km withdist # 显示到中间距离的位置\n1) 1) \"chongqi\"\n   2) \"341.9374\"\n2) 1) \"xian\"\n   2) \"483.8340\"\n127.0.0.1:6379> GEORADIUS china:city 110 30 500 km withcoord # 显示他人的定位信息\n1) 1) \"chongqi\"\n   2) 1) \"106.49999767541885376\"\n      2) \"29.52999957900659211\"\n2) 1) \"xian\"\n   2) 1) \"108.96000176668167114\"\n      2) \"34.25999964418929977\"\n127.0.0.1:6379> GEORADIUS china:city 110 30 500 km withdist withcoord count 1 #\n筛选出指定的结果！\n1) 1) \"chongqi\"\n   2) \"341.9374\"\n   3) 1) \"106.49999767541885376\"\n      2) \"29.52999957900659211\"\n127.0.0.1:6379> GEORADIUS china:city 110 30 500 km withdist withcoord count 2\n1) 1) \"chongqi\"\n   2) \"341.9374\"\n   3) 1) \"106.49999767541885376\"\n      2) \"29.52999957900659211\"\n2) 1) \"xian\"\n   2) \"483.8340\"\n   3) 1) \"108.96000176668167114\"\n      2) \"34.25999964418929977\"\n```\n\n> GEORADIUSBYMEMBER\n\n```bash\n# 找出位于指定元素周围的其他元素！\n127.0.0.1:6379> GEORADIUSBYMEMBER china:city beijing 1000 km\n1) \"beijing\"\n2) \"xian\"\n127.0.0.1:6379> GEORADIUSBYMEMBER china:city shanghai 400 km\n1) \"hangzhou\"\n2) \"shanghai\"\n```\n\n> GEOHASH 命令 - 返回一个或多个位置元素的 Geohash 表示\n\n该命令将返回 11 个字符的 Geohash 字符串~\n\n```bash\n# 将二维的经纬度转换为一维的字符串，如果两个字符串越接近，那么则距离越近！\n127.0.0.1:6379> geohash china:city beijing chongqi\n1) \"wx4fbxxfke0\"\n2) \"wm5xzrybty0\"\n```\n\n> GEO 底层的实现原理其实就是 Zset！我们可以使用过 Zset 命令来操作 geo！\n\n```bash\n127.0.0.1:6379> ZRANGE china:city 0 -1 # 查看地图中全部的元素\n1) \"chongqi\"\n2) \"xian\"\n3) \"shengzhen\"\n4) \"hangzhou\"\n5) \"shanghai\"\n6) \"beijing\"\n127.0.0.1:6379> zrem china:city beijing # 移除指定元素！\n(integer) 1\n127.0.0.1:6379> ZRANGE china:city 0 -1\n1) \"chongqi\"\n2) \"xian\"\n3) \"shengzhen\"\n4) \"hangzhou\"\n5) \"shanghai\"\n```\n\n## Hyperloglog\n\nRedis 在 2.8.9 版本添加了 HyperLogLog 结构。\n\nRedis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。\n\n在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。\n\n但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。\n\n> 什么是基数？\n\nA {1,3,5,7,8,7}\n\nB{1,3,5,7,8}\n\n基数（不重复的元素） = 5，可以接受误差！\n\n优点：占用的内存是固定，2^64 不同的元素的基数，只需要废 12KB 内存！如果要从内存角度来比较的 话 Hyperloglog 首选！\n\n**网页的 UV （一个人访问一个网站多次，但是还是算作一个人！）**\n\n传统的方式， set 保存用户的 id，然后就可以统计 set 中的元素数量作为标准判断 !\n\n这个方式如果保存大量的用户 id，就会比较麻烦！我们的目的是为了计数，而不是保存用户 id；\n\n0.81% 错误率！ 统计 UV 任务，可以忽略不计的！\n\n| 序号 | 命令及描述                                                                                                                                         |\n| :--- | :------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | [PFADD key element [element ...]](https://www.runoob.com/redis/hyperloglog-pfadd.html) <br />添加指定元素到 HyperLogLog 中。                       |\n| 2    | [PFCOUNT key [key ...]](https://www.runoob.com/redis/hyperloglog-pfcount.html) <br />返回给定 HyperLogLog 的基数估算值。                           |\n| 3    | [PFMERGE destkey sourcekey [sourcekey ...]](https://www.runoob.com/redis/hyperloglog-pfmerge.html) <br />将多个 HyperLogLog 合并为一个 HyperLogLog |\n\n> 测试使用\n\n```bash\n127.0.0.1:6379> PFadd mykey a b c d e f g h i j # 创建第一组元素 mykey\n(integer) 1\n127.0.0.1:6379> PFCOUNT mykey # 统计 mykey 元素的基数数量\n(integer) 10\n127.0.0.1:6379> PFadd mykey2 i j z x c v b n m # 创建第二组元素 mykey2\n(integer) 1\n127.0.0.1:6379> PFCOUNT mykey2\n(integer) 9\n127.0.0.1:6379> PFMERGE mykey3 mykey mykey2 # 合并两组 mykey mykey2 => mykey3 并集\nOK\n127.0.0.1:6379> PFCOUNT mykey3 # 看并集的数量！\n(integer) 15\n```\n\n## Bitmap\n\n为什么其他教程都不喜欢讲这些？这些在生活中或者开发中，都有十分多的应用场景，学习了，就是就 是多一个思路！\n\n技多不压身！\n\n> 位储存\n\n统计用户信息，活跃，不活跃！ 登录 、 未登录！ 打卡，365 打卡！ 两个状态的，都可以使用 Bitmaps！\n\nBitmap 位图，数据结构！ 都是操作二进制位来进行记录，就只有 0 和 1 两个状态！\n\n365 天 = 365 bit 1 字节 = 8bit 46 个字节左右！\n\n> 测试\n\n![image-20210502234525977](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210502234526.png)\n\n使用 bitmap 来记录 周一到周日的打卡！\n\n周一：1 周二：0 周三：0 周四：1 ......\n\n![image-20210502234703108](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210502234703.png)\n\n查看某一天是否有打卡！\n\n```bash\n127.0.0.1:6379> getbit sign 3\n(integer) 1\n127.0.0.1:6379> getbit sign 6\n(integer) 0\n```\n\n统计操作，统计 打卡的天数！\n\n```bash\n127.0.0.1:6379> bitcount sign # 统计这周的打卡记录，就可以看到是否有全勤！\n(integer) 3\n```\n\n# 事务\n\nRedis 事务本质：一组命令的集合！ 一个事务中的所有命令都会被序列化，在事务执行过程的中，会按 照顺序执行！\n\n一次性、顺序性、排他性！执行一系列的命令！\n\n`------ 队列 set set set 执行------`\n\n==Redis 事务没有没有隔离级别的概念！==\n\n所有的命令在事务中，并没有直接被执行！只有发起执行命令的时候才会执行！Exec\n\n==Redis 单条命令式保存原子性的，但是事务不保证原子性！==\n\nredis 的事务：\n\n- 开启事务（multi）\n- 命令入队（......）\n- 执行事务（exec）\n\n> 正常执行事务！\n\n```bash\n127.0.0.1:6379> multi # 开启事务\nOK\n# 命令入队\n127.0.0.1:6379> set k1 v1\nQUEUED\n127.0.0.1:6379> set k2 v2\nQUEUED\n127.0.0.1:6379> get k2\nQUEUED\n127.0.0.1:6379> set k3 v3\nQUEUED\n127.0.0.1:6379> exec # 执行事务\n1) OK\n2) OK\n3) \"v2\"\n4) OK\n```\n\n> 放弃事务\n\n```bash\n127.0.0.1:6379> multi # 开启事务\nOK\n127.0.0.1:6379> set k1 v1\nQUEUED\n127.0.0.1:6379> set k2 v2\nQUEUED\n127.0.0.1:6379> set k4 v4\nQUEUED\n127.0.0.1:6379> DISCARD # 取消事务\nOK\n127.0.0.1:6379> get k4 # 事务队列中命令都不会被执行！\n(nil)\n```\n\n> 编译型异常（代码有问题！命令有错！），事务中所有的命令都不会执行！\n\n```bash\n127.0.0.1:6379> multi\nOK\n127.0.0.1:6379> set k1 v1\nQUEUED\n127.0.0.1:6379> set k2 v2\nQUEUED\n127.0.0.1:6379> set k3 v3\nQUEUED\n127.0.0.1:6379> getset k3 # 错误的命令\n(error) ERR wrong number of arguments for 'getset' command\n127.0.0.1:6379> set k4 v4\nQUEUED\n127.0.0.1:6379> set k5 v5\nQUEUED\n127.0.0.1:6379> exec # 执行事务报错！\n(error) EXECABORT Transaction discarded because of previous errors.\n127.0.0.1:6379> get k5 # 所有的命令都不会被执行！\n(nil)\n```\n\n> 运行时异常（1/0）， 如果事务队列中存在语法性，那么执行命令的时候，其他命令是可以正常执行 的，错误命令抛出异常！\n\n```bash\n127.0.0.1:6379> set k1 \"v1\"\nOK\n127.0.0.1:6379> multi\nOK\n127.0.0.1:6379> incr k1 # 会执行的时候失败！\nQUEUED\n127.0.0.1:6379> set k2 v2\nQUEUED\n127.0.0.1:6379> set k3 v3\nQUEUED\n127.0.0.1:6379> get k3\nQUEUED\n127.0.0.1:6379> exec\n1) (error) ERR value is not an integer or out of range # 虽然第一条命令报错了，但是依旧正常执行成功了！\n2) OK\n3) OK\n4) \"v3\"\n127.0.0.1:6379> get k2\n\"v2\"\n127.0.0.1:6379> get k3\n\"v3\"\n```\n\n> 监控！ Watch （面试常问！）\n\n悲观锁：\n\n- 很悲观，认为什么时候都会出问题，无论做什么都会加锁！\n\n乐观锁：\n\n- 很乐观，认为什么时候都不会出问题，所以不会上锁！ 更新数据的时候去判断一下，在此期间是否 有人修改过这个数据\n- 获取 version\n- 更新的时候比较 version\n\n> Redis 监视测试\n\n正常执行成功！\n\n```bash\n127.0.0.1:6379> set money 100\nOK\n127.0.0.1:6379> set out 0\nOK\n127.0.0.1:6379> watch money # 监视 money 对象\nOK\n127.0.0.1:6379> multi # 事务正常结束，数据期间没有发生变动，这个时候就正常执行成功！\nOK\n127.0.0.1:6379> DECRBY money 20\nQUEUED\n127.0.0.1:6379> INCRBY out 20\nQUEUED\n127.0.0.1:6379> exec\n1) (integer) 80\n2) (integer) 20\n```\n\n测试多线程修改值 , 使用 watch 可以当做 redis 的乐观锁操作！\n\n```bash\n127.0.0.1:6379> watch money # 监视 money\nOK\n127.0.0.1:6379> multi\nOK\n127.0.0.1:6379> DECRBY money 10\nQUEUED\n127.0.0.1:6379> INCRBY out 10\nQUEUED\n127.0.0.1:6379> exec # 执行之前，另外一个线程，修改了我们的值，这个时候，就会导致事务执行失败！\n(nil)\n```\n\n如果修改失败，获取最新的值就好\n\n![image-20210503001012808](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503001012.png)\n\n# Jedis\n\n我们要使用 Java 来操作 Redis，知其然并知其所以然，授人以渔！ 学习不能急躁，慢慢来会很快！\n\n> 什么是 Jedis 是 Redis 官方推荐的 java 连接开发工具！ 使用 Java 操作 Redis 中间件！如果你要使用 java 操作 redis，那么一定要对 jedis 十分熟悉！\n\n> 测试\n\n1、导入对应的依赖\n\n```xml\n<!--导入jedis的包-->\n<dependencies>\n    <!-- https://mvnrepository.com/artifact/redis.clients/jedis -->\n    <dependency>\n        <groupId>redis.clients</groupId>\n        <artifactId>jedis</artifactId>\n        <version>3.2.0</version>\n    </dependency>\n    <!--fastjson-->\n    <dependency>\n        <groupId>com.alibaba</groupId>\n        <artifactId>fastjson</artifactId>\n        <version>1.2.62</version>\n    </dependency>\n</dependencies>\n```\n\n2、编码测试\n\n- 连接数据库\n- 操作命令\n- 断开连接！\n\n```java\nimport redis.clients.jedis.Jedis;\n\n/**\n * @author IRVING\n * @create 2021-05-03 0:20\n */\npublic class TestPing {\n    public static void main(String[] args) {\n        // 1、 new Jedis 对象即可\n        Jedis jedis = new Jedis(\"127.0.0.1\",6379);\n        jedis.auth(\"123456\");\n        // 2、jedis 所有的命令就是我们之前学习的所有指令！所以之前的指令学习很重要！\n\n        System.out.println(jedis.ping());\n    }\n}\n```\n\n输出：\n\n![image-20210503002523989](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503002524.png)\n\n## 常用的 API\n\n- string\n- list\n- set\n- hash\n- zset\n- geo\n- bitmap\n- hyperloglog\n\n> 所有的 api 命令，就是我们对应的上面学习的指令，一个都没有变化！\n\n> 事务\n\n```java\nimport com.alibaba.fastjson.JSONObject;\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.Transaction;\n\n/**\n * @author IRVING\n * @create 2021-05-03 0:31\n */\npublic class TestTX {\n    public static void main(String[] args) {\n        // 1、 new Jedis 对象即可\n        Jedis jedis = new Jedis(\"127.0.0.1\",6379);\n        jedis.auth(\"123456\");\n\n        jedis.flushDB();\n\n        JSONObject jsonObject = new JSONObject();\n        jsonObject.put(\"hello\",\"world\");\n        jsonObject.put(\"name\",\"ouwen\");\n\n        //开启事务\n        Transaction multi = jedis.multi();\n        String result = jsonObject.toJSONString();\n\n        try {\n            multi.set(\"user1\",result);\n            int i = 1/0;\n            multi.set(\"user2\",result);\n            //执行事务\n            multi.exec();\n        } catch (Exception e) {\n            //放弃事务\n            multi.discard();\n            e.printStackTrace();\n        } finally {\n            System.out.println(jedis.get(\"user1\"));\n            System.out.println(jedis.get(\"user2\"));\n            //关闭连接\n            jedis.close();\n        }\n\n    }\n}\n```\n\n# SpringBoot 整合\n\nSpringBoot 操作数据：spring-data jpa jdbc mongodb redis！\n\nSpringData 也是和 SpringBoot 齐名的项目！\n\n说明： 在 SpringBoot2.x 之后，原来使用的 jedis 被替换为了 lettuce?\n\njedis : 采用的直连，多个线程操作的话，是不安全的，如果想要避免不安全的，使用 jedis pool 连接 池！ 更像 BIO 模式\n\nlettuce : 采用 netty，实例可以再多个线程中进行共享，不存在线程不安全的情况！可以减少线程数据 了，更像 NIO 模式\n\n源码分析：\n\n```java\n@Bean\n@ConditionalOnMissingBean(name = \"redisTemplate\") // 我们可以自己定义一个\nredisTemplate来替换这个默认的！\npublic RedisTemplate<Object, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory)\n    throws UnknownHostException {\n    // 默认的 RedisTemplate 没有过多的设置，redis 对象都是需要序列化！\n    // 两个泛型都是 Object, Object 的类型，我们后使用需要强制转换 <String, Object>\n    RedisTemplate<Object, Object> template = new RedisTemplate<>();\n    template.setConnectionFactory(redisConnectionFactory);\n    return template;\n}\n@Bean\n@ConditionalOnMissingBean // 由于 String 是redis中最常使用的类型，所以说单独提出来了一个bean！\npublic StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory)\n\tthrows UnknownHostException {\n    StringRedisTemplate template = new StringRedisTemplate();\n    template.setConnectionFactory(redisConnectionFactory);\n    return template;\n}\n```\n\n> 整合测试一下\n\n1、导入依赖\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n```\n\n2、配置连接\n\n```yaml\nspring:\n    redis:\n        host: 127.0.0.1\n        port: 6379\n        password: 123456\n```\n\n3、测试！\n\n```java\npackage com.luojunjie;\n\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.data.redis.connection.RedisConnection;\nimport org.springframework.data.redis.core.RedisTemplate;\n\n@SpringBootTest\nclass Redis02SpringbootApplicationTests {\n\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    @Test\n    void contextLoads() {\n        // redisTemplate 操作不同的类型，api和我们的指令是一样的\n        // opsForValue 操作字符串 类似string\n        // opsForList\n        // opsForSet\n        // opsForZSet\n        // opsForHash\n        // opsForGeo\n        // opsForHyperLogLog\n        //redisTemplate.opsForValue();\n\n        //除了基本的操作，我们常用的方法都可以直接通过redisTemplate操作，比如事务和基本的CRUD\n\n        // 获取redis连接对象\n        //RedisConnection conn = redisTemplate.getConnectionFactory().getConnection();\n        //conn.flushAll();\n        //conn.flushDb();\n\n        redisTemplate.opsForValue().set(\"mykey\",\"湖南长沙\");\n        System.out.println(redisTemplate.opsForValue().get(\"mykey\"));\n    }\n\n}\n```\n\n![image-20210503102342174](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503102342.png)\n\n我们来编写一个自己的 RedisTemplete\n\n```java\npackage com.luojunjie.config;\n\nimport com.fasterxml.jackson.annotation.JsonAutoDetect;\nimport com.fasterxml.jackson.annotation.PropertyAccessor;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.data.redis.connection.RedisConnectionFactory;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;\nimport org.springframework.data.redis.serializer.StringRedisSerializer;\n\nimport java.net.UnknownHostException;\n\n/**\n * @author IRVING\n * @create 2021-05-03 10:24\n */\n@Configuration\npublic class RedisConfig {\n\n    // 这是我给大家写好的一个固定模板，大家在企业中，拿去就可以直接使用！\n    // 自己定义了一个 RedisTemplate\n    @Bean\n    @SuppressWarnings(\"all\")\n    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory\n                                                               factory) {\n        // 我们为了自己开发方便，一般直接使用 <String, Object>\n        RedisTemplate<String, Object> template = new RedisTemplate<String,\n                Object>();\n        template.setConnectionFactory(factory);\n        // Json序列化配置\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new\n                Jackson2JsonRedisSerializer(Object.class);\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n        // String 的序列化\n        StringRedisSerializer stringRedisSerializer = new\n                StringRedisSerializer();\n        // key采用String的序列化方式\n        template.setKeySerializer(stringRedisSerializer);\n        // hash的key也采用String的序列化方式\n        template.setHashKeySerializer(stringRedisSerializer);\n        // value序列化方式采用jackson\n        template.setValueSerializer(jackson2JsonRedisSerializer);\n        // hash的value序列化方式采用jackson\n        template.setHashValueSerializer(jackson2JsonRedisSerializer);\n        template.afterPropertiesSet();\n        return template;\n    }\n\n}\n```\n\n所有的 redis 操作，其实对于 java 开发人员来说，十分的简单，更重要是要去理解 redis 的思想和每一种数 据结构的用处和作用场景！\n\n# Redis.conf 详解\n\n启动的时候，就通过配置文件来启动！\n\n工作中，一些小小的配置，可以让你脱颖而出！\n\n> 单位\n\n![image-20210503105120545](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503105120.png)\n\n配置文件对大小写不敏感！\n\n> 包含\n\n![image-20210503105216614](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503105216.png)\n\n就是好比我们学习 Spring、Improt， include\n\n> 网络\n\n```bash\nbind 127.0.0.1 # 绑定的ip\nprotected-mode yes # 保护模式\nport 6379 # 端口设置\n```\n\n> 通用 GENERAL\n\n```bash\ndaemonize yes # 以守护进程的方式运行，默认是 no，我们需要自己开启为yes！\npidfile /var/run/redis_6379.pid # 如果以后台的方式运行，我们就需要指定一个 pid 文件！\n# 日志\n# Specify the server verbosity level.\n# This can be one of:\n# debug (a lot of information, useful for development/testing)\n# verbose (many rarely useful info, but not a mess like the debug level)\n# notice (moderately verbose, what you want in production probably) 生产环境\n# warning (only very important / critical messages are logged)\nloglevel notice\nlogfile \"\" # 日志的文件位置名\ndatabases 16 # 数据库的数量，默认是 16 个数据库\nalways-show-logo yes # 是否总是显示LOGO\n```\n\n> 快照\n\n持久化， 在规定的时间内，执行了多少次操作，则会持久化到文件 .rdb. aof\n\nredis 是内存数据库，如果没有持久化，那么数据断电就会丢失！\n\n```bash\n# 如果900s内，如果至少有一个1 key进行了修改，我们及进行持久化操作\nsave 900 1\n# 如果300s内，如果至少10 key进行了修改，我们及进行持久化操作\nsave 300 10\n# 如果60s内，如果至少10000 key进行了修改，我们及进行持久化操作\nsave 60 10000\n# 我们之后学习持久化，会自己定义这个测试！\nstop-writes-on-bgsave-error yes # 持久化如果出错，是否还需要继续工作！\nrdbcompression yes # 是否压缩 rdb 文件，需要消耗一些cpu资源！\nrdbchecksum yes # 保存rdb文件的时候，进行错误的检查校验！\ndir ./ # rdb 文件保存的目录！\n```\n\n> SECURITY 安全\n\n可以设置 redis 密码，默认是没有密码的\n\n```bash\n127.0.0.1:6379> ping\nPONG\n127.0.0.1:6379> config get requirepass # 获取redis的密码\n1) \"requirepass\"\n2) \"\"\n127.0.0.1:6379> config set requirepass \"123456\" # 设置redis的密码\nOK\n127.0.0.1:6379> config get requirepass # 发现所有的命令都没有权限了\n(error) NOAUTH Authentication required.\n127.0.0.1:6379> ping\n(error) NOAUTH Authentication required.\n127.0.0.1:6379> auth 123456 # 使用密码进行登录！\nOK\n127.0.0.1:6379> config get requirepass\n1) \"requirepass\"\n2) \"123456\"\n```\n\n> 限制 CLIENTS\n\n```bash\nmaxclients 10000 # 设置能连接上redis的最大客户端的数量\n\nmaxmemory <bytes> # redis 配置最大的内存容量\n\nmaxmemory-policy noeviction # 内存到达上限之后的处理策略\n    1、volatile-lru：只对设置了过期时间的key进行LRU（默认值）\n    2、allkeys-lru ： 删除lru算法的key\n    3、volatile-random：随机删除即将过期key\n    4、allkeys-random：随机删除\n    5、volatile-ttl ： 删除即将过期的\n    6、noeviction ： 永不过期，返回错误\n```\n\n> APPEND ONLY 模式 aof 配置\n\n```bash\nappendonly no # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分所有的情况下，rdb完全够用！\nappendfilename \"appendonly.aof\" # 持久化的文件的名字\n\n# appendfsync always # 每次修改都会 sync。消耗性能\nappendfsync everysec # 每秒执行一次 sync，可能会丢失这1s的数据！\n# appendfsync no # 不执行 sync，这个时候操作系统自己同步数据，速度最快！\n```\n\n# Redis 持久化\n\n面试和工作，持久化都是重点！\n\nRedis 是内存数据库，如果不将内存中的数据库状态保存到磁盘 ，那么一旦服务器进程退出，服务器中的数据库状态也会消失。所以 Redis 提供了持久化功能！\n\n## RDB（Redis DataBase）\n\n> 什么是 RDB？\n\n在主从复制中，rdb 就是备用了，放在从机上。\n\n![image-20210503143056239](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503143056.png)\n\n在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的 Snapshot 快照，它恢复时是将快 照文件直接读到内存里。\n\nRedis 会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程 都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何 IO 操作的。 这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。RDB 的缺点是最后一次持久化后的数据可能丢失。我们默认的就是 RDB，一般情况下不需要修改这个配置！\n\n==rdb 保存的文件是 dump.rdb== 都是在我们的配置文件中快照中进行配置的！\n\n![image-20210503143817471](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503143817.png)\n\n> 触发机制\n\n1、save 的规则满足的情况下，会自动触发 rdb 规则\n\n2、执行 flushall 命令，也会触发我们的 rdb 规则！\n\n3、退出 redis，也会产生 rdb 文件！ 备份就自动生成一个 dump.rdb\n\n![image-20210503143856958](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503143857.png)\n\n> 如何恢复 rdb 文件！\n\n1、只需要将 rdb 文件放在我们 redis 启动目录就可以，redis 启动的时候会自动检查 dump.rdb 恢复其中 的数据！\n\n2、查看需要存在的位置\n\n```bash\n127.0.0.1:6379> config get dir\n1) \"dir\"\n2) \"/usr/local/bin\" # 如果在这个目录下存在 dump.rdb 文件，启动就会自动恢复其中的数据\n```\n\n**优点：**\n\n1、适合大规模的数据恢复！\n\n2、对数据的完整性要不高！\n\n**缺点：**\n\n1、需要一定的时间间隔进程操作！如果 redis 意外宕机了，这个最后一次修改数据就没有的了！\n\n2、fork 进程的时候，会占用一定的内容空间！\n\n## AOF（Append Only File）\n\n将我们的所有命令都记录下来，history，恢复的时候就把这个文件全部在执行一遍！\n\n> 是什么？\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503144252.png)\n\n以日志的形式来记录每个写操作，将 Redis 执行过的所有指令记录下来（读操作不记录），只许追加文件 但不可以改写文件，redis 启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件 的内容将写指令从前到后执行一次以完成数据的恢复工作。\n\n==AOF 保存的是`appendonly.aof`文件==\n\n> append\n\n![image-20210503144546005](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503144546.png)\n\n默认是不开启的，我们需要手动进行配置！我们只需要将 appendonly 改为 yes 就开启了 aof！ 重启，redis 就可以生效了！\n\n如果这个 aof 文件有错误，这时候 redis 是启动不起来的，我们需要修复这个 aof 文件\n\nredis 给我们提供了一个工具 `redis-check-aof --fix`\n\n![image-20210503144822428](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503144822.png)\n\n如果文件正常，重启就可以直接恢复了！\n\n![image-20210503144919410](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503144919.png)\n\n> 重写规则说明\n\naof 默认就是文件的无限追加，文件会越来越大！\n\n![image-20210503145247104](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503145247.png)\n\n如果 aof 文件大于 64m，太大了！ fork 一个新的进程来将我们的文件进行重写！\n\n> 优点和缺点！\n\n```bash\nappendonly no # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分所有的情况下，rdb完全够用！\nappendfilename \"appendonly.aof\" # 持久化的文件的名字\n\n# appendfsync always # 每次修改都会 sync。消耗性能\nappendfsync everysec # 每秒执行一次 sync，可能会丢失这1s的数据！\n# appendfsync no # 不执行 sync，这个时候操作系统自己同步数据，速度最快！\n```\n\n**优点：**\n\n1、每一次修改都同步，文件的完整会更加好！\n\n2、每秒同步一次，可能会丢失一秒的数据\n\n3、从不同步，效率最高的！\n\n**缺点：**\n\n1、相对于数据文件来说，aof 远远大于 rdb，修复的速度也比 rdb 慢！\n\n2、Aof 运行效率也要比 rdb 慢，所以我们 redis 默认的配置就是 rdb 持久化！\n\n**扩展：**\n\n1、RDB 持久化方式能够在指定的时间间隔内对你的数据进行快照存储\n\n2、AOF 持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始 的数据，AOF 命令以 Redis 协议追加保存每次写的操作到文件末尾，Redis 还能对 AOF 文件进行后台重 写，使得 AOF 文件的体积不至于过大。\n\n3、==只做缓存，如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化==\n\n4、同时开启两种持久化方式\n\n- 在这种情况下，当 redis 重启的时候会优先载入 AOF 文件来恢复原始的数据，因为在通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数据集要完整。\n- RDB 的数据不实时，同时使用两者时服务器重启也只会找 AOF 文件，那要不要只使用 AOF 呢？作者 建议不要，因为 RDB 更适合用于备份数据库（AOF 在不断变化不好备份），快速重启，而且不会有 AOF 可能潜在的 Bug，留着作为一个万一的手段。\n\n5、性能建议\n\n- 因为 RDB 文件只用作后备用途，建议只在 Slave 上持久化 RDB 文件，而且只要 15 分钟备份一次就够 了，只保留 save 900 1 这条规则。\n- 如果 Enable AOF ，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只 load 自 己的 AOF 文件就可以了，代价一是带来了持续的 IO，二是 AOF rewrite 的最后将 rewrite 过程中产 生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少 AOF rewrite 的频率，AOF 重写的基础大小默认值 64M 太小了，可以设到 5G 以上，默认超过原大小 100%大小重 写可以改到适当的数值。\n- 如果不 Enable AOF ，仅靠 Master-Slave Repllcation 实现高可用性也可以，能省掉一大笔 IO，也 减少了 rewrite 时带来的系统波动。代价是如果 Master/Slave 同时倒掉，会丢失十几分钟的数据， 启动脚本也要比较两个 Master/Slave 中的 RDB 文件，载入较新的那个，微博就是这种架构。\n\n# Redis 发布订阅\n\nRedis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。微信、 微博、关注系统！\n\nRedis 客户端可以订阅任意数量的频道。\n\n订阅/发布消息图：\n\n第一个：消息发送者， 第二个：频道 第三个：消息订阅者！\n\n![image-20210503153104671](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503153104.png)\n\n下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的 关系：\n\n![image-20210503153133504](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503153133.png)\n\n当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：\n\n![image-20210503153155660](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503153155.png)\n\n> 命令\n\n这些命令被广泛用于构建即时通信应用，比如网络聊天室(chatroom)和实时广播、实时提醒等。\n\n| 序号 | 命令及描述                                                                                                                        |\n| :--- | :-------------------------------------------------------------------------------------------------------------------------------- |\n| 1    | [PSUBSCRIBE pattern [pattern ...]](https://www.runoob.com/redis/pub-sub-psubscribe.html) <br />订阅一个或多个符合给定模式的频道。 |\n| 2    | [PUBSUB subcommand [argument [argument ...]](https://www.runoob.com/redis/pub-sub-pubsub.html) <br />查看订阅与发布系统状态。     |\n| 3    | [PUBLISH channel message](https://www.runoob.com/redis/pub-sub-publish.html) <br />将信息发送到指定的频道。                       |\n| 4    | [PUNSUBSCRIBE [pattern [pattern ...]](https://www.runoob.com/redis/pub-sub-punsubscribe.html) <br />退订所有给定模式的频道。      |\n| 5    | [SUBSCRIBE channel [channel ...]](https://www.runoob.com/redis/pub-sub-subscribe.html) <br />订阅给定的一个或多个频道的信息。     |\n| 6    | [UNSUBSCRIBE [channel [channel ...]](https://www.runoob.com/redis/pub-sub-unsubscribe.html) <br />指退订给定的频道。              |\n\n> 测试\n\n**订阅端：**\n\n```bash\n[root@ouwen owconfig]# ../\n-bash: ../: Is a directory\n[root@ouwen owconfig]# redis-cli\n127.0.0.1:6379> SUBSCRIBE ouwenshuo\nReading messages... (press Ctrl-C to quit)\n1) \"subscribe\"\n2) \"ouwenshuo\"\n3) (integer) 1\n1) \"message\" #消息\n2) \"ouwenshuo\" #哪个频道的消息\n3) \"hello redis\" #消息内容\n```\n\n**发送端：**\n\n```bash\n127.0.0.1:6379> PUBLISH ouwenshuo \"hello redis\" #发布者发布消息到频道！\n(integer) 1\n```\n\n> 原理\n\nRedis 是使用 C 实现的，通过分析 Redis 源码里的 pubsub.c 文件，了解发布和订阅机制的底层实现，借此加深对 Redis 的理解。\n\nRedis 通过 PUBLISH 、SUBSCRIBE 和 PSUBSCRIBE 等命令实现发布和订阅功能。\n\n通过 SUBSCRIBE 命令订阅某频道后，redis-server 里维护了一个字典，字典的键就是一个个 频道！， 而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。SUBSCRIBE 命令的关键， 就是将客户端添加到给定 channel 的订阅链表中。\n\n通过 PUBLISH 命令向订阅者发送消息，redis-server 会使用给定的频道作为键，在它所维护的 channel 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。\n\nPub/Sub 从字面上理解就是发布（Publish）与订阅（Subscribe），在 Redis 中，你可以设定对某一个 key 值进行消息发布及消息订阅，当一个 key 值上进行了消息发布后，所有订阅它的客户端都会收到相应 的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。\n\n**使用场景：**\n\n1、实时消息系统！\n\n2、实时聊天！（频道当做聊天室，将信息回显给所有人即可！）\n\n3、订阅，关注系统都是可以的！ 稍微复杂的场景我们就会使用 消息中间件 MQ （）\n\n# Redis 主从复制\n\n## 概念\n\n主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为主节点 (master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。 Master 以写为主，Slave 以读为主。\n\n默认情况下，每台 Redis 服务器都是主节点；\n\n且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。\n\n**主从复制的作用主要包括：**\n\n1、数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。\n\n2、故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务 的冗余。\n\n3、负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 （即写 Redis 数据时应用连接主节点，读 Redis 数据时应用连接从节点），分担服务器负载；尤其是在写 少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。\n\n4、高可用（集群）基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是 Redis 高可用的基础。\n\n**一般来说，要将 Redis 运用于工程项目中，只使用一台 Redis 是万万不能的（宕机），原因如下：**\n\n1、从结构上，单个 Redis 服务器会发生单点故障，并且一台服务器需要处理所有的请求负载，压力较 大；\n\n2、从容量上，单个 Redis 服务器内存容量有限，就算一台 Redis 服务器内存容量为 256G，也不能将所有 内存用作 Redis 存储内存，一般来说，单台 Redis 最大使用内存不应该超过 20G。 电商网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是\"多读少写\"。\n\n**对于这种场景，我们可以使如下这种架构：**\n\n![image-20210503160753106](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503160753.png)\n\n主从复制，读写分离！ 80% 的情况下都是在进行读操作！减缓服务器的压力！架构中经常使用！ 一主 二从！\n\n只要在公司中，主从复制就是必须要使用的，因为在真实的项目中不可能单机使用 Redis！\n\n## 环境配置\n\n只配置从库，不用配置主库！\n\n```bash\n127.0.0.1:6379> info replication # 查看当前库的信息\n# Replication\nrole:master # 角色 master\nconnected_slaves:0 # 没有从机\nmaster_replid:b63c90e6c501143759cb0e7f450bd1eb0c70882a\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:0\nsecond_repl_offset:-1\nrepl_backlog_active:0\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:0\nrepl_backlog_histlen:0\n```\n\n复制 3 个配置文件，然后修改对应的信息：\n\n1、端口\n\n2、pid 名字\n\n3、log 文件名字\n\n4、dump.rdb 名字\n\n修改完毕之后，启动我们的 3 个 redis 服务器，可以通过进程信息查看~\n\n![image-20210503162204439](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503162204.png)\n\n## 一主二从\n\n默认情况下，每台 Redis 服务器都是主节点；==我们一般情况下只用配置从机就好了！\n\n认老大！ 一主 （79）二从（80，81）\n\n```bash\n127.0.0.1:6380> SLAVEOF 127.0.0.1 6379 #SLAVEOF host port 找谁当自己的老大 认主机\nOK\n127.0.0.1:6380> info replication\n# Replication\nrole:slave #当前角色是从机\nmaster_host:127.0.0.1 #可以看到主机的信息\nmaster_port:6379\nmaster_link_status:up\nmaster_last_io_seconds_ago:2\nmaster_sync_in_progress:0\nslave_repl_offset:0\nslave_priority:100\nslave_read_only:1\nconnected_slaves:0\nmaster_replid:e3379979becc4e424bf681c1a5fe7672bee18d37\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:0\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:0\n\n#在主机中查看\n127.0.0.1:6379> info replication\n# Replication\nrole:master\nconnected_slaves:1 #多了从机的配置\nslave0:ip=127.0.0.1,port=6380,state=online,offset=28,lag=0 #可以查看从机的信息\nmaster_replid:e3379979becc4e424bf681c1a5fe7672bee18d37\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:28\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:28\n```\n\n如果两个都配置完了，就是有两个从机的\n\n![image-20210503162814852](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503162814.png)\n\n真实的从主配置应该在配置文件中配置，这样的话是永久的，我们这里使用的是命令，暂时的！\n\n> 细节\n\n主机可以写，从机不能写只能读！主机中的所有信息和数据，都会自动被从机保存！\n\n主机写：\n\n![image-20210503163059937](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503163100.png)\n\n从机只能读取内容！\n\n![image-20210503163113429](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503163113.png)\n\n测试：主机断开连接，从机依旧连接到主机的，但是没有写操作，这个时候，主机如果回来了，从机依旧可以直接获取到主机写的信息！\n\n如果是使用命令行，来配置的主从，这个时候如果重启了，就会变回主机！只要变为从机，立马就会从 主机中获取值！\n\n> 复制原理\n\nSlave 启动成功连接到 master 后会发送一个 sync 同步命令\n\nMaster 接到命令，启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行 完毕之后，**master 将传送整个数据文件到 slave，并完成一次完全同步。**\n\n- 全量复制：而 slave 服务在接收到数据库文件数据后，将其存盘并加载到内存中。\n\n- 增量复制：Master 继续将新的所有收集到的修改命令依次传给 slave，完成同步\n\n**但是只要是重新连接 master，一次完全同步（全量复制）将被自动执行！ 我们的数据一定可以在从机中 看到！**\n\n> 层层链路\n\n上一个 M 链接下一个 S！\n\n![image-20210503174711032](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503174711.png)\n\n这时候也可以完成我们的主从复制！\n\n> 如果没有老大了，这个时候能不能选择一个老大出来呢？ 手动！\n\n**谋朝篡位**\n\n如果主机断开了连接，我们可以使用`SLAVEOF no one` 让自己变成主机！其他的节点就可以手动连 接到最新的这个主节点（手动）！如果这个时候老大修复了，那就重新连接！\n\n# 哨兵模式\n\n（自动选举老大的模式）\n\n> 概述\n\n主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工 干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑 哨兵模式。Redis 从 2.8 开始正式提供了 Sentinel（哨兵） 架构来解决这个问题。\n\n谋朝篡位的自动版，能够后台监控主机是否故障，如果故障了根据投票数**自动将从库转换为主库**。\n\n哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是**哨兵通过发送命令，等待 Redis 服务器响应，从而监控运行的多个 Redis 实例。**\n\n![image-20210503180007839](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503180007.png)\n\n这里的哨兵有两个作用\n\n- 通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器。\n- 当哨兵监测到 master 宕机，会自动将 slave 切换成 master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。\n\n然而一个哨兵进程对 Redis 服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。\n\n![image-20210503180127096](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503180127.png)\n\n假设主服务器宕机，哨兵 1 先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵 1 主观的认 为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover[故障转移]操作。 切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为 **客观下线**。\n\n> 测试！\n\n目前的状态是：一主二从！\n\n1、配置哨兵配置文件 `sentinel.conf`\n\n```bash\n# sentinel monitor 被监控的名称 host port 1\nsentinel monitor myredis 127.0.0.1 6379 1\n```\n\n后面的这个数字 1，代表主机挂了，slave 投票看让谁接替成为主机，票数最多的，就会成为主机！\n\n2、启动哨兵\n\n````bash\n[root@ouwen bin]# redis-sentinel owconfig/sentinel.conf\n5922:X 03 May 2021 18:13:03.144 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n5922:X 03 May 2021 18:13:03.144 # Redis version=5.0.8, bits=64, commit=00000000, modified=0, pid=5922, just started\n5922:X 03 May 2021 18:13:03.144 # Configuration loaded\n                _._\n           _.-``__ ''-._\n      _.-``    `.  `_.  ''-._           Redis 5.0.8 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._\n (    '      ,       .-`  | `,    )     Running in sentinel mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 26379\n |    `-._   `._    /     _.-'    |     PID: 5922\n  `-._    `-._  `-./  _.-'    _.-'\n |`-._`-._    `-.__.-'    _.-'_.-'|\n |    `-._`-._        _.-'_.-'    |           http://redis.io\n  `-._    `-._`-.__.-'_.-'    _.-'\n |`-._`-._    `-.__.-'    _.-'_.-'|\n |    `-._`-._        _.-'_.-'    |\n  `-._    `-._`-.__.-'_.-'    _.-'\n      `-._    `-.__.-'    _.-'\n          `-._        _.-'\n              `-.__.-'\n\n5922:X 03 May 2021 18:13:03.145 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n5922:X 03 May 2021 18:13:03.150 # Sentinel ID is 0ab5ef20110ebfc67bc2a5e93addbe0871ffd748\n5922:X 03 May 2021 18:13:03.150 # +monitor master myredis 127.0.0.1 6379 quorum 1\n5922:X 03 May 2021 18:13:03.151 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ myredis 127.0.0.1 6379\n5922:X 03 May 2021 18:13:03.156 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ myredis 127.0.0.1 6379\n````\n\n如果 Master 节点断开了，这个时候就会从从机中随机选择一个服务器！（这里面有一个投票算法！）\n\n![image-20210503181752988](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503181753.png)\n\n**哨兵日志：**\n\n![image-20210503181828520](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503181828.png)\n\n如果主机此时回来了，==只能归并到新的主机下，当做从机==，这就是哨兵模式的规则！\n\n> 哨兵模式\n\n**优点：**\n\n1、哨兵集群，基于主从复制模式，所有的主从配置优点，它全有\n\n2、主从可以切换，故障可以转移，系统的可用性就会更好\n\n3、哨兵模式就是主从模式的升级，手动到自动，更加健壮！\n\n**缺点：**\n\n1、Redis 不好做在线扩容的，集群容量一旦达到上限，在线扩容就会十分麻烦！\n\n2、实现哨兵模式的配置其实是很麻烦的，里面有很多选择！\n\n> 哨兵模式的全部配置！！\n\n```bash\n# Example sentinel.conf\n# 哨兵sentinel实例运行的端口 默认26379\nport 26379\n# 哨兵sentinel的工作目录\ndir /tmp\n# 哨兵sentinel监控的redis主节点的 ip port\n# master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符\".-_\"组成。\n# quorum 配置多少个sentinel哨兵统一认为master主节点失联 那么这时客观上认为主节点失联了\n# sentinel monitor <master-name> <ip> <redis-port> <quorum>\nsentinel monitor mymaster 127.0.0.1 6379 2\n# 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提供密码\n# 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码\n# sentinel auth-pass <master-name> <password>\nsentinel auth-pass mymaster MySUPER--secret-0123passw0rd\n# 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒\n# sentinel down-after-milliseconds <master-name> <milliseconds>\nsentinel down-after-milliseconds mymaster 30000\n# 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行 同步，这个数字越小，完成failover所需的时间就越长，但是如果这个数字越大，就意味着越 多的slave因为replication而不可用。可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态。\n# sentinel parallel-syncs <master-name> <numslaves>\nsentinel parallel-syncs mymaster 1\n# 故障转移的超时时间 failover-timeout 可以用在以下这些方面：\n#1. 同一个sentinel对同一个master两次failover之间的间隔时间。\n#2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那\n里同步数据时。\n#3.当想要取消一个正在进行的failover所需要的时间。\n#4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，\nslaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了\n# 默认三分钟\n# sentinel failover-timeout <master-name> <milliseconds>\nsentinel failover-timeout mymaster 180000\n# SCRIPTS EXECUTION\n#配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知\n相关人员。\n#对于脚本的运行结果有以下规则：\n#若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10\n#若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。\n#如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。\n#一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。\n#通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，一个是事件的类型，一个是事件的描述。如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。\n#通知脚本\n# shell编程\n# sentinel notification-script <master-name> <script-path>\nsentinel notification-script mymaster /var/redis/notify.sh\n# 客户端重新配置主节点参数脚本\n# 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。\n# 以下参数将会在调用脚本时传给脚本:\n# <master-name> <role> <state> <from-ip> <from-port> <to-ip> <to-port>\n# 目前<state>总是“failover”,\n# <role>是“leader”或者“observer”中的一个。\n# 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的\n# 这个脚本应该是通用的，能被多次调用，不是针对性的。\n# sentinel client-reconfig-script <master-name> <script-path>\nsentinel client-reconfig-script mymaster /var/redis/reconfig.sh # 一般都是由运维来配置！\n```\n\n# Redis 缓存穿透和雪崩\n\n> 服务的高可用问题！\n\n在这里我们不会详细的区分析解决方案的底层！\n\nRedis 缓存的使用，极大的提升了应用程序的性能和效率，特别是数据查询方面。但同时，它也带来了一 些问题。其中，最要害的问题，就是数据的一致性问题，从严格意义上讲，这个问题无解。如果对数据的一致性要求很高，那么就不能使用缓存。\n\n另外的一些典型问题就是，缓存穿透、缓存雪崩和缓存击穿。目前，业界也都有比较流行的解决方案。\n\n![image-20210503183005078](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503183005.png)\n\n## 缓存穿透（查不到）\n\n> 概念\n\n缓存穿透的概念很简单，用户想要查询一个数据，发现 redis 内存数据库没有，也就是缓存没有命中，于是向持久层数据库查询。发现也没有，于是本次查询失败。当用户很多的时候，缓存都没有命中（秒 杀！），于是都去请求了持久层数据库。这会给持久层数据库造成很大的压力，这时候就相当于出现了缓存穿透。\n\n> 解决方案\n\n**布隆过滤器**\n\n布隆过滤器是一种数据结构，对所有可能查询的参数以 hash 形式存储，在控制层先进行校验，不符合则丢弃，从而避免了对底层存储系统的查询压力；\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503183137.png\" alt=\"image-20210503183137788\" style=\"zoom: 50%;\" />\n\n**缓存空对象**\n\n当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间，之后再访问这个数据将会从缓存中获取，保护了后端数据源；\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503183210.png\" alt=\"image-20210503183210887\" style=\"zoom:50%;\" />\n\n但是这种方法会存在两个问题：\n\n1、如果空值能够被缓存起来，这就意味着缓存需要更多的空间存储更多的键，因为这当中可能会有很多 的空值的键；\n\n2、即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于 需要保持一致性的业务会有影响。\n\n## 缓存击穿（量太大，缓存过期！）\n\n> 概述\n\n这里需要注意和缓存击穿的区别，缓存击穿，是指一个 key 非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个 key 在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一 个屏障上凿开了一个洞。\n\n当某个 key 在过期的瞬间，有大量的请求并发访问，这类数据一般是热点数据，由于缓存过期，会同时访问数据库来查询最新数据，并且回写缓存，会导使数据库瞬间压力过大。\n\n> 解决方案\n\n**设置热点数据永不过期**\n\n从缓存层面来看，没有设置过期时间，所以不会出现热点 key 过期后产生的问题。\n\n**加互斥锁**\n\n分布式锁：使用分布式锁，保证对于每个 key 同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。\n\n## 缓存雪崩\n\n> 概念\n\n缓存雪崩，是指在某一个时间段，缓存集中过期失效。Redis 宕机~\n\n产生雪崩的原因之一，比如在写本文的时候，马上就要到双十二零点，很快就会迎来一波抢购，这波商 品时间比较集中的放入了缓存，假设缓存一个小时。那么到了凌晨一点钟的时候，这批商品的缓存就都过期了。而对这批商品的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰。于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。\n\n![image-20210503183725407](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503183725.png)\n\n其实集中过期，倒不是非常致命，比较致命的缓存雪崩，是缓存服务器某个节点宕机或断网。因为自然形成的缓存雪崩，一定是在某个时间段集中创建缓存，这个时候，数据库也是可以顶住压力的。无非就是对数据库产生周期性的压力而已。而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的，很有可能瞬间就把数据库压垮。\n\n> 解决方案\n\n**redis 高可用**\n\n这个思想的含义是，既然 redis 有可能挂掉，那我多增设几台 redis，这样一台挂掉之后其他的还可以继续 工作，其实就是搭建的集群。（异地多活！）\n\n**限流降级**\n\n这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对 某个 key 只允许一个线程查询数据和写缓存，其他线程等待。\n\n**数据预热**\n\n数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数 据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的 key，设置不同的过期时间，让缓存失效的时间点尽量均匀。\n","tags":["笔记","Redis"],"categories":["中间件"]},{"title":"JUC 并发编程","slug":"JUC并发编程","url":"/2021/05/16/eb9166f8.html","content":"\n## 什么是 JUC\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404140130.png)\n\nJUC 是 java.util.concurrent 的简写。在 jdk 官方手册中可以看到 juc 相关的 jar 包有三个。\n\n用中文概括一下，JUC 的意思就是 java 并发编程工具包\n\n## 线程和进程\n\n> 如果不能使用一句话说出来的技术，不扎实！\n\n进程：一个程序，QQ.exe Music.exe 程序的集合\n\n一个进程往往可以包含多个线程，至少包含一个！\n\nJava 默认有几个线程？ 2 个 main、GC\n\n线程：线程是程序执行中一个单一的顺序控制流程\n\n对于 Java 而言：Thread、Runnable、Callable\n\n**Java 真的可以开启线程吗？** 开不了\n\n```java\npublic synchronized void start() {\n        /**\n         * This method is not invoked for the main method thread or \"system\"\n         * group threads created/set up by the VM. Any new functionality added\n         * to this method in the future may have to also be added to the VM.\n         *\n         * A zero status value corresponds to state \"NEW\".\n         */\n        if (threadStatus != 0)\n            throw new IllegalThreadStateException();\n\n        /* Notify the group that this thread is about to be started\n         * so that it can be added to the group's list of threads\n         * and the group's unstarted count can be decremented. */\n        group.add(this);\n\n        boolean started = false;\n        try {\n            start0();\n            started = true;\n        } finally {\n            try {\n                if (!started) {\n                    group.threadStartFailed(this);\n                }\n            } catch (Throwable ignore) {\n                /* do nothing. If start0 threw a Throwable then\n                  it will be passed up the call stack */\n            }\n        }\n    }\n\t// 本地方法，底层的C++，Java无法直接操作硬件\n    private native void start0();\n```\n\n### 并发、并行\n\n并发编程：并发、并行\n\n并发（多线程操作同一个资源）\n\n- CPU 一核，模拟出来多条线程，天下武功，唯快不破，快速交替\n\n并行（多个人一起行走）\n\n- CPU 多核，多个线程可以同时执行；线程池\n\n```java\npackage com.ouwen.demo01;\n\n/**\n * @author IRVING\n * @create 2021-04-04 14:20\n */\npublic class Test {\n\n    public static void main(String[] args) {\n        // 获取CPU的核心数\n        // CPU密集型，IO密集型\n        System.out.println(Runtime.getRuntime().availableProcessors());\n    }\n}\n```\n\n并发编程的本质：**充分利用 CPU 的资源**\n\n所有的公司都很看重！\n\n### 线程有几个状态\n\n```java\npublic enum State {\n       \t//新生\n        NEW,\n\n        //运行\n        RUNNABLE,\n\n        //阻塞\n        BLOCKED,\n\n        //等待\n        WAITING,\n\n        //超时等待\n        TIMED_WAITING,\n\n        //终止\n        TERMINATED;\n    }\n```\n\n### wait/sleep 的区别\n\n1. **来自不同的类**\n\n   wait => Object\n\n   sleep => Thread\n\n2. **关于锁的释放**\n\n   wait 会释放锁，sleep 睡觉了，抱着锁睡觉，不会释放！\n\n3. **使用的范围是不同的**\n\n   wait：只能在同步代码块中使用\n\n   sleep：可以在任何地方睡\n\n## Lock 锁（重点）\n\n### 传统 synchronized\n\n```java\npackage com.ouwen.demo01;\n\n/**\n * 真正的多线程开发，公司中的开发，降低耦合性\n * * 线程就是一个单独的资源类，没有任何附属的操作！\n * * 1、 属性、方法\n *\n * @author IRVING\n * @create 2021-04-04 14:42\n */\n\npublic class SaleTicketDemo01 {\n    public static void main(String[] args) {\n        // 并发：多线程操作同一个资源类, 把资源类丢入线程\n        Ticket ticket = new Ticket();\n        // @FunctionalInterface 函数式接口，jdk1.8 lambda表达式 (参数)->{ 代码 }\n        new Thread(() -> {\n            for (int i = 1; i < 40; i++) {\n                ticket.sale();\n            }\n        }, \"A\").start();\n        new Thread(() -> {\n            for (int i = 1; i < 40; i++) {\n                ticket.sale();\n            }\n        }, \"B\").start();\n        new Thread(() -> {\n            for (int i = 1; i < 40; i++) {\n                ticket.sale();\n            }\n        }, \"C\").start();\n    }\n}\n\n// 资源类 OOP\nclass Ticket {\n    // 属性、方法\n    private int number = 30;\n\n    // 卖票的方式\n    // synchronized 本质: 队列，锁\n    public synchronized void sale() {\n        if (number > 0) {\n            System.out.println(Thread.currentThread().getName() + \"卖出了\" + (number--) + \"票,剩余：\" + number);\n        }\n    }\n}\n```\n\n### Lock 接口\n\n![image-20210404145103174](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404145103.png)\n\n![image-20210404145122205](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404145122.png)\n\n![image-20210404145431054](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404145431.png)\n\n公平锁：十分公平；可以先来后到\n\n**非公平锁：十分不公平；可以插队（默认）**\n\n```java\npackage com.ouwen.demo01;\n\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\n/**\n * @author IRVING\n * @create 2021-04-04 14:42\n */\n\npublic class SaleTicketDemo02 {\n    public static void main(String[] args) {\n        // 并发：多线程操作同一个资源类, 把资源类丢入线程\n        Ticket2 ticket = new Ticket2();\n\n        new Thread(() -> {\n            for (int i = 1; i < 40; i++) {\n                ticket.sale();\n            }\n        }, \"A\").start();\n        new Thread(() -> {\n            for (int i = 1; i < 40; i++) {\n                ticket.sale();\n            }\n        }, \"B\").start();\n        new Thread(() -> {\n            for (int i = 1; i < 40; i++) {\n                ticket.sale();\n            }\n        }, \"C\").start();\n    }\n}\n\n/**\n * Lock三部曲\n * 1.new ReentrantLock();\n * 2.Lock.lock() //加锁\n * 3.finally => lock.unlock() //解锁\n */\nclass Ticket2 {\n    // 属性、方法\n    private int number = 30;\n\n    Lock lock = new ReentrantLock();\n\n    // 卖票的方式\n    public void sale() {\n\n        lock.lock();//加锁\n\n\n        try {\n            //业务代码\n            if (number > 0) {\n                System.out.println(Thread.currentThread().getName() + \"卖出了第\" + (number--) + \"票,剩余：\" + number);\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            //解锁\n            lock.unlock();\n        }\n    }\n}\n```\n\n### synchronized 和 Lock 区别\n\n1. synchronize 内置的 Java 关键字，Lock 是一个 Java 类\n2. synchronized 无法判断获取锁的状态，Lock 可以判断是否获取到了锁\n3. synchronized 会自动释放锁，Lock 必须要手动释放锁！如果不释放锁，**死锁**\n4. synchronized 线程 1（获得锁，阻塞）、线程 2（等待，傻傻的等）；Lock 锁就不一定会等待下去；\n5. synchronized 可重入锁，不可以中断的，非公平；Lock 可重入锁，可以判断锁，非公平（可以自己设置）\n6. synchronized 适合锁少量的代码同步问题，Lock 适合锁大量的同步代码！\n\n## 生产者和消费者问题\n\n### 生产者和消费者问题 synchronized 版\n\n```java\npackage com.ouwen.pc;\n\nimport com.sun.org.apache.bcel.internal.generic.NEW;\n\n/**\n * 线程之间的通信问题：生产者与消费者问题！ 等待唤醒，通知唤醒\n * 线程交替执行 A B 操作同一个变量 num = 0\n * A num+1\n * B num-1\n * @author IRVING\n * @create 2021-04-04 15:10\n */\npublic class A {\n\n    public static void main(String[] args) {\n        Data data = new Data();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.increment();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        },\"A\").start();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.decrement();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        },\"B\").start();\n    }\n}\n\n// 判断等待、业务、通知\n//数字 资源类\nclass Data {\n    private int number = 0;\n\n    //+1\n    public synchronized void increment() throws InterruptedException {\n        if (number != 0) {\n            //等待\n            this.wait();\n        }\n        number++;\n        System.out.println(Thread.currentThread().getName() + \"=>\" + number);\n        // 通知其他线程，我+1完毕了\n        this.notifyAll();\n    }\n\n    //-1\n    public synchronized void decrement() throws InterruptedException {\n        if (number == 0) {\n            //等待\n            this.wait();\n        }\n        number--;\n        // 通知其他线程，我-1完毕了\n        System.out.println(Thread.currentThread().getName() + \"=>\" + number);\n        this.notifyAll();\n    }\n}\n```\n\n> 问题存在，A B C D 4 个线程 虚假唤醒\n\n![image-20210404152512622](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404152512.png)\n\n**if 改为 while 判断**\n\n```java\npackage com.ouwen.pc;\n\nimport com.sun.org.apache.bcel.internal.generic.NEW;\n\n/**\n * 线程之间的通信问题：生产者与消费者问题！ 等待唤醒，通知唤醒\n *\n * @author IRVING\n * @create 2021-04-04 15:10\n */\npublic class A {\n\n    public static void main(String[] args) {\n        Data data = new Data();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.increment();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        },\"A\").start();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.decrement();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        },\"B\").start();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.increment();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        },\"C\").start();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.decrement();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        },\"D\").start();\n    }\n}\n\n// 判断等待、业务、通知\n//数字 资源类\nclass Data {\n    private int number = 0;\n\n    //+1\n    public synchronized void increment() throws InterruptedException {\n        while (number != 0) {\n            //等待\n            this.wait();\n        }\n        number++;\n        System.out.println(Thread.currentThread().getName() + \"=>\" + number);\n        // 通知其他线程，我+1完毕了\n        this.notifyAll();\n    }\n\n    //-1\n    public synchronized void decrement() throws InterruptedException {\n        while (number == 0) {\n            //等待\n            this.wait();\n        }\n        number--;\n        // 通知其他线程，我-1完毕了\n        System.out.println(Thread.currentThread().getName() + \"=>\" + number);\n        this.notifyAll();\n    }\n}\n```\n\n### JUC 版的生产者与消费者问题\n\n![image-20210404153311646](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404153425.png)\n\n**通过 Lock 找到 Condition**\n\n![image-20210404160949444](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404160949.png)\n\n代码实现：\n\n```java\npackage com.ouwen.pc;\n\nimport java.lang.reflect.Constructor;\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\n/**\n * @author IRVING\n * @create 2021-04-04 16:01\n */\npublic class B {\n\n    public static void main(String[] args) {\n        Data2 data = new Data2();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.increment();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"A\").start();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.decrement();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"B\").start();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.increment();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"C\").start();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    data.decrement();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"D\").start();\n    }\n}\n\n// 判断等待、业务、通知\n//数字 资源类\nclass Data2 {\n    private int number = 0;\n\n    Lock lock = new ReentrantLock();\n    Condition condition = lock.newCondition();\n    //condition.await();  //等待\n    //condition.signalAll(); //唤醒全部\n\n\n    //+1\n    public void increment() throws InterruptedException {\n        lock.lock();\n        try {\n            //业务代码\n            while (number != 0) {\n                //等待\n                condition.await();\n            }\n            number++;\n            System.out.println(Thread.currentThread().getName() + \"=>\" + number);\n            // 通知其他线程，我+1完毕了\n            condition.signalAll();\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    //-1\n    public void decrement() throws InterruptedException {\n        lock.lock();\n        try {\n            while (number == 0) {\n                //等待\n                condition.await();\n            }\n            number--;\n            // 通知其他线程，我-1完毕了\n            System.out.println(Thread.currentThread().getName() + \"=>\" + number);\n            condition.signalAll();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n\n    }\n}\n```\n\n**任何一个新的技术诞生，绝不是仅仅只是覆盖了原来的技术，一定存在优势和补充！**\n\n### Condition 精准的通知和唤醒线程\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404161317.png\" alt=\"image-20210404161317196\"  />\n\n代码测试：\n\n```java\npackage com.ouwen.pc;\n\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\n/**\n * @author IRVING\n * @create 2021-04-04 16:14\n * A执行完调用B，B执行完调用C，C执行完调用A\n */\npublic class C {\n\n    public static void main(String[] args) {\n\n        Data3 data3 = new Data3();\n\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                data3.printA();\n            }\n        }, \"A\").start();\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                data3.printB();\n            }\n        }, \"B\").start();\n        new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                data3.printC();\n            }\n        }, \"C\").start();\n    }\n}\n\n//资源类 Lock\nclass Data3 {\n\n    private Lock lock = new ReentrantLock();\n    Condition condition1 = lock.newCondition();\n    Condition condition2 = lock.newCondition();\n    Condition condition3 = lock.newCondition();\n    private int number = 1; // 1A 2B 3C\n\n    public void printA() {\n        lock.lock();\n\n        try {\n            //业务，判断 -> 执行 -> 通知\n            while (number != 1) {\n                //等待\n                condition1.await();\n            }\n            System.out.println(Thread.currentThread().getName() + \"=>AAAAAAA\");\n            //唤醒，唤醒指定的人，B\n            number = 2;\n            condition2.signal();\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void printB() {\n        lock.lock();\n\n        try {\n            //业务，判断 -> 执行 -> 通知\n            while (number != 2) {\n                //等待\n                condition2.await();\n            }\n            System.out.println(Thread.currentThread().getName() + \"=>BBBBBB\");\n            //唤醒，唤醒指定的人，C\n            number = 3;\n            condition3.signal();\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void printC() {\n        lock.lock();\n\n        try {\n            //业务，判断 -> 执行 -> 通知\n            while (number != 3) {\n                //等待\n                condition3.await();\n            }\n            System.out.println(Thread.currentThread().getName() + \"=>CCCCCCCC\");\n            //唤醒，唤醒指定的人，A\n            number = 1;\n            condition1.signal();\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n\n## 8 锁现象\n\n任何判断锁的是谁！永远的知道什么是锁，锁到底锁的是谁！\n\n**深刻理解我们的锁 **\n\n```java\npackage com.ouwen.lock8;\n\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 8锁，就是关于锁的8个问题\n * 1、标准情况下，两个线程先打印 发短信还是 打电话？ 1发短信 2打电话\n * 1、sendSms延迟4秒，两个线程先打印 发短信还是 打电话？ 1发短信 2打电话\n * @author IRVING\n * @create 2021-04-04 16:30\n */\npublic class Test1 {\n\n    public static void main(String[] args) {\n        Phone phone = new Phone();\n\n        //锁的存在\n        new Thread(()->{\n            phone.sendSms();\n        }).start();\n\n        try {\n            TimeUnit.SECONDS.sleep(1);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        new Thread(()->{\n            phone.call();\n        }).start();\n    }\n}\n\nclass Phone {\n\n    // synchronized 锁的对象是方法的调用者！\n    // 两个方法用的是同一所，谁先拿到谁执行！\n    public synchronized void sendSms() {\n        try {\n            TimeUnit.SECONDS.sleep(4);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"发短信\");\n    }\n\n    public synchronized void call() {\n        System.out.println(\"打电话\");\n    }\n}\n```\n\n```java\npackage com.ouwen.lock8;\n\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 3. 增加了一个普通方法！先执行发短信还是hello？  普通方法hello\n * 4. 两个对象，两个同步方法，发短信还是打电话？  //打电话\n * @author IRVING\n * @create 2021-04-04 16:36\n */\npublic class Test2  {\n\n    public static void main(String[] args) {\n        //两个不同的对象 两把锁\n        Phone2 phone1 = new Phone2();\n        Phone2 phone2 = new Phone2();\n\n        //锁的存在\n        new Thread(()->{\n            phone1.sendSms();\n        },\"A\").start();\n\n        try {\n            TimeUnit.SECONDS.sleep(1);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        new Thread(()->{\n            phone2.call();\n        },\"B\").start();\n    }\n}\n\nclass Phone2 {\n\n    // synchronized 锁的对象是方法的调用者！\n    // 两个方法用的是同一锁，谁先拿到谁执行！\n    public synchronized void sendSms() {\n        try {\n            TimeUnit.SECONDS.sleep(4);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"发短信\");\n    }\n\n    public synchronized void call() {\n        System.out.println(\"打电话\");\n    }\n\n    // 这里没有锁！不是同步方法！不受锁的影响\n    public void hello(){\n        System.out.println(\"hello\");\n    }\n}\n```\n\n```java\npackage com.ouwen.lock8;\n\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 5.增加两个静态同步方法，只有一个对象，先打印 发短信？打电话？ 发短信\n * 6.增加两个静态同步方法，两个对象！，先打印 发短信？打电话？ 发短信\n * @author IRVING\n * @create 2021-04-04 17:22\n */\npublic class Test3 {\n\n    public static void main(String[] args) {\n        //两个不同的对象 类模板Class只有一个 static，锁的是Class\n        Phone3 phone1 = new Phone3();\n        Phone3 phone2 = new Phone3();\n\n        //锁的存在\n        new Thread(() -> {\n            phone1.sendSms();\n        }, \"A\").start();\n\n        try {\n            TimeUnit.SECONDS.sleep(1);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        new Thread(() -> {\n            phone2.call();\n        }, \"B\").start();\n    }\n}\n\nclass Phone3 {\n\n    // synchronized 锁的对象是方法的调用者！\n    // staic静态方法\n    // 类一加载就有了！锁的是Class Phone3.class\n    public static synchronized void sendSms() {\n        try {\n            TimeUnit.SECONDS.sleep(4);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"发短信\");\n    }\n\n    public static synchronized void call() {\n        System.out.println(\"打电话\");\n    }\n}\n```\n\n```java\npackage com.ouwen.lock8;\n\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 7. 一个静态同步方法，一个普通同步方法 一个对象 先打印 发短信？打电话？ 打电话\n * 8. 一个静态同步方法，一个普通同步方法 两个对象 先打印 发短信？打电话？ 打电话\n *\n * @author IRVING\n * @create 2021-04-04 17:27\n */\npublic class Test4 {\n\n    public static void main(String[] args) {\n        //两个不同的对象 类模板Class只有一个 static，锁的是Class\n        Phone4 phone1 = new Phone4();\n        Phone4 phone2 = new Phone4();\n\n        //锁的存在\n        new Thread(() -> {\n            phone1.sendSms();\n        }, \"A\").start();\n\n        try {\n            TimeUnit.SECONDS.sleep(1);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        new Thread(() -> {\n            phone2.call();\n        }, \"B\").start();\n    }\n}\n\nclass Phone4 {\n\n    // staic静态同步方法  锁的是Class\n    public static synchronized void sendSms() {\n        try {\n            TimeUnit.SECONDS.sleep(4);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"发短信\");\n    }\n\n    //普通同步方法 锁的是调用对象\n    public synchronized void call() {\n        System.out.println(\"打电话\");\n    }\n}\n```\n\n> 小结\n\nnew this 具体的一个对象\n\nstatic Class 唯一的模板\n\n## 集合类不安全\n\n### List 不安全\n\n```java\npackage com.ouwen.unsafe;\n\nimport java.util.*;\nimport java.util.concurrent.CopyOnWriteArrayList;\n\n/**\n * java.util.ConcurrentModificationException 并发修改异常;\n *\n * @author IRVING\n * @create 2021-04-04 17:34\n */\npublic class ListTest {\n\n    public static void main(String[] args) {\n        // 并发下 ArrayList 不安全的\n        /**\n         * 解决方案：\n         * 1、List<String> list = new Vector<>();\n         * 2、List<String> list = Collections.synchronizedList(new ArrayList<>());\n         * 3、List<String> list = new CopyOnWriteArrayList<>();\n         */\n        // CopyOnWriter COW 计算机程序设计领域的一种优化策略：\n        // 多个线程调用的时候，list，读取时是固定的，写入（覆盖）\n        // 在写入的时候避免覆盖，造成数据问题  -- 读写分离\n        // CopyOnWriterList 比 Vector NB在哪里？ => 前者效率高\n        List<String> list = new CopyOnWriteArrayList<>();\n        for (int i = 0; i < 10; i++) {\n            new Thread(() -> {\n                list.add(UUID.randomUUID().toString().substring(0, 5));\n                System.out.println(list);\n            }, String.valueOf(i)).start();\n        }\n    }\n}\n```\n\n学习方法推荐：1、先会用、2、货比 3 家，寻找其他解决方案，3、分析源码！\n\n### Set 不安全\n\n```java\npackage com.ouwen.unsafe;\n\nimport java.util.Collections;\nimport java.util.HashSet;\nimport java.util.Set;\nimport java.util.UUID;\nimport java.util.concurrent.CopyOnWriteArraySet;\n\n/**\n * 同理可证：java.util.ConcurrentModificationException 并发修改异常\n * @author IRVING\n * @create 2021-04-04 17:49\n */\npublic class SetList {\n    public static void main(String[] args) {\n        //Set<String> set = new HashSet<>();\n        //Set<String> set = Collections.synchronizedSet(new HashSet<>());\n        Set<String> set = new CopyOnWriteArraySet<>();\n        for (int i = 0; i < 300; i++) {\n            new Thread(() -> {\n                set.add(UUID.randomUUID().toString().substring(0, 5));\n                System.out.println(set);\n            }, String.valueOf(i)).start();\n        }\n    }\n}\n```\n\n**HashSet 底层是什么？**\n\n```java\npublic HashSet() {\n    map = new HashMap<>();\n}\n\n//add set 本质就是map key是无法重复的！！\npublic boolean add(E e) {\n    return map.put(e, PRESENT)==null;\n}\n\nprivate static final Object PRESENT = new Object(); //常量 不变的值！\n```\n\n### Map 不安全\n\n```java\npackage com.ouwen.unsafe;\n\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.UUID;\nimport java.util.concurrent.ConcurrentHashMap;\n\n/**\n * @author IRVING\n * @create 2021-04-04 17:57\n */\npublic class MapTest {\n\n    public static void main(String[] args) {\n        // map 是这样的用的吗？ 不是，工作中不用HashMap()\n        //  默认等价于什么 new HashMap<>(16,0.75f);\n        //Map<String,String> map =  new HashMap<>();\n        //Map<String,String> map = Collections.synchronizedMap(new HashMap<>());\n        // 研究ConcurrentHashMap原理\n        Map<String,String> map = new ConcurrentHashMap<>();\n        for (int i = 0; i < 30; i++) {\n            new Thread(()->{\n                map.put(Thread.currentThread().getName(), UUID.randomUUID().toString().substring(0,5));\n                System.out.println(map);\n            },String.valueOf(i)).start();\n        }\n    }\n}\n```\n\n## Callable（简单）\n\n![image-20210404181130827](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404181130.png)\n\n1. 可以有返回值\n2. 可以抛出异常\n3. 方法不同 ，run()/call()\n\n**代码测试：**\n\n```java\npackage com.ouwen.callable;\n\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.FutureTask;\n\n/**\n * 启动Callable\n *\n * @author IRVING\n * @create 2021-04-04 18:13\n */\npublic class CallableTest {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        //怎么启动callable\n        // 1.new Thread(new Runnable()).start();\n        // 2.new Thread(new FutureTask<V>()).start();\n        // 3.new Thread(new FutureTask<V>(new Callable())).start();\n\n\n        MyThread myThread = new MyThread();\n        //适配类 FutureTask\n        FutureTask<String> task = new FutureTask<>(myThread);\n        new Thread(task, \"A\").start();\n        new Thread(task, \"B\").start(); //结果会被缓存，效率高\n\n        String s = task.get(); // 这个get方法可能会产生阻塞！ 把它放到最后，或者使用异步通信来处理\n        System.out.println(s);\n    }\n}\n\nclass MyThread implements Callable<String> {\n    @Override\n    public String call() throws Exception {\n        System.out.println(Thread.currentThread().getName()+\"call()\");\n        return \"123\";\n    }\n}\n\n```\n\n细节：\n\n1. 有缓存\n2. 结果可能需要等待，会阻塞！\n\n## 常用的辅助类\n\n### CountDownLatch\n\n![image-20210404211341279](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404211341.png)\n\n```java\npackage com.ouwen.add;\n\nimport java.util.concurrent.CountDownLatch;\n\n/**\n * 计数器\n * @author IRVING\n * @create 2021-04-04 21:14\n */\npublic class CountDownLatchDemo {\n\n    public static void main(String[] args) throws InterruptedException {\n        //总数是6\n        CountDownLatch countDownLatch = new CountDownLatch(6);\n\n        for (int i = 0; i < 6; i++) {\n            new Thread(()->{\n                System.out.println(Thread.currentThread().getName()+\"Go Out\");\n                countDownLatch.countDown(); //数量-1\n            },String.valueOf(i)).start();\n        }\n\n        countDownLatch.await(); //等待计数器归零，再向下执行\n\n        System.out.println(\"关门\");\n    }\n\n}\n```\n\n原理：\n\n==countDownLatch.countDown()== //数量-1\n\n==countDownLatch.await()== //等待计数器归零，然后再向下执行\n\n每次有线程调用 countDownLatch()数量-1，假设计数器变为 0，countDownLatch.await()就会被唤醒，继续往下执行\n\n### CyclicBarrier\n\n![image-20210404212739912](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404212740.png)\n\n加法计数器\n\n```java\npackage com.ouwen.add;\n\nimport java.util.concurrent.BrokenBarrierException;\nimport java.util.concurrent.CyclicBarrier;\n\n/**\n * @author IRVING\n * @create 2021-04-04 21:28\n */\npublic class CycliBarrierDemo {\n\n    public static void main(String[] args) {\n        /**\n         * 集齐七颗龙珠，召唤神龙\n         */\n        //召唤龙珠的线程\n        CyclicBarrier barrier = new CyclicBarrier(7,()->{\n            System.out.println(\"召唤神龙成功\");\n        });\n\n        for (int i = 0; i < 7; i++) {\n            int temp = i;\n            // lambda能操作i吗\n            new Thread(()->{\n                System.out.println(Thread.currentThread().getName()+\"收集\"+temp+\"个龙珠\");\n                try {\n                    barrier.await(); //等待\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } catch (BrokenBarrierException e) {\n                    e.printStackTrace();\n                }\n            }).start();\n        }\n    }\n}\n```\n\n### Semaphore\n\n![image-20210404213555658](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210404213555.png)\n\n```java\npackage com.ouwen.add;\n\nimport java.util.concurrent.Semaphore;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * @author IRVING\n * @create 2021-04-04 21:36\n */\npublic class SemaphoreDemo {\n\n    public static void main(String[] args) {\n        //线程数量：停车位\n        Semaphore semaphore = new Semaphore(3);\n\n        for (int i = 0; i < 6; i++) {\n            new Thread(() -> {\n                //acquire()得到\n                try {\n                    semaphore.acquire();\n                    System.out.println(Thread.currentThread().getName() + \"抢到车位\");\n                    TimeUnit.SECONDS.sleep(2);\n                    System.out.println(Thread.currentThread().getName() + \"离开车位\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    //release()释放\n                    semaphore.release();\n                }\n            },String.valueOf(i)).start();\n        }\n    }\n}\n```\n\n原理：\n\n==semaphore.acquire();== // 获得，假设已经满了，等待，等待被释放为止！\n\n==semaphore.release();== // 释放，会将当前的信号量释放+1，然后唤醒等待的线程！\n\n作用：多个共享资源互斥的使用！并发限流，控制并发的线程数\n\n## 读写锁\n\nReadWriteLock\n\n![image-20210405142730413](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405142737.png)\n\n```java\npackage com.ouwen.rw;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReadWriteLock;\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\n\n/**\n * 独占锁（写锁） 一次只能被一个线程占有\n * 共享锁（读锁）  多个线程可以同时占有\n * ReadWriteLock\n * 读-读 可以共存！\n * 读-写 不能共存！\n * 写-写 不能共存！\n * @author IRVING\n * @create 2021-04-05 14:28\n */\npublic class ReadWriteLockDemo {\n    public static void main(String[] args) {\n        MyCacheLock myCache = new MyCacheLock();\n\n        //写入\n        for (int i = 0; i < 5; i++) {\n            final int temp = i;\n            new Thread(() -> {\n                myCache.put(temp + \"\", temp);\n            }, String.valueOf(i)).start();\n        }\n\n        //读取\n        for (int i = 0; i < 5; i++) {\n            final int temp = i;\n            new Thread(() -> {\n                myCache.get(temp + \"\");\n            }, String.valueOf(i)).start();\n        }\n    }\n}\n\n/**\n * 自定义缓存\n */\nclass MyCache {\n    private volatile Map<String, Object> map = new HashMap<>();\n\n    // 存，写\n    public void put(String key, Object value) {\n        System.out.println(Thread.currentThread().getName() + \"写入\" + key);\n        map.put(key, value);\n        System.out.println(Thread.currentThread().getName() + \"写入完毕\");\n    }\n\n    // 取，读\n    public void get(String key) {\n        System.out.println(Thread.currentThread().getName() + \"读取\" + key);\n        Object o = map.get(key);\n        System.out.println(Thread.currentThread().getName() + \"读取完毕\");\n    }\n}\n\nclass MyCacheLock {\n    private volatile Map<String, Object> map = new HashMap<>();\n    // 读写锁，更加细粒度的控制\n    private ReadWriteLock readWriteLock = new ReentrantReadWriteLock();\n\n    // 存，写入的时候，只希望同时只有一个线程写\n    public void put(String key, Object value) {\n        readWriteLock.writeLock().lock();\n\n        try {\n            System.out.println(Thread.currentThread().getName() + \"写入\" + key);\n            map.put(key, value);\n            System.out.println(Thread.currentThread().getName() + \"写入完毕\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            readWriteLock.writeLock().unlock();\n        }\n\n    }\n\n    // 取，读\n    public void get(String key) {\n        readWriteLock.readLock().lock();\n        try {\n            System.out.println(Thread.currentThread().getName() + \"读取\" + key);\n            Object o = map.get(key);\n            System.out.println(Thread.currentThread().getName() + \"读取完毕\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            readWriteLock.readLock().unlock();\n        }\n\n    }\n}\n```\n\n## 阻塞队列\n\n![image-20210405160056615](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405160056.png)\n\n### 阻塞队列\n\n![image-20210405160225524](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405160225.png)\n\n![image-20210405160713694](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405160713.png)\n\n### **BlockingQueue**\n\n不是新的东西，属于 Collection 集合框架下\n\n![image-20210405160927280](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405160927.png)\n\n什么情况下我们会使用阻塞队列：多线程并发处理，线程池！\n\n### **学会使用队列**\n\n添加、移除\n\n**四组 API**\n\n| 方式         | 有返回值，抛出异常 | 有返回值，不抛出异常 | 阻塞等待 | 超时等待  |\n| ------------ | ------------------ | -------------------- | -------- | --------- |\n| 添加         | add                | offer()              | put()    | offer(,,) |\n| 移除         | remove             | foll()               | take()   | foll(,)   |\n| 检测队首元素 | element            | peek                 | -        | -         |\n\n```java\n/**\n * 抛出异常\n */\npublic static void test1() {\n    //队列的大小\n    ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue(3);\n    System.out.println(blockingQueue.add(\"a\"));\n    System.out.println(blockingQueue.add(\"b\"));\n    System.out.println(blockingQueue.add(\"c\"));\n    //java.lang.IllegalStateException: Queue full 抛出异常！队列已满\n    //System.out.println(blockingQueue.add(\"d\"));\n\n    System.out.println(\"==========\");\n\n    System.out.println(blockingQueue.remove());\n    System.out.println(blockingQueue.remove());\n    System.out.println(blockingQueue.remove());\n    //java.util.NoSuchElementException 抛出异常！没有元素\n    System.out.println(blockingQueue.remove());\n}\n```\n\n```java\n/**\n * 有返回值，不抛出异常\n */\npublic static void test2(){\n    ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue(3);\n\n    System.out.println(blockingQueue.offer(\"a\"));\n    System.out.println(blockingQueue.offer(\"b\"));\n    System.out.println(blockingQueue.offer(\"c\"));\n    //System.out.println(blockingQueue.offer(\"d\"));  //返回false\n\n    System.out.println(\"========\");\n\n    System.out.println(blockingQueue.poll());\n    System.out.println(blockingQueue.poll());\n    System.out.println(blockingQueue.poll());\n    System.out.println(blockingQueue.poll());  //返回null\n}\n```\n\n```java\n/**\n * 阻塞等待\n */\npublic static void test3() throws InterruptedException {\n    ArrayBlockingQueue<Object> blockingQueue = new ArrayBlockingQueue<>(3);\n\n    blockingQueue.put(\"a\");\n    blockingQueue.put(\"b\");\n    blockingQueue.put(\"c\");\n    //blockingQueue.put(\"d\"); //程序一直阻塞\n\n    System.out.println(\"========\");\n\n    System.out.println(blockingQueue.take());\n    System.out.println(blockingQueue.take());\n    System.out.println(blockingQueue.take());\n    System.out.println(blockingQueue.take()); //程序一直阻塞\n}\n```\n\n```java\n/**\n * 超时等待\n */\npublic static void test4() throws InterruptedException {\n    ArrayBlockingQueue<Object> blockingQueue = new ArrayBlockingQueue<>(3);\n\n    System.out.println(blockingQueue.offer(\"a\"));\n    System.out.println(blockingQueue.offer(\"b\"));\n    System.out.println(blockingQueue.offer(\"c\"));\n    //System.out.println(blockingQueue.offer(\"d\",2, TimeUnit.SECONDS));  //超时等待2秒\n\n    System.out.println(\"=========\");\n\n    System.out.println(blockingQueue.poll());\n    System.out.println(blockingQueue.poll());\n    System.out.println(blockingQueue.poll());\n    System.out.println(blockingQueue.poll(2,TimeUnit.SECONDS)); //超时等待2秒\n}\n```\n\n### SynchronousQueue\n\n**同步队列**\n\n进去一个元素，必须等待取出来之后，才能再往里面放一个元素！\n\nput、take\n\n```java\npackage com.ouwen.bq;\n\nimport java.util.concurrent.BlockingQueue;\nimport java.util.concurrent.SynchronousQueue;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 同步队列\n * 和其他的BlockingQueue不一样，SynchronousQueue 不存储元素\n * put了一个元素，必须从里面先take出来，否则无法继续往里面put值\n * @author IRVING\n * @create 2021-04-05 17:03\n */\npublic class SynchronousQueueTest {\n\n    public static void main(String[] args) {\n        BlockingQueue<String> blockingQueue = new SynchronousQueue<>();//同步队列\n\n        new Thread(()->{\n            try {\n                System.out.println(Thread.currentThread().getName()+\"put 1\");\n                blockingQueue.put(\"1\");\n                System.out.println(Thread.currentThread().getName()+\"put 2\");\n                blockingQueue.put(\"2\");\n                System.out.println(Thread.currentThread().getName()+\"put 3\");\n                blockingQueue.put(\"3\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        },\"t1\").start();\n\n\n        new Thread(()->{\n            try {\n                TimeUnit.SECONDS.sleep(2);\n                System.out.println(Thread.currentThread().getName()+blockingQueue.take());\n                TimeUnit.SECONDS.sleep(2);\n                System.out.println(Thread.currentThread().getName()+blockingQueue.take());\n                TimeUnit.SECONDS.sleep(2);\n                System.out.println(Thread.currentThread().getName()+blockingQueue.take());\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        },\"t2\").start();\n    }\n}\n```\n\n## 线程池（重点）\n\n线程池：三大方法、七大参数、四种拒绝策略\n\n### 池化技术\n\n程序的运行，本质：占用系统的资源！优化资源的使用！=>池化技术\n\n线程池、连接池、内存池、对象池....创建、销毁。十分浪费资源\n\n池化技术：事先准备好一些资源，有人要用，就到我这里来拿，用完之后还给我。\n\n### 线程池的好处\n\n1. 降低资源的消耗\n2. 提高响应的速度\n3. 方便管理\n\n==**线程复用，可以控制最大并发数、管理线程**==\n\n### 线程池：三大方法\n\n![image-20210405171659980](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405171700.png)\n\n```java\npackage com.ouwen.pool;\n\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\n/**\n * Executors 工具类 3大方法\n * @author IRVING\n * @create 2021-04-05 17:19\n */\npublic class Demo01 {\n    public static void main(String[] args) {\n        //ExecutorService threadPool =  Executors.newSingleThreadExecutor(); //单个线程\n        //ExecutorService threadPool =  Executors.newFixedThreadPool(5); //创建一个固定大小的线程池\n        ExecutorService threadPool =  Executors.newCachedThreadPool(); //可伸缩的，缓存线程池\n\n\n        try {\n            for (int i = 0; i < 10; i++) {\n                threadPool.execute(()->{\n                    System.out.println(Thread.currentThread().getName());\n                });\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            threadPool.shutdown();  //关闭线程池\n        }\n    }\n}\n```\n\n### 七大参数\n\n**源码分析：**\n\n```java\npublic static ExecutorService newSingleThreadExecutor() {\n    return new FinalizableDelegatedExecutorService\n        (new ThreadPoolExecutor(1, 1,\n                                0L, TimeUnit.MILLISECONDS,\n                                new LinkedBlockingQueue<Runnable>()));\n}\n\npublic static ExecutorService newFixedThreadPool(int nThreads) {\n    return new ThreadPoolExecutor(nThreads, nThreads,\n                                  0L, TimeUnit.MILLISECONDS,\n                                  new LinkedBlockingQueue<Runnable>());\n}\n\npublic static ExecutorService newCachedThreadPool() {\n    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                  60L, TimeUnit.SECONDS,\n                                  new SynchronousQueue<Runnable>());\n}\n\n//本质都是ThreadPoolExecutor()\npublic ThreadPoolExecutor(int corePoolSize,  //核心线程池大小\n                          int maximumPoolSize, //最大核心线程池大小\n                          long keepAliveTime,  //超时了没有人调用就会释放\n                          TimeUnit unit,  //超时单位\n                          BlockingQueue<Runnable> workQueue,  //阻塞队列\n                          ThreadFactory threadFactory,  //线程工厂，创建线程的，一般不用动\n                          RejectedExecutionHandler handler  //拒绝策略) {\n    if (corePoolSize < 0 ||\n        maximumPoolSize <= 0 ||\n        maximumPoolSize < corePoolSize ||\n        keepAliveTime < 0)\n        throw new IllegalArgumentException();\n    if (workQueue == null || threadFactory == null || handler == null)\n        throw new NullPointerException();\n    this.corePoolSize = corePoolSize;\n    this.maximumPoolSize = maximumPoolSize;\n    this.workQueue = workQueue;\n    this.keepAliveTime = unit.toNanos(keepAliveTime);\n    this.threadFactory = threadFactory;\n    this.handler = handler;\n}\n```\n\n![image-20210405181241166](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405181241.png)\n\n![image-20210405181515918](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405190839.png)\n\n### 手动创建线程池\n\n```java\npackage com.ouwen.pool;\n\nimport java.util.concurrent.*;\n\n/**\n * Executors 工具类 3大方法\n * @author IRVING\n * @create 2021-04-05 17:19\n */\npublic class Demo01 {\n    public static void main(String[] args) {\n        //自定义线程池！工作中 ThreadPoolExecutor\n        ExecutorService threadPool = new ThreadPoolExecutor(2,\n                5,\n                3,\n                TimeUnit.SECONDS,\n                new LinkedBlockingDeque<>(3),\n                Executors.defaultThreadFactory(),\n                /**\n                 * 四种拒绝策略\n                 * 1.new ThreadPoolExecutor.AbortPolicy());  // 银行满了，还有人进来，不处理这个人的，抛出异常\n                 * 2.new ThreadPoolExecutor.CallerRunsPolicy());  // 哪来的去哪里\n                 * 3.new ThreadPoolExecutor.DiscardPolicy());  // 队列满了，不会抛出异常，丢弃\n                 * 4.new ThreadPoolExecutor.DiscardOldestPolicy());  // 队列满了，丢弃最早的任务，添加新任务\n                 */\n                new ThreadPoolExecutor.DiscardOldestPolicy());  // 队列满了，丢弃最早的任务，添加新任务\n\n        try {\n            // 最大承载：Deque + max\n            // 抛出 java.util.concurrent.RejectedExecutionException\n            for (int i = 0; i < 9; i++) {\n                threadPool.execute(()->{\n                    System.out.println(Thread.currentThread().getName());\n                });\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            threadPool.shutdown();  //关闭线程池\n        }\n    }\n}\n```\n\n### 四种拒绝策略\n\n![image-20210405185214360](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405185214.png)\n\n```java\n/**\n * 四种拒绝策略\n * 1.new ThreadPoolExecutor.AbortPolicy());  // 银行满了，还有人进来，不处理这个人的，抛出异常\n * 2.new ThreadPoolExecutor.CallerRunsPolicy());  // 哪来的去哪里\n * 3.new ThreadPoolExecutor.DiscardPolicy());  // 队列满了，不会抛出异常，丢弃\n * 4.new ThreadPoolExecutor.DiscardOldestPolicy());  // 队列满了，丢弃最早的任务，添加新任务\n */\n```\n\n### 小结和扩展\n\n最大线程池大小如何去设置！\n\n了解：IO 密集型，CPU 密集型：（调优）！\n\n```java\npackage com.ouwen.pool;\n\nimport java.util.concurrent.*;\n\n/**\n * @author IRVING\n * @create 2021-04-05 17:19\n */\npublic class Demo01 {\n    public static void main(String[] args) {\n        //自定义线程池！工作中 ThreadPoolExecutor\n\n        /**\n         * 最大线程到底该如何定义？\n         * 1. CPU密集型，几核，就是几，可以保持CPU效率最高\n         * 2. IO密集型，判断你程序中十分耗IO的线程\n         * 程序  15个大型任务  io十分占用资源！ -> 30个\n         */\n\n        //获取CPU的核心数\n        System.out.println(Runtime.getRuntime().availableProcessors());\n\n        ExecutorService threadPool = new ThreadPoolExecutor(2,\n                Runtime.getRuntime().availableProcessors(),\n                3,\n                TimeUnit.SECONDS,\n                new LinkedBlockingDeque<>(3),\n                Executors.defaultThreadFactory(),\n                new ThreadPoolExecutor.DiscardOldestPolicy());\n        try {\n            // 最大承载：Deque + max\n            // 抛出 java.util.concurrent.RejectedExecutionException\n            for (int i = 0; i < 9; i++) {\n                threadPool.execute(()->{\n                    System.out.println(Thread.currentThread().getName());\n                });\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            threadPool.shutdown();  //关闭线程池\n        }\n    }\n}\n```\n\n## 四大函数式接口（重点、必需掌握）\n\n新时代的程序员：lambda 表达式、链式编程、函数式接口、Stream 流式计算\n\n### 函数式接口：只有一个方法的接口\n\n```java\n@FunctionalInterface\npublic interface Runnable {\n    public abstract void run();\n}\n\n//超级多的FunctionInterface\n//简化编程模型，在新版本的框架底层大量应用！\n//forEach(消费者类型的函数式接口)\n```\n\n![image-20210405193839177](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405193839.png)\n\n**代码测试：**\n\n### Function 接口\n\n函数型接口\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405195016.png\" alt=\"image-20210405195016832\" style=\"zoom:50%;\" />\n\n```java\npackage com.ouwen.function;\n\nimport java.util.function.Function;\n\n/**\n * Function 函数型接口，有一个输入参数，有一个输出参数\n * 只要是函数型接口，都可以用lambda表达式简化\n *\n * @author IRVING\n * @create 2021-04-05 19:45\n */\npublic class Demo01 {\n\n    public static void main(String[] args) {\n        //Function<String, String> function = new Function<String, String>() {\n        //    @Override\n        //    public String apply(String s) {\n        //        return s;\n        //    }\n        //};\n\n       \t//使用lambda表达式简化\n        Function<String, String> function = (str) -> {return str;};\n\n        System.out.println(function.apply(\"asd\"));\n    }\n}\n```\n\n### Predicate 接口\n\n断定型接口\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405195655.png\" alt=\"image-20210405195655121\" style=\"zoom:50%;\" />\n\n```java\npackage com.ouwen.function;\n\nimport java.util.function.Predicate;\n\n/**\n * 断定型接口：有一个输入参数，返回值只能是布尔值！\n * @author IRVING\n * @create 2021-04-05 19:51\n */\npublic class Demo02 {\n    public static void main(String[] args) {\n        //判断字符是否为空\n        //Predicate<String> predicate = new Predicate<String>() {\n        //    @Override\n        //    public boolean test(String s) {\n        //        return s.isEmpty();\n        //    }\n        //};\n\n        Predicate<String> predicate = str -> str.isEmpty();\n\n        System.out.println(predicate.test(\"\"));\n    }\n}\n```\n\n### Consumer 接口\n\n消费型接口\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405200414.png\" alt=\"image-20210405200414021\" style=\"zoom:50%;\" />\n\n```java\npackage com.ouwen.function;\n\nimport com.sun.org.apache.bcel.internal.generic.NEW;\n\nimport java.util.function.Consumer;\n\n/**\n * 消费性接口：一个输入参数，没有返回值\n * @author IRVING\n * @create 2021-04-05 20:00\n */\npublic class Demo03 {\n\n    public static void main(String[] args) {\n        //Consumer<String> consumer = new Consumer<String>() {\n        //    @Override\n        //    public void accept(String s) {\n        //        System.out.println(s);\n        //    }\n        //};\n\n        Consumer<String> consumer = str -> System.out.println(str);\n\n        consumer.accept(\"asd\");\n    }\n}\n```\n\n### Supplier 接口\n\n供给型接口\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405200437.png\" alt=\"image-20210405200437068\" style=\"zoom:50%;\" />\n\n```java\npackage com.ouwen.function;\n\nimport java.util.function.Supplier;\n\n/**\n * Supplier供给型接口 没有参数，只有返回值\n * @author IRVING\n * @create 2021-04-05 20:03\n */\npublic class Demo04 {\n    public static void main(String[] args) {\n        //Supplier<Integer> supplier = new Supplier<Integer>() {\n        //    @Override\n        //    public Integer get() {\n        //        return 1024;\n        //    }\n        //};\n\n        Supplier<Integer> supplier = () -> 1024;\n\n        System.out.println(supplier.get());\n    }\n}\n```\n\n## Stream 流式计算\n\n### 什么是流式计算？\n\n大数据时代：存储+计算\n\n集合是用来存储东西的\n\n计算都应该交给流来操作！\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210405225822.png\" alt=\"image-20210405225822466\" style=\"zoom:67%;\" />\n\n```java\npackage com.ouwen.stream;\n\nimport java.util.Arrays;\nimport java.util.Comparator;\nimport java.util.List;\nimport java.util.function.Function;\n\n/**\n * 现有5个用户，筛选：\n * 1. ID偶数的\n * 2. 年纪大于23岁\n * 3. 用户名转为大写字母\n * 4. 用户名字母倒排序\n * 5. 只输出一个用户\n * <p>\n * * @author IRVING\n * * @create 2021-04-05 22:49\n */\npublic class Test {\n\n    public static void main(String[] args) {\n        User u1 = new User(1, \"a\", 21);\n        User u2 = new User(2, \"b\", 22);\n        User u3 = new User(3, \"c\", 23);\n        User u4 = new User(4, \"d\", 24);\n        User u5 = new User(6, \"e\", 26);\n\n        List<User> users = Arrays.asList(u1, u2, u3, u4, u5);\n\n        users.stream()\n                .filter(u -> u.getId() % 2 == 0)\n                .filter(u -> u.getAge() > 23)\n                .peek(user -> user.setName(user.getName().toUpperCase()))\n                .sorted(Comparator.comparing(User::getName, Comparator.reverseOrder()))\n                .limit(1)\n                .forEach(System.out::println);\n    }\n}\n\n```\n\n## ForkJoin\n\n分支合并\n\n### 什么是 ForkJoin？\n\nForkJoin 在 JDK1.7，并行执行任务！提高效率，大数据量！\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406124700.png\" alt=\"image-20210406124653585\" style=\"zoom: 50%;\" />\n\n> ForkJoin 特点：工作窃取\n\n这个里面维护的都是双端队列\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406125200.png\" alt=\"image-20210406125200490\" style=\"zoom:50%;\" />\n\n### 如何使用 ForkJoin?\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406130207.png\" alt=\"image-20210406130207157\" style=\"zoom:50%;\" />\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406132051.png\" alt=\"image-20210406132051647\" style=\"zoom:50%;\" />\n\n## 异步回调\n\nFuture 设计的初衷：对将来的某个事件的结果进行建模\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406221746.png\" alt=\"image-20210406221739820\" style=\"zoom:67%;\" />\n\n```java\npackage com.ouwen.future;\n\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 异步调用：CompletableFuture\n * 异步执行\n * 成功回调\n * 失败回调\n *\n * @author IRVING\n * @create 2021-04-06 22:18\n */\npublic class Demo01 {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        //发起一个请求\n        //CompletableFuture<Void> completableFuture = CompletableFuture.runAsync(() -> {\n        //    try {\n        //        TimeUnit.SECONDS.sleep(5);\n        //    } catch (InterruptedException e) {\n        //        e.printStackTrace();\n        //    }\n        //    System.out.println(Thread.currentThread().getName() + \"runAsync=>Void\");\n        //});\n        //\n        //System.out.println(\"1111\");\n        //\n        //completableFuture.get(); //获取阻塞执行结果\n\n        //有返回值的\n        CompletableFuture<Integer> completableFuture = CompletableFuture.supplyAsync(() -> {\n            System.out.println(Thread.currentThread().getName() + \"runAsync=>Integer\");\n            int i = 10/0;\n            return 1024;\n        });\n\n        completableFuture.whenComplete((t,u)->{\n            System.out.println(t); //正常的返回结果\n            System.out.println(u); //错误信息 java.util.concurrent.CompletionException: java.lang.ArithmeticException: / by zero\n        }).exceptionally((e)->{\n            System.out.println(e.getMessage()); //可以获取到错误的返回结果\n            return 233;\n        });\n    }\n}\n```\n\n## JMM\n\n### 请你谈谈你对 Volatile 的理解\n\nVolatile 是 Java 虚拟机提供的**轻量级的同步机制**\n\n1. 保证可见性\n2. 不保证原子性\n3. 禁止指令重排\n\n### 什么是 JMM\n\nJMM：java 内存模型，不存在的东西，概念！约定！\n\n**关于 JMM 一些同步的约定：**\n\n1. 线程解锁前，必须把共享变量立刻刷回主内存\n2. 线程加锁前，必须读取主内存中的最新值到工作内存中！\n3. 加锁和解锁必须是同一把锁！\n\n线程 **工作内存、主内存**\n\n### 8 种操作\n\n![image-20210406224257522](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406224257.png)\n\n![image-20210406224329039](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406224329.png)\n\n**内存交互操作有 8 种，虚拟机实现必须保证每一个操作都是原子的，不可在分的（对于 double 和 long 类型的变量来说，load、store、read 和 write 操作在某些平台上允许例外）**\n\n- lock （锁定）：作用于主内存的变量，把一个变量标识为线程独占状态\n- unlock （解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定\n- read （读取）：作用于主内存变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用\n- load （载入）：作用于工作内存的变量，它把 read 操作从主存中变量放入工作内存中\n- use （使用）：作用于工作内存中的变量，它把工作内存中的变量传输给执行引擎，每当虚拟机遇到一个需要使用到变量的值，就会使用到这个指令\n- assign （赋值）：作用于工作内存中的变量，它把一个从执行引擎中接受到的值放入工作内存的变量副本中\n- store （存储）：作用于主内存中的变量，它把一个从工作内存中一个变量的值传送到主内存中，以便后续的 write 使用\n- write 　（写入）：作用于主内存中的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中\n\n**JMM 对这八种指令的使用，制定了如下规则：**\n\n- 不允许 read 和 load、store 和 write 操作之一单独出现。即使用了 read 必须 load，使用了 store 必须 write\n\n- 不允许线程丢弃他最近的 assign 操作，即工作变量的数据改变了之后，必须告知主存\n- 不允许一个线程将没有 assign 的数据从工作内存同步回主内存\n- 一个新的变量必须在主内存中诞生，不允许工作内存直接使用一个未被初始化的变量。就是怼变量实施 use、store 操作之前，必须经过 assign 和 load 操作\n- 一个变量同一时间只有一个线程能对其进行 lock。多次 lock 后，必须执行相同次数的 unlock 才能解锁\n- 如果对一个变量进行 lock 操作，会清空所有工作内存中此变量的值，在执行引擎使用这个变量前，必须重新 load 或 assign 操作初始化变量的值\n- 如果一个变量没有被 lock，就不能对其进行 unlock 操作。也不能 unlock 一个被其他线程锁住的变量\n- 对一个变量进行 unlock 操作之前，必须把此变量同步回主内存\n\n问题：程序不知道主内存的值被修改过了！！\n\n![image-20210406224933254](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406224933.png)\n\n```java\npackage com.ouwen.volatile1;\n\nimport java.util.concurrent.TimeUnit;\n\n/**\n * @author IRVING\n * @create 2021-04-06 22:50\n */\npublic class JMMDemo {\n\n    private static int num = 0;\n    public static void main(String[] args) throws InterruptedException {\n        new Thread(()->{\n            while (num ==  0){ //线程1对主内存的变化不知道\n\n            }\n        }).start();\n\n        TimeUnit.SECONDS.sleep(1);\n\n        num = 1;\n        System.out.println(num);\n    }\n}\n```\n\n## Volatile\n\n### 保证可见性\n\n```java\npackage com.ouwen.volatile1;\n\nimport java.util.concurrent.TimeUnit;\n\n/**\n * @author IRVING\n * @create 2021-04-06 22:50\n */\npublic class JMMDemo {\n    /*\n      不加 volatile 程序就会死循环\n      加 volatile 可以保证可见性\n     */\n    private volatile static int num = 0;\n    public static void main(String[] args) throws InterruptedException {\n        new Thread(()->{\n            while (num ==  0){ //线程1对主内存的变化不知道\n\n            }\n        }).start();\n\n        TimeUnit.SECONDS.sleep(1);\n\n        num = 1;\n        System.out.println(num);\n    }\n}\n```\n\n### 不保证原子性\n\n原子性：不可分割\n\n线程 A 在执行任务的时候，不能被打扰的，也不能被分割，要么同时成功，要么同时失败！\n\n```java\npackage com.ouwen.volatile1;\n\n/**\n * @author IRVING\n * @create 2021-04-06 22:55\n */\npublic class Demo2 {\n\n    //volatile不保证原子性\n    private volatile static int num = 0;\n\n    public static void add() {\n        num++; //不是一个原子性操作\n    }\n\n    public static void main(String[] args) {\n        //理论上num结果为2万\n        for (int i = 0; i < 20; i++) {\n            new Thread(() -> {\n                for (int i1 = 0; i1 < 1000; i1++) {\n                    add();\n                }\n            }).start();\n        }\n\n        while (Thread.activeCount() > 2) { //main gc\n            Thread.yield();\n        }\n\n        System.out.println(Thread.currentThread().getName() + \"==>\" + num);\n    }\n}\n```\n\n**如果不加 lock 和 synchronized，怎样保持原子性**\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406230445.png\" alt=\"image-20210406230445570\" style=\"zoom:67%;\" />\n\n使用原子类，解决原子性问题\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406230556.png\" alt=\"image-20210406230556520\" style=\"zoom:50%;\" />\n\n```java\npackage com.ouwen.volatile1;\n\nimport java.util.concurrent.atomic.AtomicInteger;\n\n/**\n * @author IRVING\n * @create 2021-04-06 22:55\n */\npublic class Demo2 {\n\n    //volatile不保证原子性\n    //使用原子类的Integer\n    private volatile static AtomicInteger num = new AtomicInteger();\n\n    public static void add() {\n        //num++; //不是一个原子性操作\n        num.getAndIncrement();  // AtomicInteger +1 方法 CAS\n    }\n\n    public static void main(String[] args) {\n        //理论上num结果为2万\n        for (int i = 0; i < 20; i++) {\n            new Thread(() -> {\n                for (int i1 = 0; i1 < 1000; i1++) {\n                    add();\n                }\n            }).start();\n        }\n\n        while (Thread.activeCount() > 2) { //main gc\n            Thread.yield();\n        }\n\n        System.out.println(Thread.currentThread().getName() + \"==>\" + num);\n    }\n}\n```\n\n这些类的底层都直接和操作系统挂钩！！直接在内存中修改只！Usafe 类是一个很特殊的存在！\n\n### 指令重排\n\n什么是指令重排：**你写的程序，计算机并不是按照你写的那样去执行的**\n\n源代码 --> 编译器优化的重排 --> 指令并行也可能会重排 --> 内存也可能会重排 -->执行\n\n==**处理器在进行指令重排的时候，考虑：数据之间的依赖性！**==\n\n可能造成影响的结果：a b x y 四个数都是 0\n\n| 线程 A | 线程 B |\n| ------ | ------ |\n| x=a    | y=b    |\n| b=1    | a=2    |\n\n正常的结果：x=0 y=0 但是可能由于指令重排\n\n| 线程 A | 线程 B |\n| ------ | ------ |\n| b=1    | a=2    |\n| x=a    | y=b    |\n\n指令重排导致的诡异结果：x=2 y=1\n\n**volatile 可以避免指令重排：**\n\n内存屏障。CPU 指令。\n\n作用：\n\n1、保证特定的操作的执行顺序！\n\n2、可以保证某些变量的内存可见性 （利用这些特性 volatile 实现了可见性）\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406232313.png\" alt=\"image-20210406232313816\" style=\"zoom:67%;\" />\n\n**Volatile 是可以保持可见性，不能保证原子性，因为内存屏障，可以保证避免指令重排的现象产生！**\n\n## 深入理解 CAS\n\n### 什么是 CAS？\n\n```java\npackage com.ouwen.cas;\n\nimport java.util.concurrent.atomic.AtomicInteger;\n\n/**\n * @author IRVING\n * @create 2021-04-06 23:52\n */\npublic class CASDemo {\n\n    //CAS  compareAndSet：比较并交换 compareAndSwap\n    public static void main(String[] args) {\n        AtomicInteger atomicInteger = new AtomicInteger(2020);\n\n        // 期望、更新\n        // public final boolean compareAndSet(int expect, int update)\n        // 如果我期望的值达到了，那么就会更新，否则就不更新 CAS 是CPU的并发原语\n        System.out.println(atomicInteger.compareAndSet(2020, 2021));\n        System.out.println(atomicInteger.get());\n\n        System.out.println(atomicInteger.compareAndSet(2020, 2021));\n        System.out.println(atomicInteger.get());\n    }\n}\n```\n\n### Unsafe 类\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406235854.png\" alt=\"image-20210406235854081\" style=\"zoom:67%;\" />\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210406235912.png\" alt=\"image-20210406235912021\" style=\"zoom:67%;\" />\n\nCAS ： 比较当前工作内存中的值和主内存中的值，如果这个值是期望的，那么则执行操作！如果不是就 一直循环！\n\n缺点：\n\n1、 循环会耗时\n\n2、一次性只能保证一个共享变量的原子性\n\n3、ABA 问题\n\n### ABA 问题（狸猫换太子）\n\n![image-20210407000535708](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210407000535.png)\n\n```java\npackage com.ouwen.cas;\n\nimport java.util.concurrent.atomic.AtomicInteger;\n\n/**\n * @author IRVING\n * @create 2021-04-06 23:52\n */\npublic class CASDemo {\n\n    //CAS  compareAndSet：比较并交换 compareAndSwap\n    public static void main(String[] args) {\n        AtomicInteger atomicInteger = new AtomicInteger(2020);\n\n        // 对于我们写的SQL ：乐观锁！\n        // 期望、更新\n        // public final boolean compareAndSet(int expect, int update)\n        // 如果我期望的值达到了，那么就会更新，否则就不更新 CAS 是CPU的并发原语\n        // ==============捣乱的线程==============\n        System.out.println(atomicInteger.compareAndSet(2020, 2021));\n        System.out.println(atomicInteger.get());\n\n        System.out.println(atomicInteger.compareAndSet(2021, 2020));\n        System.out.println(atomicInteger.get());\n\n        // ==============期望的线程==============\n        System.out.println(atomicInteger.compareAndSet(2020, 6666));\n        System.out.println(atomicInteger.get());\n    }\n}\n```\n\n## 原子引用\n\n解决 ABA 问题，引入原子引用！对应的思想就是我们的乐观锁\n\n带版本号的原子操作！\n\n```java\npackage com.ouwen.cas;\n\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.concurrent.atomic.AtomicStampedReference;\nimport java.util.zip.DeflaterOutputStream;\n\n/**\n * @author IRVING\n * @create 2021-04-07 0:10\n */\npublic class CASDemo02 {\n\n    public static void main(String[] args) {\n        // AtomicStampedReference 注意：如果泛型是一个包装类，注意对象的引用问题\n\n        // 正常在业务操作，这里面比较的都是一个个对象\n        AtomicStampedReference<Integer> integer = new AtomicStampedReference<>(1, 1);\n\n        //乐观锁的原理\n        new Thread(() -> {\n            int stamp = integer.getStamp();  //获得版本号\n            System.out.println(\"a1=>\"+stamp);\n\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n\n            System.out.println(integer.compareAndSet(1, 2, integer.getStamp(), integer.getStamp() + 1));\n            System.out.println(\"a2=>\"+integer.getStamp());\n\n            System.out.println(integer.compareAndSet(2, 1, integer.getStamp(), integer.getStamp() + 1));\n            System.out.println(\"a3=>\"+integer.getStamp());\n\n        }, \"a\").start();\n\n        new Thread(() -> {\n            int stamp = integer.getStamp();  //获得版本号\n            System.out.println(\"b1=>\"+stamp);\n            try {\n                TimeUnit.SECONDS.sleep(2);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n\n            System.out.println(integer.compareAndSet(1, 6, stamp, stamp + 1));\n            System.out.println(\"b2=>\"+integer.getStamp());\n        }, \"b\").start();\n    }\n}\n```\n\n**注意：**\n\n**Integer 使用了对象缓存机制，默认范围是 -128 ~ 127 ，推荐使用静态工厂方法 valueOf 获取对象实 例，而不是 new，因为 valueOf 使用缓存，而 new 一定会创建新的对象分配新的内存空间；**\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210407002800.png\" alt=\"image-20210407002800024\" style=\"zoom: 67%;\" />\n\n## 各种锁的理解\n\n### 公平锁、非公平锁\n\n公平锁：非常公平，不能够插队，必须先来后到！\n\n非公平锁：非常不公平，可以插队（默认都是非公平）\n\n```java\npublic ReentrantLock() {\n\tsync = new NonfairSync();\n}\n\npublic ReentrantLock(boolean fair) {\n\tsync = fair ? new FairSync() : new NonfairSync();\n}\n```\n\n### 可重入锁（递归锁）\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210407003348.png\" alt=\"image-20210407003347941\" style=\"zoom:67%;\" />\n\n> synchronized 版\n\n```java\npackage com.ouwen.lock;\n\n/**\n * @author IRVING\n * @create 2021-04-07 0:39\n */\npublic class Demo01 {\n\n    public static void main(String[] args) {\n        Phone phone = new Phone();\n        new Thread(()->{\n            phone.sms();\n        },\"A\").start();\n\n        new Thread(()->{\n            phone.sms();\n        },\"B\").start();\n    }\n}\n\nclass Phone {\n\n    public synchronized void sms() {\n        System.out.println(Thread.currentThread().getName() + \"sms\");\n        call(); //这里也有锁\n    }\n\n    public synchronized void call() {\n        System.out.println(Thread.currentThread().getName() + \"call\");\n    }\n}\n```\n\n> Lock 版\n\n```java\npackage com.ouwen.lock;\n\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\n/**\n * @author IRVING\n * @create 2021-04-07 0:39\n */\npublic class Demo02 {\n\n    public static void main(String[] args) {\n        Phone2 phone = new Phone2();\n        new Thread(() -> {\n            phone.sms();\n        }, \"A\").start();\n\n        new Thread(() -> {\n            phone.sms();\n        }, \"B\").start();\n    }\n}\n\nclass Phone2 {\n\n    Lock lock = new ReentrantLock();\n\n    public void sms() {\n        lock.lock(); //细节问题：lock.lock()，lock.unlock(); //lock锁必须配对，否则就会死在里面\n        lock.lock();\n        try {\n            System.out.println(Thread.currentThread().getName() + \"sms\");\n            call(); //这里也有锁\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n            lock.unlock();\n        }\n    }\n\n    public synchronized void call() {\n        lock.lock();\n        try {\n            System.out.println(Thread.currentThread().getName() + \"call\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n\n### 自选锁\n\nspinlock\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210407004626.png\" alt=\"image-20210407004626556\" style=\"zoom:67%;\" />\n\n**自定义锁：**\n\n```java\npackage com.ouwen.lock;\n\nimport java.util.concurrent.atomic.AtomicReference;\n\n/**\n * 自旋锁\n *\n * @author IRVING\n * @create 2021-04-07 0:52\n */\npublic class SpinlockDemo {\n\n    AtomicReference<Thread> atomicReference = new AtomicReference<>();\n\n    //加锁\n    public void mylock() {\n        Thread thread = Thread.currentThread();\n        System.out.println(thread.getName() + \"==>mylock\");\n\n        //自旋锁\n        while (!atomicReference.compareAndSet(null, thread)) {\n\n        }\n    }\n\n    //解锁\n    public void myunlock() {\n        Thread thread = Thread.currentThread();\n        System.out.println(thread.getName() + \"==>myunlock\");\n        atomicReference.compareAndSet(thread, null);\n    }\n}\n```\n\n**测试代码：**\n\n```java\npackage com.ouwen.lock;\n\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.locks.ReentrantLock;\n\n/**\n * @author IRVING\n * @create 2021-04-07 0:59\n */\npublic class TestSpinLock {\n\n    public static void main(String[] args) throws InterruptedException {\n        //ReentrantLock lock = new ReentrantLock();\n        //lock.lock();\n        //lock.unlock();\n\n        //地层使用CAS实现自旋锁\n        SpinlockDemo lock = new SpinlockDemo();\n\n        new Thread(()->{\n            lock.mylock();\n            try {\n                TimeUnit.SECONDS.sleep(5);\n            } catch (Exception e) {\n                e.printStackTrace();\n            } finally {\n                lock.myunlock();\n            }\n\n        },\"T1\").start();\n\n        TimeUnit.SECONDS.sleep(1);\n\n        new Thread(()->{\n\n            lock.mylock();\n            try {\n                TimeUnit.SECONDS.sleep(5);\n            } catch (Exception e) {\n                e.printStackTrace();\n            } finally {\n                lock.myunlock();\n            }\n\n        },\"T2\").start();\n    }\n}\n```\n\n### 死锁\n\n死锁是什么？\n\n <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210407010904.png\" alt=\"image-20210407010904630\" style=\"zoom:67%;\" />\n\n#### 如何解决死锁问题？\n\n1、使用`jps -l`定位进程号\n\n![image-20210407011207227](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210407011207.png)\n\n2、使用`jstack 进程号` 找到死锁问题\n\n![image-20210407011248176](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210407011248.png)\n\n**查看堆栈信息，找到死锁问题！**\n","tags":["技巧","笔记"],"categories":["后端开发"]},{"title":"JVM 理论探究","slug":"JVM探究","url":"/2021/05/06/eb9166f8.html","content":"\n- 请你谈谈你对 JVM 的理解，Java8 虚拟机和之前的变化更新？\n- 什么是 OOM，什么是栈溢出 StackOverFlowError？怎么分析？\n- JVM 常用调优参数有哪些？\n- 内存快照如何抓取，怎么分析 Dump 文件？\n- 谈谈 JVM 中，类加载器你的认识？\n\n## JVM 的位置\n\n![JVM图解](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501155102.png)\n\n## JVM 的体系结构\n\n![image-20210502005237430](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210502005237.png)\n\n百分之 99 的 JVM 调优都是在堆中调优，Java 栈、本地方法栈、程序计数器是不会有垃圾存在的。\n\n## 类加载器\n\n作用：加载 Class 文件~\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501161637.png)\n\n- 虚拟机自带的加载器\n- 启动类（根）加载器\n- 扩展类加载器\n- 应用程序（系统类）加载器\n\n## 双清委派机制\n\n![img](https://img-blog.csdnimg.cn/20201217213314510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvZGV5YW5iYW8=,size_16,color_FFFFFF,t_70)\n\n## 沙箱安全机制\n\nJava 安全模型的核心就是 Java 沙箱(sandbox)\n\n什么是沙箱?沙箱是一个限制程序运行的环境。沙箱机制就是将 Java 代码限定在虚拟机(JVM)特定的运行范围中，并且严格限制代码对本地系统资源访问，通过这样的措施来保证对代码的有效隔离，防止对本地系统造成破坏。\n\n沙箱主要限制系统资源访问，那系统资源包括什么? CPU、内存、文件系统、网络。不同级别的沙箱对这些资源访问的限制也可以不一样。\n\n所有的 Java 程序运行都可以指定沙箱，可以定制安全策略。\n\n在 Java 中将执行程序分成本地代码和远程代码两种，本地代码默认视为可信任的，而远程代码则被看作是不受信的。对于授信的本地代码,可以访问一切本地资源。而对于非授信的远程代码在早期的 Java 实现中，安全依赖于沙箱 Sandbox)机制。如下图所示 JDK1.0 安全模型\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501163417.png)\n\n但如此严格的安全机制也给程序的功能扩展带来障碍，比如当用户希望远程代码访问本地系统的文件时候，就无法实现。因此在后续的 Java1.1 版本中，针对安全机制做了改进，增加了安全策略，允许用户指定代码对本地资源的访问权限。如下图所示 JDK1.1 安全模型\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501164943.png)\n\n在 Java1.2 版本中，再次改进了安全机制，增加了代码签名。不论本地代码或是远程代码，都会按照用户的安全策略设定，由类加载器加载到虚拟机中权限不同的运行空间，来实现差异化的代码执行权限控制。如下图所示\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501164956.png)\n\n当前最新的安全机制实现，则引入了域(Domain)的概念。虚拟机会把所有代码加载到不同的系统域和应用域,系统域部分专门负责与关键资源进行交互，而各个应用域部分则通过系统域的部分代理来对各种需要的资源进行访问。虚拟机中不同的受保护域(Protected Domain),对应不一样的权限(Permission)。存在于不同域中的类文件就具有了当前域的全部权限，如下图所示最新的安全模型(jdk 1.6)\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501165007.png)\n\n**组成沙箱的基本条件**\n\n- 字节码校验器(bytecode verifier) :确保 Java 类文件遵循 Java 语言规范。这样可以帮助 Java 程序实现内存保护。但并不是所有的类文件都会经过字节码校验，比如核心类。\n- 类裝载器(class loader) :其中类装载器在 3 个方面对 Java 沙箱起作用\n  - 它防止恶意代码去干涉善意的代码;\n  - 它守护了被信任的类库边界;\n  - 它将代码归入保护域,确定了代码可以进行哪些操作；\n\n虚拟机为不同的类加载器载入的类提供不同的命名空间，命名空间由一系列唯一的名称组成， 每一个被装载的类将有一个名字，这个命名空间是由 Java 虚拟机为每一个类装载器维护的，它们互相之间甚至不可见。\n\n类装载器采用的机制是双亲委派模式。\n\n1. 从最内层 JVM 自带类加载器开始加载,外层恶意同名类得不到加载从而无法使用;\n2. 由于严格通过包来区分了访问域,外层恶意的类通过内置代码也无法获得权限访问到内层类，破坏代码就自然无法生效。\n\n- 存取控制器(access controller) :存取控制器可以控制核心 API 对操作系统的存取权限，而这个控制的策略设定,可以由用户指定。\n- 安全管理器(security manager) : 是核心 API 和操作系统之间的主要接口。实现权限控制，比存取控制器优先级高。\n- 安全软件包(security package) : java.security 下的类和扩展包下的类，允许用户为自己的应用增加新的安全特性，包括:\n  - 安全提供者\n  - 消息摘要\n  - 数字签名\n  - 加密\n  - 鉴别\n\n## Native\n\n- native :凡是带了 native 关键字的，说明 java 的作用范围达不到了，回去调用底层 c 语言的库!\n- 会进入本地方法栈\n- 调用本地方法本地接口 JNI (Java Native Interface)\n- JNI 作用:开拓 Java 的使用，融合不同的编程语言为 Java 所用!最初: C、C++\n- Java 诞生的时候 C、C++横行，想要立足，必须要有调用 C、C++的程序\n- 它在内存区域中专门开辟了一块标记区域: Native Method Stack，登记 native 方法\n- 在最终执行的时候，加载本地方法库中的方法通过 JNI\n\n### **Native Method Stack**\n\n它的具体做法是 Native Method Stack 中登记 native 方法，在( Execution Engine )执行引擎执行的时候加载 Native Libraies。[本地库]\n\n### **Native Interface 本地接口**\n\n本地接口的作用是融合不同的编程语言为 Java 所用，它的初衷是融合 C/C++程序, Java 在诞生的时候是 C/C++横行的时候，想要立足，必须有调用 C、C++的程序，于是就在内存中专门开辟了块区域处理标记为 native 的代码，它的具体做法是在 Native Method Stack 中登记 native 方法,在( Execution Engine )执行引擎执行的时候加载 Native Libraies。\n\n目前该方法使用的越来越少了，除非是与硬件有关的应用，比如通过 Java 程序驱动打印机或者 Java 系统管理生产设备，在企业级应用中已经比较少见。因为现在的异构领域间通信很发达，比如可以使用 Socket 通信,也可以使用 Web Service 等等，不多做介绍!\n\n## PC 寄存器\n\n程序计数器: Program Counter Register\n\n每个线程都有一个程序计数器，是线程私有的，就是一个指针, 指向方法区中的方法字节码(用来存储指向像一条指令的地址， 也即将要执行的指令代码)，在执行引擎读取下一条指令, 是一个非常小的内存空间，几乎可以忽略不计\n\n## 方法区\n\n方法区是被所有线程共享,所有字段和方法字节码，以及一些特殊方法，如构造函数,接口代码也在此定义,简单说，所有定义的方法的信息都保存在该区域,此区域属于共享区间;\n\n==静态变量、常量、类信息(构造方法、接口定义)、运行时的常量池存在方法区中，但是实例变量存在堆内存中，和方法区无关==\n\n## 栈\n\n栈:先进后出\n\n桶:后进先出\n\n队列:先进先出( FIFO : First Input First Output )\n\n栈：**栈内存，主管程序的运行，生命周期和线程同步**\n\n**线程结束，栈内存也就是释放，对于栈来说，不存在垃圾回收问题**\n\n一旦线程结束，栈就 Over!\n\n栈内存中:\n\n**8 大基本类型+对象引用+实例的方法**\n\n**栈运行原理:栈帧**\n\n栈满了: StackOverflowError\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501173518.png)\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501173432.png)\n\n## 三种 JVM\n\n- **HotSpot VM**\n\n  ```\n  HotSpot VM的热点代码探测能力可以通过执行计数器找出最具有编译价值的代\n  码，然后通知JIT编译器以方法为单位进行编译。 如果一个方法被频繁调用，或方法中有效\n  循环次数很多，将会分别触发标准编译和OSR（栈上替换）编译动作。 通过编译器与解释器\n  恰当地协同工作，可以在最优化的程序响应时间与最佳执行性能中取得平衡，而且无须等待\n  本地代码输出才能执行程序，即时编译的时间压力也相对减小，这样有助于引入更多的代码\n  优化技术，输出质量更高的本地代码\n  ```\n\n- **JRockit**\n\n  ```\n  1.JRockit VM曾经号称“世界上速度最快的Java虚拟机”\n  2.由于专注于服务器端应用，它可以不太关注程序启动速度，因此JRockit内部不包含解析器实现，全部代码都靠即时\n  编译器编译后执行。 除此之外，JRockit的垃圾收集器和MissionControl服务套件等部分的实\n  现，在众多Java虚拟机中也一直处于领先水平\n  ```\n\n- **J9**\n\n  ```\n  1.IBM J9 VM并不是IBM公司唯一的Java虚拟机，不过是目前其主力发展的Java虚拟机，IBM J9 VM原本是内部开发代号，\n  正式名称是“IBM Technology for Java Virtual Machine”，简称IT4J，只是这个名字太拗口了一点，普及程度不如J9.\n  2.与BEA JRockit专注于服务器端应用不同，IBM J9的市场定位与Sun HotSpot比较接近，它是一款设计上从服务器端\n  到桌面应用再到嵌入式都全面考虑的多用途虚拟机***，J9的开发目的是作为IBM公司各种Java产品的执行平台，它的主\n  要市场是和IBM产品（如IBM WebSphere等）搭配以及在IBM AIX和z/OS这些平台上部署Java\n  应用。\n  ```\n\n## 堆\n\nHeap, 一个 JVM 只有一个堆内存，堆内存的大小是可以调节的。\n\n类加载器读取了类文件后，一般会把什么东西放到堆中?\n\n类, 方法，常量,变量~，保存我们所有引用类型的真实对象;\n\n堆内存中还要细分为三个区域:\n\n- 新生区(伊甸园区) Young/New\n- 老年区 old\n- 永久区 Perm\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501174842.png)\n\nGC 垃圾回收,主要是在伊甸园区和养老区~\n\n假设内存满了,OOM,堆内存不够! java.lang.OutOfMemoryError:Java heap space\n\n永久存储区里存放的都是 Java 自带的 例如 lang 包中的类 如果不存在这些，Java 就跑不起来了\n\n在 JDK8 以后，永久存储区改了个名字(元空间)\n\n[参考链接](https://www.cnblogs.com/duanxz/p/3726574.html)\n\n## 新生区、老年区\n\n- 对象：诞生和成长的地方，甚至死亡;\n- 伊甸园，所有的对象都是在伊甸园区 new 出来的!\n- 幸存者区(0,1)\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501175400.png)\n\n**伊甸园满了就触发轻 GC，经过轻 GC 存活下来的就到了幸存者区，幸存者区满之后意味着新生区也满了，则触发重 GC，经过重 GC 之后存活下来的就到了养老区。**\n\n真理:经过研究，99%的对象都是临时对象!|\n\n[参考链接](https://www.cnblogs.com/duanxz/p/3726574.html)\n\n## 永久区\n\n这个区域常驻内存的。用来存放 JDK 自身携带的 Class 对象。Interface 元数据，存储的是 Java 运行时的一些环境~ 这个区域不存在垃圾回收，关闭虚拟机就会释放内存\n\n- jdk1.6 之前：永久代,常量池是在方法区;\n- jdk1.7：永久代,但是慢慢的退化了，去永久代，常量池在堆中\n- jdk1.8 之后：无永久代,常量池在元空间\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501180058.png)\n\n元空间：逻辑上存在，物理上不存在 (因为存储在本地磁盘内) 所以最后并不算在 JVM 虚拟机内存中\n\n## 堆内存调优\n\n测试代码：\n\n```java\npublic static void main(String[] args) {\n    String s = \"\";\n    while (true) {\n        s += \"11111111111111111111111111111111111111111111111111111\";\n    }\n}\n```\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200715152713345.png#pic_center)\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501190206.png)\n\n**在一个项目中，突然出现了 OOM 故障,那么该如何排除 研究为什么出错~**\n\n- 能够看到代码第几行出错:内存快照分析工具，MAT, Jprofiler\n- Debug, 一行行分析代码!\n\n**MAT, Jprofiler 作用**\n\n- 分析 Dump 内存文件,快速定位内存泄露;\n- 获得堆中的数据\n- 获得大的对象~\n\n**Jprofile 使用**\n\n1. 在 idea 中下载 jprofile 插件\n2. 联网下载 jprofile 客户端\n3. 在 idea 中 VM 参数中写参数 -Xms1m -Xmx8m -XX: +HeapDumpOnOutOfMemoryError\n4. 运行程序后在 jprofile 客户端中打开找到错误 告诉哪个位置报错\n\n**命令参数详解**\n\n- -Xms 设置初始化内存分配大小/164\n- -Xmx 设置最大分配内存，默以 1/4\n- -XX: +PrintGCDetails // 打印 GC 垃圾回收信息\n- -XX: +HeapDumpOnOutOfMemoryError //oom **DUMP**\n\n## GC\n\n![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501191953.png)\n\nJVM 在进行 GC 时，并不是对这三个区域统一回收。 大部分时候，回收都是新生代~\n\n- 新生代\n- **幸存区(form，to)**\n- 老年区\n\nGC 两种类:轻 GC (普通的 GC)， 重 GC (全局 GC)\n\nGC 常见面试题目:\n\n- **JVM 的内存模型和分区~详细到每个区放什么?**\n\n  ![在这里插入图片描述](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210501192059.png)\n\n- **堆里面的分区有哪些?**\n\n  Eden, form, to, 老年区,说说他们的特点!\n\n- **GC 的算法有哪些?**\n\n  标记清除法，标记整理,复制算法，引用计数器\n\n- **轻 GC 和重 GC 分别在什么时候发生?**\n\n[参考链接](https://www.cnblogs.com/qianguyihao/p/4744233.html)\n","tags":["技巧","笔记"],"categories":["后端开发"]},{"title":"ElasticSearch 的概述和使用","slug":"ElasticSearch 的概述和使用","url":"/2021/05/04/e33c148b.html","content":"\n## ElasticSearch 概述\n\nElaticsearch，简称为 es， es 是一个开源的**高扩展**的**分布式全文检索引擎**，它可以近乎**实时的存储、检索数据**；本身扩展性很好，可以扩展到上百台服务器，处理 PB 级别（大数据时代）的数据。es 也使用 Java 开发并使用 Lucene 作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的**RESTful API**来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。\n\n据国际权威的数据库产品评测机构 DB Engines 的统计，在 2016 年 1 月，ElasticSearch 已超过 Solr 等，**成为排名第一的搜索引擎类应用。**\n\n## ES 和 solr 的差别\n\n### Elasticsearch 简介\n\nElasticsearch 是一个实时分布式搜索和分析引擎。它让你以前所未有的速度处理大数据成为可能。\n\n它用于**全文搜索、结构化搜索、分析**以及将这三者混合使用：\n\n维基百科使用 Elasticsearch 提供全文搜索并高亮关键字，以及输入实时搜索(search-asyou-type)和搜索纠错(did-you-mean)等搜索建议功能。\n\n英国卫报使用 Elasticsearch 结合用户日志和社交网络数据提供给他们的编辑以实时的反馈，以便及时了解公众对新发表的文章的回应。\n\nStackOverflow 结合全文搜索与地理位置查询，以及 more-like-this 功能来找到相关的问题和答案。\n\nGithub 使用 Elasticsearch 检索 1300 亿行的代码。\n\n但是 Elasticsearch 不仅用于大型企业，它还让像 DataDog 以及 Klout 这样的创业公司将最初的想法变成可扩展的解决方案。\n\nElasticsearch 可以在你的笔记本上运行，也可以在数以百计的服务器上处理 PB 级别的数据 。\n\nElasticsearch 是一个基于 Apache Lucene(TM)的开源搜索引擎。无论在开源还是专有领域，Lucene 可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。\n\n但是，Lucene 只是一个库。想要使用它，你必须使用 Java 来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene 非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。\n\nElasticsearch 也使用 Java 开发并使用 Lucene 作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的**RESTful API**来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。\n\n### Solr 简介\n\nSolr 是 Apache 下的一个顶级开源项目，采用 Java 开发，它是基于 Lucene 的全文搜索服务器。Solr 提供了比 Lucene 更为丰富的查询语言，同时实现了可配置、可扩展，并对索引、搜索性能进行了优化\n\nSolr 可以独立运行，运行在 Jetty、Tomcat 等这些 Servlet 容器中，Solr 索引的实现方法很简单，**用 POST 方法向 Solr 服务器发送一个描述 Field 及其内容的 XML 文档，Solr 根据 xml 文档添加、删除、更新索引**。Solr 搜索只需要发送 HTTP GET 请求，然后对 Solr 返回 Xml、json 等格式的查询结果进行解析，组织页面布局。Solr 不提供构建 UI 的功能，Solr 提供了一个管理界面，通过管理界面可以查询 Solr 的配置和运行情况。\n\nsolr 是基于 lucene 开发企业级搜索服务器，实际上就是封装了 lucene。\n\nSolr 是一个独立的企业级搜索应用服务器，它对外提供类似于==Web-service 的 API 接口==。用户可以通过 http 请求，向搜索引擎服务器提交一定格式的文件，生成索引；也可以通过提出查找请求，并得到返回结果。\n\n### Lucene 简介\n\nLucene 是 apache 软件基金会 4 jakarta 项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。Lucene 是一套用于全文检索和搜寻的开源程式库，由 Apache 软件基金会支持和提供。Lucene 提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。**在 Java 开发环境里 Lucene 是一个成熟的免费开源工具。就其本身而言，Lucene 是当前以及最近几年最受欢迎的免费 Java 信息检索程序库**。人们经常提到信息检索程序库，虽然与搜索引擎有关，但不应该将信息检索程序库与搜索引擎相混淆。\n\nLucene 是一个全文检索引擎的架构。那什么是全文搜索引擎？\n\n全文搜索引擎是名副其实的搜索引擎，国外具代表性的有 Google、Fast/AllTheWeb、AltaVista、Inktomi、Teoma、WiseNut 等，国内著名的有百度（Baidu）。它们都是通过从互联网上提取的各个网站的信息（以网页文字为主）而建立的数据库中，检索与用户查询条件匹配的相关记录，然后按一定的排列顺序将结果返回给用户，因此他们是真正的搜索引擎。\n\n从搜索结果来源的角度，全文搜索引擎又可细分为两种，一种是拥有自己的检索程序（Indexer），俗称“蜘蛛”（Spider）程序或“机器人”（Robot）程序，并自建网页数据库，搜索结果直接从自身的数据库中调用，如上面提到的 7 家引擎；另一种则是租用其他引擎的数据库，并按自定的格式排列搜索结果，如 Lycos 引擎。\n\n### Elasticsearch 和 Solr 比较\n\n![image-20210503223554497](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503223554.png)\n\n![image-20210503223607286](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503223607.png)\n\n![image-20210503223616904](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503223616.png)\n\n![image-20210503223627835](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503223627.png)\n\n### ElasticSearch vs Solr 总结\n\n1. es 基本是开箱即用（解压就可以用 ! ），非常简单。Solr 安装略微复杂一丢丢！\n2. Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能。\n3. Solr 支持更多格式的数据，比如 JSON、XML、CSV，而 Elasticsearch 仅支持 json 文件格式。\n4. Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供，例如图形化界面需要 kibana 友好支撑~!\n5. Solr 查询快，但更新索引时慢（即插入删除慢），用于电商等查询多的应用；\n   - ES 建立索引快（即查询慢），**即实时性查询快**，用于 facebook 新浪等搜索。\n   - Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用\n6. Solr 比较成熟，有一个更大，更成熟的用户、开发和贡献者社区，而 Elasticsearch 相对开发维护者较少，更新太快，学习使用成本较高。（趋势！）\n\n## ElasticSearch 安装\n\n声明：JDK1.8 ，最低要求！ ElasticSearch 客户端，界面工具！\nJava 开发，ElasticSearch 的版本和我们之后对应的 Java 的核心 jar 包！ 版本对应！JDK 环境是正常！\n\n> 下载\n\n官网：[https://www.elastic.co/](https://www.elastic.co/)\n\n下载地址：[https://www.elastic.co/cn/downloads/elasticsearch](https://www.elastic.co/cn/downloads/elasticsearch)\n\n> window 下安装！\n\n### 解压就可以使用了！\n\n![image-20210503224753729](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503224753.png)\n\n### 熟悉目录！\n\n```java\nbin 启动文件\nconfig 配置文件\n    log4j2 日志配置文件\n    jvm.options java 虚拟机相关的配置\n    elasticsearch.yml  elasticsearch 的配置文件！ 默认 9200 端口！ 跨域！\nlib   相关jar包\nlogs   日志！\nmodules 功能模块\nplugins 插件！\n```\n\n### 启动，访问 9200\n\n运行`bin/elasticsearch.bat`，启动！\n\n![image-20210503225150680](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503225150.png)\n\n### 访问测试！\n\n![image-20210503225235923](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503225236.png)\n\n> 安装可视化界面插件 es head 的插件\n\n需要 node.js 环境\n\n1. 下载地址：[https://github.com/mobz/elasticsearch-head/](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fmobz%2Felasticsearch-head%2F)\n\n2. 启动\n\n   ```bash\n   npm install\n   npm run start\n   ```\n\n3. 连接测试发现，存在跨域问题：配置 es\n\n   ```yaml\n   http.cors.enabled: true\n   http.cors.allow-origin: \"*\"\n   ```\n\n4. 重启 es 服务器，然后再次连接\n\n   ![image-20210503230107069](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503230107.png)\n\n初学，就把 es 当做一个数据库！ （可以建立索引（库），文档（库中的数据！））\n\n**这个 head 我们就把它当做数据展示工具！我们后面所有的查询，去 Kibana 进行！**\n\n> 了解 ELK\n\nELK 是 Elasticsearch、Logstash、Kibana 三大开源框架首字母大写简称。市面上也被成为 ElasticStack。其中 Elasticsearch 是一个基于 Lucene、分布式、通过 Restful 方式进行交互的近实时搜索平台框架。像类似百度、谷歌这种大数据全文搜索引擎的场景都可以使用 Elasticsearch 作为底层支持框架，可见 Elasticsearch 提供的搜索能力确实强大,市面上很多时候我们简称 Elasticsearch 为 es。Logstash 是 ELK 的中央数据流引擎，用于从不同目标（文件/数据存储/MQ）收集的不同格式数据，经过过滤后支持输出到不同目的地（文件/MQ/redis/elasticsearch/kafka 等）。Kibana 可以将 elasticsearch 的数据通过友好\n的页面展示出来，提供实时分析的功能。\n\n市面上很多开发只要提到 ELK 能够一致说出它是一个日志分析架构技术栈总称，但实际上 ELK 不仅仅适用于日志分析，它还可以支持其它任何数据分析和收集的场景，日志分析和收集只是更具有代表性。并非唯一性。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503230537.webp)\n\n> 安装 Kibana\n\nKibana 是一个针对 Elasticsearch 的开源分析及可视化平台，用来搜索、查看交互存储在 Elasticsearch 索引中的数据。使用 Kibana，可以通过各种图表进行高级数据分析及展示。Kibana 让海量数据更容易理解。它操作简单，基于浏览器的用户界面可以快速创建仪表板（dashboard）实时显示 Elasticsearch 查询动态。设置 Kibana 非常简单。无需编码或者额外的基础架构，几分钟内就可以完成 Kibana 安装并启动 Elasticsearch 索引监测。\n\n官网：[https://www.elastic.co/cn/kibana](https://www.elastic.co/cn/kibana)\n\nKibana 版本要和 Es 一致！\n\n> 启动测试！\n\n1、解压后的目录\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503233229.png\" alt=\"image-20210503233229181\" style=\"zoom:67%;\" />\n\n2、启动`kibana.bat`\n\n![image-20210503233731775](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503233731.png)\n\n3、访问测试\n\n![image-20210503233752142](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503233752.png)\n\n4、开发工具！ （Post、curl、head、谷歌浏览器插件测试！）\n\n![image-20210503233835622](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503233835.png)\n\n5、汉化！自己修改 kibana 配置即可！ zh-CN！\n\nkibaba.yml 文件末尾添加\n\n```yaml\ni18n.locale: \"zn-CH\"\n```\n\n![image-20210503234155128](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503234155.png)\n\n## ES 核心概念\n\n1. 索引\n2. 字段类型（mapping）\n3. 文档（documents）\n\n> 概述\n\n在前面的学习中，我们已经掌握了 es 是什么，同时也把 es 的服务已经安装启动，那么 es 是如何去存储数据，数据结构是什么，又是如何实现搜索的呢？我们先来聊聊 ElasticSearch 的相关概念吧！\n\n**集群，节点，索引，类型，文档，分片，映射是什么？**\n\n> elasticsearch 是面向文档，关系行数据库 和 elasticsearch 客观的对比！一切都是 JSON！\n\n| **Relational DB** | **Elasticsearch** |\n| :---------------: | :---------------: |\n| 数据库(database)  |   索引(indices)   |\n|    表(tables)     |       types       |\n|     行(rows)      |     documents     |\n|   字段(columns)   |      fields       |\n\nelasticsearch(集群)中可以包含多个索引(数据库)，每个索引中可以包含多个类型(表)，每个类型下又包含多 个文档(行)，每个文档中又包含多个字段(列)。\n\n**物理设计：**\n\nelasticsearch 在后台把每个索引划分成多个分片，每分分片可以在集群中的不同服务器间迁移\n\n一个人就是一个集群！默认的集群名称就是 elaticsearh\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503234530.webp)\n\n**逻辑设计：**\n\n一个索引类型中，包含多个文档，比如说文档 1，文档 2。 当我们索引一篇文档时，可以通过这样的一各顺序找到 它: 索引 ▷ 类型 ▷ 文档 ID ，通过这个组合我们就能索引到某个具体的文档。 注意:ID 不必是整数，实际上它是个字符串。\n\n> 文档\n\n就是我们的一条条数据\n\n```undefined\nuser\n1  zhangsan  18\n2  ouwen  3\n```\n\n之前说 elasticsearch 是面向文档的，那么就意味着索引和搜索数据的最小单位是文档，elasticsearch 中，文档有几个 重要属性 :\n\n- 自我包含，一篇文档同时包含字段和对应的值，也就是同时包含 key:value！\n- 可以是层次型的，一个文档中包含自文档，复杂的逻辑实体就是这么来的！ {就是一个 json 对象！fastjson 进行自动转换！}\n- 灵活的结构，文档不依赖预先定义的模式，我们知道关系型数据库中，要提前定义字段才能使用，在 elasticsearch 中，对于字段是非常灵活的，有时候，我们可以忽略该字段，或者动态的添加一个新的字段。\n\n尽管我们可以随意的新增或者忽略某个字段，但是，每个字段的类型非常重要，比如一个年龄字段类型，可以是字符 串也可以是整形。因为 elasticsearch 会保存字段和类型之间的映射及其他的设置。这种映射具体到每个映射的每种类型，这也是为什么在 elasticsearch 中，类型有时候也称为映射类型。\n\n> 类型\n\n类型是文档的逻辑容器，就像关系型数据库一样，表格是行的容器。 类型中对于字段的定义称为映射，比如 name 映 射为字符串类型。 我们说文档是无模式的，它们不需要拥有映射中所定义的所有字段，比如新增一个字段，那么 elasticsearch 是怎么做的呢?elasticsearch 会自动的将新字段加入映射，但是这个字段的不确定它是什么类型，elasticsearch 就开始猜，如果这个值是 18，那么 elasticsearch 会认为它是整形。 但是 elasticsearch 也可能猜不对， 所以最安全的方式就是提前定义好所需要的映射，这点跟关系型数据库殊途同归了，先定义好字段，然后再使用，别 整什么幺蛾子。\n\n> 索引\n\n就是数据库！\n\n索引是映射类型的容器，elasticsearch 中的索引是一个非常大的文档集合。索引存储了映射类型的字段和其他设置。 然后它们被存储到了各个分片上了。 我们来研究下分片是如何工作的。\n\n物理设计 ：节点和分片 如何工作\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503235339.webp)\n\n一个集群至少有一个节点，而一个节点就是一个 elasricsearch 进程，节点可以有多个索引默认的，如果你创建索引，那么索引将会有个 5 个分片 ( primary shard ,又称主分片 ) 构成的，每一个主分片会有一个副本 ( replica shard ,又称复制分片 )\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503235352.webp)\n\n上图是一个有 3 个节点的集群，可以看到主分片和对应的复制分片都不会在同一个节点内，这样有利于某个节点挂掉 了，数据也不至于丢失。 实际上，一个分片是一个 Lucene 索引，一个包含倒排索引的文件目录，**倒排索引**的结构使 得 elasticsearch 在不扫描全部文档的情况下，就能告诉你哪些文档包含特定的关键字。 不过，等等，倒排索引是什 么鬼?\n\n> 倒排索引\n\nelasticsearch 使用的是一种称为倒排索引的结构，采用 Lucene 倒排索作为底层。这种结构适用于快速的全文搜索， 一个索引由文档中所有不重复的列表构成，对于每一个词，都有一个包含它的文档列表。 例如，现在有两个文档， 每个文档包含如下内容：\n\n```bash\nStudy every day, good good up to forever  # 文档1包含的内容\nTo forever, study every day, good good up # 文档2包含的内容\n```\n\n为了创建倒排索引，我们首先要将每个文档拆分成独立的词(或称为词条或者 tokens)，然后创建一个包含所有不重 复的词条的排序列表，然后列出每个词条出现在哪个文档 :\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503235436.png\" alt=\"image-20210503235436309\" style=\"zoom:50%;\" />\n\n现在，我们试图搜索 to forever，只需要查看包含每个词条的文档 score\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503235452.png\" alt=\"image-20210503235452613\" style=\"zoom:50%;\" />\n\n两个文档都匹配，但是第一个文档比第二个匹配程度更高。如果没有别的条件，现在，这两个包含关键字的文档都将返回。\n\n再来看一个示例，比如我们通过博客标签来搜索博客文章。那么倒排索引列表就是这样的一个结构 :\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503235510.webp)\n\n如果要搜索含有 python 标签的文章，那相对于查找所有原始数据而言，查找倒排索引后的数据将会快的多。只需要 查看标签这一栏，然后获取相关的文章 ID 即可。完全过滤掉无关的所有数据，提高效率！\n\nelasticsearch 的索引和 Lucene 的索引对比\n\n在 elasticsearch 中， 索引 （库）这个词被频繁使用，这就是术语的使用。 在 elasticsearch 中，索引被分为多个分片，每份 分片是一个 Lucene 的索引。所以一个 elasticsearch 索引是由多个 Lucene 索引组成的。别问为什么，谁让 elasticsearch 使用 Lucene 作为底层呢! 如无特指，说起索引都是指 elasticsearch 的索引。\n\n## IK 分词器插件\n\n> 什么是 IK 分词器？\n\n分词：即把一段中文或者别的划分成一个个的关键字，我们在搜索时候会把自己的信息进行分词，会把数据库中或者索引库中的数据进行分词，然后进行一个匹配操作，默认的中文分词是将每个字看成一个词，比如 “我爱狂神” 会被分为\"我\",\"爱\",\"狂\",\"神\"，这显然是不符合要求的，所以我们需要安装中文分词器 ik 来解决这个问题。\n\n如果要使用中文，建议使用 ik 分词器！\n\nIK 提供了两个分词算法：ik_smart 和 ik_max_word，其中 ik_smart 为最少切分，ik_max_word 为最细粒度划分！\n\n> 安装\n\n1、[https://github.com/medcl/elasticsearch-analysis-ik](https://github.com/medcl/elasticsearch-analysis-ik)\n\n2、下载完毕后，放入到我们的 elasticsearch 插件即可\n\n![image-20210503235943039](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210503235943.png)\n\n3、重启观察 ES，可以看到 ik 分词器被加载了！\n\n![image-20210504000047514](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504000047.png)\n\n4、elasticsearch-plugin 可以通过这个命令来查看加载进来的插件\n\n![image-20210504000146656](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504000351.png)\n\n5、使用 kibana 进行测试\n\n> 查看不同的分词效果\n\nik_smart 为最少切分\n\n![image-20210504000856743](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504000943.png)\n\nik_max_word 为最细粒度划分，穷尽词库的可能！字典！\n\n![image-20210504001030482](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504001030.png)\n\n> 我们输入 超级喜欢狂神说 Java\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504001209.webp)\n\n发现问题：狂神说被拆开了！\n\n这种自己需要的词，需要自己加到我们的分词器的字典中！\n\n> ik 分词器增加自己的配置！\n\n![image-20210504001411652](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504001411.png)\n\n重启 es，看细节！\n\n![image-20210504001513405](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504001513.png)\n\n再次测试一下狂神说，看下效果！\n\n![image-20210504001619667](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504001619.png)\n\n## Rest 风格说明\n\n一种软件架构风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。\n\n基本 Rest 命令说明：\n\n| method | url 地址                                          | 描述                    |\n| ------ | ------------------------------------------------- | ----------------------- |\n| PUT    | localhost:9200/索引名称/类型名称/文档 id          | 创建文档（指定文档 id） |\n| POST   | localhost:9200/索引名称/类型名称                  | 创建文档（随机文档 id） |\n| POST   | localhost:9200/索引名称/类型名称/文档 id/\\_update | 修改文档                |\n| DELETE | localhost:9200/索引名称/类型名称/文档 id          | 删除文档                |\n| GET    | localhost:9200/索引名称/类型名称/文档 id          | 查询文档通过文档 id     |\n| POST   | localhost:9200/索引名称/类型名称/\\_search         | 查询所有数据            |\n\n## 关于索引的基本操作\n\n### 创建一个索引！\n\n```restructuredtext\nPUT /索引名/~类型名~/文档id\n{请求体}\n```\n\n![image-20210504002137968](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504002138.png)\n\n完成了自动增加了索引！数据也成功的添加了，这就是我说大家在初期可以把它当做数据库学习的原因！\n\n![image-20210504002239404](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504002239.png)\n\n那么 name 这个字段用不用指定类型呢。毕竟我们关系型数据库 是需要指定类型的啊 !\n\n- 字符串类型\n  text 、 keyword\n- 数值类型\n  long, integer, short, byte, double, float, half_float, scaled_float\n- 日期类型\n  date\n- 布尔值类型\n  boolean\n- 二进制类型\n  binary\n- 等等.....\n\n### 指定字段的类型\n\n![image-20210504002816478](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504002816.png)\n\n获得这个规则！ 可以通过 GET 请求获取具体的信息！\n\n![image-20210504002902783](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504002902.png)\n\n### 查看默认的信息\n\n![image-20210504003207460](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504003207.png)\n\n![image-20210504003219494](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504003219.png)\n\n如果自己的文档字段没有指定，那么 es 就会给我们默认配置字段类型！\n\n**扩展**： 通过命令 elasticsearch 索引情况！ 通过`GET _cat/` 可以获得 es 的当前的很多信息！\n\n![image-20210504003418475](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504003418.png)\n\n> 修改 提交还是使用 PUT 即可！ 然后覆盖！最新办法！\n\n曾经！\n\n![image-20210504003608862](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504003608.png)\n\n现在的方法！\n\n![image-20210504003757886](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504003757.png)\n\n> 删除索引！\n\n通过 DELETE 命令实现删除、 根据你的请求来判断是删除索引还是删除文档记录！\n\n使用 RESTFUL 风格是我们 ES 推荐大家使用的！\n\n![image-20210504003924263](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504003924.png)\n\n## 关于文档的基本操作（重点）\n\n> 基本操作\n\n### 添加数据\n\n```json\nPUT /ouwen/user/3\n{\n  \"name\": \"小红\",\n  \"age\": 22,\n  \"desc\": \"我是一个美女\",\n  \"tags\": [\"睡觉\",\"靓女\",\"吃饭\"]\n}\n```\n\n![image-20210504004712396](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504004712.png)\n\n### 获取数据 GET\n\n![image-20210504004741798](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504004741.png)\n\n### 更新数据 PUT\n\n![image-20210504004901746](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504004901.png)\n\n### Post \\_update , 推荐使用这种更新方式！\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504005345.png)\n\n### 简单地搜索！\n\n```\nGET ouwen/user/1\n```\n\n简答的条件查询，可以根据默认的映射规则，产生基本的查询！\n\n![image-20210504005803020](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504005803.png)\n\n![image-20210504005944771](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504005944.png)\n\n### 复杂操作搜索 select ( 排序，分页，高亮，模糊查询，精准查询！)\n\n![image-20210504010146616](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504010155.png)\n\n![image-20210504010602133](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504010602.png)\n\n输出结果，不想要那么多！\n\n![image-20210504010722580](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504010722.png) 我们之后使用 Java 操作 es ，所有的方法和对象就是这里面的 key！\n\n> 排序！\n\n![image-20210504011018343](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504011018.png)\n\n> 分页查询！\n\n![image-20210504011149220](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504011149.png)\n\n数据下标还是从 0 开始的，和学的所有数据结构是一样的！\n\n`/search/{current}/{pagesize}`\n\n> 布尔值查询\n\n**must （and）**，所有的条件都要符合 where id = 1 and name = xxx\n\n![image-20210504011607517](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504011607.png)\n\n**should（or）**，所有的条件都要符合 where id = 1 or name = xxx\n\n![image-20210504011736768](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504011736.png)\n\n**must_not （not）**\n\n![image-20210504011831232](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504011831.png)\n\n**过滤器 filter**\n\n![image-20210504012021112](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504012021.png)\n\n- gt 大于\n- gte 大于等于\n- lt 小于\n- lte 小于等于！\n\n![image-20210504012126745](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504012126.png)\n\n> 匹配多个条件！\n\n![image-20210504012405631](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504012405.png)\n\n> 精确查询！\n\nterm 查询是直接通过倒排索引指定的词条进程精确查找的！\n\n**关于分词：**\n\n- term ，直接查询精确的\n- match，会使用分词器解析！（先分析文档，然后在通过分析的文档进行查询！）\n\n**两个类型 `text` `keyword`**\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504012855.webp)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504012909.webp)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504013020.webp)\n\n> 多个值匹配精确查询\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504014024.webp)\n\n> 高亮查询！\n\n![image-20210504014305845](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504014306.png)\n\n![image-20210504014541346](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504014541.png)\n\n## 集成 SpringBoot\n\n> 找官方文档！\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504131313.webp)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504131324.webp)\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504131333.webp)\n\n1、找到原生的依赖\n\n```xml\n<dependency>\n  <groupId>org.elasticsearch.client</groupId>\n  <artifactId>elasticsearch-rest-high-level-client</artifactId>\n  <version>7.6.2</version>\n</dependency>\n```\n\n2、找对象\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504131416.webp)\n\n3、分析这个类中的方法即可！\n\n> 配置基本的项目\n\n源码中提供对象！\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210504133033.webp)\n\n虽然这里导入 3 个类，静态内部类，核心类就一个！\n\n```java\n/**\n* Elasticsearch rest client infrastructure configurations.\n*\n* @author Brian Clozel\n* @author Stephane Nicoll\n*/\nclass RestClientConfigurations {\n    @Configuration(proxyBeanMethods = false)\n    static class RestClientBuilderConfiguration {\n        // RestClientBuilder\n        @Bean\n        @ConditionalOnMissingBean\n        RestClientBuilder elasticsearchRestClientBuilder(RestClientProperties\n                                                         properties,\n                                                         ObjectProvider<RestClientBuilderCustomizer> builderCustomizers) {\n            HttpHost[] hosts =\n                properties.getUris().stream().map(HttpHost::create).toArray(HttpHost[]::new);\n            RestClientBuilder builder = RestClient.builder(hosts);\n            PropertyMapper map = PropertyMapper.get();\n            map.from(properties::getUsername).whenHasText().to((username) -> {\n                CredentialsProvider credentialsProvider = new\n                    BasicCredentialsProvider();\n                Credentials credentials = new\n                    UsernamePasswordCredentials(properties.getUsername(),\n                                                properties.getPassword());\n                credentialsProvider.setCredentials(AuthScope.ANY, credentials);\n                builder.setHttpClientConfigCallback(\n                    (httpClientBuilder) ->\n                    httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider));\n            });\n            builder.setRequestConfigCallback((requestConfigBuilder) -> {\n\n                map.from(properties::getConnectionTimeout).whenNonNull().asInt(Duration::toMill\n                                                                               is)\n                    .to(requestConfigBuilder::setConnectTimeout);\n\n                map.from(properties::getReadTimeout).whenNonNull().asInt(Duration::toMillis)\n                    .to(requestConfigBuilder::setSocketTimeout);\n                return requestConfigBuilder;\n            });\n            builderCustomizers.orderedStream().forEach((customizer) ->\n                                                       customizer.customize(builder));\n            return builder;\n        }\n    }\n    @Configuration(proxyBeanMethods = false)\n    @ConditionalOnClass(RestHighLevelClient.class)\n    static class RestHighLevelClientConfiguration {\n        // RestHighLevelClient 高级客户端，也是我们这里要讲，后面项目会用到的客户端\n        @Bean\n        @ConditionalOnMissingBean\n        RestHighLevelClient elasticsearchRestHighLevelClient(RestClientBuilder\n                                                             restClientBuilder) {\n            return new RestHighLevelClient(restClientBuilder);\n        }\n        @Bean\n        @ConditionalOnMissingBean\n        RestClient elasticsearchRestClient(RestClientBuilder builder,\n                                           ObjectProvider<RestHighLevelClient> restHighLevelClient) {\n            RestHighLevelClient client = restHighLevelClient.getIfUnique();\n            if (client != null) {\n                return client.getLowLevelClient();\n            }\n            return builder.build();\n        }\n    }\n    @Configuration(proxyBeanMethods = false)\n    static class RestClientFallbackConfiguration {\n        // RestClient 普通的客户端！\n        @Bean\n        @ConditionalOnMissingBean\n        RestClient elasticsearchRestClient(RestClientBuilder builder) {\n            return builder.build();\n        }\n    }\n}\n```\n\n> 具体的 API 测试！\n\n1. 创建索引\n2. 判断索引是否存在\n3. 删除索引\n4. 创建文档\n5. crud 文档！\n\n```java\npackage com.luojunjie;\n\nimport cn.hutool.json.JSON;\nimport cn.hutool.json.JSONString;\nimport cn.hutool.json.JSONUtil;\nimport com.luojunjie.pojo.User;\nimport org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;\nimport org.elasticsearch.action.bulk.BulkRequest;\nimport org.elasticsearch.action.bulk.BulkResponse;\nimport org.elasticsearch.action.delete.DeleteRequest;\nimport org.elasticsearch.action.delete.DeleteResponse;\nimport org.elasticsearch.action.get.GetRequest;\nimport org.elasticsearch.action.get.GetResponse;\nimport org.elasticsearch.action.index.IndexRequest;\nimport org.elasticsearch.action.index.IndexResponse;\nimport org.elasticsearch.action.search.SearchRequest;\nimport org.elasticsearch.action.search.SearchResponse;\nimport org.elasticsearch.action.support.master.AcknowledgedResponse;\nimport org.elasticsearch.action.update.UpdateRequest;\nimport org.elasticsearch.action.update.UpdateResponse;\nimport org.elasticsearch.client.RequestOptions;\nimport org.elasticsearch.client.RestHighLevelClient;\nimport org.elasticsearch.client.indices.CreateIndexRequest;\nimport org.elasticsearch.client.indices.CreateIndexResponse;\nimport org.elasticsearch.client.indices.GetIndexRequest;\nimport org.elasticsearch.common.unit.TimeValue;\nimport org.elasticsearch.common.xcontent.XContentType;\nimport org.elasticsearch.index.query.QueryBuilders;\nimport org.elasticsearch.index.query.TermQueryBuilder;\nimport org.elasticsearch.search.SearchHit;\nimport org.elasticsearch.search.builder.SearchSourceBuilder;\nimport org.elasticsearch.search.fetch.subphase.FetchSourceContext;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.beans.factory.annotation.Qualifier;\nimport org.springframework.boot.test.context.SpringBootTest;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.concurrent.TimeUnit;\n\n@SpringBootTest\nclass JunjieEsApiApplicationTests {\n\n    @Autowired\n    @Qualifier(\"restHighLevelClient\")\n    private RestHighLevelClient client;\n\n    //测试索引的创建 Request\n    @Test\n    void testCreateIndex() throws IOException {\n        // 1、创建索引对象\n        CreateIndexRequest request = new CreateIndexRequest(\"ouwen_index\");\n        // 2、客户端执行请求 IndicesClient 请求后获得响应结果\n        CreateIndexResponse createIndexResponse =\n                client.indices().create(request, RequestOptions.DEFAULT);\n\n        System.out.println(createIndexResponse);\n    }\n\n    // 测试获取索引 判断其是否存在\n    @Test\n    void testExistIndex() throws IOException {\n        GetIndexRequest request = new GetIndexRequest(\"ouwen_index\");\n        boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);\n        System.out.println(exists);\n    }\n\n    // 测试删除索引\n    @Test\n    void testDeleteIndex() throws IOException {\n        DeleteIndexRequest request = new DeleteIndexRequest(\"ouwen_index\");\n        AcknowledgedResponse delete = client.indices().delete(request, RequestOptions.DEFAULT);\n        System.out.println(delete.isAcknowledged());\n    }\n\n    // 测试添加文档\n    @Test\n    void testAddDocument() throws IOException {\n        //创建对象\n        User user = new User(\"欧文\", 18);\n        //创建请求\n        IndexRequest request = new IndexRequest(\"ouwen_index\");\n\n        //规则 PUT /ouwen_index/_doc/1\n        request.id(\"1\");\n        request.timeout(TimeValue.timeValueSeconds(1));\n\n        //将我们的数据放入请求 json\n        request.source(JSONUtil.toJsonStr(user), XContentType.JSON);\n\n        //客户端发送请求\n        IndexResponse index = client.index(request, RequestOptions.DEFAULT);\n\n        System.out.println(index.toString());\n        System.out.println(index.status()); //对应命令返回的状态\n    }\n\n    //获取文档，判断是否存在\n    @Test\n    void testIsExists() throws IOException {\n        GetRequest getRequest = new GetRequest(\"ouwen_index\", \"1\");\n        //不获取返回的 _source 的上下文 效率更高\n        getRequest.fetchSourceContext(new FetchSourceContext(false));\n\n        boolean exists = client.exists(getRequest, RequestOptions.DEFAULT);\n        System.out.println(exists);\n    }\n\n    //获得文档的内容\n    @Test\n    void testGetDocument() throws IOException {\n        GetRequest getRequest = new GetRequest(\"ouwen_index\", \"1\");\n        GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT);\n        //打印文档的内容\n        System.out.println(getResponse.getSourceAsString());\n        //返回的全部内容跟命令是一样的\n        System.out.println(getResponse);\n    }\n\n    //更新文档的内容\n    @Test\n    void testUpdateDocument() throws IOException {\n        UpdateRequest updateRequest = new UpdateRequest(\"ouwen_index\", \"1\");\n        updateRequest.timeout(\"1s\");\n\n        User user = new User(\"ouwen666\", 22);\n        updateRequest.doc(JSONUtil.toJsonStr(user), XContentType.JSON);\n\n        UpdateResponse updateResponse = client.update(updateRequest, RequestOptions.DEFAULT);\n        System.out.println(updateResponse.status());\n    }\n\n    //删除文档的内容\n    @Test\n    void testDeleteDocument() throws IOException {\n        DeleteRequest deleteRequest = new DeleteRequest(\"ouwen_index\", \"1\");\n        deleteRequest.timeout(\"1s\");\n\n        DeleteResponse response = client.delete(deleteRequest, RequestOptions.DEFAULT);\n        System.out.println(response.status());\n    }\n\n    //批量添加数据\n    @Test\n    void testBulkRequest() throws IOException {\n        BulkRequest bulkRequest = new BulkRequest();\n        bulkRequest.timeout(\"60s\");\n        List<User> users = new ArrayList<User>();\n        users.add(new User(\"ouwen1\", 63));\n        users.add(new User(\"ouwen2\", 53));\n        users.add(new User(\"ouwen3\", 43));\n        users.add(new User(\"junjie1\", 33));\n        users.add(new User(\"junjie2\", 23));\n        users.add(new User(\"junjie3\", 13));\n        //处理批量请求\n        for (int i = 0; i < users.size(); i++) {\n            bulkRequest.add(new IndexRequest(\"ouwen_index\")\n                    .id(\"\" + (i + 1))\n                    .source(JSONUtil.toJsonStr(users.get(i)), XContentType.JSON));\n        }\n\n        BulkResponse responses = client.bulk(bulkRequest, RequestOptions.DEFAULT);\n        System.out.println(responses.hasFailures()); //是否失败 false代表成功\n    }\n\n    // 查询\n    // SearchRequest 搜索请求\n    // SearchSourceBuilder 条件构造\n    // HighlightBuilder 构建高亮\n    // TermQueryBuilder 精确查询\n    // MatchAllQueryBuilder\n    // xxx QueryBuilder 对应我们刚才看到的命令！\n    @Test\n    void testSearch() throws IOException {\n        SearchRequest searchRequest = new SearchRequest(\"ouwen_index\");\n        //构建搜索条件\n        SearchSourceBuilder sourceBuilder = new SearchSourceBuilder();\n\n        // 查询条件，我们可以使用 QueryBuilders 工具来实现\n        // QueryBuilders.termQuery 精确\n        // QueryBuilders.matchAllQuery() 匹配所有\n        TermQueryBuilder termQuery = QueryBuilders.termQuery(\"name\", \"ouwen1\");\n\n        sourceBuilder.query(termQuery);\n        sourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS));\n        searchRequest.source(sourceBuilder);\n        SearchResponse search = client.search(searchRequest,RequestOptions.DEFAULT);\n        System.out.println(JSONUtil.toJsonStr(search.getHits()));\n        System.out.println(\"==========================================\");\n        for (SearchHit hit : search.getHits()) {\n            System.out.println(hit.getSourceAsMap());\n        }\n    }\n}\n```\n","tags":["笔记","ES"],"categories":["后端开发"]},{"title":"RabbitMQ 消息队列","slug":"RabbitMQ消息队列","url":"/2021/04/19/eb9166f8.html","content":"\n## 什么是 MQ\n\n消息队列（Message Queue，简称 MQ），从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是 message 而已。其主要用途：不同进程 Process/线程 Thread 之间通信。\n\n**为什么会产生消息队列？有几个原因：**\n\n- 不同进程（process）之间传递消息时，两个进程之间耦合程度过高，改动一个进程，引发必须修改另一个进程，为了隔离这两个进程，在两进程间抽离出一层（一个模块），所有两进程之间传递的消息，都必须通过消息队列来传递，单独修改某一个进程，不会影响另一个；\n- 不同进程（process）之间传递消息时，为了实现标准化，将消息的格式规范化了，并且，某一个进程接受的消息太多，一下子无法处理完，并且也有先后顺序，必须对收到的消息进行排队，因此诞生了事实上的消息队列；\n\n## RabbitMQ\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20211212181732.png)\n\n**RabbitMQ 简介**\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210414173139.png\" alt=\"img\"  />\n\n**开发语言：Erlang - 面向并发的编程语言**\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210414173220.png\" alt=\"img\"  />\n\n**AMQP 协议**\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210414230450.png)\n\n**学习五种队列**\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210414230702.png)\n\n## RabbitMQ 的第一个程序\n\n### 第一种模型（直连）\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210414235259.png\" alt=\"image-20210414235259013\" style=\"zoom:50%;\" />\n\n- P：生产者：也就是要发送消息的程序\n- C：消费者：消息的接受者，会一直等待消息的到来\n- queue：消息队列，图中红色部分，类似一个邮箱，可以缓存消息；生产者向其中投递消息，消费者从其中取出消息\n\n#### 建立一个 maven 项目\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210414231107.png\" alt=\"image-20210414231107272\" style=\"zoom:50%;\" />\n\n#### 导入 RabbitMQ 的客户端依赖\n\n```xml\n <!-- 引入rabbitmq的相关依赖 -->\n<dependency>\n    <groupId>com.rabbitmq</groupId>\n    <artifactId>amqp-client</artifactId>\n    <version>5.7.2</version>\n</dependency>\n```\n\n#### 编写生产者\n\n```java\n@Test\npublic void testSendMessage() throws IOException, TimeoutException {\n    //创建连接mq的连接工厂对象\n    ConnectionFactory connectionFactory = new ConnectionFactory();\n    //设置连接rabbitmq主机\n    connectionFactory.setHost(\"192.168.90.140\");\n    //设置端口号\n    connectionFactory.setPort(5672);\n    //设置连接哪个虚拟主机\n    connectionFactory.setVirtualHost(\"/ems\");\n    //设置访问虚拟主机的用户名和密码\n    connectionFactory.setUsername(\"ems\");\n    connectionFactory.setPassword(\"ems\");\n\n    //获取连接对象\n    Connection connection = connectionFactory.newConnection();\n\n    //获取连接中的通道对象\n    Channel channel = connection.createChannel();\n\n    //通道绑定对应的消息队列\n    //参数一：队列名称 如果不存在自动创建\n    //参数二：用来定义队列特性是否要持久化，true持久化队列 false不持久化\n    //参数三：exclusive 是否独占队列 ture独占队列 false 不独占队列\n    //参数四：autoDelete 是否在消费完成后自动删除队列 true 自动删除 false 不自动删除\n    //参数五：额外参数\n    channel.queueDeclare(\"hello\",false,false,false,null);\n\n    //发布消息\n    //参数一：交换机名称 参数二：队列名称 参数三：传递消息额外名称 参数四：消息的具体内容\n    channel.basicPublish(\"\",\"hello\",null,\"hello rabbitmq\".getBytes());\n\n    channel.close();\n    connection.close();\n}\n```\n\n#### 编写消费者\n\n```java\n//创建连接工厂\nConnectionFactory connectionFactory = new ConnectionFactory();\nconnectionFactory.setHost(\"192.168.90.140\");\nconnectionFactory.setPort(5672);\nconnectionFactory.setVirtualHost(\"/ems\");\nconnectionFactory.setUsername(\"ems\");\nconnectionFactory.setPassword(\"ems\");\n\n//创建连接对象\nConnection connection = connectionFactory.newConnection();\n\n//创建通道\nChannel channel = connection.createChannel();\n\n//通道绑定对象\nchannel.queueDeclare(\"hello\", false, false, false, null);\n\n//消费消息\n//参数1；消费哪个队列的消息，队列名称\n//参数2：开始消息的自动确认机制\n//参数3：消费时的回调接口\nchannel.basicConsume(\"hello\", true, new DefaultConsumer(channel) {\n    @Override //最后一个参数：消息队列中取出的消息\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {\n        System.out.println(\"new String(body)==>\" + new String(body));\n    }\n});\n```\n\n**注意：需要在 rabbitmq 管理页面中添加用户和虚拟主机**\n\n![image-20210414231807927](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210414231808.png)\n\n#### 编写连接工具类\n\n```java\npublic class RabbitMQUtils {\n\n    public static ConnectionFactory connectionFactory;\n\n    static {\n        //重量级资源 类加载的时候执行，只执行一次\n        connectionFactory = new ConnectionFactory();\n        connectionFactory.setHost(\"192.168.159.140\");\n        connectionFactory.setPort(5672);\n        connectionFactory.setVirtualHost(\"/ems\");\n        connectionFactory.setUsername(\"ems\");\n        connectionFactory.setPassword(\"ems\");\n    }\n\n    //定义提供连接的方法\n    public static Connection getConnection() throws IOException, TimeoutException {\n        try {\n            return connectionFactory.newConnection();\n\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return null;\n    }\n\n    //定义关闭通道和关闭连接工具方法\n    public static void closeConnectionAndChanel(Channel channel, Connection connection) {\n        try {\n            if (channel != null) {\n                channel.close();\n            }\n            if (connection != null) {\n                connection.close();\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n### 第二种模型（work queue）\n\n`Work queue`，也被称为（`Task queue`），任务模型。当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理，此时就可以使用 work 模型，让多个消费者绑定到一个队列，共同消费队列中的消息，队列中的消息一旦消费，就会消失，因此任务是不会被重复执行的。\n\n![image-20210415000422705](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210415000422.png)\n\n角色：\n\n- P：生产者：任务的发布者\n- C1：消费者：领取任务并且完成任务，假设完成速度较慢\n- C2：消费者 2：领取任务并完成任务，假设完成速度快\n\n#### 编写生产者\n\n```java\n//获取连接对象\nConnection connection = RabbitMQUtils.getConnection();\n//获取连接通道\nChannel channel = connection.createChannel();\n\n//通过通道声明队列\nchannel.queueDeclare(\"work\", true, false, false, null);\n\nfor (int i = 0; i < 20; i++) {\n    //生产消息\n    channel.basicPublish(\"\", \"work\", null, (i + \"hello work queue\").getBytes());\n}\n\n//关闭资源\nRabbitMQUtils.closeConnectionAndChanel(channel, connection);\n```\n\n#### 编写消费者-1\n\n```java\n//获取连接\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\nchannel.queueDeclare(\"work\",true,false,false,null);\n\nchannel.basicConsume(\"work\",true,new DefaultConsumer(channel){\n    @Override\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,byte[] body) throws IOException {\n        System.out.println(\"消费者--1：\"+new String(body));\n    }\n});\n```\n\n#### 编写消费者-2\n\n```java\n//获取连接\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\nchannel.queueDeclare(\"work\",true,false,false,null);\n\nchannel.basicConsume(\"work\",true,new DefaultConsumer(channel){\n    @Override\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,byte[] body) throws IOException {\n        System.out.println(\"消费者--2：\"+new String(body));\n    }\n});\n```\n\n#### 测试结果\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210415190334.png\" alt=\"image-20210415190327510\"  />\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210415190348.png\" alt=\"image-20210415190348026\"  />\n\n==**总结：默认情况下，RabbitMQ 将按顺序将每个消息发送给下一个使用者。平均而言，每个消费者都会收到相同数量的消息。这种分发消息的方式成为循环**==\n\n### 消息自动确认机制\n\n> 完成一项任务可能只需要几秒钟。您可能想知道，如果其中一个消费者启动了一个很长的任务，并且只完成了部分任务而死亡，会发生什么情况。在我们当前的代码中，一旦 RabbitMQ 向消费者发送消息，它就会立即标记该消息为删除。在本例中，如果您杀死一个 worker，我们将丢失它正在处理的消息。我们还将丢失所有已发送到这个特定工作器但尚未处理的消息。\n\n```java\n//每一次只能消费一个消息\nchannel.basicQos(1);\n//参数1：队列名称 参数2：消息自动确认 true 消费者自动向rabbitmq确认消息消费 false 不会自动确认\nchannel.basicConsume(\"work\",false,new DefaultConsumer(channel){\n\t@Override\n\tpublic void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {\n        System.out.println(\"消费者--1：\"+new String(body));\n        // 参数1：确认队列中哪个具体消息 参数2：是否开启多个消息同时确认\n        channel.basicAck(envelope.getDeliveryTag(),false);\n    }\n});\n```\n\n- 设置通道一次只能消费一个消息\n- 关闭消息的自动确认，开启手动确认消息\n\n![image-20210415193731262](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210415193731.png)\n\n![image-20210415193743820](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210415193743.png)\n\n### 第三种模型（fanout）\n\n==`fanout` 扇出 也称为广播==\n\n![image-20210415194629428](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210415194629.png)\n\n在广播模式下，消息发送流程是这样的：\n\n- 可以有多个消费者\n- 每个**消费者有自己的 queue**（队列）\n- 每个**队列都要绑定到 Exchange**（交换机）\n- **生产者发送的消息，只能发送到交换机**，交换机来决定要发给哪个队列，生产者无法决定\n- 交换机把消息发送给绑定过的所有队列\n- 队列的消费者都能拿到消息，实现一条消息被多个消费者消费\n\n#### 编写生产者\n\n```java\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\n//将通道声明指定交换机 参数1：交换机名称 参数2：交换机类型 fanout 广播类型\nchannel.exchangeDeclare(\"logs\", \"fanout\");\n\n//发送消息\nchannel.basicPublish(\"logs\", \"\", null, \"fanout type message\".getBytes());\n\n//释放资源\nRabbitMQUtils.closeConnectionAndChanel(channel, connection);\n```\n\n#### 编写消费者-1\n\n```java\n//获取连接对象\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\n//通道绑定交换机\nchannel.exchangeDeclare(\"logs\", \"fanout\");\n\n//临时队列\nString queue = channel.queueDeclare().getQueue();\n\n//绑定交换机和队列\nchannel.queueBind(queue, \"logs\", \"\");\n\n//消费消息\nchannel.basicConsume(queue, true, new DefaultConsumer(channel) {\n    @Override\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,byte[] body) throws IOException {\n        System.out.println(\"消费者1==>\" + new String(body));\n    }\n});\n```\n\n#### 编写消费者-2\n\n```java\n//获取连接对象\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\n//通道绑定交换机\nchannel.exchangeDeclare(\"logs\", \"fanout\");\n\n//临时队列\nString queue = channel.queueDeclare().getQueue();\n\n//绑定交换机和队列\nchannel.queueBind(queue, \"logs\", \"\");\n\n//消费消息\nchannel.basicConsume(queue, true, new DefaultConsumer(channel) {\n    @Override\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,byte[] body) throws IOException {\n        System.out.println(\"消费者2==>\" + new String(body));\n    }\n});\n```\n\n### 第四种模型（Routing）\n\n#### Routing 之订阅模型 -Direct（直连）\n\n==在 Fanout 模式中，一条消息，会被所有订阅的队列消息。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到 Direct 类型的 Exchange。==\n\n在 Direct 模型下：\n\n- 队列与交换机的绑定，不能是任意绑定了，而是要指定一个 `RoutingKey`（路由 key）\n- 消息的发送方在向 Exchange 发送消息是，也必须指定消息的 `RoutingKey`\n- Exchange 不再把消息交给每一个绑定的队列，而是根据消息的 `RoutingKey` 进行判断，只有队列的`RoutingKey` 与消息的 `RoutingKey` 完全一致，才会接收到消息\n\n流程：\n\n![image-20210415201126889](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210415201126.png)\n\n图解：\n\n- P：生产者，向 Exchange 发送消息，发送消息是，会指定一个 Routing Key\n- X：Exchange（交换机），接收生产者消息，然后把消息递交给与 Routing Key 完全匹配的队列\n- C1：消费者，其所在队列指定了需要 Routing Key 为 error 的消息\n- C2：消费者，其所在队列指定了需要 Routing Key 为 info、 error、warning 的消息\n\n##### 编写生产者\n\n```java\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\nString exchangeName = \"logs_direct\";\n\n//将通道声明指定交换机 参数1：交换机名称 参数2：交换机类型 direct 路由模式\nchannel.exchangeDeclare(exchangeName, \"direct\");\n\n//发送消息\nString routingKey = \"info\";\nchannel.basicPublish(exchangeName, routingKey, null, (\"这是direct模型发布对的基于routing key[\"+routingKey+\"]==>发送的消息\").getBytes());\n\n//释放资源\nRabbitMQUtils.closeConnectionAndChanel(channel, connection);\n```\n\n##### 编写消费者-1\n\n```java\n//获取连接对象\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\nString exchangeName = \"logs_direct\";\n\n//临时队列\nString queue = channel.queueDeclare().getQueue();\n\n//基于route key绑定队列和交换机\nchannel.queueBind(queue, exchangeName, \"error\");\n\n//获取消费的消息\nchannel.basicConsume(queue, true, new DefaultConsumer(channel) {\n    @Override\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,byte[] body) throws IOException {\n        System.out.println(\"消费者1==>\" + new String(body));\n    }\n});\n```\n\n##### 编写消费者-2\n\n```java\n//获取连接对象\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\nString exchangeName = \"logs_direct\";\n\n//临时队列\nString queue = channel.queueDeclare().getQueue();\n\n//绑定交换机和临时队列\nchannel.queueBind(queue, exchangeName, \"info\");\nchannel.queueBind(queue, exchangeName, \"error\");\nchannel.queueBind(queue, exchangeName, \"warning\");\n\n//消费消息\nchannel.basicConsume(queue, true, new DefaultConsumer(channel) {\n    @Override\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,byte[] body) throws IOException {\n        System.out.println(\"消费者2==>\" + new String(body));\n    }\n});\n```\n\n#### Routing 之订阅模型 -Topic\n\n`Topic` 类型的 `Exchange` 与 `Direct` 相比，都可以根据 `RoutingKey` 把消息路由到不用的队列。只不过 `Topic` 类型的 `Exchange` 可以让队列在绑定 `RoutingKey` 的时候使用通配符！这种模型 `RoutingKey` 一般都是由一个或多个单词组成，多个单词之间以“.”分割，例如： `item.insert`\n\n![image-20210416092201943](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210416092208.png)\n\n##### 编写生产者\n\n```java\n//获取连接对象\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\n//声明交换机以及交换机类型 topic\nchannel.exchangeDeclare(\"topics\", \"topic\");\n\n//定义路由key\nString routingKey = \"user.save\";\n//发送消息\nchannel.basicPublish(\"topics\", routingKey, null, (\"这里是topic动态路由模型，routingKey：\" + routingKey).getBytes());\n\n//释放资源\nRabbitMQUtils.closeConnectionAndChanel(channel, connection);\n```\n\n##### 编写消费者-1\n\n```java\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\n//创建一个临时队列\nString queue = channel.queueDeclare().getQueue();\n//绑定队列和交换机，动态通配符形式routingKey\nchannel.queueBind(queue, \"topics\", \"user.*\");\n\n//消费消息\nchannel.basicConsume(queue, true, new DefaultConsumer(channel) {\n    @Override\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties,byte[] body) throws IOException {\n        System.out.println(\"消费者1 ==>\" + new String(body));\n    }\n});\n```\n\n##### 编写消费者-2\n\n```java\nConnection connection = RabbitMQUtils.getConnection();\nChannel channel = connection.createChannel();\n\n//创建一个临时队列\nString queue = channel.queueDeclare().getQueue();\n//绑定队列和交换机，动态通配符形式routingKey\nchannel.queueBind(queue, \"topics\", \"user.#\");\n\n//消费消息\nchannel.basicConsume(queue, true, new DefaultConsumer(channel) {\n    @Override\n    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {\n        System.out.println(\"消费者2 ==>\" + new String(body));\n    }\n});\n```\n\n##### 结果：\n\n![image-20210416094708394](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210416094708.png)\n\n![image-20210416094717636](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210416094717.png)\n\n## SpringBoot 整合 RabbitMQ\n\n### 搭建初始环境\n\n#### 引入依赖\n\n```xml\n<!-- 引入spring-rabbitmq依赖-->\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-amqp</artifactId>\n</dependency>\n```\n\n#### 配置配置文件\n\n```yaml\nspring:\n    application:\n        name: rabbitmq-springboot\n    rabbitmq:\n        host: 192.168.80.140\n        port: 5672\n        username: ems\n        password: ems\n        virtual-host: /ems\n```\n\n==`RabbitTemplate` 用来简化操作 使用时候直接在项目中注入即可使用==\n\n### HelloWorld 模型\n\n#### 编写生产者\n\n```java\n//注入rabbitTemplate\n@Autowired\nprivate RabbitTemplate rabbitTemplate;\n\n//hello world\n@Test\npublic void testHello() {\n    rabbitTemplate.convertAndSend(\"hello\", \"hello world\");\n}\n```\n\n#### 编写消费者\n\n```java\n@Component  //持久化 不独占 不是自动删除队列\n@RabbitListener(queuesToDeclare = @Queue(\"hello\"))\npublic class HelloConsumer {\n\n    @RabbitHandler\n    public void read(String message) {\n        System.out.println(\"message==\" + message);\n    }\n}\n```\n\n### Work 模型\n\n#### 编写生产者\n\n```java\n//注入rabbitTemplate\n@Autowired\nprivate RabbitTemplate rabbitTemplate;\n\n//work\n@Test\npublic void testWork() {\n    for (int i = 0; i < 10; i++) {\n        rabbitTemplate.convertAndSend(\"work\", \"work模型\" + i);\n    }\n}\n```\n\n#### 编写消费者\n\n```java\n@Component\npublic class WorkConsumer {\n    //一个消费者\n    @RabbitListener(queuesToDeclare = @Queue(\"work\"))\n    public void read1(String message) {\n        System.out.println(\"message1=\" + message);\n    }\n\n    //二个消费者\n    @RabbitListener(queuesToDeclare = @Queue(\"work\"))\n    public void read2(String message) {\n        System.out.println(\"message2=\" + message);\n    }\n}\n```\n\n==**说明：默认在 Spring AMQP 实现中 Work 这种方式就是公平调度，如果需要实现能者多劳需要额外配置**==\n\n### Fanout 广播模型\n\n#### 编写生产者\n\n```java\n//注入rabbitTemplate\n@Autowired\nprivate RabbitTemplate rabbitTemplate;\n\n//fanout 广播\n@Test\npublic void testFanout() {\n    rabbitTemplate.convertAndSend(\"logs\", \"\", \"Fanout的模型发送的消息\");\n}\n```\n\n#### 编写消费者-1\n\n```java\n@RabbitListener(bindings = {\n    @QueueBinding(\n        value = @Queue,//绑定临时队列\n        exchange = @Exchange(value = \"logs\", type = \"fanout\") //绑定的交换机\n    )\n})\npublic void read1(String message) {\n    System.out.println(\"message1=\"+message);\n}\n```\n\n#### 编写消费者-2\n\n```java\n@RabbitListener(bindings = {\n    @QueueBinding(\n        value = @Queue,//绑定临时队列\n        exchange = @Exchange(value = \"logs\", type = \"fanout\") //绑定的交换机\n    )\n})\npublic void read2(String message) {\n    System.out.println(\"message2=\"+message);\n}\n```\n\n### Routing 路由模型\n\n#### 编写生产者\n\n```java\n//注入rabbitTemplate\n@Autowired\nprivate RabbitTemplate rabbitTemplate;\n\n//routing 路由模式\n@Test\npublic void testRoute() {\n    rabbitTemplate.convertAndSend(\"directs\", \"info\", \"发送info的key的路由信息\");\n}\n```\n\n#### 编写消费者-1\n\n```java\n@RabbitListener(bindings = {\n    @QueueBinding(\n        value = @Queue, //创建临时队列\n        exchange = @Exchange(value = \"directs\", type = \"direct\"), //自定义交换机名称和类型\n        key = {\"info\", \"error\", \"warn\"}\n    )\n})\npublic void read1(String message) {\n    System.out.println(\"message1==>\" + message);\n}\n```\n\n#### 编写消费者-2\n\n```java\n@RabbitListener(bindings = {\n    @QueueBinding(\n        value = @Queue, //创建临时队列\n        exchange = @Exchange(value = \"directs\", type = \"direct\"), //自定义交换机名称和类型\n        key = {\"info\"}\n    )\n})\npublic void read2(String message) {\n    System.out.println(\"message1==>\" + message);\n}\n```\n\n### Topic 动态路由模型\n\n#### 编写生产者\n\n```java\n//注入rabbitTemplate\n@Autowired\nprivate RabbitTemplate rabbitTemplate;\n\n//topic 动态路由 订阅模式\n@Test\npublic void testTopic() {\n    rabbitTemplate.convertAndSend(\"topics\", \"user.save\", \"user.save 路由消息\");\n}\n```\n\n#### 编写消费者-1\n\n```java\n@RabbitListener(bindings = {\n    @QueueBinding(\n        value = @Queue,\n        exchange = @Exchange(type = \"topic\", value = \"topics\"),\n        key = {\"user.save\", \"user.*\"}\n    )\n})\npublic void read1(String message) {\n    System.out.println(\"message1==>\" + message);\n}\n```\n\n#### 编写消费者-2\n\n```java\n@RabbitListener(bindings = {\n    @QueueBinding(\n        value = @Queue,\n        exchange = @Exchange(type = \"topic\", value = \"topics\"),\n        key = {\"user.save\", \"user.*\"}\n    )\n})\npublic void read2(String message) {\n    System.out.println(\"message2==>\" + message);\n}\n```\n\n### MQ 的应用场景\n\n#### 异步处理\n\n==场景说明：用户注册后，需要发注册邮件和注册短信，传统的做法有两种 1. 串行的方式 2. 并行的方式==\n\n- **串行方式：**讲注册信息写入数据库后，发送注册邮件， 再发送注册短信，以上三个任务全部完成后才返回给客户端。这有一个问题是，邮件，短信并不是必须的，它只是一个通知，而这种做法让客户端等待没有必要等待没有必要等待的东西。\n- **并行方式：**将信息写入数据库后，发送邮件的同时，发送短信，以上三个任务完成后，返回客户端，并行的方式能提高处理的时间。\n- **消息队列：**假设三个业务点分别使用 50ms，串行方式使用时间 150ms，并行使用时间 100ms。虽然并行已经提高了处理时间，但是，前面说过，邮件和短信不对我正常的使用网站没有任何影响，客户端没有必要等着其发送完成才显示注册成功，应该是写入数据库后就返回。引入消息队列后，把发送邮件，短信等不是必须的业务逻辑异步处理。\n\n#### 应用解耦\n\n==场景说明：双 11 是购物狂欢节，用户下单后，订单系统需要通知库存系统，传统的做法就是订单系统调用库存系统的接口==\n\n这样做法有一个缺点：\n\n当库存系统出现故障时，订单就会失效。订单系统和库存系统高耦合，引入消息队列\n\n- **订单系统：**用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功\n- **库存系统：**订阅下单的消息，获取下单消息，进行库操作。就算库存系统出现故障，消息队列也能保证消息的可靠投递，不会导致消息丢失\n\n#### 流量削锋\n\n==场景说明：秒杀活动，一般会因为流量过大，导致应用挂掉，为了解决这个问题，一般在应用前端加入消息队列。==\n\n作用：\n\n1. 可以控制活动人数，超过此一定阈值的订单直接丢弃\n2. 可以缓解短时间的高流量压垮应用\n","tags":["技巧","笔记","RabbitMQ"],"categories":["中间件"]},{"title":"Java 多线程与线程同步","slug":"多线程与线程同步","url":"/2021/04/17/dcfce7ce.html","content":"## 多线程\n\n### Process 与 Thread（进程与线程）\n\n- 说起进程，就不得不说下**程序**。程序是指令和数据的有序集合，其本身没有任何运行的含义，是一个静态的概念。\n- 而**进程**则是执行程序的一次执行过程，它是一个动态的概念。是系统资源分配的单位。\n- 通常在一个进程中可以包含若干个**线程**，当然一个进程中至少有一个线程，不然没有存在的意义。线程是CPU调度和执行的单位。\n\n### 多线程核心概念\n\n- 线程就是独立的执行路径；\n- 在程序运行时，就是没有自己创建线程，后台也会有多个线程，如主线程、gc线程；\n- main()线程称之为主线程，为系统的入口，用于执行整个程序；\n- 在一个进程中，如果开辟了多个线程，线程的运行由调度器安排调度，调度器是与操作系统紧密相关的，先后顺序是不能人为干预的；\n- 对同一份资源操作时，会存在资 源抢占问题，需要加入并发控制；\n- 线程会带来额外的开销，如CPU调度时间，并发控制开销；\n- 每个线程在自己的工作内存交互，内存控制不当会造成数据不一致；\n\n### 线程创建\n\n共有三种方式：Thread、Runnable、Callable\n\n- Thread.class -> 继承Thread类（重点）\n- Runnable接口 -> 实现Runnable接口（重点）\n- Callable接口 -> 实现Callable接口（了解）\n\n#### Thread\n\n1. 自定义线程类继承**Thread类**\n2. 重写**run()**方法，编写线程执行体\n3. 创建线程对象，调用**start()**方法启动线程\n\n```java\npackage thread;\n\n/**\n * 创建线程方式一：继承Thread类，重写run()方法，调用start()开启线程\n * 总结：注意，线程开启不一定立即执行，由cpu调度执行\n * @author IRVING\n * @create 2021-04-02 14:59\n */\npublic class TestThread extends Thread {\n\n    @Override\n    public void run() {\n        //run方法线程体\n        for (int i = 0; i < 20; i++) {\n            System.out.println(\"我在看代码---\" + i);\n        }\n    }\n\n    public static void main(String[] args) {\n        //main线程，主线程\n\n        //创建一个线程对象\n        TestThread testThread = new TestThread();\n\n        //调用start()方法开启线程\n        testThread.start();\n\n        for (int i = 0; i < 20; i++) {\n            System.out.println(\"我在学习多线程---\" + i);\n        }\n    }\n}\n```\n\n#### Runnable\n\n1. 定义MyRunnable类实现**Runnable类**\n2. 实现**run()**方法，编写线程执行体\n3. 创建线程对象，调用**start()**方法启动线程\n\n```java\npackage thread;\n\n/**\n * 创建线程方式2：实现Runnable接口，重写run方法，执行线程需要丢入runnable接口实现类，调用start()方法\n *\n * @author IRVING\n * @create 2021-04-02 15:13\n */\npublic class TestThread2 implements Runnable {\n    @Override\n    public void run() {\n        //run方法线程体\n        for (int i = 0; i < 20; i++) {\n            System.out.println(\"我在看代码---\" + i);\n        }\n    }\n\n    public static void main(String[] args) {\n\n        //创建一个runnable接口实现类对象\n        TestThread2 testThread2 = new TestThread2();\n\n        //创建线程对象，通过线程对象来开启我们的线程，代理\n        //Thread thread = new Thread(testThread2);\n        //\n        //thread.start();\n\n        new Thread(testThread2).start();\n\n        for (int i = 0; i < 20; i++) {\n            System.out.println(\"我在学习多线程---\" + i);\n        }\n    }\n}\n```\n\n#### 小结\n\n- <u>*继承Thread类*</u>\n  - 子类继承Thread类具备多线程能力\n  - 启动线程：子类对象.start()\n  - **不建议使用：避免OOP单继承局限性**\n- <u>*实现Runnable接口*</u>\n  - 实现接口Runnable具备多线程能力\n  - 启动线程：传入目标对象+Thread对象.start()\n  - **推荐使用：避免单线程局限性，灵活方便，方便同一个对象被多个线程使用**\n\n```java\npackage thread;\n\nimport sun.applet.Main;\n\n/**\n * 多个线程同时操作同一个对象\n * 卖火车票的例子\n * 发现问题：多个线程操作同一个资源的情况下，线程不安全，数据紊乱\n *\n * @author IRVING\n * @create 2021-04-02 15:27\n */\npublic class TestThread3 implements Runnable {\n\n    //票数\n    private int ticketNums = 10;\n\n    @Override\n    public void run() {\n        while (true) {\n            if (ticketNums <= 0) {\n                break;\n            }\n            //模拟延时\n            try {\n                Thread.sleep(200);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n\n            System.out.println(Thread.currentThread().getName() + \"--->拿到了第\" + ticketNums-- + \"张票\");\n        }\n    }\n\n    public static void main(String[] args) {\n        TestThread3 t1 = new TestThread3();\n\n        new Thread(t1,\"小明\").start();\n        new Thread(t1,\"小黄\").start();\n        new Thread(t1,\"小黑\").start();\n    }\n}\n\n```\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210402153415.png\" alt=\"image-20210402153407320\" style=\"zoom: 33%;\" />\n\n#### 模拟龟兔赛跑\n\n```java\npackage thread;\n\n/**\n * 模拟龟兔赛跑\n *\n * @author IRVING\n * @create 2021-04-02 22:45\n */\npublic class Race implements Runnable {\n\n    //胜利者\n    private static String winner;\n\n    @Override\n    public void run() {\n        for (int i = 0; i <= 100; i++) {\n            //模拟兔子休息\n            if(Thread.currentThread().getName().equals(\"兔子\") && i%10==0){\n                try {\n                    Thread.sleep(10);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            //判断比赛是否结束\n            boolean flag = gameOver(i);\n            if (flag) {\n                break;\n            }\n            System.out.println(Thread.currentThread().getName() + \"-->跑了\" + i + \"步\");\n        }\n    }\n\n    //判断是否完成\n    private boolean gameOver(int steps) {\n        //判断是否有胜利者\n        if (winner != null) {\n            return true;\n        }\n        {\n            if (steps >= 100) {\n                winner = Thread.currentThread().getName();\n                System.out.println(\"winner is \" + winner);\n                return true;\n            }\n        }\n        return false;\n    }\n\n    public static void main(String[] args) {\n        Race race = new Race();\n\n        new Thread(race,\"乌龟\").start();\n        new Thread(race,\"兔子\").start();\n    }\n}\n\n```\n\n#### Callable接口（了解）\n\n1. 实现Callable接口，需要返回值类型\n2. 重写call方法，需要抛出异常\n3. 创建目标对象\n4. 创建执行服务：ExecutorService ser = Executors.newFixedThreadPool(1);\n5. 提交执行：Future<Boolean> result = ser.submit(callable);\n6. 获取结果：boolean r1 = result.get();\n7. 关闭服务：ser.shutdownNow();\n\n```java\npackage thread;\n\nimport java.util.concurrent.*;\n\n/**\n * 线程创建方式三：实现Callable接口\n * 总结：callable的好处： 1.有返回值 2.可以抛出异常\n * @author IRVING\n * @create 2021-04-02 23:53\n */\npublic class TestCallable implements Callable<Boolean> {\n    @Override\n    public Boolean call() throws Exception {\n        for (int i = 0; i < 20; i++) {\n            System.out.println(\"我在看代码---\" + i);\n        }\n        return true;\n    }\n\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n\n        //创建一个runnable接口实现类对象\n        TestCallable testCallable = new TestCallable();\n        TestCallable testCallable1 = new TestCallable();\n        TestCallable testCallable2 = new TestCallable();\n\n        //创建执行服务\n        ExecutorService ser = Executors.newFixedThreadPool(3);\n\n        //提交执行\n        Future<Boolean> r1 = ser.submit(testCallable);\n        Future<Boolean> r2 = ser.submit(testCallable1);\n        Future<Boolean> r3 = ser.submit(testCallable2);\n\n        //获取结果\n        boolean rs1 = r1.get();\n        boolean rs2 = r2.get();\n        boolean rs3 = r3.get();\n\n        //关闭服务\n        ser.shutdownNow();\n\n\n        for (int i = 0; i < 20; i++) {\n            System.out.println(\"我在学习多线程---\" + i);\n        }\n    }\n}\n\n```\n\n#### 静态代理\n\n```java\npackage proxy;\n\n/**\n * 实现静态代理\n * 静态代理模式总结：\n * 真实对象和代理对象都要实现同一个接口\n * 代理对象要代理真实角色\n * 好处：\n * 代理对象可以做很多真实对象做不了的事情\n * 真实对象专注做自己的事情\n *\n * @author IRVING\n * @create 2021-04-03 0:01\n */\npublic class StaticProxy {\n    public static void main(String[] args) {\n        //你要结婚\n        You you = new You();\n\n        //线程中的代理模式\n        new Thread(() -> System.out.println(\"我爱你\")).start();\n\n        new WeddingCompany(new You()).HappyMarry();\n    }\n}\n\ninterface Marry {\n    void HappyMarry();\n}\n\n//真实角色，你去结婚\nclass You implements Marry {\n\n    @Override\n    public void HappyMarry() {\n        System.out.println(\"王老师要结婚了，超开心！\");\n    }\n}\n\n//代理角色，帮助你结婚\nclass WeddingCompany implements Marry {\n\n    //代理谁 --> 真实角色\n    private Marry target;\n\n    public WeddingCompany(Marry target) {\n        this.target = target;\n    }\n\n    @Override\n    public void HappyMarry() {\n        before();\n        this.target.HappyMarry(); //这就是真实对象\n        after();\n    }\n\n    private void after() {\n        System.out.println(\"结婚之后，收尾款\");\n    }\n\n    private void before() {\n        System.out.println(\"结婚之前，布置现场\");\n    }\n}\n\n```\n\n#### Lambda表达式\n\n- **为什么要使用lambda表达式**\n  - 避免匿名内部类定义过多\n  - 可以让你的代码看起来很简洁\n  - 去掉了一堆没有意义的代码，只留下核心逻辑\n- **注意：<u>接口必须为函数式接口（只有一个抽象方法）</u>**\n\n```java\npackage lambda;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\n/**\n * @author IRVING\n * @create 2021-04-01 23:53\n */\npublic class TestLambda {\n    public static void main(String[] args) {\n        \n\n        //1.使用接口实现类\n        Comparator comparator = new MyComparetor();\n\n        //2.使用匿名内部类\n        Comparator comparator1 = new Comparator() {\n            @Override\n            public int compare(int a, int b) {\n                return a-b;\n            }\n        };\n\n        //3.使用lambda表达式来实现接口\n        Comparator comparator2 = (a,b) -> a-b;\n    }\n}\n\nclass MyComparetor implements Comparator {\n\n    @Override\n    public int compare(int a, int b) {\n        return 0;\n    }\n}\n\ninterface Comparator {\n    int compare(int a, int b);\n}\n\n```\n\n- ##### 总结：\n\n  - lambda表达式只能有一行代码的情况下才能简化成一行，如果有多行，那么就用代码块包裹\n  - 前提是接口为函数式接口（接口中只有一个方法）\n  - 多个参数也可以去掉参数类型，要去掉就都去掉，必须加上括号\n\n### Thread类\n\n#### 线程状态\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210403003514.jpeg)\n\n1. **新建(NEW)**：新创建了一个线程对象。\n\n2. **可运行(RUNNABLE)**：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 。\n\n3. **运行(RUNNING)**：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。\n\n4. **阻塞(BLOCKED)**：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种： \n\n   > (一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。\n   > (二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。\n   > (三). 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。\n\n5. **死亡(DEAD)**：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。\n\n#### 线程方法\n\n|              方法              |                    说明                    |\n| :----------------------------: | :----------------------------------------: |\n|  setPriority(int newPriority)  |              更改线程的优先级              |\n| static void sleep(long millis) |   在指定毫秒数内让当前正在执行的线程休眠   |\n|          void join()           |               等待该线程终止               |\n|      static void yield()       | 暂停当前正在执行的线程对象，并执行其他线程 |\n|        void interrupt()        |           中断线程，别用这个方式           |\n|       boolean isAlive()        |          测试线程是否处于活动状态          |\n\n#### 停止线程\n\n- 不推荐使用JDK提供的stop()、destroy()方法。*<u>【已废弃】</u>*\n- 推荐线程自己停止下来\n- 建议使用一个标志位进行终止变量，当flag=false，则终止线程运行\n\n```java\npackage thread;\n\nimport com.sun.org.apache.bcel.internal.generic.NEW;\n\n/**\n * 测试stop\n * 1.建议线程正常停止 --> 利用次数，不建议死循环\n * 2.建议使用标志位 -->设置一个标志位\n * 3.不要使用stop()获取destroy()等过时或者JDK不建议使用的方法\n *\n * @author IRVING\n * @create 2021-04-03 0:45\n */\npublic class TestStop implements Runnable {\n\n    //1.设置一个标志位\n    private boolean flag = true;\n\n    @Override\n    public void run() {\n        int i = 0;\n        while (flag) {\n            System.out.println(\"run...Thread\" + i++);\n\n        }\n    }\n\n    //2.设置一个公开的方法停止线程，转换标志位\n    public void stop() {\n        this.flag = false;\n    }\n\n    public static void main(String[] args) {\n        TestStop testStop = new TestStop();\n\n        new Thread(testStop).start();\n\n        for (int i = 0; i < 1000; i++) {\n            System.out.println(\"main\" + i);\n            if (i == 900) {\n                //调用stop方法切换标志位，让线程停止\n                testStop.stop();\n                System.out.println(\"线程该停止了\");\n            }\n        }\n    }\n}\n\n```\n\n#### 线程休眠\n\n- sleep(时间)指定当前线程线程阻塞的毫秒数\n- sleep存在异常InterruptedException\n- sleep时间达到后线程进入就绪状态\n- sleep可以模拟网络延时，倒计时等\n- 每一个对象都有一个锁，sleep不会释放锁\n\n#### 线程礼让\n\n- 礼让线程，让当前正在执行的线程暂停，但不堵塞\n- 将线程从运行状态转为就绪状态\n- **<u>让cpu重新调度，礼让不一定成功，看cpu心情</u>*\n\n```java\npackage thread;\n\n/**\n * 测试礼让线程\n * 礼让不一定成功，看cpu心情\n * @author IRVING\n * @create 2021-04-03 1:00\n */\npublic class TestYield {\n\n    public static void main(String[] args) {\n        MyYield myYield = new MyYield();\n\n        new Thread(myYield,\"a\").start();\n        new Thread(myYield,\"b\").start();\n    }\n}\n\nclass MyYield implements Runnable{\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName()+\"线程正在执行\");\n        //礼让\n        Thread.yield();\n        System.out.println(Thread.currentThread().getName()+\"线程停止执行\");\n    }\n}\n\n```\n\n#### Join\n\n- Join合并线程，待此线程执行完成后，再执行其他线程，其他线程阻塞\n- 可以想象成插队\n\n#### 观测线程状态\n\n```java\npackage thread;\n\n/**\n * 观察测试线程的状态\n *\n * @author IRVING\n * @create 2021-04-03 1:11\n */\npublic class TestState {\n\n    public static void main(String[] args) throws InterruptedException {\n        Thread thread = new Thread(() -> {\n            for (int i = 0; i < 5; i++) {\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            System.out.println(\"///\");\n        });\n\n        //观察状态\n        Thread.State state = thread.getState();\n        System.out.println(state);\n\n        //观察启动后\n        thread.start();\n        state = thread.getState();\n        System.out.println(state);\n\n        //只要线程不终止，就一直输出状态\n        while (state != Thread.State.TERMINATED){\n            Thread.sleep(100);\n            //更新线程状态\n            state = thread.getState();\n            System.out.println(state);\n        }\n    }\n}\n\n```\n\n#### 线程优先级\n\n- Java提供一个线程调度器来监控程序中启动后进入就绪状态的所有线程，线程调度器按照优先级决定应该调度那个线程来执行\n- 线程的优先级用数字表示，范围从1~10\n  - Thread.MIN_PRIORITY = 1\n  - Thread.MAX_PRIORITY = 10\n  - Thread.NORM_PRIORITY = 5\n- 使用以下方式改变或获取优先级\n  - getPriority()、setPriority(int xxx)\n\n*<u>**注意：优先级的设定一定要在启动之前；优先级低只是意味着获得调度的概率低，并不是优先级低就不会被调用了，这都是看cpu的调度**</u>*\n\n#### 守护(daemon)线程\n\n- 线程分为**用户线程**和**守护线程**\n- 虚拟机必须确保用户线程执行完毕\n- 虚拟机不用等待守护线程执行完毕\n- 如，后台记录操作日志，监控内存，垃圾回收等待\n\n```java\npackage thread;\n\n/**\n * 测试守护线程\n * 上帝守护你\n *\n * @author IRVING\n * @create 2021-04-03 1:28\n */\npublic class TestDaemon {\n\n    public static void main(String[] args) {\n        God god = new God();\n        You you = new You();\n\n        Thread thread = new Thread(god);\n        //默认是false表示是用户线程，正常的线程都是用户线程\n        thread.setDaemon(true);\n        thread.start();\n\n        new Thread(you).start();\n    }\n}\n\n//上帝\nclass God implements Runnable {\n    @Override\n    public void run() {\n        while (true){\n            System.out.println(\"====上帝保佑你\");\n        }\n    }\n}\n\n//你\nclass You implements Runnable {\n    @Override\n    public void run() {\n        for (int i = 0; i < 36500; i++) {\n            System.out.println(\"你一生都开心的或者\");\n        }\n        System.out.println(\"====goodbyte\");\n    }\n}\n\n```\n\n### 多线程常见面试题\n\n#### 1、Java中实现多线程有几种方法\n\n- 继承Thread类\n- 实现Runnable接口\n- 实现Callable接口，通过FutureTask包装器来创建Thread线程\n- 使用ExecutorService、Callable、Future实现有返回值的多线程（实际上就是使用ExecutorService管理上面三种方式）\n\n#### 2、如何停止一个正在运行的线程\n\n- 使用退出标志，使线程正常退出，也就是当线程的run方法执行完毕后终止\n- 使用stop、destroy方法强行停止线程，不过不推荐这个方法\n- 使用interrupt方法中断线程\n\n#### 3、notify()和notifyAll()有什么区别\n\n- notifyAll()唤醒所有等待线程，notify()随机唤醒一个\n- notify()使用不当可能会造成死锁\n\n#### 4、sleep()和wait() 有什么区别？\n\n- 来自不同的类，sleep()Thread类的一个静态方法，wait()是Object类的一个成员方法\n- sleep()不会释放锁，执行此方法的线程暂停指定的时间\n- 而wait()会释放锁，进入等待该对象的等待锁定池中         \n\n#### 5、Thread 类中的start() 和 run() 方法有什么区别？\n\n- start()方法是用来启动被创建的线程，此时线程为就绪状态，等待cpu的调度执行，而cpu调度执行时就是执行run()方法中的内容，当run()方法完成后，线程也就终止了。\n- 直接调用run()方法并不能起到多线程的作用，只是作为普通方法进行调用，程序中也就只有main主线程一个线程。\n\n#### 6、为什么wait, notify 和 notifyAll这些方法不在thread类里面？\n\n明显的原因是Java中提供的锁是对象级的而不是线程级的，每个对象都有一把锁，通过线程获得。锁是属于对象的。\n\n## 线程同步\n\n多个线程操作同一个资源\n\n### 并发\n\n<u>并发：**同一个对象**被**多个线程**同时操作</u>\n\n处理多线程问题时，多个线程访问同一个对象，并且某些线程还想修改这个对象。这时候我们就需要线程同步，线程同步其实就是一种等待机制，多个需要同时访问此对象的线程进入这个**对象的等待池**形成队列，等待前面的线程使用完毕，下一个线程再使用。\n\n### 队列和锁\n\n**队列+锁**才能解决多线程的安全性\n\n### 线程同步\n\n由于同一进程的多个线程共享一块存储空间，在带来方便的同时，也带来了访问冲突问题，为了保证数据在方法中被访问时的正确性，在访问时加入**锁机制synchronized**，当一个线程获得对象的排它锁，独占资源，其他线程必须等待，使用后释放锁即可。但存在以下问题：\n\n- 一个线程持有锁会导致其他所有需要此锁的线程挂起；\n- 在多线程竞争下，加锁，释放锁会导致比较多的上下文切换和调度延时，引起性能问题；\n- 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能问题；\n\n### 同步方法\n\n- synchronized关键字，它包括两种用法：synchronized方法和synchronized块\n- synchronized方法控制“对象”的访问，每个对象对应一把锁，每个synchronized方法都必须获得调用该方法的对象的锁才能执行，否则线程会阻塞，方法一旦执行，就独占该锁，直到该方法返回才释放锁，后面被阻塞的线程才能获得这个锁，继续执行。\n- *<u>**缺陷：若将一个大的方法声明为synchronized将会影响效率**</u>*\n\n### 同步块\n\n- 同步块：synchronized**(Obj)**{}\n- Obj称之为同步监视器\n  - Obj可以是任何对象，但是推荐使用共享资源作为同步监视器\n  - 同步方法中无需指定同步监视器，因为同步方法的同步监视器就是this，就是这个对象本身，或者是class\n- 同步监视器的执行过程\n  1. 第一个线程访问，锁定同步监视器，执行其中代码\n  2. 第二个线程访问，发现同步监视器被锁定，无法访问\n  3. 第一个线程访问完毕，解锁同步监视器\n  4. 第二个线程方法，发现同步监视器没有锁，然后锁定并访问\n\n### 死锁\n\n多个线程各自占有一些共享资源，并且互相等待其他线程占有的资源才能运行，而导致两个或者多个线程都在等待对方释放资源，都停止执行的情形，某一个同步块同时拥有**“两个以上对象的锁”**时，就可能会发生“死锁”的问题。\n\n```java\npackage sync;\n\n/**\n * 死锁：多个线程互相抱着对方需要的资源，然后形成僵持\n *\n * @author IRVING\n * @create 2021-04-03 14:07\n */\npublic class DeadLock {\n\n    public static void main(String[] args) {\n        Makeup g1 = new Makeup(0,\"灰姑凉\");\n        Makeup g2 = new Makeup(1,\"白雪公主\");\n\n        g1.start();\n        g2.start();\n    }\n}\n\n//口红\nclass Lipstick {\n\n}\n\n//镜子\nclass Mirror {\n\n}\n\nclass Makeup extends Thread {\n\n    //需要的资源只有一份，用static来保证只有一份\n    static Lipstick lipstick = new Lipstick();\n    static Mirror mirror = new Mirror();\n\n    //选择\n    int choice;\n    //使用化妆品的人\n    String name;\n\n    Makeup(int choice, String name) {\n        this.choice = choice;\n        this.name = name;\n    }\n\n    @Override\n    public void run() {\n        //化妆\n        try {\n            makeup();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    //化妆，互相持有对方的锁，就是需要对方的资源\n    private void makeup() throws InterruptedException {\n        if (choice == 0) {\n            //获得口红的锁\n            synchronized (lipstick) {\n                System.out.println(this.name + \"获得口红的锁\");\n                Thread.sleep(1000);\n                //一秒钟后想获得镜子的锁\n                synchronized (mirror) {\n                    System.out.println(this.name + \"获得镜子的锁\");\n                }\n            }\n        } else {\n            //获得镜子的锁\n            synchronized (lipstick) {\n                System.out.println(this.name + \"获得镜子的锁\");\n                Thread.sleep(2000);\n                //两秒钟后想获得口红的锁\n                synchronized (mirror) {\n                    System.out.println(this.name + \"获得口红的锁\");\n                }\n            }\n        }\n    }\n}\n\n```\n\n产生死锁的四个必要条件：\n\n- 互斥条件：一个资源每次只能被一个进程使用\n- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放\n- 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺\n- 循环等待条件：若干个进程之间形成一种头尾相接的循环等待资源关系\n\n### Lock锁\n\n常用实现类：ReentrantLock（可重入锁）\n\n#### synchronized与Lock的对比\n\n- Lock是显式锁（手动开启和关闭锁，别忘记关闭锁），synchronized是隐式锁，除了作用域自动释放\n- Lock只有代码块锁，synchronized有代码块和方法锁\n- 使用Lock锁，JVM将花费较少的时间来调度线程，性能更好。并且具有更好的扩展性（提供更多的子类）\n- 优先使用顺序：\n  - Lock > 同步代码块（已经进入了方法体，分配了相应资源）> 同步方法（在方法体之外）\n\n### 线程通信\n\nJava提供了几个方法解决线程之间的通信问题\n\n| 方法名             | 作用                                                         |\n| ------------------ | ------------------------------------------------------------ |\n| wait()             | 表示线程一直等待，直到其他线程通知，与sleep不同，会释放锁    |\n| wait(long timeout) | 指定等待的毫秒数                                             |\n| notify()           | 唤醒一个处于等待状态的线程                                   |\n| notifyAll()        | 唤醒同一对象上所有调用wait()方法的线程，优先级别高的线程优先调度 |\n\n#### 并发协作模型“生产者/消费者模式” --> 管程法\n\n- 生产者：负责生产数据的模块\n- 消费者：负责处理数据的模块\n- 缓冲区：消费者不能直接使用生产者的数据，他们之间又个缓冲区\n\n**生产者将生产好的数据放入缓冲区，消费者从缓冲区拿出数据**\n\n#### 并发协作模型“生产者/消费者模式” --> 信号灯法\n\n通过一个标志判断是否等待/唤醒\n\n### 使用线程池\n\n- 思路：提前创建好多个线程，放入线程池中，使用时直接获取，使用完放回池中。可以避免频繁创建销毁，实现重复利用。类似生活中的公共交通工具。\n- 好处：\n  - 提高响应速度（减少了创建新线程的时间）\n  - 降低资源消耗（重复利用线程池中线程，不需要每次都创建）\n  - 便于线程管理（···）\n    - corePoolSize：核心池的大小\n    - maximumPoolSize：最大线程数\n    - keepAliveTime：线程没有任务时最多保持多长时间后会终止\n- 使用：\n  - JDK5.0起提供了线程池相关的API：**ExecutorService**和**Executors**\n  - ExecutorService：真正的线程池接口。常见子类ThreadPoolExecutor\n    - `void execute(Runnable command)`：执行任务/命令，没有返回值，一般用来执行Runnable\n    - `<T>Future<T> submit(Callable<T> task) `：执行任务，有返回值，一般用来执行Callable\n    - `void shutdown()`：关闭连接池\n  - Executors：工具类，线程池的工厂类，用于创建并返回不同类型的线程池\n\n","tags":["笔记","Java"],"categories":["后端开发"]},{"title":"分布式系统理论","slug":"分布式系统理论","url":"/2021/04/13/41166861.html","content":"\n## 什么是分布式系统？\n\n分布式是若干独立计算机的集合，这些计算机对于用户来说就像单个相关系统。\n\n分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是**利用更多的机器，处理更多的数据**。\n\n首先需要明确的是，只有当单个节点的处理能力无法满足日益增长的计算、存储任务的时候，且硬件的提升（加内存、加磁盘、使用更好的 CPU）高昂到得不偿失的时候，应用程序也不能进一步优化的时候，我们才需要考虑分布式系统。因为，分布式系统要解决的问题本身就是和单机系统一样的，而由于分布式系统多节点、通过网络通信的拓扑结构，会引入很多单机系统没有的问题，为了解决这些问题又会引入更多的机制、协议，带来更多的问题。\n\n## Dubbo 文档\n\n随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，急需**一个治理系统**确保架构有条不紊的演进。\n\n在 Dubbo 的官网文档有这样一张图\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413110820.png)\n\n### **单一应用架构**\n\n当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413110902.png)\n\n适用于小型网站，小型管理系统，将所有功能都部署到一个功能里，简单易用。\n\n**缺点：**\n\n1、性能扩展比较难\n\n2、协同开发问题\n\n3、不利于升级维护\n\n### 垂直应用架构\n\n当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的 Web 框架(MVC)是关键。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413110941.png)\n\n通过切分业务来实现各个模块独立部署，降低了维护和部署的难度，团队各司其职更易管理，性能扩展也更方便，更有针对性。\n\n缺点：公用模块无法重复利用，开发性的浪费\n\n### 分布式服务架构\n\n当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的**分布式服务框架(RPC)**是关键。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413111036.png)\n\n### 流式计算架构\n\n当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于**提高机器利用率的资源调度和治理中心**(SOA)[Service Oriented Architecture]是关键。\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413111136.png)\n\n## RPC\n\n### 什么是 RPC？\n\nRPC【Remote Procedure Call】是指远程过程调用，是一种进程间通信方式，他是一种技术的思想，而不是规范。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。\n\n也就是说两台服务器 A，B，一个应用部署在 A 服务器上，想要调用 B 服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。为什么要用 RPC 呢？就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，比如不同的系统间的通讯，甚至不同的组织间的通讯，由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用。RPC 就是要像调用本地的函数一样去调远程函数。\n\n推荐阅读文章：https://www.jianshu.com/p/2accc2840a1b\n\n### RPC 基本原理\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413111312.png)\n\n### 步骤解析：\n\n![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413111426.png)\n\nRPC 的两个核心模块：通讯、序列化！\n\n## 测试环境搭建\n\n### Dubbo\n\nApache Dubbo`|ˈdʌbəʊ|`是一款高性能、轻量级的开源 Java RPC 框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。\n\ndubbo 官网 http://dubbo.apache.org/zh-cn/index.html\n\n1.了解 Dubbo 的特性\n\n2.查看官方文档\n\n**dubbo 基本概念**\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413112417.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n**服务提供者（Provider）：**暴露服务的服务提供方，服务提供者在启动时，向注册中心注册自己提供的服务。\n\n**服务消费者（Consumer）：**调用远程服务的服务消费方，服务消费者在启动时，向注册中心订阅自己所需的服务，服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。\n\n**注册中心（Registry）：**注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者\n\n**监控中心（Monitor）：**服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心\n\n调用关系说明\n\n> 服务容器负责启动，加载，运行服务提供者。\n\n> 服务提供者在启动时，向注册中心注册自己提供的服务。\n\n> 服务消费者在启动时，向注册中心订阅自己所需的服务。\n\n> 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。\n\n> 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。\n\n> 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。\n\n### Dubbo 环境搭建\n\n- 安装 Zookeeper 注册中心\n\n  1. 点击下载[zookeeper](https://downloads.apache.org/zookeeper/zookeeper-3.5.9/apache-zookeeper-3.5.9-bin.tar.gz)，直接解压\n\n  2. 运行`/bin/zkServer.cmd`，初次运行会报错，没有`zoo.cfg`配置文件\n\n  3. 修改 zoo.cfg 配置文件\n\n     将 conf 文件夹下面的 zoo_sample.cfg 复制一份改名为 zoo.cfg 即可。\n\n<img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413155414.png\" alt=\"image-20210413155414083\" style=\"zoom: 67%;\" />\n\n### 安装 Dubbo-admin\n\ndubbo 本身并不是一个服务软件。它其实就是一个 jar 包，能够帮你的 java 程序连接到 zookeeper，并利用 zookeeper 消费、提供服务。\n\n但是为了让用户更好的管理监控众多的 dubbo 服务，官方提供了一个可视化的监控程序 dubbo-admin，不过这个监控即使不装也不影响使用。\n\n#### 1、下载 dubbo-admin\n\n地址：[点击下载](https://github.com/apache/dubbo-admin/tree/master)\n\n#### 2、解压进入目录\n\n修改 dubbo-admin\\src\\main\\resources \\application.properties 指定 zookeeper 地址\n\n```properties\nserver.port=7001\nspring.velocity.cache=false\nspring.velocity.charset=UTF-8\nspring.velocity.layout-url=/templates/default.vm\nspring.messages.fallback-to-system-locale=false\nspring.messages.basename=i18n/message\nspring.root.password=root\nspring.guest.password=guest\n\ndubbo.registry.address=zookeeper://127.0.0.1:2181\n```\n\n#### 3、在项目目录下打包 dubbo-admin\n\n```bash\nmvn clean package -Dmaven.test.skip=true\n```\n\n#### 4、执行 dubbo-admin\\target 下的 dubbo-admin-0.0.1-SNAPSHOT.jar\n\n```bash\njava -jar dubbo-admin-0.0.1-SNAPSHOT.jar\n```\n\n==【注意：zookeeper 的服务一定要打开！】==\n\n执行成功，访问[localhost:7001/](localhost:7001)，需要输入用户名/密码，默认是`root/root`\n\n登录成功，查看界面\n\n![image-20210413160348304](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413160348.png)\n\n安装完成！\n\n### SpringBoot + Dubbo + Zookeeper\n\n#### 1、框架搭建\n\n1. 启动 zookeeper ！\n\n2. IDEA 创建一个空项目\n\n3. 创建一个模块，实现服务提供者：provider-server ， 选择 web 依赖即可\n\n4. 项目创建完毕，我们写一个服务，比如卖票的服务\n\n   编写接口\n\n   ```java\n   package com.kuang.provider.service;\n\n   public interface TicketService {\n      public String getTicket();\n   }\n   ```\n\n   编写实现类\n\n   ```java\n   package com.kuang.provider.service;\n\n   public class TicketServiceImpl implements TicketService {\n      @Override\n      public String getTicket() {\n          return \"这是一张来自服务提供者的票\";\n     }\n   }\n   ```\n\n5. 创建一个模块，实现服务消费者：consumer-server，选择 web 依赖即可\n\n6. 项目创建完毕，我们写一个服务，比如用户买票的服务\n\n   编写 service\n\n   ```java\n   package com.kuang.consumer.service;\n   \n   public class UserService {\n      //我们需要去拿去注册中心的服务\n   }\n   ```\n\n   需求：用户 想调用服务提供者的买票服务，应该怎么做？\n\n#### 2、服务提供者\n\n1. 将服务提供者注册到注册中心，我们需要整合 Dubbo 和 zookeeper，所以需要导包\n\n   首先，导入 springboot 与 dubbo 的整合包\n\n   ```xml\n   <!-- https://mvnrepository.com/artifact/org.apache.dubbo/dubbo-spring-boot-starter -->\n   <dependency>\n       <groupId>org.apache.dubbo</groupId>\n       <artifactId>dubbo-spring-boot-starter</artifactId>\n       <version>2.7.8</version>\n   </dependency>\n   ```\n\n   zookeeper 客户端的包我们去 maven 的仓库下载\n\n   ```xml\n   <!-- https://mvnrepository.com/artifact/com.github.sgroschupf/zkclient -->\n   <dependency>\n       <groupId>com.github.sgroschupf</groupId>\n       <artifactId>zkclient</artifactId>\n       <version>0.1</version>\n   </dependency>\n   ```\n\n   **【新版的坑】zookeeper 及其依赖包，解决日志冲突，还需要剔除日志依赖；**\n\n   ```xml\n   <!-- 引入zookeeper -->\n   <dependency>\n       <groupId>org.apache.curator</groupId>\n       <artifactId>curator-framework</artifactId>\n       <version>2.12.0</version>\n   </dependency>\n   <dependency>\n       <groupId>org.apache.curator</groupId>\n       <artifactId>curator-recipes</artifactId>\n       <version>2.12.0</version>\n   </dependency>\n   <dependency>\n       <groupId>org.apache.zookeeper</groupId>\n       <artifactId>zookeeper</artifactId>\n       <version>3.4.14</version>\n       <!--排除这个slf4j-log4j12-->\n       <exclusions>\n           <exclusion>\n               <groupId>org.slf4j</groupId>\n               <artifactId>slf4j-log4j12</artifactId>\n           </exclusion>\n       </exclusions>\n   </dependency>\n   ```\n\n2. 在 springboot 配置文件中配置 dubbo 相关属性！\n\n   ```properties\n   #当前应用名字\n   dubbo.application.name=provider-server\n   #注册中心地址\n   dubbo.registry.address=zookeeper://127.0.0.1:2181\n   #扫描指定包下的服务\n   dubbo.scan.base-packages=com.luojunjie.service\n   ```\n\n3. 在 service 的实现类中配置服务注解，发布服务\n\n   ```java\n   package com.luojunjie.service;\n   \n   import org.apache.dubbo.config.annotation.DubboService;\n   import org.springframework.stereotype.Component;\n   \n   /**\n    * @author IRVING\n    * @create 2021-04-13 15:11\n    */\n   @Component //放在spring容器中\n   @DubboService //将服务注册到dubbo\n   public class TicketServiceImpl implements TicketService {\n   \n       public String getTicket() {\n           return \"我是一张票！！\";\n       }\n   }\n   ```\n\n   **逻辑理解 ：应用启动起来，dubbo 就会扫描指定的包下带有@component 注解的服务，将它发布在指定的注册中心中！**\n\n#### 3、服务消费者\n\n1. 导入依赖，和服务提供者的依赖一样\n\n   ```xml\n   <!-- 导入依赖dubbo+zookeeper -->\n   \n   <!-- https://mvnrepository.com/artifact/org.apache.dubbo/dubbo-spring-boot-starter -->\n   <dependency>\n       <groupId>org.apache.dubbo</groupId>\n       <artifactId>dubbo-spring-boot-starter</artifactId>\n       <version>2.7.8</version>\n   </dependency>\n\n\n   <!-- https://mvnrepository.com/artifact/com.github.sgroschupf/zkclient -->\n   <dependency>\n       <groupId>com.github.sgroschupf</groupId>\n       <artifactId>zkclient</artifactId>\n       <version>0.1</version>\n   </dependency>\n\n   <!-- 引入zookeeper -->\n   <dependency>\n       <groupId>org.apache.curator</groupId>\n       <artifactId>curator-framework</artifactId>\n       <version>2.12.0</version>\n   </dependency>\n   <dependency>\n       <groupId>org.apache.curator</groupId>\n       <artifactId>curator-recipes</artifactId>\n       <version>2.12.0</version>\n   </dependency>\n   <dependency>\n       <groupId>org.apache.zookeeper</groupId>\n       <artifactId>zookeeper</artifactId>\n       <version>3.4.14</version>\n       <!--排除这个slf4j-log4j12-->\n       <exclusions>\n           <exclusion>\n               <groupId>org.slf4j</groupId>\n               <artifactId>slf4j-log4j12</artifactId>\n           </exclusion>\n       </exclusions>\n   </dependency>\n   ```\n\n2. 配置参数\n\n   ```properties\n   #当前应用名字\n   dubbo.application.name=consumer-server\n   #注册中心地址\n   dubbo.registry.address=zookeeper://127.0.0.1:2181\n   ```\n\n3. **本来正常步骤是需要将服务提供者的接口打包，然后用 pom 文件导入，我们这里使用简单的方式，直接将服务的接口拿过来，路径必须保证正确，即和服务提供者相同；**\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413162217.png\" alt=\"image-20210413162217567\" style=\"zoom:33%;\" />\n\n4. 完善消费者的服务类\n\n   ```java\n   package com.luojunjie.service;\n\n   import org.apache.dubbo.config.annotation.DubboReference;\n   import org.springframework.stereotype.Service;\n\n   /**\n    * @author IRVING\n    * @create 2021-04-13 15:12\n    */\n   @Service\n   public class UserService {\n\n       @DubboReference  //远程引用指定的服务，他会按照全类名进行匹配，看谁给注册中心注册了这个全类名\n       private TicketService ticketService;\n\n       //想拿到票\n       public void bugTicket(){\n           System.out.println(\"在注册中心中拿到=>\"+ticketService.getTicket());\n       }\n   }\n   ```\n\n5. 测试！\n\n   ```java\n   package com.luojunjie;\n   \n   import com.luojunjie.service.UserService;\n   import org.junit.jupiter.api.Test;\n   import org.springframework.beans.factory.annotation.Autowired;\n   import org.springframework.boot.test.context.SpringBootTest;\n   \n   @SpringBootTest\n   class ConsumerServerApplicationTests {\n   \n       @Autowired\n       private UserService userService;\n   \n       @Test\n       void contextLoads() {\n           userService.bugTicket();\n       }\n   \n   }\n   ```\n\n#### 4、启动测试\n\n1. 开启 zookeeper\n\n2. 打开 dubbo-admin 实施监控\n\n3. 开启服务者\n\n4. 消费者测试结果：\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413162711.png\" alt=\"image-20210413162711583\" style=\"zoom:50%;\" />\n\n5. dubbo-admin 监控中心\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210413162803.png\" alt=\"image-20210413162802948\" style=\"zoom:50%;\" />\n","tags":["笔记","分布式"],"categories":["随笔小记"]},{"title":"Java 中的位运算","slug":"Java位运算","url":"/2021/04/09/f789481e.html","content":"\n## 前言\n\n日常开发中位运算不是很常用，但是巧妙的使用位运算可以大量减少运行开销，优化算法。\n\n<!-- more -->\n\n## 位运算符\n\nJava支持的位运算有7种，具体如下：\n\n- **&：按位与。**\n- **|：按位或。**\n- **~：按位非。**\n- **^：按位异或。**\n- **<<：左位移运算符。**\n- **>>：右位移运算符。**\n- **<<<：无符号右移运算符。**\n\n### 按位与(&)\n\n按位与的运算规则\n\n| 操作数1     | **0** | **0** | **1** | **1** |\n| ----------- | ----- | ----- | ----- | ----- |\n| **操作数2** | **0** | **1** | **0** | **1** |\n| **按位与**  | **0** | **0** | **0** | **1** |\n\n**规则总结：**只有两个操作数对应位同为1时，结果为1，其余全为0（或者是只要有一个操作数为0，结果就为0）\n\n**举例：**\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/yu.png)\n\n### 按位或(|)\n\n按位或的运算规则\n\n| 操作数1     | **0** | **0** | **1** | **1** |\n| ----------- | ----- | ----- | ----- | ----- |\n| **操作数2** | **0** | **1** | **0** | **1** |\n| **按位或**  | **0** | **1** | **1** | **1** |\n\n**规则总结：**只有两个操作数对应位同为0时，结果为0，其余全为1（或者是只要有一个操作数为1，结果就为1）\n\n### 按位非(~)\n\n按位非的运算规则\n\n| 操作数     | 0     | 1     |\n| ---------- | ----- | ----- |\n| **按位或** | **1** | **0** |\n\n**规则总结：**取反操作，在求负数的源码中使用过\n\n### 按位异或(^)\n\n按位异或的运算规则\n\n| 操作数1      | **0** | **0** | **1** | **1** |\n| ------------ | ----- | ----- | ----- | ----- |\n| **操作数2**  | **0** | **1** | **0** | **1** |\n| **按位异或** | **0** | **1** | **1** | **0** |\n\n**规则总结：**只有两个操作数不相同时，结果为1，其余全为0（或者是只要两个操作数相同就为0）\n\n### 左位移(<<)\n\n**运算规则：**算术左移，溢出截断，符号位不变，低位补0。如：2<<2结果为8。\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/zuoweiyi.png)\n\n### 右位移(>>)\n\n**运算规则：**算术右移，溢出截断，符号位不变，用符号位补高位。如：-6>>2结果为-2。\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/youweiyi.png)\n\n### 无符号右移(>>>)\n\n**运算规则：**低位溢出，高位补0\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/wufuhao.png)\n\n## 常见使用\n\n因位运算在日常开发中并不是很常用的，这里举两个例子加强理解\n\n### 判断一个数n的奇偶性\n\n```java\nn&1 == 1?\"奇数\":\"偶数\"\n```\n\n为什么与1能判断奇偶？所谓的二进制就是满2进1，那么好了，偶数的最低位肯定是0（恰好满2，对不对？），同理，奇数的最低位肯定是1。int类型的1，前31位都是0，无论是1&0还是0&0结果都是0，那么有区别的就是1的最低位上的1了，若n的二进制最低位是1（奇数）与上1，结果为1，反则结果为0。\n\n### 取绝对值\n\n```java\n(a^(a>>31))-(a>>31)\n```\n\n先整理一下使用位运算取绝对值的思路：若a为正数，则不变，需要用异或0保持的特点；若a为负数，则其补码为源码翻转每一位后+1，先求其源码，补码-1后再翻转每一位，此时需要使用异或1具有翻转的特点。\n\n任何正数右移31后只剩符号位0，最终结果为0，任何负数右移31后也只剩符号位1，溢出的31位截断，空出的31位补符号位1，最终结果为-1.右移31操作可以取得任何整数的符号位。\n\n那么综合上面的步骤，可得到公式。a>>31取得a的符号，若a为正数，a>>31等于0，a^0=a，不变；若a为负数,a>>31等于-1 ，a^-1翻转每一位。\n\n### 不用临时变量交换两个数\n\n连续三次使用异或，并没有临时变量就完成了两个数字交换，怎么实现的呢？\n\n```\nint a = 3,b = 4;\na = a^b;\nb = b^a; //b=b^(a^b)-->b=a\na = a^b; //a=(a^b)^(b^(a^b))-->a=b\n```\n\n上面的计算主要遵循了一个计算公式：b^(a^b)=a。\n\n我们可以对以上公式做如下的推导：\n\n任何数异或本身结果为0.且有定理a^b=b^a。异或是一个无顺序的运算符，则b^a^b=b^b^a，结果为0^a。\n\n再次列出异或的计算表:\n\n| 操作数1      | **0** | **0** | **1** | **1** |\n| ------------ | ----- | ----- | ----- | ----- |\n| **操作数2**  | **0** | **1** | **0** | **1** |\n| **按位异或** | **0** | **1** | **1** | **0** |\n\n可以发现，异或0具有保持的特点，而异或1具有翻转的特点。使用这些特点可以进行取数的操作。\n\n那么0^a，使用异或0具有保持的特点，最终结果就是a。\n\n其实java中的异或运算法则完全遵守数学中的计算法则：\n\n①  a ^ a =0\n\n②  a ^ b =b ^ a\n\n③  a ^b ^ c = a ^ (b ^ c) = (a ^ b) ^ c;\n\n④  d = a ^b ^ c 可以推出 a = d ^ b ^ c.\n\n⑤  a ^ b ^a = b.\n","tags":["笔记","Java"],"categories":["后端开发"]},{"title":"Java 中的注解与反射","slug":"Java注解与反射","url":"/2021/04/07/13a54546.html","content":"\n## 注解\n\njava.Annotation\n\n### 什么是注解？\n\n- Annotation 是从 JDK5.0 引入的新技术\n- Annotation 的作用：\n  - 不是程序本身，可以对程序作出解释\n  - **可以被其他程序(比如编译器等)读取**\n- Annotation 的格式：\n  - 注解是以“@注释名”在代码中存在的，还可以添加一些参数值\n- Annotation 在哪里使用？\n  - 可以附加在 package、class、method、field 等上面，相当于给他们添加了额外的辅助信息，我们可以通过反射机制编程实现对这些元数据的访问\n\n### 内置注解\n\n- @Override：定义在 java.lang.Override 中，此注释只适用于修辞方法，表示一个方法声明打算重写超类中的另一个方法声明。\n- @Deprecated：此注释可以用于修辞方法，属性，类，表示不鼓励程序员使用这样的元素，通常是因为它很危险或者存在更好的选择。\n- @SuppressWarning：用来抑制编译时的警告信息。\n\n### 元注解\n\n- 元注解的作用就是负责注解其他注解。Java 定义了 4 个标准的 meta-annotation 类型，他们用来提供对其他 annotation 类型作说明\n- 在 java.lang.annotation 中可以找到：\n  - **@Target**：用于描述注解的使用范围（即：被描述的注解可以用在什么地方）\n  - **@Retention**：表示需要在什么级别保存该注释信息，用于描述注解的生命周期你\n    - （SOURCE < CLASS < **RUNTIME**）\n  - @Document：说明该注解将被包含在 javadoc 中\n  - @Inherited：说明子类可以继承**父类**中的注解\n\n### 自定义注解\n\n- 使用 **@interface**自定义注解是，自动继承了 java.lang.annotation.Annotation 接口\n- 分析：\n  - @interface 用来声明一个注解，格式：public @interface 注解名{ 定义内容 }\n  - 其中的每一个方法实际上是声明了一个配置参数\n  - 方法的名称就是参数的名称\n  - 返回值类型就是参数的类型 （返回值只能是基本类型，Class，String，enum）\n  - 可以通过 default 来声明参数的默认值\n  - 如果只有一个参数成员，一般参数名为 value\n  - 注解元素必须要有值，我们定义注解元素时，经常使用空字符串，0 作为默认值\n\n## 反射机制\n\nReflection（反射）是 Java 被视为动态语言的关键，反射机制允许程序在执行期借助于 Reflection API 取得任何类的内部信息，并能直接操作任意对象的内部属性及方法。\n\n```java\nClass c = Class.forName(\"java.lang.String\")\n```\n\n加载完类之后，在堆内存的方法区中就产生了一个 Class 类型的对象（一个类只要一个 Class 对象），这个对象就包含了完整的类的结构信息。我们可以通过这个对象看到类的结构。这个对象就像一面镜子，透过这个镜子看到类的结构，所以，我们形象的称之为：反射！\n\n### 反射相关的主要 API\n\n- java.lang.Class：代表一个类\n- java.lang.reflect.Method：代表类的方法\n- javaz.lang.reflect.Field：代表类的成员变量\n- java.lang.reflect.Contructor：代表类的构造器\n\n### Class 类\n\n对于每个类而言，JRE 都为其保留了一个不变的 Class 类型的对象。一个 Class 对象包含了特定某个结构(class/interface/enum/annotation)\n\n- Class 本身也是一个类\n- Class 对象只能由系统建立对象\n- 一个加载的类在 JVM 中只会有一个 Class 实例\n- 一个 Class 对象对应的是一个加载到 JVM 中的一个.class 文件\n- 每个类的实例都会记得自己是由哪个 Class 实例所生成\n- 通过 Class 可以完整地得到一个类中的所有被加载的结构\n- Class 类是 Relfection 的根源，针对任何你想动态加载、运行的类，唯有先获得相应的 Class 对象\n\n### Class 类相关方法\n\n- **获得类相关的方法**\n\n| 方法                       | 用途                                                   |\n| -------------------------- | ------------------------------------------------------ |\n| asSubclass(Class<U> clazz) | 把传递的类的对象转换成代表其子类的对象                 |\n| Cast                       | 把对象转换成代表类或是接口的对象                       |\n| getClassLoader()           | 获得类的加载器                                         |\n| getClasses()               | 返回一个数组，数组中包含该类中所有公共类和接口类的对象 |\n| getDeclaredClasses()       | 返回一个数组，数组中包含该类中所有类和接口类的对象     |\n| forName(String className)  | 根据类名返回类的对象                                   |\n| getName()                  | 获得类的完整路径名字                                   |\n| newInstance()              | 创建类的实例                                           |\n| getPackage()               | 获得类的包                                             |\n| getSimpleName()            | 获得类的名字                                           |\n| getSuperclass()            | 获得当前类继承的父类的名字                             |\n| getInterfaces()            | 获得当前类实现的类或是接口                             |\n\n- **获得类中属性相关的方法**\n\n| 方法                          | 用途                   |\n| ----------------------------- | ---------------------- |\n| getField(String name)         | 获得某个公有的属性对象 |\n| getFields()                   | 获得所有公有的属性对象 |\n| getDeclaredField(String name) | 获得某个属性对象       |\n| getDeclaredFields()           | 获得所有属性对象       |\n\n- **获得类中注解相关的方法**\n\n| 方法                                            | 用途                                   |\n| ----------------------------------------------- | -------------------------------------- |\n| getAnnotation(Class<A> annotationClass)         | 返回该类中与参数类型匹配的公有注解对象 |\n| getAnnotations()                                | 返回该类所有的公有注解对象             |\n| getDeclaredAnnotation(Class<A> annotationClass) | 返回该类中与参数类型匹配的所有注解对象 |\n| getDeclaredAnnotations()                        | 返回该类所有的注解对象                 |\n\n- **获得类中构造器相关的方法**\n\n| 方法                                               | 用途                                   |\n| -------------------------------------------------- | -------------------------------------- |\n| getConstructor(Class...<?> parameterTypes)         | 获得该类中与参数类型匹配的公有构造方法 |\n| getConstructors()                                  | 获得该类的所有公有构造方法             |\n| getDeclaredConstructor(Class...<?> parameterTypes) | 获得该类中与参数类型匹配的构造方法     |\n| getDeclaredConstructors()                          | 获得该类所有构造方法                   |\n\n- **获得类中方法相关的方法**\n\n| 方法                                                       | 用途                   |\n| ---------------------------------------------------------- | ---------------------- |\n| getMethod(String name, Class...<?> parameterTypes)         | 获得该类某个公有的方法 |\n| getMethods()                                               | 获得该类所有公有的方法 |\n| getDeclaredMethod(String name, Class...<?> parameterTypes) | 获得该类某个方法       |\n| getDeclaredMethods()                                       | 获得该类所有方法       |\n\n- **类中其他重要的方法**\n\n| 方法                                                             | 用途                              |\n| ---------------------------------------------------------------- | --------------------------------- |\n| isAnnotation()                                                   | 如果是注解类型则返回 true         |\n| isAnnotationPresent(Class<? extends Annotation> annotationClass) | 如果是指定类型注解类型则返回 true |\n| isAnonymousClass()                                               | 如果是匿名类则返回 true           |\n| isArray()                                                        | 如果是一个数组类则返回 true       |\n| isEnum()                                                         | 如果是枚举类则返回 true           |\n| isInstance(Object obj)                                           | 如果 obj 是该类的实例则返回 true  |\n| isInterface()                                                    | 如果是接口类则返回 true           |\n| isLocalClass()                                                   | 如果是局部类则返回 true           |\n| isMemberClass()                                                  | 如果是内部类则返回 true           |\n\n### Field 类\n\n[Field](https://developer.android.google.cn/reference/java/lang/reflect/Field)代表类的成员变量（成员变量也称为类的属性）。\n\n| 方法                          | 用途                       |\n| ----------------------------- | -------------------------- |\n| equals(Object obj)            | 属性与 obj 相等则返回 true |\n| get(Object obj)               | 获得 obj 中对应的属性值    |\n| set(Object obj, Object value) | 设置 obj 中对应属性值      |\n\n### Method 类\n\n[Method](https://developer.android.google.cn/reference/java/lang/reflect/Method)代表类的方法。\n\n| 方法                               | 用途                                       |\n| ---------------------------------- | ------------------------------------------ |\n| invoke(Object obj, Object... args) | 传递 object 对象及参数调用该对象对应的方法 |\n\n### Constructor 类\n\n[Constructor](https://developer.android.google.cn/reference/java/lang/reflect/Constructor)代表类的构造方法。\n\n| 方法                            | 用途                       |\n| ------------------------------- | -------------------------- |\n| newInstance(Object... initargs) | 根据传递的参数创建类的对象 |\n\n### 获取 Class 类的实例\n\n- 类名.class\n- 对象.getClass\n- Class.forName(类路径)\n- 内置基本类型包装类.TYPE\n\n### 那些类型可以有 Class 对象\n\n- class：外部类，成员（成员内部类，静态内部类），局部内部类，匿名内部类\n- interface：接口\n- []：数组\n- enum：枚举\n- annotation：注解@interface\n- primitive type：基本数据类型\n- void\n\n### 类的加载与 ClassLoader 的理解\n\n- 加载：将 class 文件字节码内容加载到内存中，并将这些静态数据转换成方法区的运行时数据结构，然后生成一个代表这个类的 java.lang.Class 对象\n- 链接：将 Java 类的二进制代码合并到 JVM 的运行状态之中的过程。\n  - 验证：确保加载的类信息符合 JVM 规范，没有安全方面的问题\n  - 准备：正式为类变量（static）分配内存并设置类变量默认初始值的阶段，这些内存都将在方法区中进行分配。\n  - 解析：虚拟机常量池内的符号引用（常量名）替换为直接引用（地址）的过程\n- 初始化：\n  - 执行类构造器<clint>()方法的过程。类构造器<clint>()方法是由编译期自动收集类中所有类变量的赋值动作和静态代码块中的语句合并产生的。（类构造器是构造类信息的，不是构造该类对象的构造器）\n  - 当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化\n  - 虚拟机会保证一个类的<clint>()方法在多线程环境中被正确加锁和同步\n\n### 什么时候会发生类初始化？\n\n- 类的主动引用（一定会发生类的初始化）\n  - 当虚拟机启动，先初始化 main 方法所在的类\n  - new 一个类的对象\n  - 调用类的静态成员（除了 final 常量）和静态方法\n  - 使用 java.lang.reflect 包的方法对类进行反射调用\n  - 当初始化一个类，如果其父类没有被初始化，则先会初始化它的父类\n- 类的被动引用（不会发生类的初始化）\n  - 当访问一个静态域时，只有真正声明这个域的类才会被初始化。如：当通过子类引用父类的静态变量，不会导致子类初始化\n  - 通过数组定义类引用，不会触发此类初始化\n  - 引用常量不会触发此类的初始化（常量在链接阶段就存入调用类的常量池中了）\n\n### 类加载器的作用\n\n**类加载器的作用：**\n\n将 class 文件字节码内容加载到内存中，并将这些静态数据转换成方法区的运行时数据结构，然后在堆中生成一个代表这个类的 java.lang.Class 对象，作为方法区中类数据的访问入口。\n\n**类缓存：**\n\n标准的 JavaSE 类加载器可以按要求查找类，但一旦某个类被加载到类加载器中，它将维持加载（缓存）一段时间。不过 JVM 垃圾回收机制可以回收这些 Class 对象\n\n三大类加载器：\n\n- 引导类加载器 -- Bootstrap Classloader\n- 扩展类加载器 -- Extension Classloader\n- 系统类加载器 -- System Classloader\n","tags":["技巧","笔记"],"categories":["后端开发"]},{"title":"Java 中的 IO 流","slug":"Java中的IO流","url":"/2021/04/04/13a54546.html","content":"## 一、前言\n\nJava的I/O主要的用途就是文件数据的读写、数据的网络发送与接收等场合。\n\n流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称之为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。对于文件内容的操作主要分为两大类：字符流和字节流。\n\n## 二、I/O 流的分类\n\n根据处理数据类型的不同分为：字符流和字节流。\n\n根据数据流向不同分为：输入流和输出流。\n\n### 1、字符流和字节流\n\n字符流的由来：因为数据编码的不同，而有了对字符进行高效操作的流对象。本质其实就是基于字节流流读取时，去查了指定的码表。字节流和字符流的区别：\n\n1. 读写单位不同：字节流以字节（8bit）为单位，字符流以字符为单位，根据码表映射字符，一次可能多个字节。\n2. 处理对象不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。\n3. 字节流在操作的时候本身是不会用到缓冲区的，是文件本事的直接操作的；而字符流在操作的时候下后是会用到缓冲区的，通过缓冲区来操作文件。\n\n**结论：优先选用字节流。首先因为硬盘上的所有文件都是以字节的形式进行传输或者保存的，包括图片等内容。但是字符只是在内存汇总才会形成，所以在开发中，字节流使用广泛。**\n\n### 2、输入流和输出流\n\n对输入流只能进行读操作，对输出流只能进行写操作，程序中需要根据待传输数据的不同特性而使用不同的流。\n\n### 3、常见 I/O 流对象\n\n- InputStream\n\n  ![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210401214602.png)\n\n- OutputStream\n\n  <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210401214647.png\" alt=\"img\"  />\n\n- Reader\n\n  ![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210401214855.png)\n\n- Writer\n\n  ![img](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210401214921.png)\n\n## 三、常见问题\n\n### 1、字节流和字符流的使用情况\n\n字符流和字节流的使用范围：字节流一般用来处理图像、视频，以及PPT、Word类型的文件。字符流一般用于处理纯文本类型的文件，如txt文件等，字节流可以用来处理纯文本文件，但字符流不能用户处理图像、视频等非文本类型的文件。\n\n### 2、字符流与字节流的转换\n\n转换流的作用，文本文件在硬盘中以字节流的形式存储时，通过InputStreamReader读取后转化成字符流交给程序处理，程序处理的字符流通过OutputStreamWriter转换成字节流保存。\n\n### 3、字节流与字符流的区别\n\n字节流没有缓冲区，是直接输出的，而字符流需要输出到缓冲区的。因此在输出时，字节流不调用close()方法时，信息已经输出了，而字符流只有在调用close()方法关闭缓冲区时，信息才输出。要想字符流在未关闭时输出信息，需要手动调用flush()方法。\n\n1. 读写单位不同：字节流以字节（8bit）为单位，字符流以字符为单位，根据码表映射字符，一次可能多个字节。\n2. 处理对象不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。\n3. 字节流在操作的时候本身是不会用到缓冲区的，是文件本事的直接操作的；而字符流在操作的时候下后是会用到缓冲区的，通过缓冲区来操作文件。\n\n## 四、IO/NIO 面试题\n\n### 1、Java 中 IO 流分为几种\n\n1. 按照流的流向分：分为输入流与输出流\n2. 按照操作单元分：分为字节流与字符流\n3. 按照流的角色分：分为节点流与处理流\n\n### 2、Java IO 与 NIO的区别\n\nNIO即New IO，这个库是在JDK1.4中才引入的。NIO和IO有相同的作用和目的，NIO主要用到的是块，所以NIO的效率要比IO高很多。在Java API中提供了两套NIO，一套是针对标准输入输出NIO，另一套就是网络编程NIO。\n\n### 3、Java 中常用的 IO 类有哪些\n\n```\nFile\nFileInputStream、FileOutputStream\nBufferedInputStream、BufferedOutputStream\nFileReader、FileWrter\nBufferedReader、BufferedWriter\nObjectInputStream、ObjectOutputStream\n```\n\n### 4、字节流与字符流的区别\n\n字节流是以字节为单位进行传输，大小为8bit\n\n字符流是以字符为单位进行传输，大小为16bit\n","tags":["笔记","Java"],"categories":["后端开发"]},{"title":"到底什么是前后端分离？","slug":"到底什么是前后端分离？","url":"/2021/03/06/cc9e7a55.html","content":"\n## 前言\n\n到底什么是**前后端分离**？通俗的来说就是前端的开发与后端的开发分离，前后端分离已成为互联网项目开发的业界标准使用方式，通过**Nginx**+**Tomcat**的方式（也可以中间加一个 NodeJS）有效地对前端和后端的开发进行解耦。其实，前后端分离的核心思想就是前端 HTML 页面通过**AJAX**调用后端的**RESTFUL API**接口，并通过**JSON**数据进行交互。\n\n## 为什么要进行前后端分离？\n\n1. 前后端耦合的缺点（以 JSP 为例）\n   - 动态资源和静态资源全部耦合在一起，服务器压力大\n   - 第一次请求 JSP，必须要在 WEB 服务器中编译成 Servlet，第一次运行会较慢\n   - 如果 JSP 中的内容很多，页面响应会很慢，因为是同步加载，一次输出所有内容\n   - ······\n2. 前后端分离的优点\n   - 前后端分离可以真正地实现前后端解耦，前端服务器使用 Nginx，前端服务器负责控制页面引用、跳转和路由，前端页面通过 AJAX 异步调用后端的接口，后端服务器使用 Tomcat，加快整体响应速度\n   - 前后端分离的模式下，即使后端服务器暂时超时或宕机了，前端页面也会正常访问，只不过数据刷不出来而已\n   - 前后端分离的模式下，后台的接口可以复用。（多端应用）\n   - 页面显示再多的内容也不怕了，因为从同步加载改成了异步加载。\n   - ······\n\n## 如何实现前后端分离？\n\n这里讲解的方式是 SpringBoot+Vue 进行分离，分别部署到 Tomcat 与 NodeJs 两个不同的服务器上。\n\n### 创建一个 SpringBoot 项目\n\n...\n\n### 使用 vue-cli 创建 vue 项目\n\nvue-cli 官网：https://cli.vuejs.org/zh/\n\n1. 安装 nodejs 环境\n\n   [官网下载](https://nodejs.org/en/download/)\n\n   一直默认下一步就行，路径可以自定义，安装完之后输入`node -v`，`npm -v`查看版本号。\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210305235506.png\" alt=\"image-20210305234857573\" style=\"zoom: 67%;\" />\n\n2. 安装**vue-cli**\n\n   - npm 默认是从国外的服务器下载，受网络影响较大。设置淘宝镜像可以解决这个问题\n\n   ```\n   npm config set registry https://registry.npm.taobao.org\n   ```\n\n   - 检测是否设置成功\n\n   ```\n   npm config get registry\n   ```\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210306000237.png\" alt=\"image-20210306000227284\" style=\"zoom: 67%;\" />\n\n   - 全局安装`vue-cli`\n\n   ```\n   npm install -g @vue/cli\n   ```\n\n   - 检查是否安装成功\n\n   ```\n   vue --version\n   ```\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210306000601.png\" alt=\"image-20210306000556387\" style=\"zoom: 67%;\" />\n\n3. 创建新项目\n\n   - 运行以下命令来创建一个新项目：\n\n   ```\n   vue create hello-world\n   ```\n\n   - 选择相应的设置(预设)完成创建\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210306002820.png\" alt=\"image-20210306002818051\" style=\"zoom:67%;\" />\n\n   - 创建成功\n\n   <img src=\"https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/20210306003127.png\" alt=\"image-20210306003126725\" style=\"zoom: 50%;\" />\n\n4. 启动 vue 项目\n\n```\nnpm run serve\n```\n\n### 配置 vue 项目\n\n- 安装`axios`\n\n```\nnpm install axios\n```\n\n- 初始化 vue 项目结构\n\n  使用`vue-cli`创建 vue 项目会有一个初始页面，我们在开发过程中并不需要，将无用的东西去掉\n\n### 解决跨域的问题\n\n> 在 Web 端 Vue 项目开发过程中，跨域问题是不可避免的；\n\n#### Webpack 配置 proxy 实现代理——开发环境\n\n> 我们的项目工程是通过`Vue-cli3`来搭建的，因此没有了`Webpack`的显式配置文件；需要我们在工程根目录下手动创建`vue.config.js`去实现 Webpack 的配置\n\n1. 新增`vue.config.js`\n\n   ```js\n   module.exports = {\n     devServer: {\n       host: '127.0.0.1',\n       port: 8080,\n       open: true,// vue项目启动时自动打开浏览器\n       proxy: {\n         '/api': { // '/api'是代理标识，用于告诉node，url前面是/api的就是使用代理的\n           target: \"http://localhost:8081\", //目标地址，一般是指后台服务器地址\n           changeOrigin: true, //是否跨域\n           pathRewrite: { // pathRewrite 的作用是把实际Request Url中的'/api'用\"\"代替\n             '^/api': \"\"\n           }\n         }\n       }\n     }\n   }\n   ```\n\n   配置完成后，我们发起的每次 http 请求的 Request Url 的前面一部分都会和我们配置的源一样；\n\n   举例：\n\n   ```js\n   axios.get(\"/api/getUserList\")\n   ```\n\n   我们项目跑在开发环境下的`http://localhost:8080`上，那么上述请求的 Request Url 的就是 `http://localhost:8080/api/bookCate`;这应该就是我们的代理服务器中该资源的地址，与客户端同源；而数据的实际来源则是`http://localhost:8081/api/bookCate`，这样即实现代理跨域；\n\n## 总结\n\n前后端分离并非仅仅是一种开发模式，而是一种架构模式（前后端分离架构）。千万不要以为只有在写代码的时候把前端和后端分开就是前后端分离了，这样的理解太片面了。前后端分离是需要区分前后端项目的，即前端项目和后端项目是两个项目，放在两个不同的服务器，需要独立部署，两个不同的工程，两个不同的代码库，两组不同的开发人员。前后端开发工程师需要约定交互的接口，实现并行开发。而在开发结束之后，前端项目和后端项目都需要进行独立部署，前端通过 AJAX 来调用 HTTP 请求，调用后端的 RESTFUL API。前端只需要关注页面的样式与动态数据的解析和渲染，不用关心数据是怎么产生的；后端则专注于具体的业务逻辑，返回前端展现所需要的业务数据即可。\n","tags":["技巧","笔记"],"categories":["随笔小记"]},{"title":"Hexo + Gitee 搭建个人博客","slug":"Hexo+Gitee搭建个人博客","url":"/2021/02/06/8fe2b6a8.html","content":"\n## 前言\n\n寒假封城，只能呆在家里鼓捣电脑，有一天看到了 b 站大佬[CodeSheep](https://space.bilibili.com/384068749)的[手把手教你从 0 开始搭建自己的个人博客 |无坑版视频教程| hexo](https://www.bilibili.com/video/av44544186?t=1173),看了之后着手搭建了属于自己的博客。\n视频里博客是搭建在 Github 上的，但其终究是国外的网站，访问速度得不到保障。推荐使用 Gitee，Gitee 类似于国内的 Github，访问速度没问题。\n\n<!-- more -->\n\n## 环境要求\n\n- Windows 系统电脑(Mac 用户可以参考上面的视频)\n- [Git](https://git-scm.com/)\n- [Node.js](https://nodejs.org/en/)\n\n## 安装 Git\n\n因为我们要用到[Git](https://git-scm.com/)中的[Git Bash](https://git-scm.com/download/win)，类似于 Windows 的 cmd 命令行，不过要好用许多(我开始是用 cmd 按视频的步骤来的，运行命令容易报错)。\n\n- [下载地址](https://git-scm.com/download/win)\n- 安装步骤：双击下载好的 exe 文件，一路点击 next 就好了\n- 安装完成之后打开 Git Bash，输入`git version`查看版本：(我这里安装的版本是 2.23.0)\n\n```bash\n$ git version\ngit version 2.23.0.windows.1\n```\n\n- 能看到版本号就说明你安装成功了，之后的命令都是在这里运行的\n\n## 安装 Node.js\n\n[Hexo](https://hexo.io/)是基于[Node.js](https://nodejs.org/en/)制作的静态博客，我们要用到 Node.js 里面的[npm](https://www.npmjs.cn/)(node package manager)包管理器来安装插件，如果你想玩 Hexo 博客，那么这个 Node.js 是必装的。\n\n- [下载地址](https://nodejs.org/en/download/)(选择自己电脑版本相对应的包来下载)\n- 安装步骤：双击下载好的 msi 文件，也是一路下一步就好了\n- 安装完成后打开 Git Bash，输入`node -v`和`npm -v`查看 node 和 npm 的版本：\n\n```bash\n$ node -v\nv12.14.1\n\n$ npm -v\n6.13.4\n```\n\n- 到这里前置步骤就已经算完成了，接下来我们就来安装 Hexo 博客\n\n## 安装 Hexo\n\n安装[Hexo](https://hexo.io/)，我们需要借助[npm](https://www.npmjs.cn/)这个工具来安装，但是我们国内下载镜像源的速度很慢，所以我们可以先利用 npm 工具来安装一个[cnpm](https://npm.taobao.org/)工具(国内的淘宝 npm 镜像源)，这样一来速度会快很多。\n\n- 安装 cnpm：(安装完之后照样可以用`cnpm -v`来查看版本号验证是否成功)\n\n```bash\n$ npm install -g cnpm --registry=https://registry.npm.taobao.org\n```\n\n- 用 cnpm 安装 Hexo\n\n```bash\n$ cnpm install -g hexo-cli\n```\n\n- 接着用`Hexo -v`来验证是否安装成功\n\n```bash\n$ hexo -v\nhexo-cli: 3.1.0\nos: Windows_NT 10.0.17134 win32 x64\nnode: 12.14.1\n```\n\n如果出现以上信息，那么恭喜安装成功了\n\n- 到这里 Hexo 博客已经算是安装完成了，步骤还是非常简单的，重点是耐心~\n\n## 初始化 Hexo\n\n在你的电脑上建一个文件夹，命名没有要求，我这里创建的是 blog，文件夹路径也无所谓，最好装在出了系统盘的固态硬盘中，路径要自己找得到。\n\n- 在创建的文件夹目录下右键选择`Git Bash Here`，也就是在此处打开 Git Bash 终端\n- 输入 Hexo 初始化命令\n\n```bash\n$ hexo init\n```\n\n这个命令执行需要一定的时间，请耐心等待\n\n- 初始化完成之后可以查看指定文件夹目录下有：\n  - node_modules: 依赖包\n  - public：存放生成的页面\n  - scaffolds：生成文章的一些模板\n  - source：用来存放你的文章\n  - themes：主题\n  - \\_config.yml: 博客的配置文件\n- 打开 Hexo 服务\n\n```bash\n$ hexo s\nINFO  Start processing\nINFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.\n```\n\n这样你就可以再浏览器输入:localhost:4000 来访问你的博客啦，使用 Ctrl+C 可以关闭服务。\n大概是这样：\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/blog.jpg)\n\n- 用 Hexo 写一篇博客\n\n```bash\n$ hexo n \"我的第一篇博客\"\nINFO  Created: E:\\bolg\\source\\_posts\\我的第一篇博客.md\n```\n\n到 E:\\bolg\\source_posts 目录下打开我的第一篇博客.md 进行编辑(推荐用 vscode 进行编辑，vscode 有预览 md 文件的插件)：\n\n```bash\n---\ntitle: 我的第一篇博客\ndate: 2020-02-03 21:16:52\ntags:\n---\n\n## 第一章\n\n内容\n\n---\n\n\n## 第二章\n\n内容\n\n---\n\n## 参考资料\n\n\nhttps://ouwen.gitee.io\n```\n\n注意：这里的 md 文件是基于[markdown](https://baike.baidu.com/item/markdown/3245829?fr=aladdin)语法进行编辑的，不了解的朋友可以百度学习一下，很简单的，几分钟就能看明白，相信你不是问题。\n\n- 编辑完保存文件，重启 Hexo 服务\n\n```bash\n$ hexo clean          # 清除所有记录\n$ hexo generate       # 生成静态网页 简写：hexo g\n$ hexo server         # 启动服务 简写：hexo s\n```\n\n打开浏览器输入 localhost:4000：\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/blog2.jpg)\n\n## 将博客部署到 Gitee 上\n\n上面访问的 localhost:4000 是本地服务器端口，我们的博客不可能是放在本地服务器的，我们需要把博客部署到远端去。我这里推荐的一个免费的部署的方式就是部署到[Gitee](https://gitee.com/)上，部署好之后就可以通过访问[Gitee](https://gitee.com/)上的那个地址来访问我们的博客。\n\n- 进到[Gitee](https://gitee.com/)官网，注册账号并登陆\n- 点击个人主页右上角新建个人仓库\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/blog3.jpg)\n\n- 创建完成后进入仓库\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/blog4.jpg)\n\n- 打开 Hexo 的配置文件`_config.yml`\n\n```bash\ndeploy:\n  type: git\n  repo: https://gitee.com/ouwen666/test.git #仓库的url\n  branch: master\n```\n\n- 这里先安装一个 Hexo 插件\n\n```bash\ncnpm install hexo-deployer-git --save  #通过cpnm安装git插件\ngit config --global user.email '******@qq.com'  #设置gitee邮箱（gitee的注册邮箱）\ngit config --global user.name '****'            #设置用户名（gitee的y注册昵称）\nhexo d  #上传到gitee的远端仓库\n# 在上传时，需要再次输入gitee的用户名username和密码password\n```\n\n- 上传成功仓库会多出一些文件\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/blog5.jpg)\n\n- 接着打开 Gitee Page 服务\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/blog6.jpg)\n\n然后点击启动或更新即可。**注意每次更改网页重新上传到仓库都要到这里来更新服务。**\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/blog7.jpg)\n\n- 访问 Gitee Page 服务的网站地址\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/blog8.jpg)\n\n从图中地址栏中的网址可以看出我们已经成功将本地的博客部署到了远端仓库，这样你的小伙伴也能在自己的电脑访问你的 Gitee Page 服务网站看到你的博客啦。\n\n## 总结\n\nHexo 博客搭建总的来说还是比较简单的，搭配 Gitee 码云使用起来还是比较方便的，访问速度也还行。总结下面几点：\n\n1. Hexo 博客个性化定制的话，大家可以多参考 Hexo 官方中文文档\n2. 更新完代码可以访问 localhost:4000 预览效果再上传，上传后千万记得更新 Gitee Page 服务，否则刷新页面会出现没更新的情况\n3. Hexo 还支持很多主题，有兴趣的小伙伴可以自行搜索更改，参照官方文档进行操作也是不难的哦\n4. 小伙伴们注意将自己写的代码保存好哦！我是将代码备份到 Github 上保存的，将博客部署到 Gitee 码云进行访问\n","tags":["笔记","教程"],"categories":["Hexo"]},{"title":"MongoDB 数据库","slug":"MongoDB数据库","url":"/2020/06/18/bd0448f7.html","content":"\n## **前言**\n\nMongoDB 数据库的学习\n\n<!-- more -->\n\n## MongoDB 的简介\n\n### MongoDB 的概述\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/mongo.jpg)\n\n- MongoDB 是由 C++语言编写的，是一个基于分布式文件存储的开源数据库系统。\n- 在高负载的情况下，添加更多的节点，可以保证服务器性能。\n- MongoDB 旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。\n- MongoDB 将数据存储为一个文档，数据结构由键值(key=>value)对组成\n- MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。\n\n## MongoDB 的安装\n\n### 安装\n\n`apt install mongodb`\n\n安装完成可以用`mongo -version`来查看版本检查是否安装成功\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/mongo1.jpg)\n\n### MongoDB 基本管理\n\n通过以下命令，可以对 mongoDB 数据库进行一些基本的操作：\n\n- 查看服务状态\n  service mongodb status\n- 启动服务\n  service mongodb start\n- 停止服务\n  service mongodb stop\n- 重新载入资源\n  service mongodb reload\n\n### 卸载\n\n`apt --purge remove mongodb mongodb-clients mongodb-server`\n\n## MongoDB 基本配置\n\n### MongoDB 文件结构\n\nmongoDB 数据库安装好以后，有以下四个比较重要的文件和目录：\n\n- 主启动文件：/usr/bin/mongod\n- 配置文件：/etc/mongodb.conf\n- 日志文件存放目录：/var/log/mongodb\n- 数据存放位置目录：/var/lib/mongodb\n\n## MongoDB 基本操作\n\n启动 MongoDB 服务后可以进行 MongoDB 的基本操作\n\n### 连接数据库\n\n使用`mongo`命令连接数据库：\n\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/mongo2.jpg)\n\n### 查看已有的数据库\n\n使用`show dbs`命令进行查看：\n\n```\n> show dbs\nadmin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\n>\n```\n\n### 使用数据库\n\n如果使用的数据库不存在，就创建同名数据库：\n\n```\n> use books\nswitched to db books  //选中books数据库\n```\n\n### 创建数据集合\n\n类似于一张表，命令为`db.createCollection(\"表名\")`\n\n```\n> db.createCollection(\"user\")\n{ \"ok\" : 1 }   //user创建成功\n```\n\n### 对数据集合进行操作\n\n#### 插入数据\n\n插入命令有两种\n\n`db.表名.insert({})`\n\n`db.表名.save({})`\n\n两者区别在于：插入数据时，如果\\_id 存在，insert 操作时，则插入失败，save 操作时，则更新数据\n\n##### 插入一条数据：\n\n```\n> db.user.insert({_id:1,uname:\"zhangsan\",age:20,sex:\"男\"})\nWriteResult({ \"nInserted\" : 1 })   //一般情况，第一个字段都是_id,如果没有，也会自动添加一个_id\n```\n\n##### 插入多条数据：\n\n```\n> db.user.insert([{_id:2,uname:\"lisi\",age:19,sex:\"男\"},{_id:3,uname:\"wangwu\",age:18,sex:\"女\"}])   //插入多条数据中间用逗号分开，然后用[]包起来就行\nBulkWriteResult({\n        \"writeErrors\" : [ ],\n        \"writeConcernErrors\" : [ ],\n        \"nInserted\" : 2,\n        \"nUpserted\" : 0,\n        \"nMatched\" : 0,\n        \"nModified\" : 0,\n        \"nRemoved\" : 0,\n        \"upserted\" : [ ]\n})\n```\n\n#### 查询数据\n\n##### 不带条件的查询\n\n查询命令：`db.表名.find()`\n\n```\n> db.user.find()\n{ \"_id\" : 1, \"uname\" : \"zhangsan\", \"age\" : 20, \"sex\" : \"男\" }\n{ \"_id\" : 2, \"uname\" : \"lisi\", \"age\" : 19, \"sex\" : \"男\" }\n{ \"_id\" : 3, \"uname\" : \"wangwu\", \"age\" : 18, \"sex\" : \"女\" }\n```\n\n##### 带条件的查询\n\n查询命令：`db.表名.find({条件})`\n\n```\n> db.user.find({sex:\"男\",uname:\"zhangsan\"})  //支持多条件查询\n{ \"_id\" : 1, \"uname\" : \"zhangsan\", \"age\" : 20, \"sex\" : \"男\" }\n```\n\n#### 更新数据\n\n更新命令：`db.表名.update({条件},{$set:{}})` //这里条件也和查询一样支持多条件\n\n```\n> db.user.update({_id:1},{$set:{uname:\"ouwen\"}})  //把_id为1的uname改为ouwen\nWriteResult({ \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 })\n> db.user.find()\n{ \"_id\" : 1, \"uname\" : \"ouwen\", \"age\" : 20, \"sex\" : \"男\" }  //修改成功\n{ \"_id\" : 2, \"uname\" : \"lisi\", \"age\" : 19, \"sex\" : \"男\" }\n{ \"_id\" : 3, \"uname\" : \"wangwu\", \"age\" : 18, \"sex\" : \"女\" }\n```\n\n#### 删除数据\n\n删除命令：`db.表名.remove({条件})`\n\n```\n> db.user.remove({uname:\"lisi\"}) //删除uname为lisi的数据\nWriteResult({ \"nRemoved\" : 1 })\n> db.user.find()\n{ \"_id\" : 1, \"uname\" : \"ouwen\", \"age\" : 20, \"sex\" : \"男\" }\n{ \"_id\" : 3, \"uname\" : \"wangwu\", \"age\" : 18, \"sex\" : \"女\" }\n```\n\n#### 查看所有的数据集\n\n相当于查看表：`show collections`\n\n```\nshow collections\nuser    //我这里只有一张表\n```\n\n#### 删除数据集合\n\n类似于删除表：`db.表名.drop()`\n\n```\n> db.user.drop()\ntrue    //成功删除user表\n```\n\n### 删除数据库\n\n先使用要删除的数据库：`use books`\n\n删除命令：`db.dropDatabase()`\n\n```\n> use books   //使用books数据库\nswitched to db books\n> db.dropDatabase()   //删除它\n{ \"dropped\" : \"books\", \"ok\" : 1 }\n> show dbs\nadmin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\n```\n\n### 退出数据库连接\n\n可以使用`Crl+C`或者输入`exit`回车\n\n```\n> exit\nbye\nroot@iZ2ze4ojx7qtz1wv44gajnZ:~#\n```\n","tags":["笔记","MongoDB"],"categories":["中间件"]},{"title":"Markdown 基本语法","slug":"Markdown基本语法","url":"/2020/02/19/5d36ff15.html","content":"\n## 前言\n\nMarkdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。\n\nMarkdown 能被使用来撰写电子书、博客等，当前许多网站都广泛使用 Markdown 来撰写帮助文档或是用于论坛上发表消息。例如：GitHub、简书、Gitee 等。\n\n本站的所有文章也是通过 Markdown 语法来写的。Markdown 语法虽然操作简单，但还是需要记一些语法，下面让我们来学习这些语法：\n\n<!--more-->\n\n## 标题\n\n使用 # 号可表示 1-6 级标题，一级标题对应一个`#`号，二级标题对应两个`#`号，以此类推。\n\n```\n# 一级标题\n## 二级标题\n### 三级标题\n#### 四级标题\n##### 五级标题\n###### 六级标题\n```\n\n显示效果如下：\n\n# 一级标题\n\n## 二级标题\n\n### 三级标题\n\n#### 四级标题\n\n##### 五级标题\n\n###### 六级标题\n\n---\n\n## 字体\n\nMarkdown 可以使用以下几种字体：\n\n```\n*斜体文本*\n**粗体文本**\n***粗斜体文本***\n~~这是加删除线的文字~~\n```\n\n显示效果如下：\n_斜体文本_\n**粗体文本**\n**_粗斜体文本_**\n~~这是加删除线的文字~~\n\n---\n\n## 下划线\n\n下划线可以通过 HTML 的`<u>`标签来实现：\n\n```\n<u>带下划线文本</u>\n```\n\n显示效果如下：\n\n<u>带下划线文本</u>\n\n---\n\n## 列表\n\nMarkdown 支持有序列表和无序列表。\n\n#### 无序列表\n\n无序列表使用星号(\\*)、加号(+)或是减号(-)作为列表标记：\n\n```\n* 第一项\n* 第二项\n* 第三项\n\n+ 第一项\n+ 第二项\n+ 第三项\n\n\n- 第一项\n- 第二项\n- 第三项\n```\n\n显示结果如下：\n\n- 第一项\n- 第二项\n- 第三项\n\n* 第一项\n* 第二项\n* 第三项\n\n- 第一项\n- 第二项\n- 第三项\n\n#### 有序列表\n\n有序列表使用数字并加上 . 号来表示，如：\n\n```\n1. 第一项\n2. 第二项\n3. 第三项\n```\n\n显示效果如下：\n\n1. 第一项\n2. 第二项\n3. 第三项\n\n#### 列表嵌套\n\n列表嵌套只需在子列表中的选项添加四个空格即可：\n\n```\n1. 第一项：\n    - 第一项嵌套的第一个元素\n    - 第一项嵌套的第二个元素\n2. 第二项：\n    - 第二项嵌套的第一个元素\n    - 第二项嵌套的第二个元素\n```\n\n显示效果如下：\n\n1. 第一项：\n   - 第一项嵌套的第一个元素\n   - 第一项嵌套的第二个元素\n2. 第二项：\n   - 第二项嵌套的第一个元素\n   - 第二项嵌套的第二个元素\n\n---\n\n## 引用\n\nMarkdown 引用是在段落开头使用`>`符号 ，然后后面紧跟一个空格符号，引用也可以嵌套，例如两个`>>`，三个`>>>`，以此类推：\n\n```\n> 这是引用的内容\n>> 这是引用的内容\n>>> 这是引用的内容\n```\n\n显示效果如下：\n\n> 这是引用的内容\n>\n> > 这是引用的内容\n> >\n> > > 这是引用的内容\n\n---\n\n## 分割线\n\n分割线可以三个或三个以上的`-`或者`*`都可以：\n\n```\n---\n----\n***\n*****\n```\n\n效果如下：\n\n---\n\n---\n\n---\n\n---\n\n## 代码\n\n单行代码：代码之间分别用一个反引号包起来，例如：\n\n```\n`这是单行代码`\n```\n\n代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行\n\n````\n(```)\n这是多行代码...\n这是多行代码...\n这是多行代码...\n(```)\n````\n\n> 注：为了防止演示代码与撰写博客文章的 markdown 语法转译，我这里用括号将三个反引号隔开了，实际使用时去掉括号就行了。\n\n显示效果如下：\n单行代码：\n\n`这是单行代码`\n\n代码块：\n\n```\n这是多行代码...\n这是多行代码...\n这是多行代码...\n```\n\n---\n\n## 超链接\n\n语法如下：\n\n```\n[超链接名](超链接地址 \"超链接title\")\ntitle可加可不加\n```\n\n例如：\n\n```\n[百度](http://baidu.com)\n[Irving的个人博客](https://ouwen666.gitee.io \"大爷，来玩啊！\")\n```\n\n显示效果如下：\n\n[百度](http://baidu.com)\n[Irving 的个人博客](https://ouwen666.gitee.io \"大爷，来玩啊！\")\n\n---\n\n## 表格\n\nMarkdown 制作表格使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行。\n语法如下：\n\n```\n|  表头   | 表头  |\n|  ----  | ----  |\n| 单元格  | 单元格 |\n| 单元格  | 单元格 |\n```\n\n显示效果如下：\n\n| 表头   | 表头   |\n| ------ | ------ |\n| 单元格 | 单元格 |\n| 单元格 | 单元格 |\n\n---\n\n## 图片\n\n语法如下：\n\n```\n![图片alt](图片地址 ''图片title'')\n\n图片alt就是显示在图片下面的文字，相当于对图片内容的解释。\n图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加\n```\n\n例如：\n\n```\n![Markdown](/images/md.jpg)\n```\n\n显示效果如下：\n![](https://my-typora-oss.oss-cn-shanghai.aliyuncs.com/image-master/img/md.jpg)\n\n> 注：我这里图片是保存在本地的，所以图片地址哪里是本地目录，也可以用图片的在线链接地址\n\n## 小结\n\n此篇博客总结了我写 Hexo 博客常用的 Markdown 语法，如有不妥之处请查阅 MD 官方文档。\n\n因为显示效果都是用 Markdown 语法呈现的，而我采用的主题又是通过文章的标题来显示文章目录，所以左侧的文章目录可能有点混乱···\n","tags":["技巧","Markdown"],"categories":["随笔小记"]}]